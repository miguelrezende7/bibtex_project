@article{10.14778/2824032.2824073,
author = {Qiao, Lin and Li, Yinan and Takiar, Sahil and Liu, Ziyang and Veeramreddy, Narasimha and Tu, Min and Dai, Ying and Buenrostro, Issac and Surlaker, Kapil and Das, Shirshanka and Botev, Chavdar},
title = {Gobblin: Unifying Data Ingestion for Hadoop},
year = {2015},
issue_date = {August 2015},
publisher = {VLDB Endowment},
volume = {8},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/2824032.2824073},
doi = {10.14778/2824032.2824073},
abstract = {Data ingestion is an essential part of companies and organizations that collect and analyze large volumes of data. This paper describes Gobblin, a generic data ingestion framework for Hadoop and one of LinkedIn's latest open source products. At LinkedIn we need to ingest data from various sources such as relational stores, NoSQL stores, streaming systems, REST endpoints, filesystems, etc. into our Hadoop clusters. Maintaining independent pipelines for each source can lead to various operational problems. Gobblin aims to solve this issue by providing a centralized data ingestion framework that makes it easy to support ingesting data from a variety of sources.Gobblin distinguishes itself from similar frameworks by focusing on three core principles: generality, extensibility, and operability. Gobblin supports a mixture of data sources out-of-the-box and can be easily extended for more. This enables an organization to use a single framework to handle different data ingestion needs, making it easy and inexpensive to operate. Moreover, with an end-to-end metrics collection and reporting module, Gobblin makes it simple and efficient to identify issues in production.},
journal = {Proc. VLDB Endow.},
month = {aug},
pages = {1764–1769},
numpages = {6}
}

@inproceedings{10.1145/3379310.3379322,
author = {Rozi, Muhamad Fahru and Sucahyo, Yudho Giri and Gandhi, Arfive and Ruldeviyani, Yova},
title = {Appraising Personal Data Protection in Startup Companies in Financial Technology: A Case Study of ABC Corp},
year = {2020},
isbn = {9781450376853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379310.3379322},
doi = {10.1145/3379310.3379322},
abstract = {Financial Technology (fintech) has been immerged extensively in the last decade. In the realm of disruptive world, there are many areas in which startup companies are developing their business. There is always contradiction when dealing with innovation as core of digital disruption and how privacy remains as hot issues at the edge of everybody's talks. Internet plays important roles to sustain the trends. As rapidly growing country, 68% of Indonesian has access to the Internet. It drives startup companies on financial technology to innovate more and besides that they must comply to regulation in regard with personal data protection. This research aims to appraise how startup company on financial technology protect users' personal data. Personal data protection principles from international organization and Indonesian regulation regarding personal data protection are used to appraise how ABC Corp as a startup company that deliver financial technology service in Indonesian society. To ensure that its service is qualified and trustable, ABC Corp should be appraised using relevant criteria and qualitative approach. The results showed that most of regulations from sectorial supervising agency have been adhered by ABC Corp. The results bring meaningful insight to improve performance on personal data protection. They can became lessons for similar emerging startup companies in financial technology when acquiring their qualifications to protect users' personal data and keep their sustainability.},
booktitle = {Proceedings of the 2020 2nd Asia Pacific Information Technology Conference},
pages = {9–15},
numpages = {7},
keywords = {digital economy, personal data, Financial technology, data privacy, data protection},
location = {Bali Island, Indonesia},
series = {APIT 2020}
}

@article{10.1145/3511322.3511326,
author = {Dennis, Louise A.},
title = {Conference Reports},
year = {2022},
issue_date = {September 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
url = {https://doi.org/10.1145/3511322.3511326},
doi = {10.1145/3511322.3511326},
abstract = {This section is compiled from reports of recent events sponsored or run in cooperation with ACM SIGAI. In general these reports were written and submitted by the conference organisers.},
journal = {AI Matters},
month = {jan},
pages = {15–17},
numpages = {3}
}

@inproceedings{10.1145/2656450.2656453,
author = {Kumar, Sathish Alampalayam},
title = {Designing a Graduate Program in Information Security and Analytics: Masters Program in Information Security and Analytics (MISA)},
year = {2014},
isbn = {9781450326865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2656450.2656453},
doi = {10.1145/2656450.2656453},
abstract = {This paper introduces the concept of the Master of Information Security and Analytics (MISA) program for the graduate students with a background in CS, IS and IT. The 10-course graduate level program is benchmarked against existing masters programs in the areas of Information Security and Data Analytics, and an assessment was done on the estimated demand for MISA graduates in the nation. The program outcomes were then mapped against the course objectives to insure the correct mix of courses and topics. The program's admission requirement is also being discussed. This paper discusses the design process and possible ways to reduce risk in the start-up of a new degree program. How a program is marketed to prospective students and what program graduates will do after program completion is just as important as the initial design of the program. Planning for the administration of the program and the assessment process is an important phase of the initial design.},
booktitle = {Proceedings of the 15th Annual Conference on Information Technology Education},
pages = {141–146},
numpages = {6},
keywords = {analytics, cybersecurity, information technology education},
location = {Atlanta, Georgia, USA},
series = {SIGITE '14}
}

@inproceedings{10.1145/3195106.3195177,
author = {Baolong, Yang and Hong, Wu and Haodong, Zhang},
title = {Research and Application of Data Management Based on Data Management Maturity Model (DMM)},
year = {2018},
isbn = {9781450363532},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3195106.3195177},
doi = {10.1145/3195106.3195177},
abstract = {Through the analysis and contrast of the different Data Management Maturity Model, such as DCAM, DMM, DCMM and the model of IBM, we try to make empirical research under the framework of data management maturity model. This article take a project whose main research object is about the academic career of scientists and with massive unstructured data for example, through analysis of the goal, management processes and influence factors of this project in detail, we built up an evaluation system for data management for such projects under the framework of DCMM. It is expected to have a positive significance to the evaluation of similar data management capability.},
booktitle = {Proceedings of the 2018 10th International Conference on Machine Learning and Computing},
pages = {157–160},
numpages = {4},
keywords = {Unstructured data, Measurement and evaluation, maturity model, Data management},
location = {Macau, China},
series = {ICMLC 2018}
}

@inbook{10.1145/3487075.3487110,
author = {An, Zhenpeng and Zhang, Di and Liang, Yunjie},
title = {Research on Data Governance Framework for Fire Department},
year = {2021},
isbn = {9781450389853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487075.3487110},
abstract = {This paper analyzes data governance elements, models and frameworks, provides a clear plan for data governance for fire department. Using the method of literature research, network investigation and conclude data system of fire departments, the china domestic and foreign research status of data governance is reviewed. We build the framework of data governance for fire department, including Data resource directory system, Data technology support system and Data standardization system. This paper preliminarily forms the framework of data governance for fire department. This framework was applied to the fire information planning work. The results indicate that based on the status and characteristics of fire industry, the implementation of this framework is effective and feasible, and it is also the basis of standard fire control data governance in future.},
booktitle = {The 5th International Conference on Computer Science and Application Engineering},
articleno = {35},
numpages = {5}
}

@inproceedings{10.1145/2968219.2985840,
author = {Hui, Pan and Ou, Zhonghong and Zhang, Yanyong and Striegel, Aaron D},
title = {The 7th International Workshop on Hot Topics in Planet-Scale Measurement (HotPlanet '16)},
year = {2016},
isbn = {9781450344623},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2968219.2985840},
doi = {10.1145/2968219.2985840},
abstract = {The recent advances of mobile devices, online social networks, and the emergence of the Internet of Things have driven the corresponding data collection and analytics to planetary scale. It is, thus, essential to provide a forum to discuss the technical advances, share the lessons, experiences, and challenges associated with real-world large-scale deployment. The 7th International Workshop on Hot Topics in Planet-Scale Measurement (HotPlanet '16) is to provide such a forum for the researchers and practitioners in the fields mentioned above. By bringing together the experts in these fields, and through thoughtful discussions and valuable sharing, HotPlanet '16 aims to advance the work in these fields forward.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct},
pages = {1275–1278},
numpages = {4},
keywords = {deployment experiences, crowd sensing, social computing, planet-scale measurement, crowdsourcing, cloud computing, data analytics},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@inproceedings{10.1145/3192975.3193004,
author = {Nabipourshiri, Rouzbeh and Abu-Salih, Bilal and Wongthongtham, Pornpit},
title = {Tree-Based Classification to Users' Trustworthiness in OSNs},
year = {2018},
isbn = {9781450364102},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3192975.3193004},
doi = {10.1145/3192975.3193004},
abstract = {In the light of the information revolution, and the propagation of big social data, the dissemination of misleading information is certainly difficult to control. This is due to the rapid and intensive flow of information through unconfirmed sources under the propaganda and tendentious rumors. This causes confusion, loss of trust between individuals and groups and even between governments and their citizens. This necessitates a consolidation of efforts to stop penetrating of false information through developing theoretical and practical methodologies aim to measure the credibility of users of these virtual platforms. This paper presents an approach to domain-based prediction to user's trustworthiness of Online Social Networks (OSNs). Through incorporating three machine learning algorithms, the experimental results verify the applicability of the proposed approach to classify and predict domain-based trustworthy users of OSNs.},
booktitle = {Proceedings of the 2018 10th International Conference on Computer and Automation Engineering},
pages = {190–194},
numpages = {5},
keywords = {Trust, social media, data mining, users' trustworthiness, Twitter, machine learning},
location = {Brisbane, Australia},
series = {ICCAE 2018}
}

@inproceedings{10.1145/3348445.3348464,
author = {Lin, Yuting},
title = {Government Management Model of Non-Profit Organizations Based on E-Government},
year = {2019},
isbn = {9781450371957},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3348445.3348464},
doi = {10.1145/3348445.3348464},
abstract = {With the development and popularization of Internet technology, our country is increasingly aware of the importance of e-government, and continuously expands the channels and means of e-government development in policy, such as the application of e-government to the management of non-profit organizations. However, in practice, "e-government + NPO (non-profit organization) management" still has problems such as digital divide, information sharing and insufficient disclosure, and information security. Therefore, this paper proposes a more complete non-profit organization management model based on e-government. From the perspectives of optimization services, information sharing, network supervision and information security, it is explained how to effectively realize the efficient management of non-profit organizations based on e-government.},
booktitle = {Proceedings of the 2019 7th International Conference on Computer and Communications Management},
pages = {164–168},
numpages = {5},
keywords = {non-profit organization, management model, E-government},
location = {Bangkok, Thailand},
series = {ICCCM 2019}
}

@inproceedings{10.1145/2670757.2670779,
author = {Grillenberger, Andreas and Romeike, Ralf},
title = {A Comparison of the Field Data Management and Its Representation in Secondary CS Curricula},
year = {2014},
isbn = {9781450332507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2670757.2670779},
doi = {10.1145/2670757.2670779},
abstract = {In the last few years, the focus of data management has changed from handling relatively small amounts of data, often in relational databases, to managing large amounts of data using various different database types. In many secondary school curricula, data management is mainly considered from a "database" perspective. However, in contrast to the developments in computer science research and practice, the new and changing aspects of data management have hardly been discussed with respect to CS education. We suggest re-evaluating the focus and relevance of the established database syllabi, to discuss the educational value of the newly arising developments and to prevent the teaching of outdated concepts. In this paper, we will contrast current educational standards and curricula with an up-to-date characterization of data management in order to identify gaps between the principles and concepts of data management that are considered as important today from a professional point of view on the one side, and the emphasis in current CS education on the other side.The findings of this analysis will provide a basis for aligning the concepts taught in CS education with the developments in data management research and practice, as well as for re-evaluating the educational value of these concepts.},
booktitle = {Proceedings of the 9th Workshop in Primary and Secondary Computing Education},
pages = {29–36},
numpages = {8},
keywords = {databases, standards, secondary school, curricula, data management, analysis, characterization},
location = {Berlin, Germany},
series = {WiPSCE '14}
}

@inproceedings{10.1145/3357384.3360314,
author = {Duan, Rong and Xiao, Yanghua},
title = {Enterprise Knowledge Graph From Specific Business Task to Enterprise Knowledge Management},
year = {2019},
isbn = {9781450369763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357384.3360314},
doi = {10.1145/3357384.3360314},
abstract = {Data driven Knowledge Graph is rapidly adapted by different societies. Many open domain and specific domain knowledge graphs have been constructed, and many industries have benefited from knowledge graph. Currently, enterprise related knowledge graph is classified as specific domain, but the applications span from solving a narrow specific problem to Enterprise Knowledge Management system. With the digital transform of traditional industry, Enterprise knowledge becomes more and more complicated, it involves knowledge from common domain, multiple specific domains, and corporate-specific in general. This tutorial provides an overview of current Enterprise Knowledge Graph(EKG). It distinguishes the EKG from specific domain according to the knowledge it covers, and provides the examples to illustrate the difference between EKG and specific domain KG. The tutorial further summarizes EKG into three types: Specific Business Task Enterprise KG, Specific Business Unit Enterprise KG and Cross Business Unit Enterprise KG, and illustrates the characteristics, steps, challenges, and future research in constructing and consuming of each of these three types of EKG .},
booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
pages = {2965–2966},
numpages = {2},
keywords = {relation extraction, ontology, entity recognition, knowledge graph, enterprise knowledge management},
location = {Beijing, China},
series = {CIKM '19}
}

@inproceedings{10.1145/3085228.3085280,
author = {Zeleti, Fatemeh Ahmadi and Ojo, Adegboyega},
title = {Competitive Capability Framework for Open Government Data Organizations},
year = {2017},
isbn = {9781450353175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3085228.3085280},
doi = {10.1145/3085228.3085280},
abstract = {Open data-driven organizations compete in a complex and uncertain environment with growing global competition, changing and emerging demand and market, and increasing levels of analytical tools and technology. For these organizations to exploit open data for competitive advantage, they need to develop the requisite competitive capabilities. This article presents an open data competitive capability framework grounded in theory and practice of open data. Based on extant literature and insights from domain experts, we identify and describe four dimensions of competitive capabilities required for open data driven organizations. We argue that by implementing the proposed framework, organizations can increase their chances to favorably compete in their respective markets. We further argue that by understanding open government data as a strategic resource for enterprises, government as producers or suppliers of this resource become key partners to data-driven organizations.},
booktitle = {Proceedings of the 18th Annual International Conference on Digital Government Research},
pages = {250–259},
numpages = {10},
keywords = {open data capabilities, competitive advantage, organizational capabilities, competitive strategies, open data organization, Competitiveness in open data businesses},
location = {Staten Island, NY, USA},
series = {dg.o '17}
}

@inbook{10.1145/3429889.3429921,
author = {Ren, Kang and Liu, Fan and Zhuang, Haimei and Ling, Yun},
title = {AI-Based Multimodal Data Management and Intelligent Analysis System for Parkinson's Disease: GYENNO PD CIS},
year = {2020},
isbn = {9781450388603},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3429889.3429921},
abstract = {The GYENNO PD CIS is an AI-based multimodal data management and intelligent analysis system for Parkinson's disease (PD). The main purpose is to solve the problems in traditional diagnosis of PD such as lack of objective evaluation data, lack of reproducible diagnosis system, and lack of closed-loop treatment tracking, and then to construct a multimodal data management and intelligent analysis platform for PD, which can achieve the goals - standardization of data, objectification of evaluation, standardization of diagnosis, individualization of treatment, continuousness of management. It also helps Parkinson's experts in patient management, clinical data management, analysis and data mining, and supports multi-center projects, and finally lets patients benefit a lot from innovative technology.},
booktitle = {Proceedings of the 2020 International Symposium on Artificial Intelligence in Medical Sciences},
pages = {166–170},
numpages = {5}
}

@inproceedings{10.1145/3433996.3434019,
author = {Li, Ting and Zhang, Bo},
title = {Development Dilemma and Countermeasures of Data Journalism},
year = {2020},
isbn = {9781450388641},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3433996.3434019},
doi = {10.1145/3433996.3434019},
abstract = {In the field of news, with the operation of data journalism, the traditional press is facing great innovation and shock in the production, circulation, distribution and consumption of information. As McLuhan said, the birth of new media has opened up new possibilities in this era. Data, as a medium of the new era, is creating a new way for people to understand the world.This paper mainly discusses that it is still facing the problem of low degree of data opening in the current development, and the negative impact of disclosing users' personal privacy and information cocoon room. In view of these problems, relevant departments need to further strengthen the policy of data opening, improve the legal system, and optimize the link mode of information content dissemination, so as to promote the better development of data journalism and make data benefit people truly.},
booktitle = {Proceedings of the 2020 Conference on Artificial Intelligence and Healthcare},
pages = {127–131},
numpages = {5},
keywords = {visualization, Data journalism, information cocoons, data opening},
location = {Taiyuan, China},
series = {CAIH2020}
}

@inproceedings{10.1145/2671491.2671497,
author = {Best, Daniel M. and Endert, Alex and Kidwell, Daniel},
title = {7 Key Challenges for Visualization in Cyber Network Defense},
year = {2014},
isbn = {9781450328265},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2671491.2671497},
doi = {10.1145/2671491.2671497},
abstract = {What does it take to be a successful visualization in cyber security? This question has been explored for some time, resulting in many potential solutions being developed and offered to the cyber security community. However, when one reflects upon the successful visualizations in this space they are left wondering where all those offerings have gone. Excel and Grep are still the kings of cyber security defense tools; there is a great opportunity to help in this domain, yet many visualizations fall short and are not utilized.In this paper we present seven challenges, informed by two user studies, to be considered when developing a visualization for cyber security purposes. Cyber security visualizations must go beyond isolated solutions and "pretty picture" visualizations in order to impact users. We provide an example prototype that addresses the challenges with a description of how they are met. Our aim is to assist in increasing utility and adoption rates for visualization capabilities in cyber security.},
booktitle = {Proceedings of the Eleventh Workshop on Visualization for Cyber Security},
pages = {33–40},
numpages = {8},
keywords = {visualization, cyber security, defense},
location = {Paris, France},
series = {VizSec '14}
}

@article{10.1145/2430456.2430466,
author = {Beskales, George and Das, Gautam and Elmagarmid, Ahmed K. and Ilyas, Ihab F. and Naumann, Felix and Ouzzani, Mourad and Papotti, Paolo and Quiane-Ruiz, Jorge and Tang, Nan},
title = {The Data Analytics Group at the Qatar Computing Research Institute},
year = {2013},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {4},
issn = {0163-5808},
url = {https://doi.org/10.1145/2430456.2430466},
doi = {10.1145/2430456.2430466},
journal = {SIGMOD Rec.},
month = {jan},
pages = {33–38},
numpages = {6}
}

@inproceedings{10.1145/3326365.3326374,
author = {Liu, Shuhua Monica and Pan, Liting and Lei, Yupei},
title = {What is the Role of New Generation of ICTs in Transforming Government Operation and Redefining State-Citizen Relationship in the Last Decade?},
year = {2019},
isbn = {9781450366441},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326365.3326374},
doi = {10.1145/3326365.3326374},
abstract = {This article first introduce a new government initiative emerging after the US presidential election in 2008. Comparing to the more descriptive definitions of e-government, supporters of these new government initiatives emphasize the transformative and normative aspect of the newest generation of Information and Communication Technology (ICTs). They argue that the new initiative redefines how government should operate and transform state-citizen relationships. To understand the core of this initiative and whether it offers new opportunities to solve public problems, we collected and analyzed research papers published in the e-governance area between 2008 and 2017. Our analysis demonstrates that the use of new generation of ICTs has promoted the government information infrastructure. In other words, the application of new ICTs enables the government to accumulate and use a large amount of data, so that the government makes better decisions. The advancement of open data, the wide use of social media, and the potential of data analytics have also generated pressure to address challenging questions and issues in e-democracy. However, the analysis leads us to deliberate on whether the use of new generation of ICTs worldwide have actually achieved their goal. In the conclusion, we present challenges to be addressed before new innovative ICTs realize their potential towards better public governance.},
booktitle = {Proceedings of the 12th International Conference on Theory and Practice of Electronic Governance},
pages = {65–75},
numpages = {11},
keywords = {E-governance, Transformative governance, Information and communication technology (ICT)},
location = {Melbourne, VIC, Australia},
series = {ICEGOV2019}
}

@inproceedings{10.5555/2693848.2693973,
author = {Elmegreen, Bruce G. and Sanchez, Susan M. and Szalay, Alexander S.},
title = {The Future of Computerized Decision Making},
year = {2014},
publisher = {IEEE Press},
abstract = {Computerized decision making is becoming a reality with exponentially growing data and machine capabilities. Some decision making is extremely complex, historically reserved for governing bodies or market places where the collective human experience and intelligence come to play. Other decision making can be trusted to computers that are on a path now into the future through novel software development and technological improvements in data access. In all cases, we should think about this carefully first: what data are really important for our goals and what data should be ignored or not even stored? The answer to these questions involves human intelligence and understanding before the data-to-decision process begins.},
booktitle = {Proceedings of the 2014 Winter Simulation Conference},
pages = {943–949},
numpages = {7},
location = {Savannah, Georgia},
series = {WSC '14}
}

@inproceedings{10.1145/3152465.3152473,
author = {Wang, Deqiang and Guo, Danhuai and Zhang, Hui},
title = {Spatial Temporal Data Visualization In Emergency Management: A View from Data-Driven Decision},
year = {2017},
isbn = {9781450354936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3152465.3152473},
doi = {10.1145/3152465.3152473},
abstract = {Recent years, extreme events caused a great loss of human society. Emergency management is playing a more and more important role in handling disaster events. With the raising of data-intensive decision making, how to visualize large, multi-dimension data become an important challenge. Spatial temporal data visualization, a powerful tool, could transform data in to visual structure and make core information easily be captured by human. It could support spatial analysis, decision making and be used in all phase of emergency management. In this paper, we reviewed the general method of spatial temporal data visualization and the methods in data-intensive environment. Summarized the problems of each phase of emergency management and presented how spatial temporal visualization tools applied in each phase of emergency management. Finally, we conduct a short conclusion and outlook the future of spatial temporal visualization applied in data-driven emergency management environment.},
booktitle = {Proceedings of the 3rd ACM SIGSPATIAL Workshop on Emergency Management Using},
articleno = {8},
numpages = {7},
keywords = {emergency management, review, spatio-temporal visualization},
location = {Redondo Beach, CA, USA},
series = {EM-GIS'17}
}

@inproceedings{10.5555/2814058.2814102,
author = {Barata, Andre Montoia and Prado, Edmir Parada Vasques},
title = {Data Governance in Brazilian Organizations},
year = {2015},
publisher = {Brazilian Computer Society},
address = {Porto Alegre, BRA},
abstract = {Organizations are increasingly looking for data integrity and quality to assist in strategic making decision and value creation. In this context Data Governance (DG) provide processes and practices that assist in the management and maintenance data. There are many frameworks to implementation DG process and benefits they may provide, however there are few implementation reported in the literature. This study aims to identify the DG process and frameworks implemented in Brazilian organizations and compare the benefits in implementation with those proposed by literature. For this will be carried out case studies in Brazilian organizations that implemented or are implementing DG frameworks.},
booktitle = {Proceedings of the Annual Conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1},
pages = {267–272},
numpages = {6},
keywords = {Data Governance, System Information, Management Frameworks},
location = {Goiania, Goias, Brazil},
series = {SBSI 2015}
}

@article{10.1145/3143313,
author = {Raschid, Louiqa},
title = {Editor-in-Chief (January 2014-May 2017) Farewell Report},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
issn = {1936-1955},
url = {https://doi.org/10.1145/3143313},
doi = {10.1145/3143313},
journal = {J. Data and Information Quality},
month = {oct},
articleno = {7},
numpages = {2}
}

@inproceedings{10.1145/3300115.3312508,
author = {Cassel, Lillian and Hongzhi, Wang},
title = {Panel: The Computing in Data Science},
year = {2019},
isbn = {9781450362597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3300115.3312508},
doi = {10.1145/3300115.3312508},
abstract = {This panel brings the workings and results of the ACM Education Council Task Force on Data Science Education. The task force has gathered information on existing programs and has reviewed documents such as the result of the National Academies deliberations on data science. The task force is charged with exploring the role of computer science in data science education, understanding that data science is an inherently interdisciplinary field and not exclusively a computer science field. The panel will present a summary of the task force findings by two members of the task force and perspectives from leaders in data-intensive applications from China. The goal of the panel is to present the findings, but also to obtain perspectives from the attendees in order to enrich the task force's work.},
booktitle = {Proceedings of the ACM Conference on Global Computing Education},
pages = {192–193},
numpages = {2},
keywords = {data science, computing for data science, computing curriculum},
location = {Chengdu,Sichuan, China},
series = {CompEd '19}
}

@article{10.1145/2579167,
author = {Raschid, Louiqa},
title = {Editorial},
year = {2014},
issue_date = {May 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {4},
issn = {1936-1955},
url = {https://doi.org/10.1145/2579167},
doi = {10.1145/2579167},
journal = {J. Data and Information Quality},
month = {may},
articleno = {14},
numpages = {2}
}

@inproceedings{10.1145/3085228.3085269,
author = {Chen, Yumei and Dawes, Sharon S. and Chen, Shanshan},
title = {E-Government Support for Administrative Reform in China},
year = {2017},
isbn = {9781450353175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3085228.3085269},
doi = {10.1145/3085228.3085269},
abstract = {This1 paper summarizes the history of Chinese administrative modernization and reform and discusses the ways in which China's e-government development agenda supports reform in the areas of transforming functions, streamlining processes, and enhancing transparency and citizen engagement. It offers a conceptual model of how e-government supports reform through policies, technologies, management improvements, and data designed to overcome the barriers of technical capability, staff resistance, and lack of cross-boundary collaboration. The analysis also shows how this interaction has generated new issues regarding official corruption and public engagement. We conclude with a future research agenda.},
booktitle = {Proceedings of the 18th Annual International Conference on Digital Government Research},
pages = {329–335},
numpages = {7},
keywords = {Chinese government and reform, E-government, Administrative reform},
location = {Staten Island, NY, USA},
series = {dg.o '17}
}

@inproceedings{10.1145/3428757.3429152,
author = {Philipp, Robert and Mladenow, Andreas and Strauss, Christine and V\"{o}lz, Alexander},
title = {Machine Learning as a Service: Challenges in Research and Applications},
year = {2020},
isbn = {9781450389228},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3428757.3429152},
doi = {10.1145/3428757.3429152},
abstract = {This study aims to evaluate the current state of research with regards to Machine Learning as a Service (MLaaS) and to identify challenges and research fields of this novel topic. First, a literature review on a basket of eight leading journals was performed. We motivate this study by identifying a lack of studies in the field of MLaaS. The structured literature review was further extended to established scientific databases relevant in this field. We found 30 contributions on MLaaS. As a result of the analysis we grouped them into four key concepts: Platform, Applications; Performance Enhancements and Challenges. Three of the derived concepts are discussed in detail to identify future research areas and to reveal challenges in research as well as in applications.},
booktitle = {Proceedings of the 22nd International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {396–406},
numpages = {11},
keywords = {Machine Learning Platform, Machine Learning, MLaaS, Machine Learning Services, Machine Learning as a Service},
location = {Chiang Mai, Thailand},
series = {iiWAS '20}
}

@article{10.1145/3447269,
author = {Tufi\c{s}, Mihnea and Boratto, Ludovico},
title = {Toward a Complete Data Valuation Process. Challenges of Personal Data},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {1936-1955},
url = {https://doi.org/10.1145/3447269},
doi = {10.1145/3447269},
journal = {J. Data and Information Quality},
month = {aug},
articleno = {20},
numpages = {7},
keywords = {data valuation, data markets, Datasets}
}

@article{10.1007/s00778-015-0389-y,
author = {Abedjan, Ziawasch and Golab, Lukasz and Naumann, Felix},
title = {Profiling Relational Data: A Survey},
year = {2015},
issue_date = {August    2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {24},
number = {4},
issn = {1066-8888},
url = {https://doi.org/10.1007/s00778-015-0389-y},
doi = {10.1007/s00778-015-0389-y},
abstract = {Profiling data to determine metadata about a given dataset is an important and frequent activity of any IT professional and researcher and is necessary for various use-cases. It encompasses a vast array of methods to examine datasets and produce metadata. Among the simpler results are statistics, such as the number of null values and distinct values in a column, its data type, or the most frequent patterns of its data values. Metadata that are more difficult to compute involve multiple columns, namely correlations, unique column combinations, functional dependencies, and inclusion dependencies. Further techniques detect conditional properties of the dataset at hand. This survey provides a classification of data profiling tasks and comprehensively reviews the state of the art for each class. In addition, we review data profiling tools and systems from research and industry. We conclude with an outlook on the future of data profiling beyond traditional profiling tasks and beyond relational databases.},
journal = {The VLDB Journal},
month = {aug},
pages = {557–581},
numpages = {25}
}

@article{10.1145/2782759.2782762,
author = {Laube, Patrick},
title = {The Low Hanging Fruit is Gone: Achievements and Challenges of Computational Movement Analysis},
year = {2015},
issue_date = {March 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
url = {https://doi.org/10.1145/2782759.2782762},
doi = {10.1145/2782759.2782762},
abstract = {This position paper reviews the achievements and open challenges of movement analysis within Geographical Information Science. The paper argues that the simple problems of movement analysis have mostly been addressed to a sufficient level ("the low hanging fruit"), leaving the research community with the much more challenging problems for the years ahead ("the high hanging fruit"). Whereas the community has made good progress in structuring trajectory data (segmentation, similarity, clustering) and conceptualizing and detecting movement patterns, the much harder task of semantic annotation of structures and patterns remains difficult. The position paper summarizes both achievements and challenges with two sets assertions and calls for the establishment of a unifying theory of Computational Movement Analysis.},
journal = {SIGSPATIAL Special},
month = {may},
pages = {3–10},
numpages = {8}
}

@article{10.1145/2063504.2063505,
author = {Madnick, Stuart E. and Lee, Yang W.},
title = {Editorial Notes Classification and Assessment of Large Amounts of Data: Examples in the Healthcare Industry and Collaborative Digital Libraries},
year = {2011},
issue_date = {December 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
issn = {1936-1955},
url = {https://doi.org/10.1145/2063504.2063505},
doi = {10.1145/2063504.2063505},
journal = {J. Data and Information Quality},
month = {dec},
articleno = {12},
numpages = {2}
}

@inbook{10.1145/3479645.3479669,
author = {Sulistyowati, Ira and Fransisca, Dyna and Ruldeviyani, Yova},
title = {Data Analytics Readiness Model in Indonesian Government},
year = {2021},
isbn = {9781450384070},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3479645.3479669},
abstract = {The development of information technology encourages the government to digitize business processes. It is generated with a large and varied volume from various data sources so that advanced data analytics (DA) is required to overcome this to support organization's data driven decision making. It's necessary to prepare DA based on DA readiness model so that the implementation of DA can run successfully. Whereas currently, there is limited study and no standard model for DA readiness. The focus of this study is to propose model readiness of implementing data analytics that is suitable in Indonesian government. The model refers to DA readiness model based on literature review on 15 papers relevant to DA readiness. Then it's verified by 7 experts. Furthermore, online survey was conducted to test the model that affects the readiness of implementing data analytics in Indonesian government. The survey results were analyzed using factor analysis. As a result, DA readiness model contains 4 dimensions, 11 factors, and 78 indicators where its dimensions consist of information system, organizational and cultural, organization structure and resource readiness. This model can describe 85% of the data analysis readiness requirements in the Indonesian government. In order to implement data analytics successfully, the government needs to improve the readiness of information systems, organizational and cultural, organizational structures, and resources.},
booktitle = {6th International Conference on Sustainable Information Engineering and Technology 2021},
pages = {100–105},
numpages = {6}
}

@article{10.1145/3092931.3092933,
author = {Abiteboul, Serge and Arenas, Marcelo and Barcel\'{o}, Pablo and Bienvenu, Meghyn and Calvanese, Diego and David, Claire and Hull, Richard and H\"{u}llermeier, Eyke and Kimelfeld, Benny and Libkin, Leonid and Martens, Wim and Milo, Tova and Murlak, Filip and Neven, Frank and Ortiz, Magdalena and Schwentick, Thomas and Stoyanovich, Julia and Su, Jianwen and Suciu, Dan and Vianu, Victor and Yi, Ke},
title = {Research Directions for Principles of Data Management (Abridged)},
year = {2017},
issue_date = {December 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {4},
issn = {0163-5808},
url = {https://doi.org/10.1145/3092931.3092933},
doi = {10.1145/3092931.3092933},
journal = {SIGMOD Rec.},
month = {may},
pages = {5–17},
numpages = {13}
}

@inproceedings{10.1145/3379177.3388909,
author = {Munappy, Aiswarya Raj and Mattos, David Issa and Bosch, Jan and Olsson, Helena Holmstr\"{o}m and Dakkak, Anas},
title = {From Ad-Hoc Data Analytics to DataOps},
year = {2020},
isbn = {9781450375122},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379177.3388909},
doi = {10.1145/3379177.3388909},
abstract = {The collection of high-quality data provides a key competitive advantage to companies in their decision-making process. It helps to understand customer behavior and enables the usage and deployment of new technologies based on machine learning. However, the process from collecting the data, to clean and process it to be used by data scientists and applications is often manual, non-optimized and error-prone. This increases the time that the data takes to deliver value for the business. To reduce this time companies are looking into automation and validation of the data processes. Data processes are the operational side of data analytic workflow.DataOps, a recently coined term by data scientists, data analysts and data engineers refer to a general process aimed to shorten the end-to-end data analytic life-cycle time by introducing automation in the data collection, validation, and verification process. Despite its increasing popularity among practitioners, research on this topic has been limited and does not provide a clear definition for the term or how a data analytic process evolves from ad-hoc data collection to fully automated data analytics as envisioned by DataOps.This research provides three main contributions. First, utilizing multi-vocal literature we provide a definition and a scope for the general process referred to as DataOps. Second, based on a case study with a large mobile telecommunication organization, we analyze how multiple data analytic teams evolve their infrastructure and processes towards DataOps. Also, we provide a stairway showing the different stages of the evolution process. With this evolution model, companies can identify the stage which they belong to and also, can try to move to the next stage by overcoming the challenges they encounter in the current stage.},
booktitle = {Proceedings of the International Conference on Software and System Processes},
pages = {165–174},
numpages = {10},
keywords = {DataOps, DevOps, Continuous Monitoring, Agile Methodology, Data Pipelines, Data technologies},
location = {Seoul, Republic of Korea},
series = {ICSSP '20}
}

@inproceedings{10.1145/3468784.3471607,
author = {Umejiaku, Afamefuna and Dang, Tommy},
title = {Visualising Developing Nations Health Records: Opportunities, Challenges and Research Agenda},
year = {2021},
isbn = {9781450390125},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468784.3471607},
doi = {10.1145/3468784.3471607},
abstract = { The benefits of effectively visualizing health records in huge volumes has resulted in health organizations, insurance companies, policy and decision makers, governments and drug manufactures’ transformation in the way research is conducted. This has also played a key role in determining investment of resources. Health records contain highly valuable information; processing these records in large volumes is now possible due to technological advancement which allows for the extraction of highly valuable knowledge that has resulted in breakthroughs in scientific communities. To visualize health records in large volumes, the records need to be stored in electronic forms, properly documented, processed, and analyzed. A good visualization technique is used to present the analyzed information, allowing for effective knowledge extraction which is done in a secured manner protecting the privacy of the patients whose health records were used. As research and technological advancement have improved, the quality of knowledge extracted from health records have also improved; unfortunately, the numerous benefits of visualizing health records have only been felt in developed nations, unlike other sectors where technological advancement in developed nations have had similar impact in developing nations. This paper identifies the characteristics of health records and the challenges involved in processing large volumes of health records. This is to identify possible steps that could be taken for developing nations to benefit from visualizing health records in huge volumes. },
booktitle = {The 12th International Conference on Advances in Information Technology},
articleno = {38},
numpages = {9},
keywords = {Visualisation, Health records, Developing Nations},
location = {Bangkok, Thailand},
series = {IAIT2021}
}

@inproceedings{10.1145/3351108.3351110,
author = {Hattingh, Mari\'{e} and Marshall, Linda and Holmner, Marlene and Naidoo, Rennie},
title = {Data Science Competency in Organisations: A Systematic Review and Unified Model},
year = {2019},
isbn = {9781450372657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3351108.3351110},
doi = {10.1145/3351108.3351110},
abstract = {The paper presents a systematic literature review of the literature on the competencies that are essential to develop a globally competitive workforce in the field of data science. The systematic review covers a wide range of literature but focuses primarily, but not exclusively, on the computing, information systems, management, and organisation science literature. The paper uses a broad research search strategy covering four separate electronic databases. The search strategy led the researchers to scan 139 titles, abstracts and keywords. Sixty potentially relevant articles were identified, of which 42 met the quality criteria and contributed to the analysis. A critical appraisal checklist assessed the validity of each empirical study. The researchers grouped the findings under six broad competency themes: organisational, technical, analytical, ethical and regulatory, cognitive and social. Thematic analysis was used to develop a unified model of data science competency based on the evidence of the findings. This model will be applied to case studies and survey research in future studies. A unified data science competency model, supported by empirical evidence, is crucial in closing the skills gap, thereby improving the quality and competitiveness of the South Africa's data science workforce. Researchers are encouraged to contribute to the further conceptual development of data science competency.},
booktitle = {Proceedings of the South African Institute of Computer Scientists and Information Technologists 2019},
articleno = {1},
numpages = {8},
keywords = {Data Science, Skills, Competency, Systematic Literature Review},
location = {Skukuza, South Africa},
series = {SAICSIT '19}
}

@inproceedings{10.1145/2591888.2591901,
author = {Millard, Jeremy},
title = {ICT-Enabled Public Sector Innovation: Trends and Prospects},
year = {2013},
isbn = {9781450324564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2591888.2591901},
doi = {10.1145/2591888.2591901},
abstract = {This experience paper is a personal thinkpiece which outlines many of the main issues and discussions taking place in Europe and elsewhere about the future of the public sector and how it can respond positively to some of the acute challenges it faces in light of the financial crisis and other global challenges. The paper examines how ICT-enabled public sector innovation highlights concepts like open governance, public value, government as a platform, open assets, open services and open engagement. It develops a vision of an 'open governance framework', moving beyond 'new public management', based on ICT-enabled societal-wide collaboration. It recognises that although the public sector can in principle create public value on its own, its potential to do so is greatly enhanced and extended by direct cooperation with other actors, or by facilitating public value creation by other actors on their own. It also examines the role of bottom-up innovation and public policy experimentation, as well as the need to focus on empowering civil servants and changing public sector working practices and mindsets.},
booktitle = {Proceedings of the 7th International Conference on Theory and Practice of Electronic Governance},
pages = {77–86},
numpages = {10},
keywords = {open assets, open services, open engagement, public value, open governance, government as a platform},
location = {Seoul, Republic of Korea},
series = {ICEGOV '13}
}

@inbook{10.1145/3377929.3389894,
author = {Torresen, Jim},
title = {Addressing Ethical Challenges within Evolutionary Computation Applications: GECCO 2020 Tutorial},
year = {2020},
isbn = {9781450371278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377929.3389894},
booktitle = {Proceedings of the 2020 Genetic and Evolutionary Computation Conference Companion},
pages = {1206–1223},
numpages = {18}
}

@article{10.1145/3385658.3385668,
author = {Abadi, Daniel and Ailamaki, Anastasia and Andersen, David and Bailis, Peter and Balazinska, Magdalena and Bernstein, Philip and Boncz, Peter and Chaudhuri, Surajit and Cheung, Alvin and Doan, AnHai and Dong, Luna and Franklin, Michael J. and Freire, Juliana and Halevy, Alon and Hellerstein, Joseph M. and Idreos, Stratos and Kossmann, Donald and Kraska, Tim and Krishnamurthy, Sailesh and Markl, Volker and Melnik, Sergey and Milo, Tova and Mohan, C. and Neumann, Thomas and Chin Ooi, Beng and Ozcan, Fatma and Patel, Jignesh and Pavlo, Andrew and Popa, Raluca and Ramakrishnan, Raghu and R\'{e}, Christopher and Stonebraker, Michael and Suciu, Dan},
title = {The Seattle Report on Database Research},
year = {2020},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {4},
issn = {0163-5808},
url = {https://doi.org/10.1145/3385658.3385668},
doi = {10.1145/3385658.3385668},
abstract = {Approximately every five years, a group of database researchers meet to do a self-assessment of our community, including reflections on our impact on the industry as well as challenges facing our research community. This report summarizes the discussion and conclusions of the 9th such meeting, held during October 9-10, 2018 in Seattle.},
journal = {SIGMOD Rec.},
month = {feb},
pages = {44–53},
numpages = {10}
}

@inproceedings{10.1145/2872518.2890599,
author = {Auer, S\"{o}ren and Heath, Tom and Bizer, Christian and Berners-Lee, Tim},
title = {LDOW2016: 9th Workshop on Linked Data on the Web},
year = {2016},
isbn = {9781450341448},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/2872518.2890599},
doi = {10.1145/2872518.2890599},
abstract = {The ninth workshop on Linked Data (LDOW2016) on the Web is held in Montreal, Quebec, Canada on April 12, 2016 and co-located with the 25rd International World Wide Web Conference (WWW2016). The Web is developing from a medium for publishing textual documents into a medium for sharing structured data. This trend is fueled on the one hand by the adoption of the Linked Data principles by a growing number of data providers. On the other hand, large numbers of websites have started to semantically mark up the content of their HTML pages and thus also contribute to the wealth of structured data available on the Web. The 9th Workshop on Linked Data on the Web aims to stimulate discussion and further research into the challenges of publishing, consuming, and integrating structured data from the Web as well as mining knowledge from the global Web of Data.},
booktitle = {Proceedings of the 25th International Conference Companion on World Wide Web},
pages = {1039–1040},
numpages = {2},
keywords = {linked data, semantic web, rdf},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {WWW '16 Companion}
}

@article{10.1145/2724721,
author = {Alonso, Omar},
title = {Challenges with Label Quality for Supervised Learning},
year = {2015},
issue_date = {March 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
issn = {1936-1955},
url = {https://doi.org/10.1145/2724721},
doi = {10.1145/2724721},
abstract = {Organizations that develop and use technologies around information retrieval, machine learning, recommender systems, and natural language processing depend on labels for engineering and experimentation. These labels, usually gathered via human computation, are used in machine-learned models for prediction and evaluation purposes. In such scenarios, collecting high-quality labels is a very important part of the overall process. We elaborate on these challenges and discuss research directions.},
journal = {J. Data and Information Quality},
month = {mar},
articleno = {2},
numpages = {3},
keywords = {crowdsourcing, Label quality, machine learning, human computation}
}

@inproceedings{10.1145/3397056.3397078,
author = {Ge, Juan and Han, Wenli and Zhang, Xunhu and Zhou, Jin},
title = {Research on Construction of Quality Service Platform of Survey and Mapping},
year = {2020},
isbn = {9781450377416},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397056.3397078},
doi = {10.1145/3397056.3397078},
abstract = {Quality data of Surveying and mapping is an intuitive reflection of the industry's quality situation and technical development situation. The construction of quality service platform of Surveying and mapping is discussed for the problems existing in the management of surveying and mapping quality data and for the demand for the use of quality data. It discusses the contents, framework and techniques used by the platform. The platform can be used to assist scientific decision-making and improve the service level.},
booktitle = {Proceedings of the 2020 3rd International Conference on Geoinformatics and Data Analysis},
pages = {57–61},
numpages = {5},
keywords = {Service platform, Data management, Quality},
location = {Marseille, France},
series = {ICGDA 2020}
}

@inproceedings{10.1145/3330431.3330457,
author = {Aljawarneh, Shadi and Radhakrishna, Vangipuram and Kumar, Gunupudi Rajesh},
title = {A Recent Survey on Challenges in Security and Privacy in Internet of Things},
year = {2019},
isbn = {9781450372121},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3330431.3330457},
doi = {10.1145/3330431.3330457},
abstract = {Computing environment in IoT (Internet of Things) is surrounded with huge amounts of heterogeneous data fulfilling many services in everyone's daily life. Since, communication process in IoT takes place using different devices such as smart phones, sensors, mobile devices, household devices, embedded equipment etc. With the use of these variety of devices, the exchange of data in open internet environment is prone to vulnerabilities. The main cause for these vulnerabilities is the weaknesses in the design of software components and hardware components. Bridging communications gaps in the IoT is a complex process as the data is from heterogeneous sources. An effort is made in this paper to discuss various challenges that are being faced in security and privacy of data. This will be very much helpful for researchers who want to pursue research.},
booktitle = {Proceedings of the 5th International Conference on Engineering and MIS},
articleno = {25},
numpages = {9},
keywords = {challenges in IoT, research issues, vulnerability, IoT classification, S/W weakness, security and privacy, IoT architecture, IoT services},
location = {Astana, Kazakhstan},
series = {ICEMIS '19}
}

@inproceedings{10.1145/3512826.3512836,
author = {Wu, Xueqiong and Chen, Lei and Ji, Kun and Wang, Huidong and Qian, Hao and Ma, Lidong},
title = {Design and Application of Virtual Production Command Service in Power Distribution Network Based on Artificial Intelligence},
year = {2022},
isbn = {9781450395489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3512826.3512836},
doi = {10.1145/3512826.3512836},
abstract = {Abstract: As the distribution network business hub, the distribution network production command center faces the need to improve the efficiency of the distribution network production command business. This article draws on international mainstream artificial intelligence (such as Google AlphaGo) and other independent learning models to explore the integration of artificial intelligence and power grid professional business. This paper analyzes the development trend of artificial intelligence technology in the fields of power grid distribution and power knowledge map, and proposes a distribution network virtual production commander engine with dispatch operation, remote monitoring, and intelligent screen monitoring capabilities based on the distribution network knowledge map to realize power grid dispatch Intelligent applications in the fields of operation command, emergency repair, and smart services, and some functions have been verified by the State Grid Hangzhou Electric Power Company.},
booktitle = {2022 The 3rd International Conference on Artificial Intelligence in Electronics Engineering},
pages = {33–37},
numpages = {5},
keywords = {Power Distribution Network Regulations, Power Knowledge Graph, Dispatch Professional Decision, Power Distribution Network Virtual Production Command Engine, AI},
location = {Bangkok, Thailand},
series = {AIEE 2022}
}

@inproceedings{10.1145/3227696.3227715,
author = {Tanaka, Yasuhiro and Kodate, Akihisa and Bolt, Timothy},
title = {Data Sharing System Based on Legal Risk Assessment},
year = {2018},
isbn = {9781450364652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227696.3227715},
doi = {10.1145/3227696.3227715},
abstract = {Regulations on protection of personal information vary from country to country. Therefore, when conducting international surveys for research, it is required to collect, manage and operate personal data properly complying with the laws and regulations of each country.We design a support system to fulfill conditions in terms of compliance for the proper and efficient management of data collection and utilization especially universities by making compliance management related to data cooperation a common foundation.This study aims to discuss requirements for the compliance management base system for data alliance and shared use of data.},
booktitle = {Proceedings of the 5th Multidisciplinary International Social Networks Conference},
articleno = {17},
numpages = {5},
keywords = {Legal Risk Assessment, Personal Data, Privacy Protection, Data Sharing, Information system},
location = {Saint-Etienne, France},
series = {MISNC '18}
}

@inproceedings{10.5555/3017447.3017522,
author = {Lucic, Ana and Blake, Catherine},
title = {Preparing a Workforce to Effectively Reuse Data},
year = {2016},
publisher = {American Society for Information Science},
address = {USA},
abstract = {For centuries, library and information science professionals have been responsible for curating and preserving access to information resources. The last few decades have seen an unprecedented change in how new knowledge is created, disseminated and reused both within academe and industry, which provides new opportunities to intervene within the data lifecycle. This paper documents efforts to create a graduate educational program that produces alum who understand both the social and technical aspects of data analytics and who can effectively employ data to address questions in academe and industry. We share perspectives gained from initial interviews with project partners who have data needs, and report on how those needs directly informed curricula development of the Socio-technical Data Analytics (SODA) program at the School of Information Sciences at the University of Illinois. We also provide a formative student evaluation of the program that was conducted to identify aspects that are successful, and those where further work is needed in order to help other schools who are developing similar programs that prepare a workforce who can effectively reuse data.},
booktitle = {Proceedings of the 79th ASIS&amp;T Annual Meeting: Creating Knowledge, Enhancing Lives through Information &amp; Technology},
articleno = {75},
numpages = {10},
keywords = {data analytics and evaluation, survey results, program development and evaluation, data science},
location = {Copenhagen, Denmark},
series = {ASIST '16}
}

@article{10.1145/2334184.2334188,
author = {Churchill, Elizabeth F.},
title = {From Data Divination to Data-Aware Design},
year = {2012},
issue_date = {September + October 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {5},
issn = {1072-5520},
url = {https://doi.org/10.1145/2334184.2334188},
doi = {10.1145/2334184.2334188},
journal = {Interactions},
month = {sep},
pages = {10–13},
numpages = {4}
}

@article{10.14778/3352063.3352116,
author = {Nargesian, Fatemeh and Zhu, Erkang and Miller, Ren\'{e}e J. and Pu, Ken Q. and Arocena, Patricia C.},
title = {Data Lake Management: Challenges and Opportunities},
year = {2019},
issue_date = {August 2019},
publisher = {VLDB Endowment},
volume = {12},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3352063.3352116},
doi = {10.14778/3352063.3352116},
abstract = {The ubiquity of data lakes has created fascinating new challenges for data management research. In this tutorial, we review the state-of-the-art in data management for data lakes. We consider how data lakes are introducing new problems including dataset discovery and how they are changing the requirements for classic problems including data extraction, data cleaning, data integration, data versioning, and metadata management.},
journal = {Proc. VLDB Endow.},
month = {aug},
pages = {1986–1989},
numpages = {4}
}

@article{10.1145/3450751,
author = {Zhou, Ke and Song, Jingkuan},
title = {Introduction to the Special Issue on Learning-Based Support for Data Science Applications},
year = {2021},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {2},
issn = {2691-1922},
url = {https://doi.org/10.1145/3450751},
doi = {10.1145/3450751},
journal = {ACM/IMS Trans. Data Sci.},
month = {apr},
articleno = {9},
numpages = {1}
}

@inproceedings{10.1145/3463531.3463536,
author = {Wan, Xinxin},
title = {A Study on the Current Development of Artificial Intelligence in Education Industry in China},
year = {2021},
isbn = {9781450389662},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3463531.3463536},
doi = {10.1145/3463531.3463536},
abstract = {This article first explained the definition of AI in education (AIEd) and reported findings regarding the current development of AIEd industry in the Chinese context. The research design is a context-specific case study using the supply and demand theoretical framework. From a demand-side perspective, the author made an in-depth analysis of the specific AI applications employed in different educational scenarios, including the automated speaking assessment system, the content-based image retrieval system, adaptive learning system, AI-supported classrooms, and AI-assisted campus safety system. For the supply analysis of the AIEd industry, this article summarized key AIEd industry chains and technologies currently widely used in China, obtaining the industry market scale through data collected from different sources. In addition, the iFLYTEK company, as a typical enterprise in the AIEd industry, was taken as a medium to conduct a case analysis. The employment of various AI applications in smart classrooms, smart exams, and smart terminals were comprehensively discussed. In a nutshell, this article discussed the development status and future trends of Chinese AIEd industry, with an aim to offer suggestions and implications for education practitioners.},
booktitle = {2021 7th International Conference on Education and Training Technologies},
pages = {28–35},
numpages = {8},
keywords = {Adaptive Learning, Education Informatization, Oral Assessment, AI Education, Smart Classroom},
location = {Macau, China},
series = {ICETT 2021}
}

@inproceedings{10.1145/3368756.3369005,
author = {Bentalha, Badr and Hmioui, Aziz and Alla, Lhoussaine},
title = {The Digitalization of the Supply Chain Management of Service Companies: A Prospective Approach},
year = {2019},
isbn = {9781450362894},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368756.3369005},
doi = {10.1145/3368756.3369005},
abstract = {Supply Chain Management (SCM) was born and developed first in an industrial context. In the field of services, little research has addressed the issue of the company's SCM. According to [1] "service logistics is an approach that stabilizes and guarantees the continuity of flows: it is then oriented more towards the service provided than towards reducing traffic costs". The SCM of services is of increasing interest to companies facing strong competition, market globalization and rapid changes in information and communication technologies. This evolution has led to a rapid integration of new digital practices in this field.So, how is the digitalization of the SCM of service companies looking today and what will be the future trends? On the one hand, with the help of the literature review, we seek to identify the concept of the SCM in services and its specificities, then that of digitization of the SCM and its organizational dimension. On the other hand, we are attempting a prospective approach to the current practices and digitalization prospects of the service company's SCM.},
booktitle = {Proceedings of the 4th International Conference on Smart City Applications},
articleno = {29},
numpages = {8},
keywords = {SCM, prospective approach, supply chain, digital, service company},
location = {Casablanca, Morocco},
series = {SCA '19}
}

@inproceedings{10.1145/3447548.3470814,
author = {Zhou, Zirui and Chu, Lingyang and Liu, Changxin and Wang, Lanjun and Pei, Jian and Zhang, Yong},
title = {Towards Fair Federated Learning},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3470814},
doi = {10.1145/3447548.3470814},
abstract = {Federated learning has become increasingly popular as it facilitates collaborative training of machine learning models among multiple clients while preserving their data privacy. In practice, one major challenge for federated learning is to achieve fairness in collaboration among the participating clients, because different clients' contributions to a model are usually far from equal due to various reasons. Besides, as machine learning models are deployed in more and more important applications, how to achieve model fairness, that is, to ensure that a trained model has no discrimination against sensitive attributes, has become another critical desiderata for federated learning. In this tutorial, we discuss formulations and methods such that collaborative fairness, model fairness, and privacy can be fully respected in federated learning. We review the existing efforts and the latest progress, and discuss a series of potential directions.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {4100–4101},
numpages = {2},
keywords = {data privacy, federated learning, model fairness, data leakage, distributed learning, collaborative fairness},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3047273.3047386,
author = {Matheus, Ricardo and Janssen, Marijn},
title = {How to Become a Smart City? Balancing Ambidexterity in Smart Cities},
year = {2017},
isbn = {9781450348256},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3047273.3047386},
doi = {10.1145/3047273.3047386},
abstract = {Most cities have limited resources to become a smart city. Yet some cities have been more successful than others in becoming a smart city. This raises the questions why were some cities able to become smart, whereas other were not able to do so? This research is aimed at identifying factors influencing the shift towards becoming a smart city. In this way insight is gained into factors that governments can influence to become a smart city. First, Literature was reviewed to identify dimensions and factors enabling or impeding the process of becoming a smart city. These factors were used to compare two similar type of case studies. The cases took different paths to become a smart city and had different levels of success. This enabled us to identify factors influencing the move towards smart cities. The results reveal that existing infrastructures should be used and extended in such a way that they can facilitate a variety of different applications. Synergy from legacy systems can avoid extra expenditures. Having such an infrastructure in place facilitates the development of new organizational models. These models are developed outside the existing organization structure to avoid hinder from existing practices and organizational structures. This finding suggests that smart cities focussed on structural ambidexterity innovate quicker.},
booktitle = {Proceedings of the 10th International Conference on Theory and Practice of Electronic Governance},
pages = {405–413},
numpages = {9},
keywords = {smart cities, exploitation, ambidexterity, transformation, exploration, e-government, innovation},
location = {New Delhi AA, India},
series = {ICEGOV '17}
}

@inproceedings{10.1145/2729104.2729134,
author = {Kokkinakos, Panagiotis and Koutras, Costas and Markaki, Ourania and Koussouris, Sotirios and Trutnev, Dmitrii and Glikman, Yuri},
title = {Assessing Governmental Policies' Impact through Prosperity Indicators and Open Data},
year = {2014},
isbn = {9781450334013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2729104.2729134},
doi = {10.1145/2729104.2729134},
abstract = {The aim of this paper is to provide an overview of (the theory and practice of) prosperity indicators for assessing the impact of governmental policies and the data sources associated to their calculation, touching also on the broad theme of Open Data which opens up new horizons for the calculation and exploitation of Social Indicators. Following a quick overview of the basics of prosperity indicators, their basic methodological principles and their typology, a presentation of the Policy Compass project approach and the description of its pilot application in St. Petersburg are provided, which are tackling the above mentioned issue with the provision of a powerful ICT platform.},
booktitle = {Proceedings of the 2014 Conference on Electronic Governance and Open Society: Challenges in Eurasia},
pages = {70–74},
numpages = {5},
keywords = {Policy Making, Open Data, Policy Impact Evaluation, Fuzzy Cognitive Maps, Prosperity Indicators},
location = {St. Petersburg, Russian Federation},
series = {EGOSE '14}
}

@inproceedings{10.1145/3447548.3470799,
author = {Lee, Jae-Gil and Roh, Yuji and Song, Hwanjun and Whang, Steven Euijong},
title = {Machine Learning Robustness, Fairness, and Their Convergence},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3470799},
doi = {10.1145/3447548.3470799},
abstract = {Responsible AI becomes critical where robustness and fairness must be satisfied together. Traditionally, the two topics have been studied by different communities for different applications. Robust training is designed for noisy or poisoned data where image data is typically considered. In comparison, fair training primarily deals with biased data where structured data is typically considered. Nevertheless, robust training and fair training are fundamentally similar in considering that both of them aim at fixing the inherent flaws of real-world data. In this tutorial, we first cover state-of-the-art robust training techniques where most of the research is on combating various label noises. In particular, we cover label noise modeling, robust training approaches, and real-world noisy data sets. Then, proceeding to the related fairness literature, we discuss pre-processing, in-processing, and post-processing unfairness mitigation techniques, depending on whether the mitigation occurs before, during, or after the model training. Finally, we cover the recent trend emerged to combine robust and fair training in two flavors: the former is to make the fair training more robust (i.e., robust fair training), and the latter is to consider robustness and fairness as two equals to incorporate them into a holistic framework. This tutorial is indeed timely and novel because the convergence of the two topics is increasingly common, but yet to be addressed in tutorials. The tutors have extensive experience publishing papers in top-tier machine learning and data mining venues and developing machine learning platforms.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {4046–4047},
numpages = {2},
keywords = {fairness, machine learning, robustness, convergence},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/2884781.2884783,
author = {Kim, Miryung and Zimmermann, Thomas and DeLine, Robert and Begel, Andrew},
title = {The Emerging Role of Data Scientists on Software Development Teams},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884783},
doi = {10.1145/2884781.2884783},
abstract = {Creating and running software produces large amounts of raw data about the development process and the customer usage, which can be turned into actionable insight with the help of skilled data scientists. Unfortunately, data scientists with the analytical and software engineering skills to analyze these large data sets have been hard to come by; only recently have software companies started to develop competencies in software-oriented data analytics. To understand this emerging role, we interviewed data scientists across several product groups at Microsoft. In this paper, we describe their education and training background, their missions in software engineering contexts, and the type of problems on which they work. We identify five distinct working styles of data scientists: (1) Insight Providers, who work with engineers to collect the data needed to inform decisions that managers make; (2) Modeling Specialists, who use their machine learning expertise to build predictive models; (3) Platform Builders, who create data platforms, balancing both engineering and data analysis concerns; (4) Polymaths, who do all data science activities themselves; and (5) Team Leaders, who run teams of data scientists and spread best practices. We further describe a set of strategies that they employ to increase the impact and actionability of their work.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {96–107},
numpages = {12},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/3424311.3424326,
author = {Wang, Lei and Wang, Yang},
title = {Application of Machine Learning for Process Control in Semiconductor Manufacturing},
year = {2020},
isbn = {9781450377348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3424311.3424326},
doi = {10.1145/3424311.3424326},
abstract = {In this article, the authors attempt to describe the core quality inspection during semiconductor manufacturing in terms of production efficiency and yield. Special focus is therefore given to photolithography, which is the most critical step for the fabrication of wafer patterns in front-end processes. Further, machine learning approaches are demonstrated and their applicability in semiconductor manufacturing industry is discussed. Also, a technical concept regarding virtual metrology for advanced process control in semiconductor production is introduced as a potential utilization case. Finally, current status and future trends in technology as well as application are summarized based on authors' perspective in the concluding section.},
booktitle = {Proceedings of the 2020 International Conference on Internet Computing for Science and Engineering},
pages = {109–111},
numpages = {3},
keywords = {Virtual metrology, Data analytics, Advanced process control, Semiconductor manufacturing, Machine learning},
location = {Male, Maldives},
series = {ICICSE '20}
}

@inproceedings{10.5555/2693848.2694146,
author = {Wu, Xinghao and Qiao, Fei and Poon, Kwok},
title = {Cloud Manufacturing Application in Semiconductor Industry},
year = {2014},
publisher = {IEEE Press},
abstract = {This paper aims to shed some light on how the concept of cloud manufacturing has been applied to the semiconductor manufacturing operations. It starts with describing the challenges to the semiconductor manufacturing due to evolving of outsourcing business model in global context, then discusses the different forms of cloud manufacturing and proposes the semiconductor industry oriented architecture for cloud manufacturing. Serus is used as a case study to share how the cloud manufacturing has created the values for the customer and its outsourced suppliers in the semiconductor industry.},
booktitle = {Proceedings of the 2014 Winter Simulation Conference},
pages = {2376–2383},
numpages = {8},
location = {Savannah, Georgia},
series = {WSC '14}
}

@inproceedings{10.1145/3159652.3160594,
author = {Lin, Yu-Ru and Castillo, Carlos and Yin, Jie},
title = {The 5th International Workshop on Social Web for Disaster Management(SWDM'18): Collective Sensing, Trust, and Resilience in Global Crises},
year = {2018},
isbn = {9781450355810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3159652.3160594},
doi = {10.1145/3159652.3160594},
abstract = {During large-scale emergencies such as natural and man-made disasters, a massive amount of information is posted by the public in social media. Collecting, aggregating, and presenting this information to stakeholders can be extremely challenging, particularly if an understanding of the "big picture»» is sought. This international workshop, the fifth in the series, is a key venue for researchers and practitioners to discuss research challenges and technical issues around the usage of social media in disaster management. Workshop»s website: https://sites.google.com/site/swdm2018/},
booktitle = {Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining},
pages = {791–792},
numpages = {2},
keywords = {disaster response, social media, emergency management},
location = {Marina Del Rey, CA, USA},
series = {WSDM '18}
}

@inbook{10.1145/3479162.3479167,
author = {Suaprae, Phanintorn and Nilsook, Prachyanun and Wannapiroon, Panita},
title = {System Framework of Intelligent Consulting Systems with Intellectual Technology},
year = {2021},
isbn = {9781450390071},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3479162.3479167},
abstract = {The purposes of this research were: 1) Analyze factors affecting the student retention of higher education students, 2) Develop intelligent consulting system models with intellectual technology for the student retention of higher education students, 3) Design intelligent consulting system architecture with intellectual technology for the student retention of higher education students, 4) Develop intelligent consulting systems with intellectual technology for the student retention of higher education students, and 5) Study the results of intelligent consultation systems with intellectual technology for the student retention of higher education students. An intelligent counseling system with intellectual technology for the student retention of higher education students is a system that can reduce students' mid-exit rates and increase student retention rates. The research has synthesized analysis of factors that affect Student retention applied to Cognitive technology, machine learning can provide accurate student retention forecasts. Counselors can know before students drop out.},
booktitle = {The 2021 9th International Conference on Computer and Communications Management},
pages = {31–36},
numpages = {6}
}

@article{10.1145/3356773.3356810,
author = {Xie, Xiaoyuan and Poon, Pak-Lok and Pullum, Laura L.},
title = {Workshop Summary: 2019 IEEE / ACM Fourth International Workshop on Metamorphic Testing (MET 2019)},
year = {2019},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/3356773.3356810},
doi = {10.1145/3356773.3356810},
abstract = {MET is a relatively new workshop on metamorphic testing for academic researchers and industry practitioners. The first international workshop on MET (MET 2016) was co-located with the 38th International Conference on Software Engineering (ICSE 2016) in Austin TX, USA on May 16, 2016. Since then the workshop has become an annual event. This paper reports on the fourth International Workshop on Metamorphic Testing (MET 2019) held in Montr\'{e}al, Canada on May 26, 2019, as part of the 41st International Conference on Software Engineering (ICSE 2019). We first outline the aims of the workshop, followed by a discussion of its keynote speech and technical program.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {nov},
pages = {56–59},
numpages = {4},
keywords = {software verification and validation, software testing, metamorphic testing, software engineering}
}

@inproceedings{10.1145/3394486.3406473,
author = {Pei, Jian},
title = {Data Pricing -- From Economics to Data Science},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3406473},
doi = {10.1145/3394486.3406473},
abstract = {Data are invaluable. How can we assess the value of data objectively and quantitatively? Pricing data, or information goods in general, has been studied and practiced in dispersed areas and principles, such as economics, data management, data mining, electronic commerce, and marketing. In this tutorial, we present a unified and comprehensive overview of this important direction. We examine various motivations behind data pricing, understand the economics of data pricing, review the development and evolution of pricing models, and compare the proposals of marketplaces of data. We cover both digital products, such as ebooks and MP3 music, and data products, such as data sets, data queries and machine learning models. We also connect data pricing with the highly related areas, such as cloud service pricing, privacy pricing, and decentralized privacy preserving infrastructure like blockchains.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {3553–3554},
numpages = {2},
keywords = {privacy, fairness, information goods, digital products, data products, trustfulness, data pricing, subscription, bundling, auctions, revenue maximization, arbitrage},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@article{10.1145/2883611,
author = {Cao, Tien-Dung and Pham, Tran-Vu and Vu, Quang-Hieu and Truong, Hong-Linh and Le, Duc-Hung and Dustdar, Schahram},
title = {MARSA: A Marketplace for Realtime Human Sensing Data},
year = {2016},
issue_date = {August 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {3},
issn = {1533-5399},
url = {https://doi.org/10.1145/2883611},
doi = {10.1145/2883611},
abstract = {This article introduces a dynamic cloud-based marketplace of near-realtime human sensing data (MARSA) for different stakeholders to sell and buy near-realtime data. MARSA is designed for environments where information technology (IT) infrastructures are not well developed but the need to gather and sell near-realtime data is great. To this end, we present techniques for selecting data types and managing data contracts based on different cost models, quality of data, and data rights. We design our MARSA platform by leveraging different data transferring solutions to enable an open and scalable communication mechanism between sellers (data providers) and buyers (data consumers). To evaluate MARSA, we carry out several experiments with the near-realtime transportation data provided by people in Ho Chi Minh City, Vietnam, and simulated scenarios in multicloud environments.},
journal = {ACM Trans. Internet Technol.},
month = {may},
articleno = {16},
numpages = {21},
keywords = {platform, Internet of Things, data contract, cost model}
}

@inproceedings{10.1145/3041021.3055510,
author = {Lehmann, Jens and Auer, S\"{o}ren and Capadisli, Sarven and Janowicz, Krzysztof and Bizer, Christian and Heath, Tom and Hogan, Aidan and Berners-Lee, Tim},
title = {LDOW2017: 10th Workshop on Linked Data on the Web},
year = {2017},
isbn = {9781450349147},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3041021.3055510},
doi = {10.1145/3041021.3055510},
abstract = {The 10th Linked Data on the Web workshop (LDOW2017) was held in Perth, Western Australia on April 3, 2017, co-located with the 26th International World Wide Web Conference (WWW2017). In its 10th anniversary edition, the LDOW workshop aims to stimulate discussion and further research into the challenges of publishing, consuming, and integrating structured data on the Web as well as mining knowledge from said data.},
booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
pages = {1679–1680},
numpages = {2},
keywords = {linked data, semantic web},
location = {Perth, Australia},
series = {WWW '17 Companion}
}

@inproceedings{10.1145/3450508.3464558,
author = {Bednarz, Tomasz and Hughes, Rowan T. and Mathews, Alex and Chen, Dawei and Zhu, Liming and Filonik, Daniel},
title = {Visual Analytics for Large Networks: Theory, Art and Practice},
year = {2021},
isbn = {9781450383615},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3450508.3464558},
doi = {10.1145/3450508.3464558},
booktitle = {ACM SIGGRAPH 2021 Courses},
articleno = {15},
numpages = {213},
location = {Virtual Event, USA},
series = {SIGGRAPH '21}
}

@article{10.1145/2380776.2380789,
author = {Maz\'{o}n, Jose-Norberto and Garrig\'{o}s, Irene and Daniel, Florian and Castellanos, Malu},
title = {Report of the International Workshop on Business Intelligence and the Web: BEWEB 2011},
year = {2012},
issue_date = {September 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {3},
issn = {0163-5808},
url = {https://doi.org/10.1145/2380776.2380789},
doi = {10.1145/2380776.2380789},
abstract = {The 2nd International Workshop on Business intelligencE and the WEB (BEWEB) was co-located with the EDBT/ICDT 2011 Joint Conference in Uppsala (Sweden) on March 25, 2011. BEWEB intends to be an international forum for researchers and practitioners to exchange ideas on how to leverage the huge amount of data that is available on the Web in BI applications and on how to apply Web engineering methods and techniques to the design of BI applications. This report summarizes the 2011 edition of BEWEB.},
journal = {SIGMOD Rec.},
month = {oct},
pages = {51–53},
numpages = {3}
}

@inproceedings{10.1145/2912160.2912180,
author = {Netten, Niels and Bargh, Mortaza S. and van den Braak, Susan and Choenni, Sunil and Leeuw, Frans},
title = {On Enabling Smart Government: A Legal Logistics Framework for Future Criminal Justice Systems},
year = {2016},
isbn = {9781450343398},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2912160.2912180},
doi = {10.1145/2912160.2912180},
abstract = {While in business and private settings the disruptive impact of advanced information communication technology (ICT) have already been felt, the legal sector is now starting to face great disruptions due to such ICTs. Bits and pieces of innovations in the legal sector have been emerging for some time, affecting the performance of core functions and the legitimacy of public institutions.In this paper, we present our framework for enabling the smart government vision, particularly for the case of criminal justice systems, by unifying different isolated ICT-based solutions. Our framework, coined as Legal Logistics, supports the well-functioning of a legal system in order to streamline the innovations in these legal systems. The framework targets the exploitation of all relevant data generated by the ICT-based solutions. As will be illustrated for the Dutch criminal justice system, the framework may be used to integrate different ICT-based innovations and to gain insights about the well-functioning of the system. Furthermore, Legal Logistics can be regarded as a roadmap towards a smart and open justice.},
booktitle = {Proceedings of the 17th International Digital Government Research Conference on Digital Government Research},
pages = {293–302},
numpages = {10},
keywords = {Law enforcement, efficiency, open justice, effectivity, smart governance, and penal law, legal design},
location = {Shanghai, China},
series = {dg.o '16}
}

@inproceedings{10.1145/3447548.3470825,
author = {Zalmout, Nasser and Zhang, Chenwei and Li, Xian and Liang, Yan and Dong, Xin Luna},
title = {All You Need to Know to Build a Product Knowledge Graph},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3470825},
doi = {10.1145/3447548.3470825},
abstract = {Knowledge graphs have been pivotal in supporting downstream applications like search, recommendation, and question answering, among others. Therefore, knowledge graphs have naturally become key enabling technologies in e-Commerce platforms. Developing a high coverage product knowledge graph is more challenging than generic knowledge graphs. The highly specific and complex domain, the sparsity of training data, along with the dynamic taxonomies and product types, can constrain the resulting knowledge graphs. In this tutorial we present best practices and ML innovations in industry towards building a scalable product knowledge graph. Contributions in this domain benefit from the general literature in areas including information extraction and data mining, tailored to address the specific characteristics of e-Commerce platforms.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {4090–4091},
numpages = {2},
keywords = {information extraction, taxonomy, knowledge graphs, data cleaning},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@article{10.1145/3403976,
author = {Hoffmann, Leah},
title = {Seeing Light at the End of the Cybersecurity Tunnel},
year = {2020},
issue_date = {August 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {63},
number = {8},
issn = {0001-0782},
url = {https://doi.org/10.1145/3403976},
doi = {10.1145/3403976},
abstract = {After decades of cybersecurity research, Elisa Bertino remains optimistic.},
journal = {Commun. ACM},
month = {jul},
pages = {104–ff},
numpages = {2}
}

@inproceedings{10.1145/3503823.3503900,
author = {Stakoulas, Konstantinos and Georgiou, Konstantinos and Mittas, Nikolaos and Angelis, Lefteris},
title = {An Analysis of User Profiles from Covid-19 Questions in Stack Overflow},
year = {2021},
isbn = {9781450395557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503823.3503900},
doi = {10.1145/3503823.3503900},
abstract = {The COVID-19 pandemic brought many changes in society, with one of the most important being an explosion of software development concerning technological solutions for combatting its crippling effects. In this global crisis, many software enthusiasts, combined with seasoned developers and specialists turned their attention to Questions and Answers platforms such as Stack Overflow to expand their knowledge and ask questions regarding their COVID-19 related solutions. This paper examines the different characteristics of these users, dividing them into Newcomers and Oldcomers and pinpoints popularity differences, scientific and technological backgrounds by analyzing key technologies, as well as the role of gender in their participation.},
booktitle = {25th Pan-Hellenic Conference on Informatics},
pages = {419–424},
numpages = {6},
location = {Volos, Greece},
series = {PCI 2021}
}

@inproceedings{10.5555/2873003.2873011,
author = {Barhak, Jacob},
title = {Modeling Clinical Data from Publications},
year = {2015},
isbn = {9781510801028},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {Medical data is becoming increasingly available. Access to such data is generally restricted and researchers cannot access it easily. On the other hand, clinical trial data is freely available and published without restriction for access to the public at the summary level. With proper analysis, it is possible to extract valuable conclusions from such data. This paper will review new methods to look at such public data and will discuss possible future trends.},
booktitle = {Proceedings of the Symposium on Modeling and Simulation in Medicine},
pages = {47–52},
numpages = {6},
keywords = {clinical trial, reference modeling, publications, high performance computing, disease modeling, Monte-Carlo},
location = {Alexandria, Virginia},
series = {MSM '15}
}

@inproceedings{10.1145/3085228.3085255,
author = {Parycek, P. and Pereira, G. Viale},
title = {Drivers of Smart Governance: Towards to Evidence-Based Policy-Making},
year = {2017},
isbn = {9781450353175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3085228.3085255},
doi = {10.1145/3085228.3085255},
abstract = {This paper presents the preliminary framework proposed by the authors for drivers of Smart Governance. The research question of this study is: What are the drivers for Smart Governance to achieve evidence-based policy-making? The framework suggests that in order to create a smart governance model, data governance and collaborative governance are the main drivers. These pillars are supported by legal framework, normative factors, principles and values, methods, data assets or human resources, and IT infrastructure. These aspects will guide a real time evaluation process in all levels of the policy cycle, towards to the implementation of evidence-based policies.},
booktitle = {Proceedings of the 18th Annual International Conference on Digital Government Research},
pages = {564–565},
numpages = {2},
keywords = {Data Governance, Evaluation, Collaborative Governance, Decision-making},
location = {Staten Island, NY, USA},
series = {dg.o '17}
}

@inproceedings{10.1145/3401025.3404099,
author = {Gupta, Suyash and Hellings, Jelle and Rahnama, Sajjad and Sadoghi, Mohammad},
title = {Blockchain Consensus Unraveled: Virtues and Limitations},
year = {2020},
isbn = {9781450380287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3401025.3404099},
doi = {10.1145/3401025.3404099},
abstract = {Since the introduction of Bitcoin---the first wide-spread application driven by blockchains---the interest of the public and private sector in blockchains has skyrocketed. At the core of this interest are the ways in which blockchains can be used to improve data management, e.g., by enabling federated data management via decentralization, resilience against failure and malicious actors via replication and consensus, and strong data provenance via a secured immutable ledger.In practice, high-performance blockchains for data management are usually built in permissioned environments in which the participants are vetted and can be identified. In this setting, blockchains are typically powered by Byzantine fault-tolerant consensus protocols. These consensus protocols are used to provide full replication among all honest blockchain participants by enforcing an unique order of processing incoming requests among the participants.In this tutorial, we take an in-depth look at Byzantine fault-tolerant consensus. First, we take a look at the theory behind replicated computing and consensus. Then, we delve into how common consensus protocols operate. Finally, we take a look at current developments and briefly look at our vision moving forward.},
booktitle = {Proceedings of the 14th ACM International Conference on Distributed and Event-Based Systems},
pages = {218–221},
numpages = {4},
keywords = {resilient transaction processing, consensus, geo-scale, permissioned blockchains, byzantine learning, cluster-sending, sharding},
location = {Montreal, Quebec, Canada},
series = {DEBS '20}
}

@inproceedings{10.1145/3267305.3267694,
author = {Han, Yang and Li, Victor O.K. and Lam, Jacqueline C.K. and Lu, Zhiyi},
title = {UMeAir: Predicting Momentary Happiness Towards Air Quality via Machine Learning},
year = {2018},
isbn = {9781450359665},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3267305.3267694},
doi = {10.1145/3267305.3267694},
abstract = {Subjective well-being (SWB) refers to people's subjective evaluation of their own quality of life. Previous studies show that environmental pollution, such as air pollution, has generated significant negative impacts on one's SWB. However, such works are often constrained by the lack of appropriate representation of SWB specifically related to air quality. In this study, we develop UMeAir, which collects one's real-time SWB, specifically, one's momentary happiness at a given air quality, pre-processes input data and detects outliers via Isolation Forests, trains and selects the best model via Support Vector Machine and Random Forests, and predicts the momentary happiness towards any air quality one experienced. Unlike traditional representation of air quality by pollution concentration/Air Pollution Index, UMeAir intends to represent air quality in a more user-comprehensible way, by connecting the air quality experienced at a particular time and location with the corresponding momentary happiness perceived towards the air. The higher the momentary happiness, the better the air quality one experienced. Our work is the first attempt to predict momentary happiness towards air quality in real-time, with the development of the-first-of-its-kind UMeAir Happiness Index (HAPI) towards air quality via machine learning.},
booktitle = {Proceedings of the 2018 ACM International Joint Conference and 2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers},
pages = {702–705},
numpages = {4},
keywords = {Subjective well-being prediction, Air quality, Machine learning, Data interpretability, Short-term happiness},
location = {Singapore, Singapore},
series = {UbiComp '18}
}

@inproceedings{10.1145/3428690.3429172,
author = {Khadivizand, Sam and Beheshti, Amin and Sobhanmanesh, Fariborz and Sheng, Quan Z. and Istanbouli, Elias and Wood, Steven and Pezaro, Damon},
title = {Towards Intelligent Feature Engineering for Risk-Based Customer Segmentation in Banking},
year = {2020},
isbn = {9781450389242},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3428690.3429172},
doi = {10.1145/3428690.3429172},
abstract = {Business Processes, i.e., a set of coordinated tasks and activities to achieve a business goal, and their continuous improvements are key to the operation of any organization. In banking, business processes are increasingly dynamic as various technologies have made dynamic processes more prevalent. For example, customer segmentation, i.e., the process of grouping related customers based on common activities and behaviors, could be a data-driven and knowledge-intensive process. In this paper, we present an intelligent data-driven pipeline composed of a set of processing elements to move customers' data from one system to another, transforming the data into the contextualized data and knowledge along the way. The goal is to present a novel intelligent customer segmentation process which automates the feature engineering, i.e., the process of using (banking) domain knowledge to extract features from raw data via data mining techniques, in the banking domain. We adopt a typical scenario for analyzing customer transaction records, to highlight how the presented approach can significantly improve the quality of risk-based customer segmentation in the absence of feature engineering.},
booktitle = {Proceedings of the 18th International Conference on Advances in Mobile Computing &amp; Multimedia},
pages = {74–83},
numpages = {10},
keywords = {banking processes, feature engineering, business process, risk-based customer segmentation},
location = {Chiang Mai, Thailand},
series = {MoMM '20}
}

@inproceedings{10.1145/3366625.3369437,
author = {Gupta, Suyash and Hellings, Jelle and Rahnama, Sajjad and Sadoghi, Mohammad},
title = {An In-Depth Look of BFT Consensus in Blockchain: Challenges and Opportunities},
year = {2019},
isbn = {9781450370400},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366625.3369437},
doi = {10.1145/3366625.3369437},
abstract = {Since the introduction of Bitcoin---the first wide-spread application driven by blockchains---the interest of the public and private sector in blockchains has skyrocketed. At the core of this interest are the ways in which blockchains can be used to improve data management, e.g., by enabling federated data management via decentralization, resilience against failure and malicious actors via replication and consensus, and strong data provenance via a secured immutable ledger.In practice, high-performance blockchains for data management are usually built in permissioned environments in which the participants are vetted and can be identified. In this setting, blockchains are typically powered by Byzantine fault-tolerant consensus protocols. These consensus protocols are used to provide full replication among all honest blockchain participants by enforcing an unique order of processing incoming requests among the participants.In this tutorial, we take an in-depth look at Byzantine fault-tolerant consensus. First, we take a look at the theory behind replicated computing and consensus. Then, we delve into how common consensus protocols operate. Finally, we take a look at current developments and briefly look at our vision moving forward.},
booktitle = {Proceedings of the 20th International Middleware Conference Tutorials},
pages = {6–10},
numpages = {5},
location = {Davis, CA, USA},
series = {Middleware '19}
}

@inproceedings{10.1145/3029387.3029421,
author = {Anjum, Shahid W.},
title = {Risk Magnification Framework for Clouds Computing Architects in Business Intelligence},
year = {2017},
isbn = {9781450348034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3029387.3029421},
doi = {10.1145/3029387.3029421},
abstract = {IT infrastructure and applications in enterprise systems started with traditional client-server architecture and have gone through key paradigm shifts in infrastructure, software, enterprise, and service architectures to current age of cloud computing and internet of everything. Using strengths-weaknesses-opportunities-threats and analytical hierarchy process of multi-criteria decision making frameworks together, various aspects of cloud computing characteristics related to opportunities, benefits, costs, value and risks can be understood in a more detailed way and can be ranked. This article has combined these two frameworks for the ranking of various business intelligence architects for cloud computing by using 'business automation with sustainable hedging for information risks' framework for cloud computing from conservative perspective where risk relevancy attracts the prime focus. The results have shown that moving operational business intelligence is the best business intelligence architecture for cloud computing as its strengths are more than inherent risks as has become evident by using this approach.},
booktitle = {Proceedings of the 5th International Conference on Information and Education Technology},
pages = {140–144},
numpages = {5},
keywords = {Multi Criteria Decision Making, IT Risk Management, Cloud Computing, Business Intelligence Architecture, A'WOT Analysis},
location = {Tokyo, Japan},
series = {ICIET '17}
}

@inproceedings{10.1145/3503928.3503944,
author = {Wu, Ji and Zhou, Ming and Xu, Min and Zhang, Jin and Wu, Yue and Zha, Weiwei and Zhang, Chengping},
title = {Design and Research of IoT Management Architecture for Power Grid Enterprises Based on Digital Transformation: Application of IoT in Power Grid Enterprises According to Enterprise Architecture Method},
year = {2021},
isbn = {9781450385220},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503928.3503944},
doi = {10.1145/3503928.3503944},
abstract = {Internet of things technology, as the core technology in digital transformation, helps enterprises in digital transformation to carry out comprehensive perception, intelligent management and secure transmission. Following the information architecture of State Grid Corporation of China and combined with the business objectives and Strategies of electric power company, carry out the differentiated design of power Internet of things architecture, put forward the improvement direction of power Internet of things architecture, clarify the application scenario and future evolution route of power Internet of things business, and ensure the realization of technology.},
booktitle = {2021 the 6th International Conference on Information Systems Engineering},
pages = {84–88},
numpages = {5},
keywords = {Intelligent IoT management system, IoT, Digital transformation},
location = {Shanghai, China},
series = {ICISE 2021}
}

@article{10.5555/3344081.3344085,
author = {Li, Xinming and Talburt, John R. and Li, Ting and Liu, Xiangwen},
title = {Scoring Matrix Combined with Machine Learning for Heterogeneously Structured Entity Resolution},
year = {2019},
issue_date = {April 2019},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {34},
number = {7},
issn = {1937-4771},
abstract = {This paper describes how machine learning works with "coring matrix", which is designed for measuring the similarity between heterogeneously structured references, to get a better performance in Entity Resolution (ER). In the scoring matrix, each entity reference is tokenized and all pairs of tokens between the references are scored by a similarity scoring function such as the Levenshtein edit distance. In so doing, a similarity score vector can measure the similarity between references. With the similarity score vector, machine learning is used to make the linking decision. Our experiments show that machine learning based on score vector outperforms TF-IDF and FuzzyWuzzy benchmarks. One possible explanation is that a similarity score vector conveys much more information than a single similarity score. Random forest and neural network even get better performance with raw score vector input than with the statistic characteristic input.},
journal = {J. Comput. Sci. Coll.},
month = {apr},
pages = {38–45},
numpages = {8}
}

@article{10.1145/2536669.2536682,
author = {Zhou, Xiaofang and Sadiq, Shazia},
title = {Data Centric Research at the University of Queensland},
year = {2013},
issue_date = {September 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {3},
issn = {0163-5808},
url = {https://doi.org/10.1145/2536669.2536682},
doi = {10.1145/2536669.2536682},
journal = {SIGMOD Rec.},
month = {oct},
pages = {63–68},
numpages = {6}
}

@inproceedings{10.1145/3469213.3470424,
author = {Yan, Feng},
title = {A Building Integrated Control Platform Oriented Towards Intelligent Building},
year = {2021},
isbn = {9781450390200},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3469213.3470424},
doi = {10.1145/3469213.3470424},
booktitle = {2021 2nd International Conference on Artificial Intelligence and Information Systems},
articleno = {217},
numpages = {10},
location = {Chongqing, China},
series = {ICAIIS 2021}
}

@article{10.1145/3368091,
author = {Douglas, David M.},
title = {Should Researchers Use Data from Security Breaches?},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {62},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/3368091},
doi = {10.1145/3368091},
abstract = {Evaluating the arguments for and against using digital data derived from security breaches.},
journal = {Commun. ACM},
month = {nov},
pages = {22–24},
numpages = {3}
}

@inproceedings{10.1145/3494193.3494250,
author = {Schuch de Azambuja, Luiza},
title = {Drivers and Barriers for the Development of Smart Sustainable Cities: A Systematic Literature Review},
year = {2021},
isbn = {9781450390118},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3494193.3494250},
doi = {10.1145/3494193.3494250},
abstract = {The term Smart Sustainable City (SSC) has been gaining popularity due to the growth of initiatives to address urban problems towards sustainable development. SSC can be considered as a combination of sustainable city and smart city, and some variance between the concepts may be expected. As this is a modern term, the literature falls short of studies presenting factors that hinder and/or facilitate the complex phenomenon of SSC development. Therefore, this paper aims to analyse scientific studies to identify aspects that influence the progress of smart sustainable cities. The methodological approach undertaken was a systematic literature review that included 169 papers. The results offer a comprehensive list of 57 drivers and 63 barriers, classified according to five main dimensions of a smart sustainable city, which are the three sustainability pillars (society, environment, and economy), combined to governance, and urban infrastructure. The findings revealed ‘governance’ as the most significant domain for SSC development, and multistakeholder engagement as one of the main challenges. This study shows that SSC is not a research field itself, but an interdisciplinary concept, contributing to academics, government, and policymakers for eradicating potential interferences in the development of smart and sustainable cities.},
booktitle = {14th International Conference on Theory and Practice of Electronic Governance},
pages = {422–428},
numpages = {7},
keywords = {smart city, sustainable city, enablers, challenges},
location = {Athens, Greece},
series = {ICEGOV 2021}
}

@inbook{10.1145/3310205.3310207,
title = {Introduction},
year = {2019},
isbn = {9781450371520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3310205.3310207},
abstract = {Data quality is one of the most important problems in data management, since dirty data often leads to inaccurate data analytics results and incorrect business decisions. Poor data across businesses and the U.S. government are reported to cost trillions of dollars a year. Multiple surveys show that dirty data is the most common barrier faced by data scientists. Not surprisingly, developing effective and efficient data cleaning solutions is challenging and is rife with deep theoretical and engineering problems.This book is about data cleaning, which is used to refer to all kinds of tasks and activities to detect and repair errors in the data. Rather than focus on a particular data cleaning task, we give an overview of the endto- end data cleaning process, describing various error detection and repair methods, and attempt to anchor these proposals with multiple taxonomies and views. Specifically, we cover four of the most common and important data cleaning tasks, namely, outlier detection, data transformation, error repair (including imputing missing values), and data deduplication. Furthermore, due to the increasing popularity and applicability of machine learning techniques, we include a chapter that specifically explores how machine learning techniques are used for data cleaning, and how data cleaning is used to improve machine learning models.This book is intended to serve as a useful reference for researchers and practitioners who are interested in the area of data quality and data cleaning. It can also be used as a textbook for a graduate course. Although we aim at covering state-of-the-art algorithms and techniques, we recognize that data cleaning is still an active field of research and therefore provide future directions of research whenever appropriate.},
booktitle = {Data Cleaning}
}

@inproceedings{10.1109/ICSE-Companion.2019.00023,
author = {Dang, Yingnong and Lin, Qingwei and Huang, Peng},
title = {AIOps: Real-World Challenges and Research Innovations},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion.2019.00023},
doi = {10.1109/ICSE-Companion.2019.00023},
abstract = {AIOps is about empowering software and service engineers (e.g., developers, program managers, support engineers, site reliability engineers) to efficiently and effectively build and operate online services and applications at scale with artificial intelligence (AI) and machine learning (ML) techniques. AIOps can help improve service quality and customer satisfaction, boost engineering productivity, and reduce operational cost. In this technical briefing, we first summarize the real-world challenges in building AIOps solutions based on our practice and experience in Microsoft. We then propose a roadmap of AIOps related research directions, and share a few successful AIOps solutions we have built for Microsoft service products.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings},
pages = {4–5},
numpages = {2},
keywords = {software analytics, AIOps, DevOps},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@article{10.1145/2435221.2435222,
author = {Talburt, John R.},
title = {SPECIAL ISSUE ON ENTITY RESOLUTION Overview: The Criticality of Entity Resolution in Data and Information Quality},
year = {2013},
issue_date = {March 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {2},
issn = {1936-1955},
url = {https://doi.org/10.1145/2435221.2435222},
doi = {10.1145/2435221.2435222},
journal = {J. Data and Information Quality},
month = {mar},
articleno = {6},
numpages = {2}
}

@article{10.1145/3335150,
author = {Hastings, Justine S. and Howison, Mark and Lawless, Ted and Ucles, John and White, Preston},
title = {Unlocking Data to Improve Public Policy},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {62},
number = {10},
issn = {0001-0782},
url = {https://doi.org/10.1145/3335150},
doi = {10.1145/3335150},
abstract = {When properly secured, anonymized, and optimized for research, administrative data can be put to work to help government programs better serve those in need.},
journal = {Commun. ACM},
month = {sep},
pages = {48–53},
numpages = {6}
}

@inproceedings{10.1145/3132300.3132305,
author = {Yatim, Ir. Fazilah Mat and Majid, Zulkepli and Amerudin, Shahabuddin},
title = {Locating Success Within A Geographic Information System},
year = {2017},
isbn = {9781450352895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132300.3132305},
doi = {10.1145/3132300.3132305},
abstract = {Tenaga Nasional Berhad (TNB) being one of the largest utilities in the Southeast Asia has embarked on enriching their GIS solutions suite for its business operations. A distribution station was chosen as a pilot project to run the business processes using GIS. The successful implementation is to be measured through its impact on the station day-today operations. Key success factors (KSF) were defined and will be measured with reference to component of GIS. The outcome of the measurement will guide the implementation of GIS nation-wide in TNB Distribution, Malaysia. This paper is aimed at providing insights for utilities who are keen in identifying those success factors and methodology of measuring the success of the GIS implementation.},
booktitle = {Proceedings of the International Conference on Imaging, Signal Processing and Communication},
pages = {138–142},
numpages = {5},
keywords = {GIS-Geographic Information System, TNB-Tenaga Nasional Berhad, KSF-Key Success Factors},
location = {Penang, Malaysia},
series = {ICISPC 2017}
}

@inproceedings{10.1145/3080546.3080550,
author = {Frey, Remo Manuel and Hardjono, Thomas and Smith, Christian and Erhardt, Keeley and Pentland, Alex 'Sandy'},
title = {Secure Sharing of Geospatial Wildlife Data},
year = {2017},
isbn = {9781450350471},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3080546.3080550},
doi = {10.1145/3080546.3080550},
abstract = {Modern tracking technologies enables new ways for data mining in the wild. It allows wildlife monitoring centers to permanently collect geospatial data in a non-intrusive manner in real-time and at low cost. Unfortunately, wildlife data is exposed to crime and there is already a first reported case of 'cyber-poaching'. Based on stolen geospatial data, poachers can easily track and kill animals. As a result, cautious monitoring centers limited data access for research and public use. This means that the data cannot fully exploit its potential. We propose a novel solution to overcome the security problem. It allows monitoring centers to securely answer questions from the research community and to provide aggregated data to the public while the raw data is protected against unauthorized third parties. This data service can also be monetized. Several new applications are conceivable, such as a mobile app for preventing conflicts between human and wildlife or for engaging people in wildlife donation. Besides presenting the solution and potential use cases, the intention of present article is to start a discussion about the need for data protection and privacy in the animal world.},
booktitle = {Proceedings of the Fourth International ACM Workshop on Managing and Mining Enriched Geo-Spatial Data},
articleno = {5},
numpages = {6},
keywords = {species protection, security, blockchain, wildlife, GPS, crime, geospatial, animal, hunting, cyber-poaching, privacy, data sharing},
location = {Chicago, Illinois},
series = {GeoRich '17}
}

@article{10.1145/3377391.3377398,
author = {Winslett, Marianne and Braganholo, Vanessa},
title = {Michael Franklin Speaks Out on Data Science},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {3},
issn = {0163-5808},
url = {https://doi.org/10.1145/3377391.3377398},
doi = {10.1145/3377391.3377398},
abstract = {Welcome to ACM SIGMOD Record series of interviews with distinguished members of the database community. I'm Marianne Winslett, and today we're at the 2017 SIGMOD and PODS conference in Chicago. I have here with me Mike Franklin, who is the chair of the Computer Science department at the University of Chicago. Before that, for many years, Mike was a professor at Berkeley where he also served as a chair of the Computer Science division. Mike was a co-founder and director of the Algorithms, Machines, and People Lab, better known as the AMPLab. He is an ACM fellow, a two-time winner of the SIGMOD Ten Year Test of Time Award, and a founder of the successful startup, Truviso. Mike's Ph.D. is from the University of Wisconsin Madison. So, Mike, welcome!},
journal = {SIGMOD Rec.},
month = {dec},
pages = {29–35},
numpages = {7}
}

@inproceedings{10.1145/3027385.3027414,
author = {Hoel, Tore and Griffiths, Dai and Chen, Weiqin},
title = {The Influence of Data Protection and Privacy Frameworks on the Design of Learning Analytics Systems},
year = {2017},
isbn = {9781450348706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3027385.3027414},
doi = {10.1145/3027385.3027414},
abstract = {Learning analytics open up a complex landscape of privacy and policy issues, which, in turn, influence how learning analytics systems and practices are designed. Research and development is governed by regulations for data storage and management, and by research ethics. Consequently, when moving solutions out the research labs implementers meet constraints defined in national laws and justified in privacy frameworks. This paper explores how the OECD, APEC and EU privacy frameworks seek to regulate data privacy, with significant implications for the discourse of learning, and ultimately, an impact on the design of tools, architectures and practices that now are on the drawing board. A detailed list of requirements for learning analytics systems is developed, based on the new legal requirements defined in the European General Data Protection Regulation, which from 2018 will be enforced as European law. The paper also gives an initial account of how the privacy discourse in Europe, Japan, South-Korea and China is developing and reflects upon the possible impact of the different privacy frameworks on the design of LA privacy solutions in these countries. This research contributes to knowledge of how concerns about privacy and data protection related to educational data can drive a discourse on new approaches to privacy engineering based on the principles of Privacy by Design. For the LAK community, this study represents the first attempt to conceptualise the issues of privacy and learning analytics in a cross-cultural context. The paper concludes with a plan to follow up this research on privacy policies and learning analytics systems development with a new international study.},
booktitle = {Proceedings of the Seventh International Learning Analytics &amp; Knowledge Conference},
pages = {243–252},
numpages = {10},
keywords = {data protection by design, learning analytics, data protection, learning analytics process requirements, learning analytics systems design, data protection by default, personal information, privacy by design, privacy frameworks},
location = {Vancouver, British Columbia, Canada},
series = {LAK '17}
}

@article{10.1145/2805789.2805795,
author = {Calyam, Prasad and Swany, Martin},
title = {Research Challenges in Future Multi-Domain Network Performance Measurement and Monitoring},
year = {2015},
issue_date = {July 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {3},
issn = {0146-4833},
url = {https://doi.org/10.1145/2805789.2805795},
doi = {10.1145/2805789.2805795},
abstract = {The perfSONAR-based Multi-domain Network Performance Measurement and Monitoring Workshop was held on February 20-21, 2014 in Arlington, VA. The goal of the workshop was to review the state of the perfSONAR effort and catalyze future directions by cross-fertilizing ideas, and distilling common themes among the diverse perfSONAR stakeholders that include: network operators and managers, end-users and network researchers. The timing and organization for the second workshop is significant because there are an increasing number of groups within NSF supported data-intensive computing and networking programs that are dealing with measurement, monitoring and troubleshooting of multi-domain issues. These groups are forming explicit measurement federations using perfSONAR to address a wide range of issues. In addition, the emergence and wide-adoption of new paradigms such as software-defined networking are taking shape to aid in traffic management needs of scientific communities and network operators. Consequently, there are new challenges that need to be addressed for extensible and programmable instrumentation, measurement data analysis, visualization and middleware security features in perfSONAR. This report summarizes the workshop efforts to bring together diverse groups for delivering targeted short/long talks, sharing latest advances, and identifying gaps that exist in the community for solving end-to-end performance problems in an effective, scalable fashion.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = {jul},
pages = {29–34},
numpages = {6},
keywords = {future multi-domain network monitoring, next-generation measurement infrastructures, research challenges}
}

@article{10.14778/3415478.3415565,
author = {Gupta, Suyash and Hellings, Jelle and Rahnama, Sajjad and Sadoghi, Mohammad},
title = {Building High Throughput Permissioned Blockchain Fabrics: Challenges and Opportunities},
year = {2020},
issue_date = {August 2020},
publisher = {VLDB Endowment},
volume = {13},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3415478.3415565},
doi = {10.14778/3415478.3415565},
abstract = {Since the introduction of Bitcoin---the first widespread application driven by blockchains---the interest in the design of blockchain-based applications has increased tremendously. At the core of these applications are consensus protocols that securely replicate client requests among all replicas, even if some replicas are Byzantine faulty. Unfortunately, these consensus protocols typically have low throughput, and this lack of performance is often cited as the reason for the slow wider adoption of blockchain technology. Consequently, many works focus on designing more efficient consensus protocols to increase throughput of consensus.We believe that this focus on consensus protocols only explains part of the story. To investigate this belief, we raise a simple question: Can a well-crafted system using a classical consensus protocol outperform systems using modern protocols? In this tutorial, we answer this question by diving deep into the design of blockchain systems. Further, we take an in-depth look at the theory behind consensus, which can help users select the protocol that best-fits their requirements. Finally, we share our vision of high-throughput blockchain systems that operate at large scales.},
journal = {Proc. VLDB Endow.},
month = {aug},
pages = {3441–3444},
numpages = {4}
}

@inproceedings{10.1145/3371238.3371269,
author = {Pan, Zhiwen and Zhao, Shuangye and Pacheco, Jesus and Zhang, Yuxin and Song, Xiaofan and Chen, Yiqiang and Dai, Lianjun and Zhang, Jun},
title = {Comprehensive Data Management and Analytics for General Society Survey Dataset},
year = {2019},
isbn = {9781450376402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3371238.3371269},
doi = {10.1145/3371238.3371269},
abstract = {The General Society Survey(GSS) is a kind of government-funded survey which aims at examining the Socio-economic status, quality of life, and structure of contemporary society. GSS dataset is regarded as one of the authoritative source for the government and organization practitioners to make data-driven policies. The previous analytic approaches for GSS dataset are designed by combining expert knowledges and simple statistics. In this paper, we proposed a comprehensive data management and data mining approach for GSS datasets. The approach is designed to be operated in a two-phase manner: a data management phase which can improve the quality of GSS data by performing attribute preprocessing and filter-based attribute selection; a data mining phase which can extract hidden knowledges from the dataset by performing data mining analysis including prediction analysis, classification analysis, association analysis and clustering analysis. By leveraging the power of data mining techniques, our proposed approach can explore knowledges in a fine-grained manner with minimum human interference. Experiments on Chinese General Social Survey dataset are conducted at the end to evaluate the performance of our approach.},
booktitle = {Proceedings of the 4th International Conference on Crowd Science and Engineering},
pages = {195–203},
numpages = {9},
keywords = {Society survey, Data management, Data mining, Decision support systems, Knowledge discovery},
location = {Jinan, China},
series = {ICCSE'19}
}

@inproceedings{10.1145/3396956.3396975,
author = {van Donge, W. and Bharosa, N. and Janssen, M. F. W. H. A.},
title = {Future Government Data Strategies: Data-Driven Enterprise or Data Steward? Exploring Definitions and Challenges for the Government as Data Enterprise},
year = {2020},
isbn = {9781450387910},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3396956.3396975},
doi = {10.1145/3396956.3396975},
abstract = {Comparable to the concept of a data(-driven) enterprise, the concept of a ‘government as data (-driven) enterprise’ is gaining popularity as a data strategy. However, what it implies is unclear. The objective of this paper is to clarify the concept of the government as data (-driven) enterprise, and identify the challenges and drivers that shape future data strategies. Drawing on literature review and expert interviews, this paper provides a rich understanding of the challenges for developing sound future government data strategies. Our analysis shows that two contrary data strategies dominate the debate. On the one hand is the data-driven enterprise strategy that focusses on collecting and using data to improve or enrich government processes and services (internal orientation). On the other hand, respondents point to the urgent need for governments to take on data stewardship, so other parties can use data to develop value for society (external orientation). Since these data strategies are not mutually exclusive, some government agencies will attempt to combine them, which is very difficult to pull off. Nonetheless, both strategies demand a more data minded culture. Moreover, the successful implementation of either strategy requires mature data governance – something most organisations still need to master. This research contributes by providing more depth to these strategies. The main challenge for policy makers is to decide on which strategy best fits their agency's roles and responsibilities and develop a shared roadmap with the external actors while at the same time mature on data governance.},
booktitle = {The 21st Annual International Conference on Digital Government Research},
pages = {196–204},
numpages = {9},
keywords = {e-government, Data-driven government, data governance, data enterprise, data stewardship},
location = {Seoul, Republic of Korea},
series = {dg.o '20}
}

@article{10.14778/3415478.3415504,
author = {Wang, Chen and Huang, Xiangdong and Qiao, Jialin and Jiang, Tian and Rui, Lei and Zhang, Jinrui and Kang, Rong and Feinauer, Julian and McGrail, Kevin A. and Wang, Peng and Luo, Diaohan and Yuan, Jun and Wang, Jianmin and Sun, Jiaguang},
title = {Apache IoTDB: Time-Series Database for Internet of Things},
year = {2020},
issue_date = {August 2020},
publisher = {VLDB Endowment},
volume = {13},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3415478.3415504},
doi = {10.14778/3415478.3415504},
abstract = {The amount of time-series data that is generated has exploded due to the growing popularity of Internet of Things (IoT) devices and applications. These applications require efficient management of the time-series data on both the edge and cloud side that support high throughput ingestion, low latency query and advanced time series analysis. In this demonstration, we present Apache IoTDB managing time-series data to enable new classes of IoT applications. IoTDB has both edge and cloud versions, provides an optimized columnar file format for efficient time-series data storage, and time-series database with high ingestion rate, low latency queries and data analysis support. It is specially optimized for time-series oriented operations like aggregations query, down-sampling and sub-sequence similarity search. An edge-to-cloud time-series data management application is chosen to demonstrate how IoTDB handles time-series data in real-time and supports advanced analytics by integrating with Hadoop and Spark. An end-to-end IoT data management solution is shown by integrating IoTDB with PLC4x, Calcite, and Grafana.},
journal = {Proc. VLDB Endow.},
month = {aug},
pages = {2901–2904},
numpages = {4}
}

@inproceedings{10.1145/3292500.3332296,
author = {Dong, Xin Luna and Rekatsinas, Theodoros},
title = {Data Integration and Machine Learning: A Natural Synergy},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3332296},
doi = {10.1145/3292500.3332296},
abstract = {As data volume and variety have increased, so have the ties between machine learning and data integration become stronger. For machine learning to be effective, one must utilize data from the greatest possible variety of sources; and this is why data integration plays a key role. At the same time machine learning is driving automation in data integration, resulting in overall reduction of integration costs and improved accuracy. This tutorial focuses on three aspects of the synergistic relationship between data integration and machine learning: (1) we survey how state-of-the-art data integration solutions rely on machine learning-based approaches for accurate results and effective human-in-the-loop pipelines, (2) we review how end-to-end machine learning applications rely on data integration to identify accurate, clean, and relevant data for their analytics exercises, and (3) we discuss open research challenges and opportunities that span across data integration and machine learning.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {3193–3194},
numpages = {2},
keywords = {schema mapping, data integration, entity linkage, data cleaning, data fusion},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@inproceedings{10.1145/3445969.3450427,
author = {Empl, Philip and Pernul, G\"{u}nther},
title = {A Flexible Security Analytics Service for the Industrial IoT},
year = {2021},
isbn = {9781450383196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3445969.3450427},
doi = {10.1145/3445969.3450427},
abstract = {In Cloud Computing, the cloud serves as a central data hub for the Industrial Internet of Things' (IIoT) data and is deployed in diverse application fields, e.g., Smart Grid or Smart Manufacturing. Therefore, the aggregated and contextualized data is bundled in a central data hub, bringing tremendous cybersecurity advantages. Given the threat landscape in IIoT systems, especially SMEs (small and medium-sized enterprises) need to be prepared regarding their cybersecurity, react quickly, and strengthen their overall cybersecurity. For instance, with the application of machine learning algorithms, security-related data can be analyzed predictively in order to be able to ward off a potential attack at an early stage. Since modern reference architectures for IIoT systems, such as RAMI 4.0 or IIRA, consider cybersecurity approaches on a high level and SMEs lack financial funds and knowledge, this paper conceptualizes a security analytics service used as a security add-on to these reference architectures. Thus, this paper conceptualizes a flexible security analytics service that implements security capabilities with flexible analytical techniques that fit specific SMEs' needs. The security analytics service is also evaluated with a real-world use case.},
booktitle = {Proceedings of the 2021 ACM Workshop on Secure and Trustworthy Cyber-Physical Systems},
pages = {23–32},
numpages = {10},
keywords = {industrial IoT, security as a service, security analytics},
location = {Virtual Event, USA},
series = {SAT-CPS '21}
}

@inproceedings{10.1145/2883851.2883893,
author = {Drachsler, Hendrik and Greller, Wolfgang},
title = {Privacy and Analytics: It's a DELICATE Issue a Checklist for Trusted Learning Analytics},
year = {2016},
isbn = {9781450341905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2883851.2883893},
doi = {10.1145/2883851.2883893},
abstract = {The widespread adoption of Learning Analytics (LA) and Educational Data Mining (EDM) has somewhat stagnated recently, and in some prominent cases even been reversed following concerns by governments, stakeholders and civil rights groups about privacy and ethics applied to the handling of personal data. In this ongoing discussion, fears and realities are often indistinguishably mixed up, leading to an atmosphere of uncertainty among potential beneficiaries of Learning Analytics, as well as hesitations among institutional managers who aim to innovate their institution's learning support by implementing data and analytics with a view on improving student success. In this paper, we try to get to the heart of the matter, by analysing the most common views and the propositions made by the LA community to solve them. We conclude the paper with an eight-point checklist named DELICATE that can be applied by researchers, policy makers and institutional managers to facilitate a trusted implementation of Learning Analytics.},
booktitle = {Proceedings of the Sixth International Conference on Learning Analytics &amp; Knowledge},
pages = {89–98},
numpages = {10},
keywords = {learning analytics, privacy, legal aspects, data management, ethics, educational data mining, implementation, trust},
location = {Edinburgh, United Kingdom},
series = {LAK '16}
}

@article{10.1145/3340286,
author = {Wong, Ka-Chun and Zhang, Jiao and Yan, Shankai and Li, Xiangtao and Lin, Qiuzhen and Kwong, Sam and Liang, Cheng},
title = {DNA Sequencing Technologies: Sequencing Data Protocols and Bioinformatics Tools},
year = {2019},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3340286},
doi = {10.1145/3340286},
abstract = {The recent advances in DNA sequencing technology, from first-generation sequencing (FGS) to third-generation sequencing (TGS), have constantly transformed the genome research landscape. Its data throughput is unprecedented and severalfold as compared with past technologies. DNA sequencing technologies generate sequencing data that are big, sparse, and heterogeneous. This results in the rapid development of various data protocols and bioinformatics tools for handling sequencing data.In this review, a historical snapshot of DNA sequencing is taken with an emphasis on data manipulation and tools. The technological history of DNA sequencing is described and reviewed in thorough detail. To manipulate the sequencing data generated, different data protocols are introduced and reviewed. In particular, data compression methods are highlighted and discussed to provide readers a practical perspective in the real-world setting. A large variety of bioinformatics tools are also reviewed to help readers extract the most from their sequencing data in different aspects, such as sequencing quality control, genomic visualization, single-nucleotide variant calling, INDEL calling, structural variation calling, and integrative analysis. Toward the end of the article, we critically discuss the existing DNA sequencing technologies for their pitfalls and potential solutions.},
journal = {ACM Comput. Surv.},
month = {sep},
articleno = {98},
numpages = {30},
keywords = {third-generation sequencing (TGS), history, tools, software, DNA sequencing, bioinformatics, computational biology, data protocols, technology}
}

@inproceedings{10.1145/3410886.3410913,
author = {Kritzinger, A.K. and Calitz, A.P. and Westraadt, L.},
title = {Data Wrangling for South African Smart City Crime Data},
year = {2020},
isbn = {9781450388474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410886.3410913},
doi = {10.1145/3410886.3410913},
abstract = {South Africa (S.A.) is currently facing economic and social challenges that could benefit from the implementation of international smart city guidelines. Crucial to transforming a city into a smart city is the collection and access to reliable data. One of the main problems experienced by S.A. cities is the limited access to data, resulting from a traditionally fragmented approach to data collection, sharing and use. Crime-related data is one of the most commonly collected datasets in smart cities. In S.A., crime data is predominantly collected by the S.A. Police Services (SAPS) and security companies. While the latter are not readily available for public use, SAPS crime data is consolidated and disseminated at the national level. Initial data exploration, however, shows that temporal, spatial and structural inconsistencies in the data limits the usefulness of available crime data. In this study, the inconsistencies in SAPS crime data are summarised, and standard data wrangling techniques are implemented and evaluated to clean the data. The study proposes a data wrangling model for S.A. crime data. Furthermore, this study will further developments that could benefit S.A. cities in general as they transform into smart cities.},
booktitle = {Conference of the South African Institute of Computer Scientists and Information Technologists 2020},
pages = {198–209},
numpages = {12},
keywords = {Open Data, Data Cleaning, Data Wrangling, Smart City Data},
location = {Cape Town, South Africa},
series = {SAICSIT '20}
}

@inproceedings{10.1145/3428502.3428576,
author = {Hanbal, Rajesh Dinesh and Prakash, Amit and Srinivasan, Janaki},
title = {Who Drives Data in Data-Driven Governance? The Politics of Data Production in India's Livelihood Program},
year = {2020},
isbn = {9781450376747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3428502.3428576},
doi = {10.1145/3428502.3428576},
abstract = {The increased digitisation of government information systems, as well as emerging data analytics and visualization techniques, have led lately to a surge in interest in the role of data in governance and development. The latest buzzwords in governance now include data-driven governance, data-for-development, evidence-based policy-making, and open government data. However, not much attention has been paid to understand the process of the production of data in government information systems. Our findings are based on six months of an ethnographic study of India's livelihood program- Mahatma Gandhi National Rural Employment Guarantee Act (MGNREGA) in a rural district of Karnataka. We argue that the practice of data production is carefully managed and controlled by local power elites providing an illusion of transparency in a digital information system. Understanding and recognizing the political nature of data production can help in better evaluation of development interventions, policy-making as well as in the design of more just information systems.},
booktitle = {Proceedings of the 13th International Conference on Theory and Practice of Electronic Governance},
pages = {485–493},
numpages = {9},
keywords = {data justice, Data production, Open government data},
location = {Athens, Greece},
series = {ICEGOV 2020}
}

