- Abstract: "In the era of big data, the scientific and social demand for quality\
    \ data is aggressive and urgent. This paper sheds light on the expanded role of\
    \ metrology of verifying validated procedures of data production and developing\
    \ adequate uncertainty evaluation methods to ensure the trustworthiness of data\
    \ and information. In this regard, I explore the mechanism of the national standard\
    \ reference data (SRD) program of Korea, which connects various scientific and\
    \ social sectors to metrology by applying useful metrological concepts and methods\
    \ to produce reliable data and convert such data into national standards. In particular,\
    \ the changing interpretation of metrological key concepts, such as \xE2\u20AC\
    \u0153measurement,\xE2\u20AC\x9D \xE2\u20AC\u0153traceability,\xE2\u20AC\x9D and\
    \ \xE2\u20AC\u0153uncertainty,\xE2\u20AC\x9D will be explored and reconsidered\
    \ from the perspective of data quality assurance. As a result, I suggest the concept\
    \ of \xE2\u20AC\u0153data traceability\xE2\u20AC\x9D with \xE2\u20AC\u0153the\
    \ matrix of data quality evaluation\xE2\u20AC\x9D according to the elements of\
    \ a data production system and related evaluation criteria. To conclude, I suggest\
    \ social and policy implications for the new role of metrology and standards for\
    \ producing and disseminating reliable knowledge sources from big data."
  Author: Lee, Doyoung
  Book_Title_Journal: IEEE Access
  DOI: 10.1109/ACCESS.2019.2904286
  JCS_FACTOR: 3.367
  Keywords: Standards;Uncertainty;Big Data;Metrology;Reliability;Measurement uncertainty;Biomedical
    measurement;Big data;data quality;data traceability;metrology;standard reference
    data;uncertainty
  SCI_FACTOR: 0.587
  Title: 'Big Data Quality Assurance Through Data Traceability: A Case Study of the
    National Standard Reference Data Program of Korea'
  Title_JCS: IEEE Access
  Title_SCI: IEEE Access
  Type_Publication: article
  Year: 2019
- Abstract: In this era of big data, as relational databases are inefficient, NoSQL
    databases are a workable solution for data storage. In this context, one of the
    key issues is the veracity and therefore the data quality. Indeed, as with classic
    data, geospatial big data are generally fuzzy even though they are stored as crisp
    data (perfect data). Hence, if data are geospatial and fuzzy, additional complexities
    appear because of the complex syntax and semantic features of such data. The NoSQL
    databases do not offer strict data consistency. Therefore, new challenges are
    needed to be overcome to develop efficient methods that simultaneously ensure
    the performance and the consistency in storing fuzzy geospatial big data. This
    paper presents a new methodology that tackles the storage issues and validates
    the fuzzy spatial entities' consistency in a document-based NoSQL system. Consequently,
    first, to better express the structure of fuzzy geospatial data in such a system,
    we present a logical model called Fuzzy GeoJSON schema. Second, for consistent
    storage, we implement a schema-driven pipeline based on the Fuzzy GeoJSON schema
    and semantic constraints.
  Author: Khalfi, Besma and de Runz, Cyril and Faiz, Sami and Akdag, Herman
  Book_Title_Journal: IEEE Transactions on Big Data
  DOI: 10.1109/TBDATA.2017.2725904
  JCS_FACTOR: 3.344
  Keywords: Fuzzy sets;Geospatial analysis;Big Data;Data models;NoSQL databases;Spatial
    databases;Fuzzy set theory;Spatial databases;data storage representations;schema
    and subschema;fuzzy set;imprecision;consistency;big data;NoSQL systems;JSON
  SCI_FACTOR: 0.959
  Title: A New Methodology for Storing Consistent Fuzzy Geospatial Data in Big Data
    Environment
  Title_JCS: IEEE Transactions on Big Data
  Title_SCI: IEEE Transactions on Big Data
  Type_Publication: article
  Year: 2021
- Abstract: With the rapid growth in the use of various smart digital sensors, the
    Internet of Things (IoT) is a swiftly growing technology, which has contributed
    significantly to Industry 4.0 and the promotion of IoT-based smart factories,
    which gives rise to the new challenges of big data analytics and the implementation
    of machine learning techniques. This article proposes a practical framework that
    combines IoT techniques, a data lake, data analysis, and cloud computing for manufacturing
    equipment health-state monitoring and diagnostics in smart manufacturing. It addresses
    all the required aspects in the realization of such a system and allows the seamless
    interchange of data and functionality. Due to the specific characteristics of
    IoT sensor data (low quality, redundant multisources, partial labeling), we not
    only provide a promising framework but also give detailed insights and pay considerable
    attention to data quality issues. In the proposed framework, an ingestion procedure
    is designed to manage data collection, data security, data transformation and
    data storage issues. To improve the quality of IoT big data, a high-noise feature
    filter is proposed for automated preliminary sensor selection to suppress noisy
    features, followed by a noisy data cleaning module to provide good quality data
    for unbiased diagnosis modeling. The proposed framework can achieve seamless integration
    between IoT big data ingestion from the physical factory and machine learning-based
    data analytics in the virtual systems. It is built on top of the Apache Spark
    processing engine, being capable of working in both big data and real-time environments.
    One case study has been conducted based on a four-stage syngas compressor from
    real industries, which won the Best Industry Application of IoT at the BigInsights
    Data &#x0026; AI Innovation Awards. The experimental results demonstrate the effectiveness
    of both the proposed IoT-architecture and techniques to address the data quality
    issues.
  Author: Yu, Wenjin and Liu, Yuehua and Dillon, Tharam and Rahayu, Wenny and Mostafa,
    Fahed
  Book_Title_Journal: IEEE Internet of Things Journal
  DOI: 10.1109/JIOT.2021.3096637
  JCS_FACTOR: 9.471
  Keywords: Big Data;Internet of Things;Intelligent sensors;Data analysis;Cloud computing;Smart
    manufacturing;Sensor phenomena and characterization;Big data;health state monitoring;Internet
    of Things (IoT);noisy data cleaning;real-time systems;sensor selection
  SCI_FACTOR: 2.075
  Title: An Integrated Framework for Health State Monitoring in a Smart Factory Employing
    IoT and Big Data Techniques
  Title_JCS: IEEE Internet of Things Journal
  Title_SCI: IEEE Internet of Things Journal
  Type_Publication: article
  Year: 2022
- Abstract: Daniel E. O'Leary examines the notion of the Big Data Lake and contrasts
    it with decision support-based data warehouses. In addition, some of the risks
    of the emerging Lake concept that ultimately require data governance are analyzed.
    O'Leary investigates using different AI and crowdsourcing (human intelligence)
    applications in that lake in order to integrate disparate data sources, facilitate
    master data management and analyze data quality. Although data governance often
    is not seen as a technology issue, it is seen as a critical component of making
    the Big Data Lake "work".
  Author: O'Leary, Daniel E.
  Book_Title_Journal: IEEE Intelligent Systems
  DOI: 10.1109/MIS.2014.82
  JCS_FACTOR: 3.405
  Keywords: Crowdsourcing;Artificial intelligence;Big data;Data warehouses;Decision
    support systems;Databases;Business;Big Data Lake;data warehouses;artificial intelligence;crowdsourcing;data
    governance;master data management;intelligent systems
  SCI_FACTOR: 0.806
  Title: Embedding AI and Crowdsourcing in the Big Data Lake
  Title_JCS: IEEE INTELLIGENT SYSTEMS
  Title_SCI: IEEE Intelligent Systems
  Type_Publication: article
  Year: 2014
- Abstract: 'Within an organisation, the quality in big data is a cornerstone to operational,
    transactional processes and to the reliability of business analytics for decision
    making. In fact, as organizations are harnessing multi-sources data to rise the
    benefits of their business, the quality of data becomes important and crucial.
    This paper presents a new approach to query big data sources using Resource Description
    Framework (RDF) representation to ensure data quality by harvesting more relevant
    and complete query results. Our approach handles two important types of heterogeneity
    over multiple data sources: semantic heterogeneity and URI-based entity identification.
    It proposes (1) a semantic entity resolution method based on inference mechanism
    using rules to manage the misunderstanding of data, in real world entities (2)
    Data Quality enhancement using MapReduce-based query rewriting approach includes
    the entity resolution results to infer and adds implicit data into query results
    (3) a parallel combination of MapReduce jobs of saturation and query rewriting
    inferences to handle transitive and cyclic rules for a richer rules'' expression
    language (4) experiments to assess the efficiency of the proposed approach over
    real big RDF data originating from insurance and synthetic data sets.'
  Author: Benbernou, Salima and Huang, Xin and Ouziri, Mourad
  Book_Title_Journal: IEEE Transactions on Big Data
  DOI: 10.1109/TBDATA.2017.2710346
  JCS_FACTOR: 3.344
  Keywords: Big Data;Resource description framework;Semantics;Joining processes;Erbium;Organizations;Data
    quality;big data fusion;inferences;entity resolution;query rewriting
  SCI_FACTOR: 0.959
  Title: Semantic-Based and Entity-Resolution Fusion to Enhance Quality of Big RDF
    Data
  Title_JCS: IEEE Transactions on Big Data
  Title_SCI: IEEE Transactions on Big Data
  Type_Publication: article
  Year: 2021
- Abstract: "A nonnegative latent factorization of tensors (NLFT) model precisely\
    \ represents the temporal patterns hidden in multichannel data emerging from various\
    \ applications. It often adopts a single latent factor-dependent, nonnegative\
    \ and multiplicative update on tensor (SLF-NMUT) algorithm. However, learning\
    \ depth in this algorithm is not adjustable, resulting in frequent training fluctuation\
    \ or poor model convergence caused by overshooting. To address this issue, this\
    \ study carefully investigates the connections between the performance of an NLFT\
    \ model and its learning depth via SLF-NMUT to present a joint learning-depth-adjusting\
    \ scheme for it. Based on this scheme, a Depth-adjusted Multiplicative Update\
    \ on tensor algorithm is innovatively proposed, thereby achieving a novel depth-adjusted\
    \ nonnegative latent-factorization-of-tensors (DNL) model. Empirical studies on\
    \ two industrial data sets demonstrate that compared with the state-of-the-art\
    \ NLFT models, a DNL model achieves significant accuracy gain when performing\
    \ missing data estimation on a high-dimensional and incomplete tensor with high\
    \ efficiency. Note to Practitioners\xE2\u20AC\u201DMultichannel data are often\
    \ encountered in various big-data-related applications. It is vital for a data\
    \ analyzer to correctly capture the temporal patterns hidden in them for efficient\
    \ knowledge acquisition and representation. This article focuses on analyzing\
    \ temporal QoS data, which is a representative kind of multichannel data. To correctly\
    \ extract their temporal patterns, an analyzer should correctly describe their\
    \ nonnegativity. Such a purpose can be achieved by building a nonnegative latent\
    \ factorization of tensors (NLFT) model relying on a single latent factor-dependent,\
    \ nonnegative and multiplicative update on tensor (SLF-NMUT) algorithm. But its\
    \ learning depth is not adjustable, making an NLFT model frequently suffer from\
    \ severe fluctuations in its training error or even fail to converge. To address\
    \ this issue, this study carefully investigates the learning rules for an NLFT\
    \ model\xE2\u20AC\u2122s decision parameters using an SLF-NMUT and proposes a\
    \ joint learning-depth-adjusting scheme. This scheme manipulates the multiplicative\
    \ terms in SLF-NMUT-based learning rules linearly and exponentially, thereby making\
    \ the learning depth adjustable. Based on it, this study builds a novel depth-adjusted\
    \ nonnegative latent-factorization-of-tensors (DNL) model. Compared with the existing\
    \ NLFT models, a DNL model better represents multichannel data. It meets industrial\
    \ needs well and can be used to achieve high performance in data analysis tasks\
    \ like temporal-aware missing data estimation"
  Author: Luo, Xin and Chen, Minzhi and Wu, Hao and Liu, Zhigang and Yuan, Huaqiang
    and Zhou, MengChu
  Book_Title_Journal: IEEE Transactions on Automation Science and Engineering
  DOI: 10.1109/TASE.2020.3040400
  JCS_FACTOR: 5.083
  Keywords: Tensors;Big Data;Quality of service;Computational efficiency;Machine learning;Web
    services;Algorithm;big data;dynamics;high-dimensional and incomplete (HDI) data;machine
    learning;missing data estimation;multichannel data;nonnegative latent factorization
    of tensors (NLFT);temporal pattern;quality of service (QoS);web service
  SCI_FACTOR: 1.314
  Title: Adjusting Learning Depth in Nonnegative Latent Factorization of Tensors for
    Accurately Modeling Temporal Patterns in Dynamic QoS Data
  Title_JCS: IEEE Transactions on Automation Science and Engineering
  Title_SCI: IEEE Transactions on Automation Science and Engineering
  Type_Publication: article
  Year: 2021
- Abstract: Smart urban transportation management can be considered as a multifaceted
    big data challenge. It strongly relies on the information collected into multiple,
    widespread, and heterogeneous data sources as well as on the ability to extract
    actionable insights from them. Besides data, full stack (from platform to services
    and applications) Information and Communications Technology (ICT) solutions need
    to be specifically adopted to address smart cities challenges. Smart urban transportation
    management is one of the key use cases addressed in the context of the EUBra-BIGSEA
    (Europe-Brazil Collaboration of Big Data Scientific Research through Cloud-Centric
    Applications) project. This paper specifically focuses on the City Administration
    Dashboard, a public transport analytics application that has been developed on
    top of the EUBra-BIGSEA platform and used by the Municipality stakeholders of
    Curitiba, Brazil, to tackle urban traffic data analysis and planning challenges.
    The solution proposed in this paper joins together a scalable big and fast data
    analytics platform, a flexible and dynamic cloud infrastructure, data quality
    and entity matching algorithms as well as security and privacy techniques. By
    exploiting an interoperable programming framework based on Python Application
    Programming Interface (API), it allows an easy, rapid and transparent development
    of smart cities applications.
  Author: "Fiore, Sandro and Elia, Donatello and Pires, Carlos Eduardo and Mestre,\
    \ Demetrio Gomes and Cappiello, Cinzia and Vitali, Monica and Andrade, Nazareno\
    \ and Braz, Tarciso and Lezzi, Daniele and Moraes, Regina and Basso, Tania and\
    \ Kozievitch, N\xC3\xA1dia P. and Fonseca, Keiko Ver\xC3\xB4nica Ono and Antunes,\
    \ Nuno and Vieira, Marco and Palazzo, Cosimo and Blanquer, Ignacio and Meira,\
    \ Wagner and Aloisio, Giovanni"
  Book_Title_Journal: IEEE Access
  DOI: 10.1109/ACCESS.2019.2936941
  JCS_FACTOR: 3.367
  Keywords: Urban areas;Big Data;Data analysis;Transportation;Cloud computing;Data
    mining;Europe;Big data;cloud computing;data analytics;data privacy;data quality;distributed
    environment;public transport management;smart city
  SCI_FACTOR: 0.587
  Title: An Integrated Big and Fast Data Analytics Platform for Smart Urban Transportation
    Management
  Title_JCS: IEEE Access
  Title_SCI: IEEE Access
  Type_Publication: article
  Year: 2019
- Abstract: Todays' Intelligent Transportation System (ITS) applications majorly depend
    on either limited neighbouring traffic data or crowd sourced stale traffic data.
    Enabling big traffic data analytics in ITS environments is a step closer towards
    utilizing significant traffic patterns and trends for making more precise and
    intelligent decisions particularly in connected autonomous vehicular environments.
    Towards this end, this paper presents a Traffic Aware Data Offloading (TRADING)
    approach for big traffic data centric ITS applications in connected autonomous
    vehicular environments. Specifically, TRADING balances offloading data traffic
    among gateways focusing on vehicular traffic and network status in the vicinity
    of gateways. In addition, TRADING mitigates the effect of gateway advertisement
    overhead to liberate the transmission channels for traffic big data transmission.
    The performance of TRADING is comparatively evaluated in a realistic simulation
    environment by considering gateway access overhead, load distribution among gateways,
    data offloading delay, and data offloading success ratio. The comparative performance
    evaluation results show some significant developments towards enabling big traffic
    data centric ITS.
  Author: Darwish, Tasneem S. J. and Bakar, Kamalrulnizam Abu and Kaiwartya, Omprakash
    and Lloret, Jaime
  Book_Title_Journal: IEEE Transactions on Vehicular Technology
  DOI: 10.1109/TVT.2020.2991372
  JCS_FACTOR: 5.978
  Keywords: Logic gates;Big Data;Quality of service;Delays;Real-time systems;Safety;Roads;Big
    data;gateway;intelligent transportation systems;VANET;vehicle-to-internet
  SCI_FACTOR: 1.365
  Title: 'TRADING: Traffic Aware Data Offloading for Big Data Enabled Intelligent
    Transportation System'
  Title_JCS: IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY
  Title_SCI: IEEE Transactions on Vehicular Technology
  Type_Publication: article
  Year: 2020
- Abstract: The presence of incorrect data leads to the decrease of condition-monitoring
    big data quality. As a result, unreliable or misleading results are probably obtained
    by analyzing these poor-quality data. In this paper, to improve the data quality,
    an incorrect data detection method based on an improved local outlier factor (LOF)
    is proposed for data cleaning. First, a sliding window technique is used to divide
    data into different segments. These segments are considered as different objects
    and their attributes consist of time-domain statistical features extracted from
    each segment, such as mean, maximum and peak-to-peak value. Second, a kernel-based
    LOF (KLOF) is calculated using these attributes to evaluate the degree of each
    segment being incorrect data. Third, according to these KLOF values and a threshold
    value, incorrect data are detected. Finally, a simulation of vibration data generated
    by a defective rolling element bearing and three real cases concerning a fixed-axle
    gearbox, a wind turbine, and a planetary gearbox are used to verify the effectiveness
    of the proposed method, respectively. The results demonstrate that the proposed
    method is able to detect both missing segments and abnormal segments, which are
    two typical incorrect data, effectively, and thus is helpful for big data cleaning
    of machinery condition monitoring.
  Author: Xu, Xuefang and Lei, Yaguo and Li, Zeda
  Book_Title_Journal: IEEE Transactions on Industrial Electronics
  DOI: 10.1109/TIE.2019.2903774
  JCS_FACTOR: 8.236
  Keywords: Big Data;Machinery;Feature extraction;Condition monitoring;Data integrity;Fault
    diagnosis;Cleaning;Condition-monitoring big data;data cleaning;data quality;incorrect
    data;local outlier factor (LOF)
  SCI_FACTOR: 2.393
  Title: An Incorrect Data Detection Method for Big Data Cleaning of Machinery Condition
    Monitoring
  Title_JCS: IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS
  Title_SCI: IEEE Transactions on Industrial Electronics
  Type_Publication: article
  Year: 2020
- Abstract: "Recently, its becomes easy to track down the data due to its availability\
    \ in a large number. Although for data management, processing, and obtainability,\
    \ cloud computing is considered a well-known approach for organizational development\
    \ on the internet. Despite many advantages, cloud computing has still numerous\
    \ security challenges that can affect the big-data usage on cloud computing. To\
    \ find the security issues/challenges that are faced by software vendors\xE2\u20AC\
    \u2122 organizations we conducted a systematic literature review (SLR) through\
    \ which we have find out 103 relevant research publications by developing a search\
    \ string that is inspired by the research questions. This relevant data was comprised\
    \ from different databases e.g. Google Scholar, IEEE Explore, ScienceDirect, ACM\
    \ Digital Library, and SpringerLink. Furthermore, for the detailed literature\
    \ review, we have accomplished all the steps in SLR, for example, development\
    \ of SLR protocol, Initials and final assortment of the relevant data, data extraction,\
    \ data quality assessment, and data synthesis. We identified fifteen (15) critical\
    \ security challenges which are: data secrecy, geographical data location, unauthorized\
    \ data access, lack of control, lack of data management, network-level issues,\
    \ data integrity, data recovery, lack of trust, data sharing, data availability,\
    \ asset issues, legal amenabilities, lack of quality, and lack of consistency.\
    \ Furthermore, sixty four (64) standard practices are identified for these critical\
    \ security challenges using the proposed SLR that could help vendor organizations\
    \ to overcome the security challenges for big data. The findings of our research\
    \ study demonstrate the resemblances and divergences in the identified security\
    \ challenges in different periods, continents, databases, and methods. The proposed\
    \ SLR will also support software vendor organizations for securing big data on\
    \ the cloud computing platforms. This paper has the following content: in Section\
    \ II, we have describe the Literature review; in Section III, research methodology\
    \ is specified; in Section IV, the findings of the SLR and the analysis of result\
    \ are discussed; in Section V, the limitations of this research are given; in\
    \ Section VI, we discussed our conclusions and future work."
  Author: Khan, Abudul Wahid and Khan, Maseeh Ullah and Khan, Javed Ali and Ahmad,
    Arshad and Khan, Khalil and Zamir, Muhammad and Kim, Wonjoon and Ijaz, Muhammad
    Fazal
  Book_Title_Journal: IEEE Access
  DOI: 10.1109/ACCESS.2021.3100287
  JCS_FACTOR: 3.367
  Keywords: Cloud computing;Security;Big Data;Software;Organizations;Social networking
    (online);STEM;Security challenges;big data;cloud computing;SLR;vendor;SPSS
  SCI_FACTOR: 0.587
  Title: 'Analyzing and Evaluating Critical Challenges and Practices for Software
    Vendor Organizations to Secure Big Data on Cloud Computing: An AHP-Based Systematic
    Approach'
  Title_JCS: IEEE Access
  Title_SCI: IEEE Access
  Type_Publication: article
  Year: 2021
- Abstract: 'The multimedia transmission represents a typical big data application
    in the fifth-generation (5G) wireless networks. However, supporting multimedia
    big data transmission over 5G wireless networks imposes many new and open challenges
    because multimedia big data services are both time-sensitive and bandwidth-intensive
    over time-varying wireless channels with constrained wireless resources. To overcome
    these difficulties, in this paper we propose the information-centric virtualization
    architectures for software-defined statistical delay-bounded quality of service
    (QoS) provisioning over 5G multimedia big data wireless networks. In particular,
    our proposed schemes integrate the three 5G-promising candidate techniques to
    guarantee the statistical delay-bounded QoS for multimedia big data transmissions:
    1) information-centric network (ICN), to derive the optimal in-network caching
    locations for multimedia big data; 2) network functions virtualization (NFV),
    to abstract the PHY-layer infrastructures into several virtualized networks to
    derive the optimal multimedia data contents delivery paths; and 3) software-defined
    networks (SDNs), to dynamically reconfigure wireless resources allocation architectures
    through the SDN-control plane. Under our proposed architectures, to jointly optimize
    the implementations of NFV and SDN techniques under ICN architectures, we develop
    the three virtual network selection and transmit-power allocation schemes to:
    1) maximize single user''s effective capacity; 2) jointly optimize the aggregate
    effective capacity and allocation fairness over all users; and 3) coordinate non-cooperative
    gaming among all users, respectively. By simulations and numerical analyses, we
    show that our proposed architectures and schemes significantly outperform the
    other existing schemes in supporting the statistical delay-bounded QoS provisioning
    over the 5G multimedia big data wireless networks.'
  Author: Zhang, Xi and Zhu, Qixuan
  Book_Title_Journal: IEEE Journal on Selected Areas in Communications
  DOI: 10.1109/JSAC.2019.2927088
  JCS_FACTOR: 9.144
  Keywords: Big Data;Quality of service;Wireless networks;5G mobile communication;Resource
    management;Wireless sensor networks;5G multimedia big data wireless networks;ICN;NFV;SDN;optimal
    transmit power;statistical delay-bounded QoS;effective capacity;relay selection
  SCI_FACTOR: 2.986
  Title: Information-Centric Virtualization for Software-Defined Statistical QoS Provisioning
    Over 5G Multimedia Big Data Wireless Networks
  Title_JCS: IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS
  Title_SCI: IEEE Journal on Selected Areas in Communications
  Type_Publication: article
  Year: 2019
- Abstract: Data in the real world is often dirty. Inconsistency is an important kind
    of dirty data; before repairing inconsistency, we need to detect them first. The
    time complexities of the current inconsistency detection algorithms are super-linear
    to the size of data and not suitable for the big data. For the inconsistency detection
    of big data, we develop an algorithm that detects inconsistency within the one-pass
    scan of the data according to both the functional dependency (FD) and the conditional
    functional dependency (CFD) in our previous work. In this paper, we propose inconsistency
    detection algorithms in terms of FD, CFD, and Denial Constraint (DC). DCs are
    more expressive than FDs and CFDs. Developing the algorithm to detect the violation
    of DCs increases the applicability of our inconsistency detection algorithms.
    We compare the performance of our algorithm with the performance of implementing
    SQL queries in MySQL and BigQuery. The experimental results indicate the high
    efficiency of our algorithms.
  Author: Zhang, Meifan and Wang, Hongzhi and Li, Jianzhong and Gao, Hong
  Book_Title_Journal: IEEE Access
  DOI: 10.1109/ACCESS.2019.2898707
  JCS_FACTOR: 3.367
  Keywords: Big Data;Data integrity;Detection algorithms;Databases;Time complexity;Hazards;Business;Inconsistency
    detection;big data;one-pass algorithm;data quality;denial constraint
  SCI_FACTOR: 0.587
  Title: One-Pass Inconsistency Detection Algorithms for Big Data
  Title_JCS: IEEE Access
  Title_SCI: IEEE Access
  Type_Publication: article
  Year: 2019
- Abstract: "In an era of super computing, data is increasing exponentially requiring\
    \ more proficiency from the available technologies of data storage, data processing,\
    \ and analysis. Such continuous massive growth of structured and unstructured\
    \ data is referred to as a \xE2\u20AC\u0153Big data\xE2\u20AC\x9D. The processing\
    \ and storage of big data through a conventional technique is not possible. Due\
    \ to improved proficiency of Big Data solution in handling data, such as NoSQL\
    \ caused the developers in the previous decade to start preferring big data databases,\
    \ such as Apache Cassandra, Oracle, and NoSQL. NoSQL is a modern database technology\
    \ that is designed to provide scalability to support voluminous data, leading\
    \ to the rise of NoSQL as the most viable database solution. These modern databases\
    \ aim to overcome the limitations of relational databases such as unlimited scalability,\
    \ high performance, data modeling, data distribution, and continuous availability.\
    \ These days, the larger enterprises need to shift NoSQL databases due to their\
    \ more flexible models. It is a great challenge for business organizations and\
    \ enterprises to transform their existing databases to NoSQL databases considering\
    \ heterogeneity and complexity in relational data. In addition, with the emergence\
    \ of big data, data cleansing has become a great challenge. In this paper, we\
    \ proposed an approach that has two modules: data transformation and data cleansing\
    \ module. The first phase is the transformation of a relational database to Oracle\
    \ NoSQL database through model transformation. The second phase provides data\
    \ cleansing ability to improve data quality and prepare it for big data analytics.\
    \ The experiments show the proposed approach successfully transforms the relational\
    \ database to a big data database and improve data quality."
  Author: Ramzan, Shabana and Bajwa, Imran Sarwar and Ramzan, Bushra and Anwar, Waheed
  Book_Title_Journal: IEEE Access
  DOI: 10.1109/ACCESS.2019.2916912
  JCS_FACTOR: 3.367
  Keywords: Big Data;NoSQL databases;Transforms;Scalability;Servers;Tools;Relational
    databases;NoSQL;big data;data cleansing
  SCI_FACTOR: 0.587
  Title: Intelligent Data Engineering for Migration to NoSQL Based Secure Environments
  Title_JCS: IEEE Access
  Title_SCI: IEEE Access
  Type_Publication: article
  Year: 2019
- Abstract: In this paper, a novel variational inference semisupervised Gaussian mixture
    model (VI-S2GMM) model is first proposed for semisupervised predictive modeling
    in multimode processes. Parameters of Gaussian components are identified more
    accurately with extra unlabeled samples, which improve the prediction performance
    of the regression model. Since all labeled and unlabeled data samples are involved
    in each iteration of parameter updating, intractable computing problems occur
    when facing high-dimension datasets. To tackle this problem, a scalable stochastic
    VI-S2GMM (SVI-S2GMM) is further proposed. Through taking advantage of a stochastic
    gradient optimization algorithm to maximize the evidence of lower bound, the VI-based
    algorithm becomes scalable. In the SVI-S2GMM, only one or a minibatch of samples
    is randomly selected to update parameters in each iteration, which is more efficient
    than the VI-S2GMM. Since the whole dataset is divided and transferred to iterations
    batch by batch, the scalable SVI-S2GMM algorithm can easily handle the big data
    modeling issue. In this way, a large number of unlabeled data can be useful in
    the modeling, which will further benefit the prediction performance. The SVI-S2GMM
    is then exploited for the prediction of a quality-related key performance index.
    Two examples demonstrate the feasibility and effectiveness of the proposed algorithms.
  Author: Yao, Le and Ge, Zhiqiang
  Book_Title_Journal: IEEE Transactions on Industrial Electronics
  DOI: 10.1109/TIE.2018.2856200
  JCS_FACTOR: 8.236
  Keywords: Data models;Big Data;Predictive models;Inference algorithms;Prediction
    algorithms;Semisupervised learning;Computational modeling;Big data;Gaussian mixture
    model (GMM);multimode process modeling;quality prediction;semisupervised modeling;stochastic
    variational inference (SVI)
  SCI_FACTOR: 2.393
  Title: Scalable Semisupervised GMM for Big Data Quality Prediction in Multimode
    Processes
  Title_JCS: IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS
  Title_SCI: IEEE Transactions on Industrial Electronics
  Type_Publication: article
  Year: 2019
- Abstract: Besides the conventional schema-oriented tasks, data dependencies are
    recently revisited for data quality applications, such as violation detection.
    To address the variety and veracity issues of big data, data dependencies have
    been extended as data quality rules to adapt to various data types, ranging from
    (1)categorical data with equality relationships to (2)heterogeneous data with
    similarity relationships, and (3)numerical data with order relationships. In this
    survey, we briefly review the recent proposals on data dependencies categorized
    into the aforesaid types of data. In addition to (a)the concepts of these data
    dependency notations, we investigate (b)the extension relationships between data
    dependencies, e.g., conditional functional dependencies (CFDs) extend the conventional
    functional dependencies (FDs). It forms a family tree of extensions, mostly rooted
    in FDs, helping us understand the expressive power of various data dependencies.
    Moreover, we summarize (c)the discovery of dependencies from data, since data
    dependencies are often unlikely to be manually specified in a traditional way,
    given the huge volume and high variety of big data. We further outline (d)the
    applications of the extended data dependencies, in particular in data quality
    practice. It guides users to select proper data dependencies with sufficient expressive
    power and reasonable discovery cost. Finally, we conclude with several directions
    of future studies on the emerging data.
  Author: Song, Shaoxu and Gao, Fei and Huang, Ruihong and Wang, Chaokun
  Book_Title_Journal: IEEE Transactions on Knowledge and Data Engineering
  DOI: 10.1109/TKDE.2020.3046443
  JCS_FACTOR: 6.977
  Keywords: Big Data;Phase frequency detectors;Lakes;Picture archiving and communication
    systems;Databases;Task analysis;Proposals;Integrity constraints;data dependencies
  SCI_FACTOR: 1.36
  Title: 'Data Dependencies over Big Data: A Family Tree'
  Title_JCS: IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
  Title_SCI: IEEE Transactions on Knowledge and Data Engineering
  Type_Publication: article
  Year: 2020
- Abstract: Businesses and governments exploit big data without regard for issues
    of legality, data quality, disparate data meanings, and process quality. This
    often results in poor decisions, with individuals bearing the greatest risk. The
    threats harbored by big data extend far beyond the individual, however, and call
    for new legal structures, business processes, and concepts such as a Private Data
    Commons. The Web extra at http://youtu.be/TvXoQhrrGzg is a video in which author
    Marcus Wigan expands on his article "Big Data's Big Unintended Consequences" and
    discusses how businesses and governments exploit big data without regard for issues
    of legality, data quality, disparate data meanings, and process quality. This
    often results in poor decisions, with individuals bearing the greatest risk. The
    threats harbored by big data extend far beyond the individual, however, and call
    for new legal structures, business processes, and concepts such as a Private Data
    Commons.
  Author: Wigan, Marcus R. and Clarke, Roger
  Book_Title_Journal: Computer
  DOI: 10.1109/MC.2013.195
  JCS_FACTOR: 2.683
  Keywords: Information management;Data handling;Data storage systems;Government policies;Databases;Business;Legal
    aspects;Data privacy;policy;privacy;data;social impact;big data;private data commons
  SCI_FACTOR: 0.846
  Title: Big Data's Big Unintended Consequences
  Title_JCS: COMPUTER
  Title_SCI: Computer
  Type_Publication: article
  Year: 2013
- Abstract: In the era of data science and big data analytics, people analytics help
    organizations and their human resources (HR) managers to reduce attrition by changing
    the way of attracting and retaining talent. In this context, employee attrition
    presents a critical problem and a big risk for organizations as it affects not
    only their productivity but also their planning continuity. In this context, the
    salient contributions of this research are as follows. Firstly, we propose a people
    analytics approach to predict employee attrition that shifts from a big data to
    a deep data context by focusing on data quality instead of its quantity. In fact,
    this deep data-driven approach is based on a mixed method to construct a relevant
    employee attrition model in order to identify key employee features influencing
    his/her attrition. In this method, we started thinking `big' by collecting most
    of the common features from the literature (an exploratory research) then we tried
    thinking `deep' by filtering and selecting the most important features using survey
    and feature selection algorithms (a quantitative method). Secondly, this attrition
    prediction approach is based on machine, deep and ensemble learning models and
    is experimented on a large-sized and a medium-sized simulated human resources
    datasets and then a real small-sized dataset from a total of 450 responses. Our
    approach achieves higher accuracy (0.96, 0.98 and 0.99 respectively) for the three
    datasets when compared previous solutions. Finally, while rewards and payments
    are generally considered as the most important keys to retention, our findings
    indicate that `business travel', which is less common in the literature, is the
    leading motivator for employees and must be considered within HR policies to retention.
  Author: Yahia, Nesrine Ben and Hlel, Jihen and Colomo-Palacios, Ricardo
  Book_Title_Journal: IEEE Access
  DOI: 10.1109/ACCESS.2021.3074559
  JCS_FACTOR: 3.367
  Keywords: Big Data;Organizations;Radio frequency;Predictive models;Support vector
    machines;Data models;Analytical models;Deep people analytics;employee attrition;retention;prediction;interpretation;policies
    recommendation
  SCI_FACTOR: 0.587
  Title: From Big Data to Deep Data to Support People Analytics for Employee Attrition
    Prediction
  Title_JCS: IEEE Access
  Title_SCI: IEEE Access
  Type_Publication: article
  Year: 2021
- Abstract: Because of the increasing volume of autonomously collected data objects,
    duplicate detection is an important challenge in today's data management. To evaluate
    the efficiency of duplicate detection algorithms with respect to big data, large
    test data sets are required. Existing test data generation tools, however, are
    either not able to produce large test data sets or are domain-dependent which
    limits their usefulness to a few cases. In this paper, we describe a new framework
    that can be used to pollute a clean, homogeneous and large data set from an arbitrary
    domain with duplicates, errors and inhomogeneities. To prove its concept, we implemented
    a prototype which is built upon the cluster computing framework Apache Spark and
    evaluate its performance in several experiments.
  Author: Hildebrandt, Kai and Panse, Fabian and Wilcke, Niklas and Ritter, Norbert
  Book_Title_Journal: IEEE Transactions on Big Data
  DOI: 10.1109/TBDATA.2016.2637378
  JCS_FACTOR: 3.344
  Keywords: Big data;Pollution;Databases;Generators;Prototypes;Gold;Standards;Data
    quality;duplicate detection;data pollution;Apache Spark
  SCI_FACTOR: 0.959
  Title: Large-Scale Data Pollution with Apache Spark
  Title_JCS: IEEE Transactions on Big Data
  Title_SCI: IEEE Transactions on Big Data
  Type_Publication: article
  Year: 2020
- Abstract: All people in the world are entitled to enjoy a clean environment and
    a good quality of life. With big data and artificial intelligence technologies,
    it is possible to estimate personalized air pollution exposure and synchronize
    it with activity, health, quality of life and behavioural data, and provide real-time,
    personalized and interactive alert and advice to improve the health and well-being
    of individual citizens. In this paper, we propose an overarching framework outlining
    five major challenges to personalized air pollution monitoring and health management,
    and respective methodologies in an integrated interdisciplinary manner. First,
    urban air quality data is sparse, rendering it difficult to provide timely personalized
    alert and advice. Second, collected data, especially those involving human inputs
    such as health perception, are often missing and erroneous. Third, the data collected
    are heterogeneous, and highly complex, not easily comprehensible to facilitate
    individual and collective decision-making. Fourth, the causal relationships between
    personal air pollutants exposure (specifically, PM2.5 and PM1.0 and NO2) and personal
    health conditions, and health-related quality of life perception, of young asthmatics
    and young healthy citizens in Hong Kong (HK), are yet to be established. Fifth,
    whether personalized and smart information and advice provided can induce behavioural
    change and improve health and quality of life are yet to be determined. To overcome
    these challenges, our first novelty is to develop an AI and big data framework
    to estimate and forecast air quality in high temporal-spatial resolution and real-time.
    Our second novelty includes the deployment of mobile pollution sensor platforms
    to substantially improve the accuracy of estimated and forecasted air quality
    data, and the collection of activity, health condition and perception data. Our
    third novelty is the development of visualization tools and comprehensible indexes,
    by correlating personal exposure with four types of personal data, to provide
    timely, personalized pollution, health and travel alerts and advice. Our fourth
    novelty is determining causal relationship, if any, between personal pollutants,
    PM1.0 and PM2.5, NO2 exposure and personal health condition, and personal health
    perception, based on a clinical experiment of 150 young asthmatics and 150 young
    healthy citizens in HK. Our fifth novelty is an intervention study to determine
    if smart information, presented via our proposed visualized platform, will induce
    personal behavioural change. Our novel big data AI-driven approach, when integrated
    with other analytical approaches, provides an integrated interdisciplinary framework
    for personalized air pollution monitoring and health management, easily transferrable
    to and applicable in other domains and countries.
  Author: Victor O.K. Li and Jacqueline C.K. Lam and Yang Han and Kenyon Chow
  Book_Title_Journal: Environmental Science & Policy
  DOI: https://doi.org/10.1016/j.envsci.2021.06.011
  JCS_FACTOR: 5.581
  Keywords: Air Pollution Monitoring, Health Management, Artificial Intelligence,
    Big Data, PM, Personalization, Smart Behavioural Intervention, Health and Well-being
    Improvement
  SCI_FACTOR: 0.0
  Title: A Big Data and Artificial Intelligence Framework for Smart and Personalized
    Air Pollution Monitoring and Health Management in Hong Kong
  Title_JCS: ENVIRONMENTAL SCIENCE & POLICY
  Title_SCI: N/A
  Type_Publication: article
  Year: 2021
- Abstract: "Background\nThe need is growing to create medical big data based on the\
    \ electronic health records collected from different hospitals. Errors for sure\
    \ occur and how to correct them should be explored.\nMethods\nElectronic health\
    \ records of 9,197,817 patients and 53,081,148 visits, totaling about 500 million\
    \ records for 2006\xE2\u20AC\u201C2016, were transmitted from eight hospitals\
    \ into an integrated database. We randomly selected 10% of patients, accumulated\
    \ the primary keys for their tabulated data, and compared the key numbers in the\
    \ transmitted data with those of the raw data. Errors were identified based on\
    \ statistical testing and clinical reasoning.\nResults\nData were recorded in\
    \ 1573 tables. Among these, 58 (3.7%) had different key numbers, with the maximum\
    \ of 16.34/1000. Statistical differences (P\xC2\_<\xC2\_0.05) were found in 34\
    \ (58.6%), of which 15 were caused by changes in diagnostic codes, wrong accounts,\
    \ or modified orders. For the rest, the differences were related to accumulation\
    \ of hospital visits over time. In the remaining 24 tables (41.4%) without significant\
    \ differences, three were revised because of incorrect computer programming or\
    \ wrong accounts. For the rest, the programming was correct and absolute differences\
    \ were negligible. The applicability was confirmed using the data of 2,730,883\
    \ patients and 15,647,468 patient-visits transmitted during 2017\xE2\u20AC\u201C\
    2018, in which 10 (3.5%) tables were corrected.\nConclusion\nSignificant magnitude\
    \ of inconsistent data does exist during the transmission of big data from diverse\
    \ sources. Systematic validation is essential. Comparing the number of data tabulated\
    \ using the primary keys allow us to rapidly identify and correct these scattered\
    \ errors."
  Author: Yi-Chia Lee and Ying-Ting Chao and Pei-Ju Lin and Yen-Yun Yang and Yu-Cih
    Yang and Cheng-Chieh Chu and Yu-Chun Wang and Chin-Hao Chang and Shu-Lin Chuang
    and Wei-Chun Chen and Hsing-Jen Sun and Hsin-Cheng Tsou and Cheng-Fu Chou and
    Wei-Shiung Yang
  Book_Title_Journal: Journal of the Formosan Medical Association
  DOI: https://doi.org/10.1016/j.jfma.2021.12.024
  JCS_FACTOR: 3.282
  Keywords: Big data, Electronic health record, Evidence based healthcare management,
    Validation study
  SCI_FACTOR: 0.708
  Title: Quality assurance of integrative big data for medical research within a multihospital
    system
  Title_JCS: JOURNAL OF THE FORMOSAN MEDICAL ASSOCIATION
  Title_SCI: Journal of the Formosan Medical Association
  Type_Publication: article
  Year: 2022
- Abstract: "The lack of sufficient big data-based approaches impedes the development\
    \ of human resource management (HRM) research and practices. Although scholars\
    \ have realized the importance of applying a big data approach to HRM research,\
    \ clear guidance is lacking regarding how to integrate the two. Using a clustering\
    \ algorithm based on the big data research paradigm, we first conduct a bibliometric\
    \ review to quantitatively assess and scientifically map the evolution of the\
    \ current big data HRM literature. Based on this systematic review, we propose\
    \ a general theoretical framework described as \xE2\u20AC\u0153Inductive (Prediction\
    \ paradigm: Data mining/Theory building) vs. Deductive (Explanation paradigm:\
    \ Theory testing)\xE2\u20AC\x9D. In this framework, we discuss potential research\
    \ questions, their corresponding levels of analysis, relevant methods, data sources\
    \ and software. We then summarize the general procedures for conducting big data\
    \ research within HRM research. Finally, we propose a future agenda for applying\
    \ big data approaches to HRM research and identify five promising HRM research\
    \ topics at the micro, meso and macro levels along with three challenges and limitations\
    \ that HRM scholars may face in the era of big data."
  Author: Yucheng Zhang and Shan Xu and Long Zhang and Mengxi Yang
  Book_Title_Journal: Journal of Business Research
  DOI: https://doi.org/10.1016/j.jbusres.2021.04.019
  JCS_FACTOR: 7.55
  Keywords: Human resource management research, Big data, Integrative review, Inductive
    and deductive paradigms
  SCI_FACTOR: 2.049
  Title: 'Big data and human resource management research: An integrative review and
    new directions for future research'
  Title_JCS: JOURNAL OF BUSINESS RESEARCH
  Title_SCI: Journal of Business Research
  Type_Publication: article
  Year: 2021
- Abstract: 'This study aims to develop accounting standards, curriculums, and research
    to cope with the rapid development of big data. The study presents several potential
    convergence points between big data and different accounting techniques and theories.
    The study discusses how big data can overcome the data limitations of six accounting
    issues: financial reporting, performance measurement, audit evidence, risk management,
    corporate budgeting and activity-based techniques. It presents six exciting research
    questions for future research. Then, the study explains the potential convergence
    between big data and agency theory, stakeholders theory, and legitimacy theory.
    This theoretical study develops new convergence points between big data and accounting
    by reviewing the literature and proposing new ideas and research questions. The
    conclusion indicates a significant convergence between big data and accounting
    on the premise that data is the heart of accounting. Big data and advanced analytics
    have the potential to overcome the data limitations of accounting techniques that
    require estimations and predictions. A remarkable convergence is argued between
    big data and three accounting theories. Overall, the study presents helpful insights
    to members of the accounting and auditing community on the potential of big data.'
  Author: Awad Elsayed Awad Ibrahim and Ahmed A. Elamer and Amr Nazieh Ezat
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2021.121171
  JCS_FACTOR: 8.593
  Keywords: Big data, Analytics, Accounting, Data science, Business intelligence
  SCI_FACTOR: 2.226
  Title: 'The convergence of big data and accounting: innovative research opportunities'
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2021
- Abstract: The use of big data to help explain fluctuations in the broader economy
    and key business performance indicators is now so commonplace that in some instances
    it has even begun to rival more traditional measures. Big data sources can very
    often provide advantages when compared with these more traditional data sources,
    but with these advantages also come potential pitfalls. We lay out a checklist
    called SMALL that we have developed in order to help interested parties as they
    navigate the big data minefield. Based on a set of five questions, the SMALL checklist
    should help users of big data draw justifiable conclusions and avoid making mistakes
    in matters of interpretation. To demonstrate, we provide several case studies
    that demonstrate the subtle nuances of several of these new big data sets and
    show how the problems they face often closely relate to age-old concerns that
    more traditional data sources are also forced to tackle.
  Author: Scott A. Brave and R. Andrew Butters and Michael Fogarty
  Book_Title_Journal: Business Horizons
  DOI: https://doi.org/10.1016/j.bushor.2021.06.004
  JCS_FACTOR: 6.361
  Keywords: Big data, Data analysis, Economic forecasting, Selection bias, Reporting
    lags, High-frequency data, Real-time forecasts, Leading indicator
  SCI_FACTOR: 2.174
  Title: The perils of working with big data, and a SMALL checklist you can use to
    recognize them
  Title_JCS: BUSINESS HORIZONS
  Title_SCI: Business Horizons
  Type_Publication: article
  Year: 2021
- Abstract: "Objective\nThe National Inpatient Sample (NIS) (the largest all-payer\
    \ inpatient database in the United States) is an important instrument for big\
    \ data analysis of neurosurgical inquiries. However, earlier research has determined\
    \ that many NIS studies are limited by common methodological pitfalls. In this\
    \ study, we provide the first primer of NIS methodological procedures in the setting\
    \ of neurosurgical research and review all reported neurosurgical studies using\
    \ the NIS.\nMethods\nWe designed a protocol for neurosurgical big data research\
    \ using the NIS, based on our subject matter expertise, NIS documentation, and\
    \ input and verification from the Healthcare Cost and Utilization Project. We\
    \ subsequently used a comprehensive search strategy to identify all neurosurgical\
    \ studies using the NIS in the PubMed and MEDLINE, Embase, and Web of Science\
    \ databases from inception to August 2021. Studies underwent qualitative categorization\
    \ (years of NIS studied, neurosurgical subspecialty, age group, and thematic focus\
    \ of study objective) and analysis of longitudinal trends.\nResults\nWe identified\
    \ a canonical, 4-step protocol for NIS analysis: study population selection; defining\
    \ additional clinical variables; identification and coding of outcomes; and statistical\
    \ analysis. Methodological nuances discussed include identifying neurosurgery-specific\
    \ admissions, addressing missing data, calculating additional severity and hospital-specific\
    \ metrics, coding perioperative complications, and applying survey weights to\
    \ make nationwide estimates. Inherent database limitations and common pitfalls\
    \ of NIS studies discussed include lack of disease process\xE2\u20AC\u201Cspecific\
    \ variables and data after the index admission, inability to calculate certain\
    \ hospital-specific variables after 2011, performing state-level analyses, conflating\
    \ hospitalization charges and costs, and not following proper statistical methodology\
    \ for performing survey-weighted regression. In a systematic review, we identified\
    \ 647 neurosurgical studies using the NIS. Although almost 60% of studies were\
    \ reported after 2015, <10% of studies analyzed NIS data after 2015. The average\
    \ sample size of studies was 507,352 patients (standard deviation\xC2\_= 2,739,900).\
    \ Most studies analyzed cranial procedures (58.1%) and adults (68.1%). The most\
    \ prevalent topic areas analyzed were surgical outcome trends (35.7%) and health\
    \ policy and economics (17.8%), whereas patient disparities (9.4%) and surgeon\
    \ or hospital volume (6.6%) were the least studied.\nConclusions\nWe present a\
    \ standardized methodology to analyze the NIS, systematically review the state\
    \ of the NIS neurosurgical literature, suggest potential future directions for\
    \ neurosurgical big data inquiries, and outline recommendations to improve the\
    \ design of future neurosurgical data instruments."
  Author: Oliver Y. Tang and Alisa Pugacheva and Ankush I. Bajaj and Krissia M. {Rivera
    Perla} and Robert J. Weil and Steven A. Toms
  Book_Title_Journal: World Neurosurgery
  DOI: https://doi.org/10.1016/j.wneu.2022.02.113
  JCS_FACTOR: 2.104
  Keywords: Big data, Disparities, Health care costs, Health policy, Hospital volume,
    Machine learning, National Inpatient Sample, Nationwide Inpatient Sample, NIS
  SCI_FACTOR: 0.734
  Title: 'The National Inpatient Sample: A Primer for Neurosurgical Big Data Research
    and Systematic Review'
  Title_JCS: World Neurosurgery
  Title_SCI: World Neurosurgery
  Type_Publication: article
  Year: 2022
- Abstract: "Data are an extremely important asset. Governments around the world encourage\
    \ big data sharing and trading to promote the big data economy. However, existing\
    \ data trading platforms are not fully trusted. Such platforms face the problems\
    \ of a single point of failure (SPOF), opaque transactions, uncontrollability,\
    \ untraceability, and issues of data privacy. Several blockchain-based big data\
    \ trading methods have been proposed; however, they do not adequately address\
    \ the security issues introduced by dishonesty in the data provider and data agent\
    \ or the fairness of data revenue distribution and price bargaining. In this paper,\
    \ we propose a blockchain-based decentralized data trading system in which data\
    \ trading is completed by smart contract-based data matching, price negotiation,\
    \ and reward assigning. Moreover, the proposed data trading system evaluates the\
    \ data quality on the basis of three metrics, records the evaluation results in\
    \ a side-chain, and distributes the data users\xE2\u20AC\u2122 application revenue\
    \ to the data provider according to the evaluated data quality. We verify the\
    \ security, usability, and efficiency of the proposed big data trading system."
  Author: Donghui Hu and Yifan Li and Lixuan Pan and Meng Li and Shuli Zheng
  Book_Title_Journal: Computer Networks
  DOI: https://doi.org/10.1016/j.comnet.2021.107994
  JCS_FACTOR: 4.474
  Keywords: Big data trading, Blockchain, Smart contract, Proxy re-encryption, Price
    negotiation, Value reward
  SCI_FACTOR: 0.798
  Title: A blockchain-based trading system for big data
  Title_JCS: Computer Networks
  Title_SCI: Computer Networks
  Type_Publication: article
  Year: 2021
- Abstract: Anecdotal evidence suggests that, despite the large variety of data, the
    huge volume of generated data, and the fast velocity of obtaining data (i.e.,
    big data), quality of big data is far from perfect. Therefore, many firms defer
    collecting and integrating big data as they have concerns regarding the impact
    of utilizing big data on data diagnosticity (i.e., retrieval of valuable information
    from data) and firm decision making quality. In this study, we use the Organizational
    Learning Theory and Wang and Strong's data quality framework to explore the impact
    of processing big data on firm decision quality and the mediating role of data
    quality (DQ) and data diagnosticity on this relationship. We validate the proposed
    research model using survey data from 130 firms, obtained from data analysts and
    IT managers. Results confirm the critical role of DQ in increasing data diagnosticity
    and improving firm decision quality when processing big data; suggesting important
    implications for practice and theory. Findings also reveal that while big data
    utilization positively impacts contextual DQ, accessibility DQ, and representational
    DQ, interestingly, it negatively impacts intrinsic DQ. Furthermore, findings show
    that while intrinsic DQ, contextual DQ, and representational DQ significantly
    increase data diagnosticity, accessibility DQ does not influence it. Most importantly,
    the findings show that big data utilization does not significantly impact the
    quality of firm decisions and it is fully mediated through DQ and data diagnosticity.
    The results of this study contribute to practice by providing important guidelines
    for managers to improve firm decision quality through the use of big data.
  Author: Maryam Ghasemaghaei and Goran Calic
  Book_Title_Journal: Decision Support Systems
  DOI: https://doi.org/10.1016/j.dss.2019.03.008
  JCS_FACTOR: 5.795
  Keywords: Big data utilization, Data quality, Decision quality, Data diagnosticity
  SCI_FACTOR: 1.564
  Title: Can big data improve firm decision quality? The role of data quality and
    data diagnosticity
  Title_JCS: DECISION SUPPORT SYSTEMS
  Title_SCI: Decision Support Systems
  Type_Publication: article
  Year: 2019
- Abstract: "The digitalization of the Intensive Care Unit (ICU) led to an increasing\
    \ amount of clinical data being collected at the bedside. The term \xE2\u20AC\u0153\
    Big Data\xE2\u20AC\x9D can be used to refer to the analysis of these datasets\
    \ that collect enormous amount of data of different origin and format. Complexity\
    \ and variety define the value of Big Data. In fact, the retrospective analysis\
    \ of these datasets allows to generate new knowledge, with consequent potential\
    \ improvements in the clinical practice. Despite the promising start of Big Data\
    \ analysis in medical research, which has seen a rising number of peer-reviewed\
    \ articles, very limited applications have been used in ICU clinical practice.\
    \ A close future effort should be done to validate the knowledge extracted from\
    \ clinical Big Data and implement it in the clinic. In this article, we provide\
    \ an introduction to Big Data in the ICU, from data collection and data analysis,\
    \ to the main successful examples of prognostic, predictive and classification\
    \ models based on ICU data. In addition, we focus on the main challenges that\
    \ these models face to reach the bedside and effectively improve ICU care."
  Author: "Giorgia Carra and Jorge I.F. Salluh and Fernando Jos\xC3\xA9 {da Silva\
    \ Ramos} and Geert Meyfroidt"
  Book_Title_Journal: Journal of Critical Care
  DOI: https://doi.org/10.1016/j.jcrc.2020.09.002
  JCS_FACTOR: 3.425
  Keywords: Big data, Data mining, Machine learning, Predictive modeling, Intensive
    care unit
  SCI_FACTOR: 1.149
  Title: 'Data-driven ICU management: Using Big Data and algorithms to improve outcomes'
  Title_JCS: JOURNAL OF CRITICAL CARE
  Title_SCI: Journal of Critical Care
  Type_Publication: article
  Year: 2020
- Abstract: "Despite the wide usage of big data in tourism and the hospitality sector,\
    \ little research has been done to understand the role of organizations\xE2\u20AC\
    \u2122 capability of managing big data in value creation. This study bridges this\
    \ gap by investigating how big data management capabilities lead to service innovation\
    \ and high online quality ratings. Instead of treating big data management as\
    \ a whole, we access big data management capabilities at the strategic and operational\
    \ level. Using a sample of 202 hotels in Pakistan, we collected the primary data\
    \ for big data capabilities, knowledge creation and service innovation; the secondary\
    \ data about quality rating were collected from Booking.com. Structural equation\
    \ modelling through SmartPLS was used for data analysis. The results indicated\
    \ that big data management capabilities lead to high online quality ratings through\
    \ the mediation of knowledge creation and service innovation. We contribute to\
    \ the current literature by empirically testing how strategic level big data capabilities\
    \ enable the firm to add value in innovativeness and positive online quality ratings\
    \ through acquiring, contextualizing, experimenting and applying big data."
  Author: Saqib Shamim and Yumei Yang and Najam Ul Zia and Mahmood Hussain Shah
  Book_Title_Journal: Computers in Human Behavior
  DOI: https://doi.org/10.1016/j.chb.2021.106777
  JCS_FACTOR: 6.829
  Keywords: Big data management, Dynamic capabilities, Service innovation, Knowledge
    creation, Customer generated online quality rating, Hospitality
  SCI_FACTOR: 2.108
  Title: 'Big data management capabilities in the hospitality sector: Service innovation
    and customer generated online quality ratings'
  Title_JCS: COMPUTERS IN HUMAN BEHAVIOR
  Title_SCI: Computers in Human Behavior
  Type_Publication: article
  Year: 2021
- Abstract: The management of the exponential growth of data that Next Generation
    Sequencing techniques produce has become a challenge for researchers that are
    forced to delve into an ocean of complex data in order to extract new insights
    to unravel the secrets of human diseases. Initially, this can be faced as a Big
    Data-related problem, but the genomic data have particular and relevant challenges
    that make them different from other Big Data working domains. Genomic data are
    much more heterogeneous; they are spread in hundreds of repositories, represented
    in multiple formats, and have different levels of quality. In addition, getting
    meaningful conclusions from genomic data requires considering all of the relevant
    surrounding knowledge that is under continuous evolution. In this scenario, the
    precise identification of what makes Genome Data Management so different is essential
    in order to provide effective Big Data-based solutions. Genomic projects require
    dealing with the technological problems associated with data management, nomenclature
    standards, and quality issues that only robust Information Systems that use Big
    Data techniques can provide. The main contribution of this paper is to present
    a Big Data-driven approach for managing genomic data, that is adapted to the particularities
    of the domain and to show its applicability to improve genetic diagnoses, which
    is the core of the development of accurate Precision Medicine.
  Author: "Ana Le\xC3\xB3n and \xC3\u201Cscar Pastor"
  Book_Title_Journal: Big Data Research
  DOI: https://doi.org/10.1016/j.bdr.2021.100253
  JCS_FACTOR: 3.578
  Keywords: Big Data, Genomics, Computer science, Theory and methods
  SCI_FACTOR: 0.565
  Title: 'Enhancing Precision Medicine: A Big Data-Driven Approach for the Management
    of Genomic Data'
  Title_JCS: Big Data Research
  Title_SCI: Big Data Research
  Type_Publication: article
  Year: 2021
- Abstract: In the big data era, large amounts of data are under generation and accumulation
    in various industries. However, users usually feel hindered by the data quality
    issues when extracting values from the big data. Thus, data quality issues are
    gaining more and more attention from data quality management analysts. Cutting-edge
    solutions like data ETL, data cleaning, and data quality monitoring systems have
    many deficiencies in capability and efficiency, making it difficult to cope with
    complicated situations on big data. These problems inspire us to build SparkDQ,
    a generic distributed data quality management model and framework that provides
    a series of data quality detection and repair interfaces. Users can quickly build
    custom tasks of data quality computing for various needs by utilizing these interfaces.
    In addition, SparkDQ implements a set of algorithms that in a parallel manner
    with optimizations. These algorithms aim at various data quality goals. We also
    propose several system-level optimizations, including the job-level optimization
    with multi-task execution scheduling and the data-level optimization with data
    state caching. The experimental evaluation shows that the proposed distributed
    algorithms in SparkDQ run up to 12 times faster compared to the corresponding
    stand-alone serial and multi-thread algorithms. Compared with the cutting-edge
    distributed data quality solution Apache Griffin, SparkDQ has more features, and
    its execution time is only around half of Apache Griffin on average. SparkDQ achieves
    near-linear data and node scalability.
  Author: Rong Gu and Yang Qi and Tongyu Wu and Zhaokang Wang and Xiaolong Xu and
    Chunfeng Yuan and Yihua Huang
  Book_Title_Journal: Journal of Parallel and Distributed Computing
  DOI: https://doi.org/10.1016/j.jpdc.2021.05.012
  JCS_FACTOR: 3.734
  Keywords: Parallel data quality algorithms, Distributed system, Data quality management
    system, Multi-tasks scheduling, Big data
  SCI_FACTOR: 0.638
  Title: 'SparkDQ: Efficient generic big data quality management on distributed data-parallel
    computation'
  Title_JCS: JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING
  Title_SCI: Journal of Parallel and Distributed Computing
  Type_Publication: article
  Year: 2021
- Abstract: "Although reference intervals (RIs) play an important role in clinical\
    \ diagnosis, there remain significant differences with respect to race, gender,\
    \ age and geographic location. Accordingly, the Clinical Laboratory Standards\
    \ Institute (CLSI) EP28-A3c has recommended that clinical laboratories establish\
    \ RIs appropriate to their subject population. Unfortunately, the traditional\
    \ and direct approach to establish RIs relies on the recruitment of a sufficient\
    \ number of healthy individuals of various age groups, collection and testing\
    \ of large numbers of specimens and accurate data interpretation. The advent of\
    \ the big data era has, however, created a unique opportunity to \xE2\u20AC\u0153\
    mine\xE2\u20AC\x9D laboratory information. Unfortunately, this indirect method\
    \ lacks standardization, consensus support and CLSI guidance. In this review we\
    \ provide a historical perspective, comprehensively assess data processing and\
    \ statistical methods, and post-verification analysis to validate this big data\
    \ approach in establishing laboratory specific RIs."
  Author: Dan Yang and Zihan Su and Min Zhao
  Book_Title_Journal: Clinica Chimica Acta
  DOI: https://doi.org/10.1016/j.cca.2022.01.001
  JCS_FACTOR: 3.786
  Keywords: Indirect method, Reference interval, Data pre-processing, Verification,
    Big data
  SCI_FACTOR: 0.924
  Title: Big data and reference intervals
  Title_JCS: CLINICA CHIMICA ACTA
  Title_SCI: Clinica Chimica Acta
  Type_Publication: article
  Year: 2022
- Abstract: "The implementation of the GDPR that aims at protecting European citizens\xE2\
    \u20AC\u2122 privacy is still a real challenge. In particular, in Big Data systems\
    \ where data are voluminous and heterogeneous, it is hard to track data evolution\
    \ through its complex life cycle ranging from collection, ingestion, storage and\
    \ analytics. In this context, from 2016 to 2021 research has been conducted and\
    \ several security tools designed. However, they are either specific to particular\
    \ applications or address partially the regulation articles. To identify the covered\
    \ parts, the missed ones and the necessary metrics for comparing different works,\
    \ we propose a framework for GDPR compliance. The framework identifies the main\
    \ components for the regulation implementation by mapping requirements aligned\
    \ with GDPR\xE2\u20AC\u2122s provisions to IT design requirements. Based on this\
    \ framework, we compare the main GDPR solutions in the Big Data domain and we\
    \ propose a guideline for GDPR verification and implementation in Big Data systems."
  Author: Mouna Rhahla and Sahar Allegue and Takoua Abdellatif
  Book_Title_Journal: Journal of Information Security and Applications
  DOI: https://doi.org/10.1016/j.jisa.2021.102896
  JCS_FACTOR: 3.872
  Keywords: The General Data Protection Regulation (GDPR), Big Data analytics, Privacy,
    Security
  SCI_FACTOR: 0.61
  Title: Guidelines for GDPR compliance in Big Data systems
  Title_JCS: Journal of Information Security and Applications
  Title_SCI: Journal of Information Security and Applications
  Type_Publication: article
  Year: 2021
- Abstract: Given exponential growth in the size of big data, its multi-channel sources
    and variability in quality that create challenges concerning cost-effective use,
    firms have invested significantly in databases and analytical tools to inform
    decision-making. In this regard, one means to avoid the costs associated with
    producing less than insightful reports and negative effects on performance through
    wasted resources is prioritizing data in terms of relevance and quality. The aim
    of this study is to investigate this approach by developing and testing a scale
    to evaluate Big Data Availability and the role of Big Data Prioritization for
    more effective use of big data in decision-making and performance. Focusing on
    the context of supply chain management (SCM), we validate this scale through a
    survey involving 84 managers. Findings support a positive association between
    Big Data Availability and its use in SCM decision-making, and suggest that Big
    Data Prioritization, as conceptualized in the study, has a positive impact on
    the use of big data in SCM decision-making and SCM performance. Through developing
    a scale to evaluate association between Big Data Availability and use in SCM decision-making,
    we make an empirical contribution to value generation from big data.
  Author: "Carla Wilkin and Ald\xC3\xB3nio Ferreira and Kristian Rotaru and Luigi\
    \ Red Gaerlan"
  Book_Title_Journal: International Journal of Accounting Information Systems
  DOI: https://doi.org/10.1016/j.accinf.2020.100470
  JCS_FACTOR: 4.4
  Keywords: Big data, Big data availability, Big data prioritization, Supply chain
    management, Performance
  SCI_FACTOR: 0.897
  Title: 'Big data prioritization in SCM decision-making: Its role and performance
    implications'
  Title_JCS: International Journal of Accounting Information Systems
  Title_SCI: International Journal of Accounting Information Systems
  Type_Publication: article
  Year: 2020
- Abstract: "The introduction and use of \xE2\u20AC\u02DCbig data and analytics\xE2\
    \u20AC\u2122 is an on-going issue of discussion in health sectors globally. Healthcare\
    \ systems of developed countries are trying to create more value and better healthcare\
    \ through data and use of big data technologies. With an increasing number of\
    \ articles identifying the value creation of big data and analytics for clinical\
    \ decision-making, this paper examines how big data is applied, or not applied,\
    \ in clinical practice. Using social representation theory as a theoretical foundation\
    \ the paper explores people's perceptions of big data across all levels (policy\
    \ making, planning, funding, and clinical care) of the New Zealand healthcare\
    \ sector. The findings show that although adoption of big data technologies is\
    \ planned for population health and health management, the potential of big data\
    \ for clinical care has yet to be explored in the New Zealand context. The findings\
    \ also highlight concern over data quality. The paper provides recommendations\
    \ for policy and practice particularly around the need for engagement and participation\
    \ of all levels to discuss data quality as well as big-data-based changes such\
    \ as precision medicine and technology-assisted clinical decision-making tools.\
    \ Future avenues of research are suggested."
  Author: Kasuni Weerasinghe and Shane L. Scahill and David J. Pauleen and Nazim Taskin
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2021.121222
  JCS_FACTOR: 8.593
  Keywords: Analytics, Clinical decision-making, Big data, Healthcare, Social representation
    theory
  SCI_FACTOR: 2.226
  Title: 'Big data analytics for clinical decision-making: Understanding health sector
    perceptions of policy and practice'
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2022
- Abstract: Big Data Cyber Security Analytics (BDCA) systems use big data technologies
    (e.g., Apache Spark) to collect, store, and analyse a large volume of security
    event data for detecting cyber-attacks. The volume of digital data in general
    and security event data in specific is increasing exponentially. The velocity
    with which security event data is generated and fed into a BDCA system is unpredictable.
    Therefore, a BDCA system should be highly scalable to deal with the unpredictable
    increase/decrease in the velocity of security event data. However, there has been
    little effort to investigate the scalability of BDCA systems to identify and exploit
    the sources of scalability improvement. In this paper, we first investigate the
    scalability of a Spark-based BDCA system with default Spark settings. We then
    identify Spark configuration parameters (e.g., execution memory) that can significantly
    impact the scalability of a BDCA system. Based on the identified parameters, we
    finally propose a parameter-driven adaptation approach, SCALER, for optimizing
    a system's scalability. We have conducted a set of experiments by implementing
    a Spark-based BDCA system on a large-scale OpenStack cluster. We ran our experiments
    with four security datasets. We have found that (i) a BDCA system with default
    settings of Spark configuration parameters deviates from ideal scalability by
    59.5% (ii) 9 out of 11 studied Spark configuration parameters significantly impact
    scalability and (iii) SCALER improves the BDCA system's scalability by 20.8% compared
    to the scalability with default Spark parameter setting. The findings of our study
    highlight the importance of exploring the parameter space of the underlying big
    data framework (e.g., Apache Spark) for scalable cyber security analytics.
  Author: Faheem Ullah and M. Ali Babar
  Book_Title_Journal: Journal of Network and Computer Applications
  DOI: https://doi.org/10.1016/j.jnca.2021.103294
  JCS_FACTOR: 6.281
  Keywords: Big data, Cyber security, Adaptation, Scalability, Configuration parameter,
    Spark
  SCI_FACTOR: 1.145
  Title: On the scalability of Big Data Cyber Security Analytics systems
  Title_JCS: JOURNAL OF NETWORK AND COMPUTER APPLICATIONS
  Title_SCI: Journal of Network and Computer Applications
  Type_Publication: article
  Year: 2022
- Abstract: With the boom in Internet techniques and computer science, a variety of
    big data have been introduced into forecasting research, bringing new knowledge
    and improving prediction models. This paper is the first attempt to conduct a
    literature review on full-scale big data in forecasting research. By source, big
    data in forecasting research fell into user-generated content data (from the users
    on social media in texts, photos, etc.), device-monitored data (by meteorological
    monitors, smart meters, GPS, etc.) and activity log data (for web searching/visiting,
    online/offline marketing, clinical treatments, laboratory experiments, etc.).
    Different data types, bearing distinctive information and characteristics, dominated
    different forecasting tasks, required different analysis technologies and improved
    different forecasting models. This survey provides an overall review of big data-based
    forecasting research, details what (regarding data types and sources), where (forecasting
    hotspots) and how (analysis and forecasting methods used) big data improved prediction,
    and offers insights into future prospects.
  Author: Ling Tang and Jieyi Li and Hongchuan Du and Ling Li and Jun Wu and Shouyang
    Wang
  Book_Title_Journal: Big Data Research
  DOI: https://doi.org/10.1016/j.bdr.2021.100289
  JCS_FACTOR: 3.578
  Keywords: Big data, Forecasting, Literature review, Prediction models, Information
  SCI_FACTOR: 0.565
  Title: 'Big Data in Forecasting Research: A Literature Review'
  Title_JCS: Big Data Research
  Title_SCI: Big Data Research
  Type_Publication: article
  Year: 2022
- Abstract: "This paper presents the approach to Big Data Analytics (BDA) developed\
    \ in the SIBDA (Sistema Innovativo Big Data Analytics) Project. The project aim\
    \ is to study and develop innovative solutions in the field of BDA for three companies\
    \ cooperating in a temporary association of enterprises. We discuss elements of\
    \ Big Data tackled in the project, namely document processing, mass e-mail applications\
    \ and Internet of Things sensor networks, to be integrated into a shared platform\
    \ of common assets and services for the three cooperating companies. We comment\
    \ about the \xE2\u20AC\u0153Big Data Journey\xE2\u20AC\x9D status in Italy reported\
    \ by Osservatorio Politecnico di Milano. Then, the paper presents the SIBDA project\
    \ approach and requirements, outlines the adopted architecture and provides implementation\
    \ hints, along with some experiments and considerations on the use of the proposed\
    \ architecture for Smart Cities and Smart Enterprises and Communities."
  Author: Mariagrazia Fugini and Jacopo Finocchi and Paolo Locatelli
  Book_Title_Journal: Big Data Research
  DOI: https://doi.org/10.1016/j.bdr.2021.100192
  JCS_FACTOR: 3.578
  Keywords: Big Data platforms, Unstructured data, Text analytics, Machine learning,
    Virtual enterprises, Smart communities
  SCI_FACTOR: 0.565
  Title: A Big Data Analytics Architecture for Smart Cities and Smart Companies
  Title_JCS: Big Data Research
  Title_SCI: Big Data Research
  Type_Publication: article
  Year: 2021
- Abstract: Combining query processing techniques with data quality management approaches
    enables enforcement of quality constraints, such as timeliness, accuracy and completeness,
    as part of ad-hoc query specification and execution, improving the quality of
    query results. Despite the emergence of novel data quality processing tools, there
    is a dearth of studies assessing performance and scalability in the execution
    of data quality assessment tasks during query processing. This paper reports on
    an empirical study aiming to investigate the extent to which a big data computing
    framework (Spark) can offer significant gains in performance and scalability when
    executing data quality querying tasks over a range of computational platforms
    including a single commodity multi-core machine and a cluster-based platform for
    a wide range of workloads. Our results show that substantial performance and scalability
    gains can be obtained by using optimized data science libraries combined with
    the parallel and distributed capabilities of big data computing. We also provide
    guidelines on choosing the appropriate computational infrastructure for executing
    DQ-aware queries.
  Author: Sonia Cisneros-Cabrera and Anna-Valentini Michailidou and Sandra Sampaio
    and Pedro Sampaio and Anastasios Gounaris
  Book_Title_Journal: Expert Systems with Applications
  DOI: https://doi.org/10.1016/j.eswa.2021.114858
  JCS_FACTOR: 6.954
  Keywords: Data quality-aware queries, Big data computing, Empirical evaluation
  SCI_FACTOR: 1.368
  Title: Experimenting with big data computing for scaling data quality-aware query
    processing
  Title_JCS: EXPERT SYSTEMS WITH APPLICATIONS
  Title_SCI: Expert Systems with Applications
  Type_Publication: article
  Year: 2021
- Abstract: With the development of big data technology, power system has entered
    the era of data analysis. With the help of the massive data provided by the wide
    area measurement system, the power system can be easily evaluated, and the abnormal
    operation status can be detected and positioned. As the increase of renewable
    energy permeability, more new abnormal operating status have appeared in the system.
    Aimed at the abnormal operation state in the development of new energy, this paper
    proposes an oscillation location scheme based on evidence theory and support vector
    machine, which makes up for the limitation of single oscillation location method.
    The result of location analysis of oscillation energy method, oscillation phase
    difference method and forced oscillation phase difference location method is fused
    by evidence theory.
  Author: Jian Wang
  Book_Title_Journal: Energy Reports
  DOI: https://doi.org/10.1016/j.egyr.2022.02.022
  JCS_FACTOR: 6.87
  Keywords: Oscillation identification, Big data, Evidence theory, Support vector
    machine
  SCI_FACTOR: 1.199
  Title: A novel oscillation identification method for grid-connected renewable energy
    based on big data technology
  Title_JCS: Energy Reports
  Title_SCI: Energy Reports
  Type_Publication: article
  Year: 2022
- Abstract: Big Data Analytics enables today's businesses and organisations to process
    and utilise the raw data that is generated on a daily basis. While Big Data Analytics
    has improved efficiency and created many opportunities, it has also increased
    the risk of personal data being compromised or breached. The General Data Protection
    Regulation (GDPR) mandates Data Protection Impact Assessment (DPIA) as a means
    of identifying appropriate controls to mitigate risks associated with the protection
    of personal data. However, little is currently known about how to conduct such
    a DPIA in a Big Data Analytics context. To this end, we conducted a systematic
    literature review with the aim of identifying privacy and data protection risks
    specific to the Big Data Analytics context that could negatively impact individuals'
    rights and freedoms when they occur. Based on a sample of 159 articles, we applied
    a thematic analysis to all identified risks which resulted in the definition of
    nine Privacy Touch Points that summarise the identified risks. The coverage of
    these Privacy Touch Points was then analysed for ten Privacy Impact Assessment
    (PIA) methodologies. The insights gained from our analysis will inform the next
    phase of our research, in which we aim to develop a comprehensive DPIA methodology
    that will enable data processors and data controllers to identify, analyse and
    mitigate privacy and data protection risks when storing and processing data involving
    Big Data Analytics.
  Author: Georgios Georgiadis and Geert Poels
  Book_Title_Journal: Computer Law & Security Review
  DOI: https://doi.org/10.1016/j.clsr.2021.105640
  JCS_FACTOR: 2.98
  Keywords: Big data analytics, Data protection, Data protection directive, General
    data protection regulation, Governance, Information security, Privacy, Privacy
    impact assessment, Systematic literature review
  SCI_FACTOR: 0.0
  Title: 'Towards a privacy impact assessment methodology to support the requirements
    of the general data protection regulation in a big data analytics context: A systematic
    literature review'
  Title_JCS: Computer Law & Security Review
  Title_SCI: N/A
  Type_Publication: article
  Year: 2022
- Abstract: This study examines the role of big data contractual and relational governance
    in big data decision-making performance of firms based in China. It investigates
    the mediation of big data analytics (BDA) capability in the association of contractual
    and relational governance with decision-making performance. Furthermore, moderating
    role of data-driven culture in the relationship of BDA capability and decision-making
    performance is examined. Data are collected from 108 Chinese firms engaged in
    big data-related activities. Structural equation modeling is employed to test
    the hypotheses. This study contributes towards the literature on big data management
    and governance mechanisms, by establishing the relationship of decision-making
    performance with big data contractual and relational governance directly and through
    the mediation of BDA capabilities. It also contributes towards knowledge based
    dynamic capabilities (KBDCs) view of firms, arguing that dynamic capabilities
    such as BDA capabilities can be influenced through knowledge sources and activities.
    We add to the discussions on whether contractual and relational governance are
    alternatives or they complement each other, by establishing the moderating role
    of big data relational governance in the relationship of contractual governance
    and decision-making performance. Finally, we argue that social capital can enhance
    KBDCs through contractual and relational governance in big data context.
  Author: Saqib Shamim and Jing Zeng and Zaheer Khan and Najam Ul Zia
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2020.120315
  JCS_FACTOR: 8.593
  Keywords: Big data, Contractual governance, Relational governance, Big data analytics
    capability, Culture, Decision-making performance, Emerging markets
  SCI_FACTOR: 2.226
  Title: 'Big data analytics capability and decision making performance in emerging
    market firms: The role of contractual and relational governance mechanisms'
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2020
- Abstract: Data is one of the most important assets for all types of companies, which
    have undoubtedly grown their quantity and the ways of exploiting them. Big Data
    appears in this context as a set of technologies that manage data to obtain information
    that supports decision-making. These systems were not conceived to be secure,
    resulting in significant risks that must be controlled. Security risks in Big
    Data must be analyzed and managed in an appropriate manner to protect the system
    and secure the information and the data being handled. This paper proposes a risk
    analysis approach for Big Data environments, which is based on a security analysis
    methodology called MARISMA (Methodology for the Analysis of Risks on Information
    System), supported by a technological environment in the cloud (eMARISMA tool)
    already used by numerous clients. Both MARISMA and eMARISMA are specifically designed
    to be easily adapted to particular contexts, such as Big Data. Our proposal, called
    MARISMA-BiDa, is based on the main related standards, such as ISO/IEC 27,000 and
    31,000, or the NIST Big Data reference architecture or ENISA and CSA recommendations
    for Big Data.
  Author: "David G. Rosado and Julio Moreno and Luis E. S\xC3\xA1nchez and Antonio\
    \ Santos-Olmo and Manuel A. Serrano and Eduardo Fern\xC3\xA1ndez-Medina"
  Book_Title_Journal: Computers & Security
  DOI: https://doi.org/10.1016/j.cose.2020.102155
  JCS_FACTOR: 4.438
  Keywords: Big data, Risk assessment, Risk analysis, Information security, Security
    standards
  SCI_FACTOR: 0.0
  Title: 'MARISMA-BiDa pattern: Integrated risk analysis for big data'
  Title_JCS: COMPUTERS & SECURITY
  Title_SCI: N/A
  Type_Publication: article
  Year: 2021
- Abstract: Big data analytics associated with database searching, mining, and analysis
    can be seen as an innovative IT capability that can improve firm performance.
    Even though some leading companies are actively adopting big data analytics to
    strengthen market competition and to open up new business opportunities, many
    firms are still in the early stage of the adoption curve due to lack of understanding
    of and experience with big data. Hence, it is interesting and timely to understand
    issues relevant to big data adoption. In this study, a research model is proposed
    to explain the acquisition intention of big data analytics mainly from the theoretical
    perspectives of data quality management and data usage experience. Our empirical
    investigation reveals that a firm's intention for big data analytics can be positively
    affected by its competence in maintaining the quality of corporate data. Moreover,
    a firm's favorable experience (i.e., benefit perceptions) in utilizing external
    source data could encourage future acquisition of big data analytics. Surprisingly,
    a firm's favorable experience (i.e., benefit perceptions) in utilizing internal
    source data could hamper its adoption intention for big data analytics.
  Author: Ohbyung Kwon and Namyeon Lee and Bongsik Shin
  Book_Title_Journal: International Journal of Information Management
  DOI: https://doi.org/10.1016/j.ijinfomgt.2014.02.002
  JCS_FACTOR: 14.098
  Keywords: Big data analytics, Resource-based view, Data quality management, IT capability,
    Data usage
  SCI_FACTOR: 2.77
  Title: Data quality management, data usage experience and acquisition intention
    of big data analytics
  Title_JCS: INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
  Title_SCI: International Journal of Information Management
  Type_Publication: article
  Year: 2014
- Abstract: "The recent explosive publications of big data studies have well documented\
    \ the rise of big data and its ongoing prevalence. Different types of \xE2\u20AC\
    \u0153big data\xE2\u20AC\x9D have emerged and have greatly enriched spatial information\
    \ sciences and related fields in terms of breadth and granularity. Studies that\
    \ were difficult to conduct in the past time due to data availability can now\
    \ be carried out. However, big data brings lots of \xE2\u20AC\u0153big errors\xE2\
    \u20AC\x9D in data quality and data usage, which cannot be used as a substitute\
    \ for sound research design and solid theories. We indicated and summarized the\
    \ problems faced by current big data studies with regard to data collection, processing\
    \ and analysis: inauthentic data collection, information incompleteness and noise\
    \ of big data, unrepresentativeness, consistency and reliability, and ethical\
    \ issues. Cases of empirical studies are provided as evidences for each problem.\
    \ We propose that big data research should closely follow good scientific practice\
    \ to provide reliable and scientific \xE2\u20AC\u0153stories\xE2\u20AC\x9D, as\
    \ well as explore and develop techniques and methods to mitigate or rectify those\
    \ \xE2\u20AC\u02DCbig-errors\xE2\u20AC\u2122 brought by big data."
  Author: Jianzheng Liu and Jie Li and Weifeng Li and Jiansheng Wu
  Book_Title_Journal: ISPRS Journal of Photogrammetry and Remote Sensing
  DOI: https://doi.org/10.1016/j.isprsjprs.2015.11.006
  JCS_FACTOR: 8.979
  Keywords: Big data, Data quality and error, Data ethnics, Spatial information sciences
  SCI_FACTOR: 2.96
  Title: 'Rethinking big data: A review on the data quality and usage issues'
  Title_JCS: ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
  Title_SCI: ISPRS Journal of Photogrammetry and Remote Sensing
  Type_Publication: article
  Year: 2016
- Abstract: Renal failure is a fatal disease raising global concerns. Previous risk
    models for renal failure mostly rely on the diagnosis of chronic kidney disease,
    which lacks obvious clinical symptoms and thus is mostly undiagnosed, causing
    significant omission of high-risk patients. In this paper, we proposed a framework
    to predict the risk of renal failure directly from a big data repository of chronic
    disease population without prerequisite diagnosis of chronic kidney disease. The
    electronic health records of 42,256 patients with hypertension or diabetes in
    Shenzhen Health Information Big Data Platform were collected, with 398 suffered
    from renal failure during a 3-year follow-up. Five state-of-the-art machine learning
    methods are utilized to build risk prediction models of renal failure for chronic
    disease population. Extensive experimental results show that the proposed framework
    achieves quite well performance. Particularly, the XGBoost obtains the best performance
    with an area under receiving-operating-characteristics curve (AUC) of 0.9139.
    By analyzing the effect of risk factors, we identified that serum creatine, age,
    urine acid, systolic blood pressure, and blood urea nitrogen are the top five
    factors associated with renal failure risk. Compared with existing models, our
    model can be deployed into routine chronic disease management procedures and enable
    more preemptive, widely-covered screening of renal risks, which would in turn
    reduce the damage caused by the disease through timely intervention.
  Author: Yujie Yang and Ye Li and Runge Chen and Jing Zheng and Yunpeng Cai and Giancarlo
    Fortino
  Book_Title_Journal: Big Data Research
  DOI: https://doi.org/10.1016/j.bdr.2021.100234
  JCS_FACTOR: 3.578
  Keywords: Renal failure, Risk prediction, Electronic health record, Health big data,
    Machine learning
  SCI_FACTOR: 0.565
  Title: Risk Prediction of Renal Failure for Chronic Disease Population Based on
    Electronic Health Record Big Data
  Title_JCS: Big Data Research
  Title_SCI: Big Data Research
  Type_Publication: article
  Year: 2021
- Abstract: With the ever increasing data collected from the process, the era of big
    data has arrived in the process industry. Therefore, the computational effort
    for data modeling and analytics in standalone modes has become increasingly demanding,
    particularly for large-scale processes. In this paper, a distributed parallel
    process modeling approach is presented based on a MapReduce framework for big
    data quality prediction. Firstly, the architecture for distributed parallel data
    modeling is formulated under the MapReduce framework. Secondly, a big data quality
    prediction scheme is developed based on the distributed parallel data modeling
    approach. As an example, the basic Semi-Supervised Probabilistic Principal Component
    Regression (SSPPCR) model is deployed to concurrently train a set of local models
    with split datasets. Meanwhile, Bayesian rule is utilized in a MapReduce way to
    integrate local models based on their predictive abilities. Two case studies demonstrate
    the effectiveness of the proposed method for big data quality prediction.
  Author: Le Yao and Zhiqiang Ge
  Book_Title_Journal: Journal of Process Control
  DOI: https://doi.org/10.1016/j.jprocont.2018.04.004
  JCS_FACTOR: 3.666
  Keywords: Distributed modeling, MapReduce framework, Parallel computing, Quality
    prediction, Big data analytics
  SCI_FACTOR: 1.102
  Title: 'Big data quality prediction in the process industry: A distributed parallel
    modeling framework'
  Title_JCS: JOURNAL OF PROCESS CONTROL
  Title_SCI: Journal of Process Control
  Type_Publication: article
  Year: 2018
- Abstract: Big data analytics (BDA) and the Internet of Things (IoT) tools are considered
    crucial investments for firms to distinguish themselves among competitors. Drawing
    on a strategic management perspective, this study proposes that BDA and IoT capabilities
    can create significant value in business processes if supported by a good level
    of data quality, which will lead to a better competitive advantage. Responses
    are collected from 618 European and American firms that use IoT and BDA applications.
    Partial least squares results reveal that better data quality is needed to unlock
    the value of IoT and BDA capabilities.
  Author: "Nadine C\xC3\xB4rte-Real and Pedro Ruivo and Tiago Oliveira"
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2019.01.003
  JCS_FACTOR: 7.555
  Keywords: Big data analytics, Internet of things, Strategic management, Knowledge-based
    theory, Dynamics capability theory
  SCI_FACTOR: 0.0
  Title: 'Leveraging internet of things and big data analytics initiatives in European
    and American firms: Is data quality a way to extract business value?'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: Big data analytics (BDA) and the Internet of Things (IoT) tools are considered
    crucial investments for firms to distinguish themselves among competitors. Drawing
    on a strategic management perspective, this study proposes that BDA and IoT capabilities
    can create significant value in business processes if supported by a good level
    of data quality, which will lead to a better competitive advantage. Responses
    are collected from 618 European and American firms that use IoT and BDA applications.
    Partial least squares results reveal that better data quality is needed to unlock
    the value of IoT and BDA capabilities.
  Author: "Nadine C\xC3\xB4rte-Real and Pedro Ruivo and Tiago Oliveira"
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2019.01.003
  JCS_FACTOR: 7.555
  Keywords: Big data analytics, Internet of things, Strategic management, Knowledge-based
    theory, Dynamics capability theory
  SCI_FACTOR: 0.0
  Title: 'Leveraging internet of things and big data analytics initiatives in European
    and American firms: Is data quality a way to extract business value?'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: To address the unsolved problem of the mechanism underlying the effect
    of big data analytics capabilities on competitive advantage and performance, this
    study combined quantitative and qualitative methods to test the examined framework.
    The results of 257 questionnaires from hotel marketing managers and 19 semistructured
    interviews, confirm that big data analytics capabilities develop from big data
    strategies and knowledge management and enhance competitive advantage and performance
    through sustainability marketing. Moreover, social media enhance sustainability
    marketing and competitive advantage and performance. The original findings of
    the current research contribute to the development of big data, sustainability
    marketing, and social media.
  Author: Jeou-Shyan Horng and Chih-Hsing Liu and Sheng-Fang Chou and Tai-Yi Yu and
    Da-Chian Hu
  Book_Title_Journal: Journal of Hospitality and Tourism Management
  DOI: https://doi.org/10.1016/j.jhtm.2022.02.026
  JCS_FACTOR: 5.959
  Keywords: Knowledge-based dynamic capabilities view, Big data capabilities, Knowledge
    management, Sustainability marketing, Social media, Big data strategy
  SCI_FACTOR: 1.31
  Title: 'Role of big data capabilities in enhancing competitive advantage and performance
    in the hospitality sector: Knowledge-based dynamic capabilities view'
  Title_JCS: Journal of Hospitality and Tourism Management
  Title_SCI: Journal of Hospitality and Tourism Management
  Type_Publication: article
  Year: 2022
- Abstract: It is estimated that by 2050, 70% of the population will be urban (Nations
    Unies, 2014). This massive urbanization has created unprecedented challenges for
    cities and city managers which has led many of them to look for technological
    solutions to address them, including the use of Big Data, which is among the most
    considered technological support to help improve the overall operational and service
    delivery of cities. It is estimated that around 7 billion connected objects will
    soon be implemented in cities worldwide which will produce an unprecedented and
    massive amount of real-time data that will have to be managed, used, and analyzed
    effectively. If this massive amount of data is effectively managed and used, it
    can provide important benefits and produce real positive impacts on the functioning
    of cities. Nonetheless, despite these benefits, only a few cities are able to
    use and exploit big data, and some studies have shown that less than 0.5% of all
    the available data has been explored. The objective of this study is to understand
    the factors that influence cities to use big data and the nature of such use.
    Based on a field survey involving 106 municipalities, this study investigates
    the antecedents of big data use by cities and shows how different sets of antecedents
    influence three different types of big data use by cities.
  Author: Hamza Ali and Ryad Titah
  Book_Title_Journal: Government Information Quarterly
  DOI: https://doi.org/10.1016/j.giq.2021.101600
  JCS_FACTOR: 7.279
  Keywords: Big data use, Big data use in municipalities, Smart cities, E-government,
    Municipal use of IT, Digital government
  SCI_FACTOR: 2.121
  Title: Is big data used by cities? Understanding the nature and antecedents of big
    data use by municipalities
  Title_JCS: GOVERNMENT INFORMATION QUARTERLY
  Title_SCI: Government Information Quarterly
  Type_Publication: article
  Year: 2021
- Abstract: "A universal trend in advanced manufacturing countries is defining Industry\
    \ 4.0, industrialized internet and future factories as a recent wave, which may\
    \ transform the production and its related services. Further, big data analytics\
    \ has emerged as a game changer in the business world due to its uses for increasing\
    \ accuracy in decision-making and enhancing performance of sustainable industry\
    \ 4.0 applications.\xC2\_This study intends to emphasize on how to support Industry\
    \ 4.0 with knowledge based view. For the same, a conceptual model is framed and\
    \ presented with essential components that are required for a real world implementation.\
    \ The study used qualitative analysis and was guided by a knowledge-based theoretical\
    \ framework. Thematic analysis resulted in the identification of a number of emergent\
    \ categories. Key findings highlight significant gaps in conventional decision-making\
    \ systems and demonstrate how big data enhances firms\xE2\u20AC\u2122 strategic\
    \ and operational decisions as well as facilitates informational access for improved\
    \ marketing performance. The resulting proposed model can provide managers with\
    \ a reference point for using big data to line up firms\xE2\u20AC\u2122 activities\
    \ for more effective marketing efforts and presents a conceptual basis for further\
    \ empirical studies in this area."
  Author: "Shivam Gupta and Th\xC3\xA9o Justy and Shampy Kamboj and Ajay Kumar and\
    \ Eivind Kristoffersen"
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2021.120986
  JCS_FACTOR: 8.593
  Keywords: Big data analytics, Artificial intelligence, Marketing performance, Knowledge-based
    view
  SCI_FACTOR: 2.226
  Title: 'Big data and firm marketing performance: Findings from knowledge-based view'
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2021
- Abstract: "Social Networking Services (SNSs) connect people worldwide, where they\
    \ communicate through sharing contents, photos, videos, posting their first-hand\
    \ opinions, comments, and following their friends. Social networks are characterized\
    \ by velocity, volume, value, variety, and veracity, the 5\xC2\_V\xE2\u20AC\u2122\
    s of big data. Hence, big data analytic techniques and frameworks are commonly\
    \ exploited in Social Network Analysis (SNA). By the ever-increasing growth of\
    \ social networks, the analysis of social data, to describe and find communication\
    \ patterns among users and understand their behaviors, has attracted much attention.\
    \ In this paper, we demonstrate how big data analytics meets social media, and\
    \ a comprehensive review is provided on big data analytic approaches in social\
    \ networks to search published studies between 2013 and August 2020, with 74 identified\
    \ papers. The findings of this paper are presented in terms of main journals/conferences,\
    \ yearly distributions, and the distribution of studies among publishers. Furthermore,\
    \ the big data analytic approaches are classified into two main categories: Content-oriented\
    \ approaches and network-oriented approaches. The main ideas, evaluation parameters,\
    \ tools, evaluation methods, advantages, and disadvantages are also discussed\
    \ in detail. Finally, the open challenges and future directions that are worth\
    \ further investigating are discussed."
  Author: Sepideh {Bazzaz Abkenar} and Mostafa {Haghi Kashani} and Ebrahim Mahdipour
    and Seyed Mahdi Jameii
  Book_Title_Journal: Telematics and Informatics
  DOI: https://doi.org/10.1016/j.tele.2020.101517
  JCS_FACTOR: 6.182
  Keywords: Social networks, Big data, Content analysis, Sentiment analysis, Systematic
    literature review
  SCI_FACTOR: 1.567
  Title: 'Big data analytics meets social media: A systematic review of techniques,
    open issues, and future directions'
  Title_JCS: TELEMATICS AND INFORMATICS
  Title_SCI: Telematics and Informatics
  Type_Publication: article
  Year: 2021
- Abstract: "The use of Internet of Things (IoT) networks offers great advantages\
    \ over wired networks, especially due to their simple installation, low maintenance\
    \ costs, and automatic configuration. IoT facilitates the integration of sensing\
    \ and communication for various industries, including smart farming and precision\
    \ agriculture. For several years, many researchers have strived to find new sources\
    \ of energy that are always \xE2\u20AC\u0153cleaner\xE2\u20AC\x9D and more environmentally\
    \ friendly. Energy harvesting technology is one of the most promising environment-friendly\
    \ solutions that extend the lifetime of these IoT devices. In this paper, the\
    \ state-of-art of IoT energy harvesting capabilities and communication technologies\
    \ in smart agriculture is presented. In addition, this work proposes a comprehensive\
    \ architecture that includes big data technologies, IoT components, and knowledge-based\
    \ systems for innovative farm architecture. The solution answers some of the biggest\
    \ challenges the agriculture industry faces, especially when handling small files\
    \ in a big data environment without impacting the computation performance. The\
    \ solution is built on top of a pre-defined big data architecture that includes\
    \ an abstraction layer of the data lake that handles data quality following a\
    \ data migration strategy to ensure the data's insights. Furthermore, in this\
    \ paper, we compared several machine learning algorithms to find the most suitable\
    \ smart farming analytics tools in terms of forecasting and predictions."
  Author: El Mehdi Ouafiq and Rachid Saadane and Abdellah Chehri and Seunggil Jeon
  Book_Title_Journal: Sustainable Energy Technologies and Assessments
  DOI: https://doi.org/10.1016/j.seta.2022.102093
  JCS_FACTOR: 5.353
  Keywords: Smart Farming, Energy Harvesting Capabilities, IoT, Big Data, Agriculture
    4.0, Water Management, Sustainability
  SCI_FACTOR: 1.04
  Title: AI-based modeling and data-driven evaluation for smart farming-oriented big
    data architecture using IoT with energy harvesting capabilities
  Title_JCS: Sustainable Energy Technologies and Assessments
  Title_SCI: Sustainable Energy Technologies and Assessments
  Type_Publication: article
  Year: 2022
- Abstract: 'Modern applications of Big Data are transcending from being scalable
    solutions of data processing and analysis, to now provide advanced functionalities
    with the ability to exploit and understand the underpinning knowledge. This change
    is promoting the development of tools in the intersection of data processing,
    data analysis, knowledge extraction and management. In this paper, we propose
    TITAN, a software platform for managing all the life cycle of science workflows
    from deployment to execution in the context of Big Data applications. This platform
    is characterised by a design and operation mode driven by semantics at different
    levels: data sources, problem domain and workflow components. The proposed platform
    is developed upon an ontological framework of meta-data consistently managing
    processes and models and taking advantage of domain knowledge. TITAN comprises
    a well-grounded stack of Big Data technologies including Apache Kafka for inter-component
    communication, Apache Avro for data serialisation and Apache Spark for data analytics.
    A series of use cases are conducted for validation, which comprises workflow composition
    and semantic meta-data management in academic and real-world fields of human activity
    recognition and land use monitoring from satellite images.'
  Author: "Antonio Ben\xC3\xADtez-Hidalgo and Crist\xC3\xB3bal Barba-Gonz\xC3\xA1\
    lez and Jos\xC3\xA9 Garc\xC3\xADa-Nieto and Pedro Guti\xC3\xA9rrez-Moncayo and\
    \ Manuel Paneque and Antonio J. Nebro and Mar\xC3\xADa del Mar Rold\xC3\xA1n-Garc\xC3\
    \xADa and Jos\xC3\xA9 F. Aldana-Montes and Ismael Navas-Delgado"
  Book_Title_Journal: Knowledge-Based Systems
  DOI: https://doi.org/10.1016/j.knosys.2021.107489
  JCS_FACTOR: 8.038
  Keywords: Big Data analytics, Semantics, Knowledge extraction
  SCI_FACTOR: 1.587
  Title: 'TITAN: A knowledge-based platform for Big Data workflow management'
  Title_JCS: KNOWLEDGE-BASED SYSTEMS
  Title_SCI: Knowledge-Based Systems
  Type_Publication: article
  Year: 2021
- Abstract: "Today, business success is essentially powered by data-centric software.\
    \ Big data analytics (BDA) grasp the potential of generating valuable insights\
    \ and empowering businesses to support their strategic decision-making. However,\
    \ although organizations are aware of BDAs\xE2\u20AC\u2122 potential opportunities,\
    \ they face challenges to satisfy the BDA-specific processes and integrate them\
    \ into their daily software development lifecycle. Process capability/ maturity\
    \ assessment models are used to assist organizations in assessing and realizing\
    \ the value of emerging capabilities and technologies. However, as a result of\
    \ the literature review and its analysis, it was observed that none of the existing\
    \ studies in the BDA domain provides a complete, standardized, and objective capability\
    \ maturity assessment model. To address this research gap, we focus on developing\
    \ a BDA process capability assessment model grounded on the well-accepted ISO/IEC\
    \ 330xx standard series. The proposed model comprises two main dimensions: process\
    \ and capability. The process dimension covers six BDA-specific processes: business\
    \ understanding, data understanding, data preparation, model building, evaluation,\
    \ and deployment and use. The capability dimension has six levels, from not performed\
    \ to innovating. We conducted case studies in two different organizations to validate\
    \ the applicability and usability of the proposed model. The results indicate\
    \ that the proposed model provides significant insights to improve the business\
    \ value generated by BDA via determining the current capability levels of the\
    \ organizations' BDA processes, deriving a gap analysis, and creating a comprehensive\
    \ roadmap for continuous improvement in a standardized way."
  Author: "Mert Onuralp G\xC3\xB6kalp and Ebru G\xC3\xB6kalp and Kerem Kayabay and\
    \ Selin G\xC3\xB6kalp and Altan Ko\xC3\xA7yi\xC4\u0178it and P. Erhan Eren"
  Book_Title_Journal: Computer Standards & Interfaces
  DOI: https://doi.org/10.1016/j.csi.2021.103585
  JCS_FACTOR: 2.487
  Keywords: Big data, Data analytics, Software development, Software process improvement,
    Software process assessment
  SCI_FACTOR: 0.0
  Title: A process assessment model for big data analytics
  Title_JCS: COMPUTER STANDARDS & INTERFACES
  Title_SCI: N/A
  Type_Publication: article
  Year: 2022
- Abstract: We study a firm's strategy in adopting big data technology to motivate
    consumer demand over two periods. In the first period, the firm designs a product
    to sell to the market and determines whether to apply big data to attract more
    consumers. In the second period, the firm designs a new product and determines
    whether to sell the old product and the new product simultaneously, where big
    data can also be applied in this period to stimulate more demands. We formulate
    this problem into four models considering whether the firm adopts big data in
    the first period and/or the second period, and whether the firm only sells the
    new product or sells both the old and new products in the second period. We find
    that the firm prefers to apply big data over both periods when the cost is low,
    only over the second period when the cost is median and will not apply big data
    when the cost is high. Interestingly, only applying big data over the first period
    also may bring the most profits with heterogeneous big data coefficients. Furthermore,
    applying big data in the second period is the better choice for the social welfare.
  Author: Lei Yang and Anqian Jiang and Jiahua Zhang
  Book_Title_Journal: Computers & Industrial Engineering
  DOI: https://doi.org/10.1016/j.cie.2021.107550
  JCS_FACTOR: 5.431
  Keywords: Supply chain management, Optimal strategy, Big data application, Two-period
    model, Social welfare
  SCI_FACTOR: 0.0
  Title: Optimal timing of big data application in a two-period decision model with
    new product sales
  Title_JCS: COMPUTERS & INDUSTRIAL ENGINEERING
  Title_SCI: N/A
  Type_Publication: article
  Year: 2021
- Abstract: Big Data Analytics (BDA) has attracted significant attention from both
    academicians and practitioners alike as it provides several ways to improve strategic,
    tactical and operational capabilities to eventually create a positive impact on
    the economic performance of organizations. In the present study, twelve significant
    barriers against BDA implementation are identified and assessed in the context
    of Indian manufacturing Supply Chains (SC). These barriers are modeled using an
    integrated two-stage approach, consisting of Interpretive Structural Modeling
    (ISM) in the first stage and Decision-Making Trial and Evaluation Laboratory (DEMATEL)
    in the second stage. The approach developed provides the interrelationships between
    the identified constructs and their intensities. Moreover, Fuzzy MICMAC technique
    is applied to analyze the high impact (i.e., high driving power) barriers. Results
    show that four constructs, namely lack of top management support, lack of financial
    support, lack of skills, and lack of techniques or procedures, are the most significant
    barriers. This study aids policy-makers in conceptualizing the mutual interaction
    of the barriers for developing policies and strategies to improve the penetration
    of BDA in manufacturing SC.
  Author: Rakesh D. Raut and Vinay Surendra Yadav and Naoufel Cheikhrouhou and Vaibhav
    S. Narwane and Balkrishna E. Narkhede
  Book_Title_Journal: Computers in Industry
  DOI: https://doi.org/10.1016/j.compind.2020.103368
  JCS_FACTOR: 7.635
  Keywords: Big data analytics, DEMATEL, Indian manufacturing supply chains, Interpretive
    structural modeling, MICMAC analysis
  SCI_FACTOR: 1.432
  Title: 'Big data analytics: Implementation challenges in Indian manufacturing supply
    chains'
  Title_JCS: COMPUTERS IN INDUSTRY
  Title_SCI: Computers in Industry
  Type_Publication: article
  Year: 2021
- Abstract: Smart cities are expected to improve the efficiency and effectiveness
    of urban management, including public services, public security, and environmental
    protection, and to ultimately achieve Sustainable Development Goal (SDG) 11 for
    making cities inclusive, safe, resilient, and sustainable. Big data have been
    identified as a key enabler in the development of smart cities. However, our understanding
    of how different data sources should be managed and integrated remains limited.
    By analyzing data applications in the development of a sustainable smart city,
    this case study identified three phases of development, each requiring a different
    approach to orchestrating diverse data sources. A framework identifying the phases,
    data-related issues, data orchestration and its interaction with other resources,
    focal capabilities, and development approaches is developed. This study benefits
    both researchers and practitioners by making theoretical contributions and by
    offering practical insights in the fields of smart cities and big data.
  Author: Dan Zhang and L.G. Pee and Shan L. Pan and Lili Cui
  Book_Title_Journal: Government Information Quarterly
  DOI: https://doi.org/10.1016/j.giq.2021.101626
  JCS_FACTOR: 7.279
  Keywords: Smart city, Big data, Digital sustainability, Resource orchestration,
    Socio-technical issues
  SCI_FACTOR: 2.121
  Title: 'Big data analytics, resource orchestration, and digital sustainability:
    A case study of smart city development'
  Title_JCS: GOVERNMENT INFORMATION QUARTERLY
  Title_SCI: Government Information Quarterly
  Type_Publication: article
  Year: 2022
- Abstract: In the public safety service context, government big data governance (GBDG)
    is a challenging decision-making problem that encompasses uncertainties in the
    arenas of big data and its complex links. Modeling and collaborating the key scenario
    information required for GBDG decision-making can minimize system uncertainties.
    However, existing scenario-building methods are limited by their rigidity as they
    are employed in various application contexts and the associated high costs of
    modeling. In this paper, using a design science paradigm, a model-driven scenario
    modeling approach is proposed to achieve flexible scenario modeling for various
    applications through the transfer of generic domain knowledge. The key component
    of the proposed approach is a scenario meta-model that is built from existing
    literatures and practices by integrating qualitative, quantitative, and meta-modeling
    analysis. An instantiation mechanism of the scenario meta-model is also proposed
    to generate customized scenarios under Antecedent-Behavior-Consequence (ABC) theory.
    Two real-world safety service cases in Wuhan, China were evaluated to find that
    the proposed approach reduces GBDG decision-making uncertainties significantly
    by providing key information for GBDG problem identification, solution design,
    and solution value perception. This scenario-building approach can be further
    used to develop other GBDG systems for public safety services with reduced uncertainties
    and complete decision-making functions.
  Author: Zhao-ge LIU and Xiang-yang LI and Xiao-han ZHU
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2022.103622
  JCS_FACTOR: 7.555
  Keywords: Government big data governance, Scenario-based decision-making, Scenario
    modeling, Model-driven, Data link network, Public safety services
  SCI_FACTOR: 0.0
  Title: 'scenario modeling for government big data governance decision-making: Chinese
    experience with public safety services'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2022
- Abstract: In the public safety service context, government big data governance (GBDG)
    is a challenging decision-making problem that encompasses uncertainties in the
    arenas of big data and its complex links. Modeling and collaborating the key scenario
    information required for GBDG decision-making can minimize system uncertainties.
    However, existing scenario-building methods are limited by their rigidity as they
    are employed in various application contexts and the associated high costs of
    modeling. In this paper, using a design science paradigm, a model-driven scenario
    modeling approach is proposed to achieve flexible scenario modeling for various
    applications through the transfer of generic domain knowledge. The key component
    of the proposed approach is a scenario meta-model that is built from existing
    literatures and practices by integrating qualitative, quantitative, and meta-modeling
    analysis. An instantiation mechanism of the scenario meta-model is also proposed
    to generate customized scenarios under Antecedent-Behavior-Consequence (ABC) theory.
    Two real-world safety service cases in Wuhan, China were evaluated to find that
    the proposed approach reduces GBDG decision-making uncertainties significantly
    by providing key information for GBDG problem identification, solution design,
    and solution value perception. This scenario-building approach can be further
    used to develop other GBDG systems for public safety services with reduced uncertainties
    and complete decision-making functions.
  Author: Zhao-ge LIU and Xiang-yang LI and Xiao-han ZHU
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2022.103622
  JCS_FACTOR: 7.555
  Keywords: Government big data governance, Scenario-based decision-making, Scenario
    modeling, Model-driven, Data link network, Public safety services
  SCI_FACTOR: 0.0
  Title: 'scenario modeling for government big data governance decision-making: Chinese
    experience with public safety services'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2022
- Abstract: "Due to the importance of big data technology in decision-making, production\
    \ and service provision, enterprises have adopted various big data technologies\
    \ and platforms to improve their operational efficiency. However, the number of\
    \ enterprises that have adopted big data is not promising. The purpose of this\
    \ study is to explore the current status of big data adoption by Chinese enterprises\
    \ and to reveal the possible factors that hinder big data adoption from the group\
    \ behaviour network perspective. Based on a real case survey of 54 big data platforms\
    \ (BDPs), four types of networks\xE2\u20AC\u201Di.e., the enterprise-platform\
    \ network, enterprise network, platform network and industry similarity and difference\
    \ (ISD) network\xE2\u20AC\u201Dare constructed and analysed on the basis of social\
    \ network analysis (SNA). This study finds that among Chinese enterprises, the\
    \ level and scope of big data adoption are generally low and are imbalanced among\
    \ industries; the cognitive level and adoption behaviour of enterprises on BDPs\
    \ are inconsistent, the compatibility of BDPs is different, and the density and\
    \ distance-based cohesion of networks are weak; although the current big data\
    \ adoption behaviours of Chinese enterprises have formed some structural features,\
    \ core-periphery structures and maximal complete cliques are found, and the current\
    \ network structure has little impact on individual enterprises and platforms;\
    \ enterprises in the same industry prefer to adopt the same kind of big data technology\
    \ or platform. Based on these findings, several strategies and suggestions to\
    \ improve big data adoption are provided."
  Author: Zhimei Lei and Yandan Chen and Ming K. Lim
  Book_Title_Journal: Technology in Society
  DOI: https://doi.org/10.1016/j.techsoc.2021.101570
  JCS_FACTOR: 4.192
  Keywords: Big data, Platforms, Technology adoption, Corporate group behaviour, Social
    network analysis
  SCI_FACTOR: 0.819
  Title: Modelling and analysis of big data platform group adoption behaviour based
    on social network analysis
  Title_JCS: TECHNOLOGY IN SOCIETY
  Title_SCI: Technology in Society
  Type_Publication: article
  Year: 2021
- Abstract: "Big data analytics (BDA) has emerged as a significant area of research\
    \ for both researchers and practitioners in the retail industry, indicating the\
    \ importance and influence of solving data-related problems in contemporary business\
    \ organization. The present study utilised a quantitative-methods approach to\
    \ investigate factors affecting retailers' adoption of BDA across three countries.\
    \ A survey questionnaire was used to collect data from managers and decision-makers\
    \ in the retail industry. Data of 2278 respondents were analysed through structural\
    \ equation modelling. The findings revealed that security concerns, external support,\
    \ top management support, and rational decision making culture have a greater\
    \ effect on BDA adoption in developed countries UK than in UAE and Egypt. However,\
    \ competition intensity and firm size have a greater effect on BDA adoption in\
    \ UAE and Egypt than in UK. Finally, human variables (competence of information\
    \ system's staff and staff's information system knowledge) have a greater effect\
    \ on BDA adoption in Egypt than UK and UAE. The findings indicate that a \xE2\u20AC\
    \u0153one-size-fits-all\xE2\u20AC\x9D approach is insufficient in capturing the\
    \ heterogeneity of managers across countries. Implications for practice and theory\
    \ were demonstrated."
  Author: Mayada Abd El-Aziz Youssef and Riyad Eid and Gomaa Agag
  Book_Title_Journal: Journal of Retailing and Consumer Services
  DOI: https://doi.org/10.1016/j.jretconser.2021.102827
  JCS_FACTOR: 7.135
  Keywords: Big data analytics, Technology adoption, Diffusion of innovations model,
    Cross-national differences, Retail industry
  SCI_FACTOR: 1.568
  Title: Cross-national differences in big data analytics adoption in the retail industry
  Title_JCS: Journal of Retailing and Consumer Services
  Title_SCI: Journal of Retailing and Consumer Services
  Type_Publication: article
  Year: 2022
- Abstract: An IS researcher may obtain Big Data from primary or secondary data sources.
    Sometimes, acquiring primary Big Data is infeasible due to availability, accessibility,
    cost, time, and/or complexity considerations. In this paper, we focus on Big Data-based
    IS research and discuss ways in which one may, post hoc, establish quality thresholds
    for numerical Big Data obtained from secondary sources. We also present guidelines
    for developing journal policies aimed at ensuring the veracity and verifiability
    of such data when used for research purposes.
  Author: Anita Lee-Post and Ram Pakath
  Book_Title_Journal: Decision Support Systems
  DOI: https://doi.org/10.1016/j.dss.2019.113135
  JCS_FACTOR: 5.795
  Keywords: Data quality, Big data, Secondary data, Numerical data, Quality threshold
  SCI_FACTOR: 1.564
  Title: Numerical, secondary Big Data quality issues, quality threshold establishment,
    & guidelines for journal policy development
  Title_JCS: DECISION SUPPORT SYSTEMS
  Title_SCI: Decision Support Systems
  Type_Publication: article
  Year: 2019
- Abstract: Internet of Things (IoT) is a fundamental concept of a new technology
    that will be promising and significant in various fields. IoT is a vision that
    allows things or objects equipped with sensors, actuators, and processors to talk
    and communicate with each other over the internet to achieve a meaningful goal.
    Unfortunately, one of the major challenges that affect IoT is data quality and
    uncertainty, as data volume increases noise, inconsistency and redundancy increases
    within data and causes paramount issues for IoT technologies. And since IoT is
    considered to be a massive quantity of heterogeneous networked embedded devices
    that generate big data, then it is very complex to compute and analyze such massive
    data. So this paper introduces a new model named NRDD-DBSCAN based on DBSCAN algorithm
    and using resilient distributed datasets (RDDs) to detect outliers that affect
    the data quality of IoT technologies. NRDD-DBSCAN has been applied on three different
    datasets of N-dimensions (2-D, 3-D, and 25-D) and the results were promising.
    Finally, comparisons have been made between NRDD-DBSCAN and previous models such
    as RDD-DBSCAN model and DBSCAN algorithm, and these comparisons proved that NRDD-DBSCAN
    solved the low dimensionality issue of RDD-DBSCAN model and also solved the fact
    that DBSCAN algorithm cannot handle IoT data. So the conclusion is that NRDD-DBSCAN
    proposed model can detect the outliers that exist in the datasets of N-dimensions
    by using resilient distributed datasets (RDDs), and NRDD-DBSCAN can enhance the
    quality of data exists in IoT applications and technologies.
  Author: Haitham Ghallab and Hanan Fahmy and Mona Nasr
  Book_Title_Journal: Egyptian Informatics Journal
  DOI: https://doi.org/10.1016/j.eij.2019.12.001
  JCS_FACTOR: 3.943
  Keywords: Internet of things, IoT, Big data, Data quality, Outliers Detection, DBSCAN,
    RDDs
  SCI_FACTOR: 0.728
  Title: Detection outliers on internet of things using big data technology
  Title_JCS: Egyptian Informatics Journal
  Title_SCI: Egyptian Informatics Journal
  Type_Publication: article
  Year: 2020
- Abstract: The past decade has seen tremendous development in digital health, including
    in innovative new technologies such as Electronic Health Records, telemedicine,
    virtual visits, wearable technology and sophisticated analytical tools such as
    artificial intelligence (AI) and machine learning for the deep-integration of
    big data. In the field of rare connective tissue diseases (rCTDs), these opportunities
    include increased access to scarce and remote expertise, improved patient monitoring,
    increased participation and therapeutic adherence, better patient outcomes and
    patient empowerment. In this review, we discuss opportunities and key-barriers
    to improve application of digital health technologies in the field of autoimmune
    diseases. We also describe what could be the fully digital pathway of rCTD patients.
    Smart technologies can be used to provide real-world evidence about the natural
    history of rCTDs, to determine real-life drug utilization, advanced efficacy and
    safety data for rare diseases and highlight significant unmet needs. Yet, digitalization
    remains one of the most challenging issues faced by rCTD patients, their physicians
    and healthcare systems. Digital health technologies offer enormous potential to
    improve autoimmune rCTD care but this potential has so far been largely unrealized
    due to those significant obstacles. The need for robust assessments of the efficacy,
    affordability and scalability of AI in the context of digital health is crucial
    to improve the care of patients with rare autoimmune diseases.
  Author: "Hugo Bergier and Lo\xC3\xAFc Duron and Christelle Sordet and Lou Kawka\
    \ and Aur\xC3\xA9lien Schlencker and Fran\xC3\xA7ois Chasset and Laurent Arnaud"
  Book_Title_Journal: Autoimmunity Reviews
  DOI: https://doi.org/10.1016/j.autrev.2021.102864
  JCS_FACTOR: 9.754
  Keywords: Autoimmune diseases, Digital technology, Big data, Delivery of health
    care, Telemedicine
  SCI_FACTOR: 2.621
  Title: 'Digital health, big data and smart technologies for the care of patients
    with systemic autoimmune diseases: Where do we stand?'
  Title_JCS: AUTOIMMUNITY REVIEWS
  Title_SCI: Autoimmunity Reviews
  Type_Publication: article
  Year: 2021
- Abstract: The establishment of an accurate battery model is of great significance
    to improve the reliability of electric vehicles (EVs). However, the battery is
    a complex electrochemical system with hardly observable and simulatable internal
    chemical reactions, and it is challenging to estimate the state of battery accurately.
    This paper proposes a novel flexible and reliable battery management method based
    on the battery big data platform and Cyber-Physical System (CPS) technology. First
    of all, to integrate the battery big data resources in the cloud, a Cyber-physical
    battery management framework is defined and served as the basic data platform
    for battery modeling issues. And to improve the quality of the collected battery
    data in the database, this work reports the first attempt to develop an adaptive
    data cleaning method for the cloud battery management issue. Furthermore, a deep
    learning algorithm-based feature extraction model, as well as a feature-oriented
    battery modeling method, is developed to mitigate the under-fitting problem and
    improve the accuracy of the cloud-based battery model. The actual operation data
    of electric buses is used to validate the proposed methodologies. The maximum
    data restoring error can be limited within 1.3% in the experiments, which indicates
    that the proposed data cleaning method is able to improve the cloud battery data
    quality effectively. Meanwhile, the maximum SoC estimation error in the proposed
    feature-oriented battery modeling method is within 2.47%, which highlights the
    effectiveness of the proposed method.
  Author: Shuangqi Li and Pengfei Zhao
  Book_Title_Journal: Journal of Energy Storage
  DOI: https://doi.org/10.1016/j.est.2020.102064
  JCS_FACTOR: 6.583
  Keywords: Electric vehicles, Battery energy storage, Cyber-physical battery management
    system, Big data, Deep learning
  SCI_FACTOR: 1.088
  Title: 'Big data driven vehicle battery management method: A novel cyber-physical
    system perspective'
  Title_JCS: Journal of Energy Storage
  Title_SCI: Journal of Energy Storage
  Type_Publication: article
  Year: 2021
- Abstract: "We live in an interconnected and pervasive world where huge amount of\
    \ data are collected every second. Fully exploiting data through advanced analytics,\
    \ machine learning and artificial intelligence, becomes crucial for businesses,\
    \ from micro to large enterprises, resulting in a key advantage (or shortcoming)\
    \ in the global market competition, as well as in a strong market driver for business\
    \ analytics solutions. This scenario is deeply changing the security landscape,\
    \ introducing new risks and threats that affect security and privacy of systems,\
    \ on one side, and safety of users, on the other side. Many domains that can benefit\
    \ from novel solutions based on data analytics have stringent security requirements\
    \ to fulfill. The Energy domain\xE2\u20AC\u2122s Smart Grid is a major example\
    \ of systems at the crossroads of security and data-driven intelligence. The Smart\
    \ Grid plays a crucial role in modern energy infrastructure. However, it must\
    \ face two major challenges related to security: managing front-end intelligent\
    \ devices such as power assets and smart meters securely, and protecting the huge\
    \ amount of data received from these devices. Starting from these considerations,\
    \ setting up proper analytics is a complex problem because security controls could\
    \ have the undesired side effect of decreasing the accuracy of the analytics themselves.\
    \ This is even more critical when the configuration of security controls is let\
    \ to the security expert, who often has only basic skills in data science. In\
    \ this paper, we propose a solution based on the concept of Model-Based Big Data\
    \ Analytics-as-a-Service (MBDAaaS) that bridges the gap between security experts\
    \ and data scientists. Our solution acts as a middleware allowing a security expert\
    \ and a data scientist to collaborate to the deployment of an analytics addressing\
    \ their needs."
  Author: Claudio A. Ardagna and Valerio Bellandi and Ernesto Damiani and Michele
    Bezzi and Cedric Hebert
  Book_Title_Journal: Computers & Electrical Engineering
  DOI: https://doi.org/10.1016/j.compeleceng.2021.107215
  JCS_FACTOR: 3.818
  Keywords: Artificial intelligence, Big Data Analytics, Machine learning, Security
    and privacy
  SCI_FACTOR: 0.0
  Title: 'Big Data Analytics-as-a-Service: Bridging the gap between security experts
    and data scientists'
  Title_JCS: COMPUTERS & ELECTRICAL ENGINEERING
  Title_SCI: N/A
  Type_Publication: article
  Year: 2021
- Abstract: "Information systems (IS) research has explored \xE2\u20AC\u0153effective\
    \ use\xE2\u20AC\x9D in a variety of contexts. However, it is yet to specifically\
    \ consider it in the context of the unique characteristics of big data. Yet, organizations\
    \ have a high appetite for big data, and there is growing evidence that investments\
    \ in big data solutions do not always lead to the derivation of intended value.\
    \ Accordingly, there is a need for rigorous academic guidance on what factors\
    \ enable effective use of big data. With this paper, we aim to guide IS researchers\
    \ such that the expansion of the body of knowledge on the effective use of big\
    \ data can proceed in a structured and systematic manner and can subsequently\
    \ lead to empirically driven guidance for organizations. Namely, with this paper,\
    \ we cast a wide net to understand and consolidate from literature the potential\
    \ factors that can influence the effective use of big data, so they may be further\
    \ studied. To do so, we first conduct a systematic literature review. Our review\
    \ identifies 41 factors, which we categorize into 7 themes, namely data quality;\
    \ data privacy and security and governance; perceived organizational benefit;\
    \ process management; people aspects; systems, tools, and technologies; and organizational\
    \ aspects. To explore the existence of these themes in practice, we then analyze\
    \ 45 published case studies that document insights into how specific companies\
    \ use big data successfully. Finally, we propose a framework for the study of\
    \ effective use of big data as a basis for future research. Our contributions\
    \ aim to guide researchers in establishing the relevance and relationships within\
    \ the identified themes and factors and are a step toward developing a deeper\
    \ understanding of effective use of big data."
  Author: Feliks P. Sejahtera Surbakti and Wei Wang and Marta Indulska and Shazia
    Sadiq
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2019.02.001
  JCS_FACTOR: 7.555
  Keywords: Big data, Effective use, Factors, Framework
  SCI_FACTOR: 0.0
  Title: 'Factors influencing effective use of big data: A research framework'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: "Information systems (IS) research has explored \xE2\u20AC\u0153effective\
    \ use\xE2\u20AC\x9D in a variety of contexts. However, it is yet to specifically\
    \ consider it in the context of the unique characteristics of big data. Yet, organizations\
    \ have a high appetite for big data, and there is growing evidence that investments\
    \ in big data solutions do not always lead to the derivation of intended value.\
    \ Accordingly, there is a need for rigorous academic guidance on what factors\
    \ enable effective use of big data. With this paper, we aim to guide IS researchers\
    \ such that the expansion of the body of knowledge on the effective use of big\
    \ data can proceed in a structured and systematic manner and can subsequently\
    \ lead to empirically driven guidance for organizations. Namely, with this paper,\
    \ we cast a wide net to understand and consolidate from literature the potential\
    \ factors that can influence the effective use of big data, so they may be further\
    \ studied. To do so, we first conduct a systematic literature review. Our review\
    \ identifies 41 factors, which we categorize into 7 themes, namely data quality;\
    \ data privacy and security and governance; perceived organizational benefit;\
    \ process management; people aspects; systems, tools, and technologies; and organizational\
    \ aspects. To explore the existence of these themes in practice, we then analyze\
    \ 45 published case studies that document insights into how specific companies\
    \ use big data successfully. Finally, we propose a framework for the study of\
    \ effective use of big data as a basis for future research. Our contributions\
    \ aim to guide researchers in establishing the relevance and relationships within\
    \ the identified themes and factors and are a step toward developing a deeper\
    \ understanding of effective use of big data."
  Author: Feliks P. Sejahtera Surbakti and Wei Wang and Marta Indulska and Shazia
    Sadiq
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2019.02.001
  JCS_FACTOR: 7.555
  Keywords: Big data, Effective use, Factors, Framework
  SCI_FACTOR: 0.0
  Title: 'Factors influencing effective use of big data: A research framework'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: This study aims to provide a comprehensive network analysis to understand
    the current state of big data research in tourism by investigating multi-disciplinary
    contributions relevant to big data. A comprehensive network analytical method,
    which includes co-citation, clustering and trend analysis, is applied to systematically
    analyse publications from 2008 to 2017. Two unique data sets from Web of Science
    are collected. The first data set focuses on big data research in tourism and
    hospitality. The second data set involves other disciplines, such as computer
    science, for a comparison with tourism. Results suggest that applications of social
    media and user-generated content are gaining momentum, whereas theory-based studies
    on big data in tourism remain limited. Tourism and other relevant domains have
    similar concerns with the challenges involved in big data, such as privacy, data
    quality and appropriate data use. This comparative network analysis has implications
    for future big data research in tourism.
  Author: Xin Li and Rob Law
  Book_Title_Journal: Tourism Management Perspectives
  DOI: https://doi.org/10.1016/j.tmp.2019.100608
  JCS_FACTOR: 6.586
  Keywords: Big data, Tourism studies, Co-citation analysis, Network analysis, Research
    trends
  SCI_FACTOR: 1.454
  Title: Network analysis of big data research in tourism
  Title_JCS: Tourism Management Perspectives
  Title_SCI: Tourism Management Perspectives
  Type_Publication: article
  Year: 2020
- Abstract: Big data has played an increasingly important role in using data to improve
    business value. In response to several big data challenges, the purpose of this
    study is to identify firm-level capabilities required to create value from big
    data. The adjacent theories of business process management and IT business value
    underpinned the study, together with an in-depth case study that led to the identification
    of twenty-four types of capabilities related to IT, process, performance, human,
    strategic, and organizational practices. The findings confirmed the application
    of practices and capabilities of adjacent theories, as well as certain practices
    and attributes that were both changed and reinforced at the intersection of big
    data. As an outstanding additional support to the extant big data studies, this
    work empirically confirms and portrays hitherto unexplored capabilities of big
    data and set their roles, thus providing a holistic overview of firm-level capabilities
    that are required for big data value creation.
  Author: Morten Brinch and Angappa Gunasekaran and Samuel {Fosso Wamba}
  Book_Title_Journal: Journal of Business Research
  DOI: https://doi.org/10.1016/j.jbusres.2020.07.036
  JCS_FACTOR: 7.55
  Keywords: Big data, Supply chain management, Operations management, Value creation,
    Business analytics, Capabilities
  SCI_FACTOR: 2.049
  Title: Firm-level capabilities towards big data value creation
  Title_JCS: JOURNAL OF BUSINESS RESEARCH
  Title_SCI: Journal of Business Research
  Type_Publication: article
  Year: 2021
- Abstract: "Purpose\nWe present a Health Care System (HCS) based on integrated learning\
    \ to achieve high-efficiency and high-precision integration of medical and health\
    \ big data, and compared it with an internet-based integrated system.\nMethod\n\
    The method proposed in this paper adopts the Bagging integrated learning method\
    \ and the Extreme Learning Machine (ELM) prediction model to obtain a high-precision\
    \ strong learning model. In order to verify the integration efficiency of the\
    \ system, we compare it with the Internet-based health big data integration system\
    \ in terms of integration volume, integration efficiency, and storage space capacity.\n\
    Results\nThe HCS based on integrated learning relies on the Internet in terms\
    \ of integration volume, integration efficiency, and storage space capacity. The\
    \ amount of integration is proportional to the time and the integration time is\
    \ between 170-450\xC2\_ms, which is only half of the comparison system; whereby\
    \ the storage space capacity reaches 8.3\xC3\u201428TB.\nConclusion\nThe experimental\
    \ results show that the integrated learning-based HCS integrates medical and health\
    \ big data with high integration volume and integration efficiency, and has high\
    \ space storage capacity and concurrent data processing performance."
  Author: Yuguang Ye and Jianshe Shi and Daxin Zhu and Lianta Su and Jianlong Huang
    and Yifeng Huang
  Book_Title_Journal: Computer Methods and Programs in Biomedicine
  DOI: https://doi.org/10.1016/j.cmpb.2021.106293
  JCS_FACTOR: 5.428
  Keywords: Integrated learning, Health care system, Elaboration Likelihood Machine,
    System design, Medical big data, Internet of Medical Things
  SCI_FACTOR: 0.924
  Title: 'Management of medical and health big data based on integrated learning-based
    health care system: A review and comparative analysis'
  Title_JCS: COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
  Title_SCI: Computer Methods and Programs in Biomedicine
  Type_Publication: article
  Year: 2021
- Abstract: "Over the last years, big data has emerged as a new paradigm for the processing\
    \ and analysis of massive volumes of data. Big data processing has been combined\
    \ with service and cloud computing, leading to a new class of services called\
    \ \xE2\u20AC\u0153Big Services\xE2\u20AC\x9D. In this new model, services can\
    \ be seen as an abstract layer that hides the complexity of the processed big\
    \ data. To meet users' complex and heterogeneous needs in the era of big data,\
    \ service reuse is a natural and efficient means that helps orchestrating available\
    \ services' operations, to provide customer on-demand big services. However different\
    \ from traditional Web service composition, composing big services refers to the\
    \ reuse of, not only existing high-quality services, but also high-quality data\
    \ sources, while taking into account their security constraints (e.g., data provenance,\
    \ threat level and data leakage). Moreover, composing heterogeneous and large-scale\
    \ data-centric services faces several challenges, apart from security risks, such\
    \ as the big services' high execution time and the incompatibility between providers'\
    \ policies across multiple domains and clouds. Aiming to solve the above issues,\
    \ we propose a scalable approach for big service composition, which considers\
    \ not only the quality of reused services (QoS), but also the quality of their\
    \ consumed data sources (QoD). Since the correct representation of big services\
    \ requirements is the first step towards an effective composition, we first propose\
    \ a quality model for big services and we quantify the data breaches using L-Severity\
    \ metrics. Then to facilitate processing and mining big services' related information\
    \ during composition, we exploit the strong mathematical foundation of fuzzy Relational\
    \ Concept Analysis (fuzzy RCA) to build the big services' repository as a lattice\
    \ family. We also used fuzzy RCA to cluster services and data sources based on\
    \ various criteria, including their quality levels, their domains, and the relationships\
    \ between them. Finally, we define algorithms that parse the lattice family to\
    \ select and compose high-quality and secure big services in a parallel fashion.\
    \ The proposed method, which is implemented on top of Spark big data framework,\
    \ is compared with two existing approaches, and experimental studies proved the\
    \ effectiveness of our big service composition approach in terms of QoD-aware\
    \ composition, scalability, and security breaches."
  Author: Mokhtar Sellami and Haithem Mezni and Mohand Said Hacid
  Book_Title_Journal: Journal of Network and Computer Applications
  DOI: https://doi.org/10.1016/j.jnca.2020.102732
  JCS_FACTOR: 6.281
  Keywords: Big data, Big service, Big service composition, Quality of big services,
    Fuzzy RCA, Spark
  SCI_FACTOR: 1.145
  Title: On the use of big data frameworks for big service composition
  Title_JCS: JOURNAL OF NETWORK AND COMPUTER APPLICATIONS
  Title_SCI: Journal of Network and Computer Applications
  Type_Publication: article
  Year: 2020
- Abstract: 'The future of humanity depends increasingly on the performance of cities.
    Big data provide new and powerful ways of studying and improving coupled urban
    environmental, social, and economic systems to achieve urban sustainability. However,
    the term big data has been defined variably, and its urban applications have so
    far been sporadic in terms of research topic and location. A comprehensive review
    of big data-based urban environment, society, and sustainability (UESS) research
    is much needed. The aim of this study was to summarize the big data-based UESS
    research using a systematic review approach in combination with bibliometric and
    thematic analyses. The results showed that the numbers of publications and citations
    of related articles have been increasing exponentially in recent years. The most
    frequently used big data in UESS research are human behavior data, and the major
    analytical methods are of five types: classification, clustering, regression,
    association rules, and social network analysis. The major research topics of big
    data-based UESS research include urban mobility, urban land use and planning,
    environmental sustainability, public health and safety, social equity, tourism,
    resources and energy utilization, real estate, and retail, accommodation and catering.
    Big data benefit UESS research by proving a people-oriented perspective, timely
    and real-time information, and fine-resolution spatial dynamics. In addition,
    several obstacles were identified to applying big data in UESS research, which
    are related to data quality and acquisition, data storage and management, data
    security and privacy, data cleaning and preprocessing, and data analysis and information
    mining. To move forward, future research should integrate multiple big data sources,
    develop and utilize new methods such as deep learning and cloud computing, and
    expand the application fields to focus on the interactions between human activities
    and urban environments. This review can contribute to understanding the current
    situation of big data-based UESS research, and provide a reference for studies
    of this topic in the future.'
  Author: Lingqiang Kong and Zhifeng Liu and Jianguo Wu
  Book_Title_Journal: Journal of Cleaner Production
  DOI: https://doi.org/10.1016/j.jclepro.2020.123142
  JCS_FACTOR: 9.297
  Keywords: Big data, Social media data, Urban landscape sustainability, Smart city,
    Urban planning
  SCI_FACTOR: 1.937
  Title: 'A systematic review of big data-based urban sustainability research: State-of-the-science
    and future directions'
  Title_JCS: Journal of Cleaner Production
  Title_SCI: Journal of Cleaner Production
  Type_Publication: article
  Year: 2020
- Abstract: Big data initiatives are critical for transforming traditional organizational
    decision making into data-driven decision making. However, prior information systems
    research has not paid enough attention to the impact of big data analytics usage
    on decision-making quality. Drawing on the dynamic capability theory, this study
    investigated the impact of big data analytics usage on decision-making quality
    and tested the mediating effect of data analytics capabilities. We collected data
    from 240 agricultural firms in China. The empirical results showed that big data
    analytics usage had a positive impact on decision-making quality and that data
    analytics capabilities played a mediating role in the relationship between big
    data analytics usage and decision-making quality. Hence, firms should not only
    popularize big data analytics usage in their business activities but also take
    measures to improve their data analytics capabilities, which will improve their
    decision-making quality toward competitive advantages.
  Author: Lei Li and Jiabao Lin and Ye Ouyang and Xin (Robert) Luo
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2021.121355
  JCS_FACTOR: 8.593
  Keywords: Big data analytics usage, Data analytics capabilities, Decision-making
    quality, Agricultural firms
  SCI_FACTOR: 2.226
  Title: Evaluating the impact of big data analytics usage on the decision-making
    quality of organizations
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2022
- Abstract: Today, in a smart manufacturing environment based on the Industry 4.0
    paradigm, people, technological infrastructure and machinery equipped with sensors
    can constantly generate and communicate a huge volume of data, also known as Big
    Data. The manufacturing industry takes advantage of Big Data and analytics evolution
    by improving its capability to bring out valuable information and knowledge from
    industrial processes, production systems and sensors. The adoption of model-based
    frameworks in the Big Data Analytics pipeline can better address user configuration
    requirements (e.g. type of analysis to perform, type of algorithm to be applied)
    and also provide more transparency and clearness on the execution of workflows
    and data processing. In the current state of art, an application of a model-based
    framework in a manufacturing scenario is missing. Therefore, in this study, by
    means of a case study research focused on data from sensors associated with Computer
    Numerical Control machines, the configuration and execution of a Big Data Analytics
    pipeline with a Model-based Big Data Analytics-as-a-Service framework is described.
    The case study provides to theoreticians and managerial experts useful evidence
    for managing real-time data analytics and deploying a workflow that addresses
    specific analytical goals, driven by user requirements and developer models, in
    a complex manufacturing domain.
  Author: Angelo Corallo and Anna Maria Crespino and Mariangela Lazoi and Marianna
    Lezzi
  Book_Title_Journal: Robotics and Computer-Integrated Manufacturing
  DOI: https://doi.org/10.1016/j.rcim.2022.102331
  JCS_FACTOR: 5.666
  Keywords: Big Data Analytics, BDA, MBDAaaS framework, Smart manufacturing, Industry
    4.0, Anomaly detection
  SCI_FACTOR: 1.561
  Title: 'Model-based Big Data Analytics-as-a-Service framework in smart manufacturing:
    A case study'
  Title_JCS: ROBOTICS AND COMPUTER-INTEGRATED MANUFACTURING
  Title_SCI: Robotics and Computer-Integrated Manufacturing
  Type_Publication: article
  Year: 2022
- Abstract: Personal big data can greatly promote social management, business applications,
    and personal services, and bring certain economic benefits to users. The difficulty
    with personal big data security and privacy protection lies in realizing the maximization
    of the value of personal big data and in striking a balance between data privacy
    protection and sharing on the premise of satisfying personal big data security
    and privacy protection. Thus, in this paper, we propose a personal big data pricing
    method based on differential privacy (PMDP). We design two different mechanisms
    of positive and reverse pricing to reasonbly price personal big data. We perform
    aggregate statistics on an open dataset and extensively evaluated its performance.
    The experimental results show that PMDP can provide reasonable pricing for personal
    big data and fair compensation to data owners, ensuring an arbitrage-free condition
    and finding a balance between privacy protection and data utility.
  Author: Yuncheng Shen and Bing Guo and Yan Shen and Xuliang Duan and Xiangqian Dong
    and Hong Zhang and Chuanwu Zhang and Yuming Jiang
  Book_Title_Journal: Computers & Security
  DOI: https://doi.org/10.1016/j.cose.2021.102529
  JCS_FACTOR: 4.438
  Keywords: Personal big data, Data privacy, Privacy protection, Differential privacy,
    Positive pricing, Reverse pricing, Privacy budget, Privacy compensation
  SCI_FACTOR: 0.0
  Title: Personal big data pricing method based on differential privacy
  Title_JCS: COMPUTERS & SECURITY
  Title_SCI: N/A
  Type_Publication: article
  Year: 2022
- Abstract: "Despite great potential, high hopes and big promises, the actual impact\
    \ of big data on the public sector is not always as transformative as the literature\
    \ would suggest. In this paper, we ascribe this predicament to an overly strong\
    \ emphasis the current literature places on technical-rational factors at the\
    \ expense of political decision-making factors. We express these two different\
    \ emphases as two archetypical narratives and use those to illustrate that some\
    \ political decision-making factors should be taken seriously by critiquing some\
    \ of the core \xE2\u20AC\u02DCtechno-optimist\xE2\u20AC\u2122 tenets from a more\
    \ \xE2\u20AC\u02DCpolicy-pessimist\xE2\u20AC\u2122 angle. In the conclusion we\
    \ have these two narratives meet \xE2\u20AC\u02DCeye-to-eye\xE2\u20AC\u2122, facilitating\
    \ a more systematized interrogation of big data promises and shortcomings in further\
    \ research, paying appropriate attention to both technical-rational and political\
    \ decision-making factors. We finish by offering a realist rejoinder of these\
    \ two narratives, allowing for more context-specific scrutiny and balancing both\
    \ technical-rational and political decision-making concerns, resulting in more\
    \ realistic expectations about using big data for policymaking in practice."
  Author: Simon Vydra and Bram Klievink
  Book_Title_Journal: Government Information Quarterly
  DOI: https://doi.org/10.1016/j.giq.2019.05.010
  JCS_FACTOR: 7.279
  Keywords: Big data, Analytics, Government, Public administration, Policy-making,
    Decision-making, Science-policy interface, Network governance
  SCI_FACTOR: 2.121
  Title: Techno-optimism and policy-pessimism in the public sector big data debate
  Title_JCS: GOVERNMENT INFORMATION QUARTERLY
  Title_SCI: Government Information Quarterly
  Type_Publication: article
  Year: 2019
- Abstract: "This paper examines the challenges of leveraging big data in the humanitarian\
    \ sector in support of UN Sustainable Development Goal 17 \xE2\u20AC\u0153Partnerships\
    \ for the Goals\xE2\u20AC\x9D. The full promise of Big Data is underpinned by\
    \ a tacit assumption that the heterogeneous \xE2\u20AC\u02DCexhaust trail\xE2\u20AC\
    \u2122 of data is contextually relevant and sufficiently granular to be mined\
    \ for value. This promise, however, relies on relationality \xE2\u20AC\u201C that\
    \ patterns can be derived from combining different pieces of data that are of\
    \ corresponding detail or that there are effective mechanisms to resolve differences\
    \ in detail. Here, we present empirical work integrating eight heterogeneous datasets\
    \ from the humanitarian domain to provide evidence of the inherent challenge of\
    \ complexity resulting from differing levels of data granularity. In clarifying\
    \ this challenge, we explore the reasons why it is manifest, discuss strategies\
    \ for addressing it and, as our principal contribution, identify five propositions\
    \ to guide future research."
  Author: David Bell and Mark Lycett and Alaa Marshan and Asmat Monaghan
  Book_Title_Journal: Journal of Business Research
  DOI: https://doi.org/10.1016/j.jbusres.2020.09.035
  JCS_FACTOR: 7.55
  Keywords: Big data, Veracity, Granularity, Heterogeneous datasets, Humanitarian,
    Value
  SCI_FACTOR: 2.049
  Title: Exploring future challenges for big data in the humanitarian domain
  Title_JCS: JOURNAL OF BUSINESS RESEARCH
  Title_SCI: Journal of Business Research
  Type_Publication: article
  Year: 2021
- Abstract: Digital twin takes Industrial Internet as a carrier deeply coordinating
    and integrating virtual spaces with physical spaces, which effectively promotes
    smart factory development. Digital twin-based big data learning and analysis (BDLA)
    deepens virtual and real fusion, interaction and closed-loop iterative optimization
    in smart factories. This paper proposes a digital twin-based big data virtual
    and real fusion (DT-BDVRL) reference framework supported by Industrial Internet
    towards smart manufacturing. The reference framework is synthetically designed
    from three perspectives. The first one is an overall framework of DT-BDVRL supported
    by Industrial Internet. The second one is the establishment method and flow of
    BDLA models based on digital twin. The final one is digital thread of DT-BDVRL
    in virtual and real fusion analysis, iteration and closed-loop feedback in product
    full life cycle processes. For different virtual scenes, iterative optimization
    and verification methods and processes of BDLA models in virtual spaces are established.
    Moreover, the BDLA results can drive digital twin running in virtual spaces. By
    this, the BDLA results can be validated iteratively multiple times in virtual
    spaces. At same time, the BDLA results that run in virtual spaces are synchronized
    and executed in physical spaces through Industrial Internet platforms, effectively
    improving the physical execution effect of BDLA models. Finally, the above contents
    were applied and verified in the actual production case study of power switchgear
    equipment.
  Author: Pei Wang and Ming Luo
  Book_Title_Journal: Journal of Manufacturing Systems
  DOI: https://doi.org/10.1016/j.jmsy.2020.11.012
  JCS_FACTOR: 8.633
  Keywords: Virtual and real fusion learning, Big data learning and analysis models,
    Digital twin, Industrial internet, Smart manufacturing
  SCI_FACTOR: 2.31
  Title: A digital twin-based big data virtual and real fusion learning reference
    framework supported by industrial internet towards smart manufacturing
  Title_JCS: JOURNAL OF MANUFACTURING SYSTEMS
  Title_SCI: Journal of Manufacturing Systems
  Type_Publication: article
  Year: 2021
- Abstract: 'Urban big data fusion creates huge values for urban computing in solving
    urban problems. In recent years, various models and algorithms based on deep learning
    have been proposed to unlock the power of knowledge from urban big data. To clarify
    the methodologies of urban big data fusion based on deep learning (DL), this paper
    classifies them into three categories: DL-output-based fusion, DL-input-based
    fusion and DL-double-stage-based fusion. These methods use deep learning to learn
    feature representation from multi-source big data. Then each category of fusion
    methods is introduced and some examples are shown. The difficulties and ideas
    of dealing with urban big data will also be discussed.'
  Author: Jia Liu and Tianrui Li and Peng Xie and Shengdong Du and Fei Teng and Xin
    Yang
  Book_Title_Journal: Information Fusion
  DOI: https://doi.org/10.1016/j.inffus.2019.06.016
  JCS_FACTOR: 12.975
  Keywords: Urban computing, Big data, Data fusion, Deep learning
  SCI_FACTOR: 2.776
  Title: 'Urban big data fusion based on deep learning: An overview'
  Title_JCS: Information Fusion
  Title_SCI: Information Fusion
  Type_Publication: article
  Year: 2020
- Abstract: Big Data represents a promising area for value creation and frontier research.
    The potential to extract actionable insights from Big Data has gained increasing
    attention of both academics and practitioners operating in several industries.
    Marketing domain has become from the start a field for experiments with Big Data
    approaches, even if the adoption of Big Data solutions does not always generate
    effective value for the adopters. Therefore, the gap existing between the potential
    of value creation embedded in the Big Data paradigm and the current limited exploitation
    of this value represents an area of investigation that this paper aims to explore.
    In particular, by following a systematic literature review, this study aims at
    presenting a framework that outlines the multiple value directions that the Big
    Data paradigm can generate for the adopting organizations. Eleven distinct value
    directions have been identified and then grouped in five dimensions (Informational,
    Transactional, Transformational, Strategic, Infrastructural Value), which constitute
    the pillars of the proposed framework. Finally, the framework has been also preliminarily
    applied in three case studies conducted within three Italian based companies operating
    in different industries (e-commerce, fast-moving consumer goods, and banking)
    in the final aim to see its applicability in real business scenarios.
  Author: Gianluca Elia and Gloria Polimeno and Gianluca Solazzo and Giuseppina Passiante
  Book_Title_Journal: Industrial Marketing Management
  DOI: https://doi.org/10.1016/j.indmarman.2020.03.015
  JCS_FACTOR: 6.96
  Keywords: Big Data analytics, Cognitive computing, Framework, Model, Systematic
    literature review, Value creation
  SCI_FACTOR: 2.022
  Title: A multi-dimension framework for value creation through Big Data
  Title_JCS: INDUSTRIAL MARKETING MANAGEMENT
  Title_SCI: Industrial Marketing Management
  Type_Publication: article
  Year: 2020
- Abstract: Pediatric cancer is a rare disease with a low annual incidence, which
    presents a significant challenge in being able to collect enough data to fuel
    clinical discoveries. Big data registry trials hold promise to advance the study
    of pediatric cancers by allowing for the combination of traditional randomized
    controlled trials with the power of larger cohort sizes. The emergence of big
    data resources and data-sharing initiatives are becoming transformative for pediatric
    cancer diagnosis and treatment. This review discusses the uses of big data in
    pediatric cancer, existing pediatric cancer registry initiatives and research,
    the challenges in harmonizing these data to improve accessibility for study, and
    building pediatric data commons and other important future endeavors.
  Author: Ajay Major and Suzanne M. Cox and Samuel L. Volchenboum
  Book_Title_Journal: Seminars in Oncology
  DOI: https://doi.org/10.1053/j.seminoncol.2020.02.006
  JCS_FACTOR: 4.929
  Keywords: Pediatric oncology, Pediatric cancer, Big data, Data sharing, Data science,
    Informatics
  SCI_FACTOR: 1.812
  Title: 'Using big data in pediatric oncology: Current applications and future directions'
  Title_JCS: SEMINARS IN ONCOLOGY
  Title_SCI: Seminars in Oncology
  Type_Publication: article
  Year: 2020
- Abstract: Nowadays, the world knows a high-speed development and evolution of technologies,
    vulnerable economic environments, market changes, and personalised consumer trends.
    The issue and challenge related to enterprises networks design are more and more
    critical. These networks are often designed for short terms since their strategies
    must be competitive and better adapted to the environment, social and economical
    changes. As a solution, to design a flexible and robust network, it is necessary
    to deal with the trade-off between conflicting qualitative and quantitative criteria
    such as cost, quality, delivery time, and competition, etc. To this end, using
    Big Data (BD) as emerging technology will enhance the real performances of these
    kinds of networks. Moreover, even if the literature is rich with BD models and
    frameworks developed for a single supply chain network (SCN), there is a real
    need to scale and extend these BD models to networked supply chains (NSCs). To
    do so, this paper proposes a BD architecture to drive a mixed-network of SCs that
    collaborate in serial and parallel fashions. The collaboration is set up by sharing
    their resources, capabilities, competencies, and information to imitate a unique
    organisation. The objective is to increase internal value to their shareholders
    (where value is seen as wealth) and deliver better external value to the end-customer
    (where value represents customer satisfaction). Within a mixed-network of SCs,
    both values are formally calculated considering both serial and parallel networks
    configurations. Besides, some performance factors of the proposed BD architecture
    such as security, flexibility, robustness and resilience are discussed.
  Author: Lahcen Tamym and Lyes Benyoucef and Ahmed {Nait Sidi Moh} and Moulay Driss
    {El Ouadghiri}
  Book_Title_Journal: Computer Communications
  DOI: https://doi.org/10.1016/j.comcom.2021.05.008
  JCS_FACTOR: 3.167
  Keywords: Big data architecture, Collaborative networks, Enterprises network, Supply
    chain network, Flexibility, Robustness
  SCI_FACTOR: 0.627
  Title: 'A big data based architecture for collaborative networks: Supply chains
    mixed-network'
  Title_JCS: COMPUTER COMMUNICATIONS
  Title_SCI: Computer Communications
  Type_Publication: article
  Year: 2021
- Abstract: The existing prediction model of eco-environmental water demand has the
    problem of large prediction error. In order to solve the above problems, the prediction
    model of eco-environmental water demand is constructed based on big data analysis.
    In order to reduce the prediction error of the ecological environment water demand
    prediction model, the framework of the ecological environment water demand prediction
    model is built. On this basis, the principal component analysis method is used
    to select the auxiliary variables of the model. Based on the selected auxiliary
    variables, the minimum monthly average flow method is used to analyze the basic
    water demand of the ecological environment, the leakage water demand and the water
    surface evaporation ecological environment water demand, so as to analyze based
    on the results, the water demand of ecological environment is predicted by big
    data analysis technology, and the prediction of water demand of ecological environment
    is realized. The experimental results show that compared with the existing ecological
    environment water demand prediction model, the prediction error of the model is
    within 19.3, which fully shows that the constructed ecological environment water
    demand prediction model has better prediction effect and can provide a certain
    reference value for the actual use of water resources.
  Author: Lihong Zhao
  Book_Title_Journal: Environmental Technology & Innovation
  DOI: https://doi.org/10.1016/j.eti.2020.101196
  JCS_FACTOR: 5.263
  Keywords: Big data analysis, Ecological environment, Water demand, Prediction
  SCI_FACTOR: 0.0
  Title: Prediction model of ecological environmental water demand based on big data
    analysis
  Title_JCS: Environmental Technology & Innovation
  Title_SCI: N/A
  Type_Publication: article
  Year: 2021
- Abstract: 'The application of the optimisation problems in the daily decisions of
    companies is able to be used for finding the best management according to the
    necessities of the organisations. However, optimisation problems imply a high
    computational complexity, increased by the current necessity to include a massive
    quantity of data (Big Data), for the creation of optimisation problems to customise
    products and services for their clients. The irruption of Big Data technologies
    can be a challenge but also an important mechanism to tackle the computational
    difficulties of optimisation problems, and the possibility to distribute the problem
    performance. In this paper, we propose a solution that lets the query of a data
    set supported by Big Data technologies that imply the resolution of Constraint
    Optimisation Problem (COP). This proposal enables to: (1) model COPs whose input
    data are obtained from distributed and heterogeneous data; (2) facilitate the
    integration of different data sources to create the COPs; and, (3) solve the optimisation
    problems in a distributed way, to improve the performance. It is done by means
    of a framework and supported by a tool capable of modelling, solving and querying
    the results of optimisation problems. The tool integrates the Big Data technologies
    and commercial solvers of constraint programming. The suitability of the proposal
    and the development have been evaluated with real data sets whose computational
    study and results are included and discussed.'
  Author: "\xC3\x81lvaro Valencia-Parra and \xC3\x81ngel Jes\xC3\xBAs Varela-Vaca\
    \ and Luisa Parody and Mar\xC3\xADa Teresa G\xC3\xB3mez-L\xC3\xB3pez"
  Book_Title_Journal: Journal of Computational Science
  DOI: https://doi.org/10.1016/j.jocs.2020.101180
  JCS_FACTOR: 3.976
  Keywords: Big Data, Optimisation problem, Constraint programming, Distributed data,
    Heterogeneous data format
  SCI_FACTOR: 0.704
  Title: Unleashing Constraint Optimisation Problem solving in Big Data environments
  Title_JCS: Journal of Computational Science
  Title_SCI: Journal of Computational Science
  Type_Publication: article
  Year: 2020
- Abstract: 'While commerce is one of the key activities in cities, its spatial description
    still requires further attention, especially by considering the different dimensions
    of commercial space: physical, economic and socio-symbolic. The latter is becoming
    more and more important in an era where consumption is at the centre of social
    relations. Further, although data availability has been an enduring obstacle in
    commercial research, we are witnessing the advent of new data sources, and social-network
    big data is an opportunity to unveil the places to which consumers attribute prestige
    or symbolic capital, at the extent of entire metropolitan areas. This paper compares
    the physical, economic and socio-symbolic dimensions of commercial spaces through
    the analysis of three different commercial data sources: cadastral micro-data,
    business register and social-network big data. For the case of Madrid Metropolitan
    Area, the three databases are compared with correlation analysis and density maps,
    coming out as partly redundant and partly complementary. Getis-Ord''s hotspot
    statistics integrated into a cluster analysis enable a comprehensive understanding
    of commercial environments, enriching previous spatial hierarchies. The spatial
    distribution of symbolic capital unveils a relation with socio-spatial segregation
    and paves the way to new reflections on the spatiality of consumption as a social
    practice.'
  Author: "Jos\xC3\xA9 Carpio-Pinedo and Javier Guti\xC3\xA9rrez"
  Book_Title_Journal: Cities
  DOI: https://doi.org/10.1016/j.cities.2020.102859
  JCS_FACTOR: 5.835
  Keywords: Commercial space, Retail, Retail geography, Symbolic capital, Big data,
    Foursquare, Madrid
  SCI_FACTOR: 1.771
  Title: "Consumption and symbolic capital in the metropolitan space: Integrating\
    \ \xE2\u20AC\u02DCold\xE2\u20AC\u2122 retail data sources with social big data"
  Title_JCS: CITIES
  Title_SCI: Cities
  Type_Publication: article
  Year: 2020
- Abstract: With current decentralization trends and polycentric planning efforts,
    the urban spatial structures of Chinese cities have been changing tremendously.
    To detect the true urban polycentric pattern of Chinese cities, this article analyzed
    the urban polycentricity characteristics of 294 cities. The natural cities were
    delineated by points of interest (POIs), and road networks constituted street
    blocks. Based on check-in data and new spatial units, centers within both metropolitan
    areas and central cities were identified and examined. We discovered that all
    Chinese cities have at least one natural city in their metropolitan areas because
    of rapid urban sprawl. Although a monocentric structure is still the most common
    urban spatial structure, 110 Chinese cities displayed different degrees of polycentricity
    at the metropolitan level. Many natural cities beyond central cities contribute
    to polycentric development at the metropolitan level. Central cities have maintained
    their original vitality and importance, most Chinese cities have dispersed urban
    structures in central cities, and 45 central cities are polycentric. The spatial
    structures in metropolitan areas are more polycentric than those in central cities.
    The only 36 cities with polycentric urban structures at both the metropolitan
    and central city levels are all national or regional central cities in eastern
    China.
  Author: Yongqiang Lv and Lin Zhou and Guobiao Yao and Xinqi Zheng
  Book_Title_Journal: Cities
  DOI: https://doi.org/10.1016/j.cities.2021.103298
  JCS_FACTOR: 5.835
  Keywords: Polycentricity, Urban centers, Multi-scale, Street blocks, Geospatial
    big data, Chinese cities
  SCI_FACTOR: 1.771
  Title: 'Detecting the true urban polycentric pattern of Chinese cities in morphological
    dimensions: A multiscale analysis based on geospatial big data'
  Title_JCS: CITIES
  Title_SCI: Cities
  Type_Publication: article
  Year: 2021
- Abstract: 'The purpose of this study is to enrich the existing state-of-the-art
    literature on the impact of big data on business growth by examining how dozens
    of organizational theories can be applied to enhance the understanding of the
    effects of big data on organizational performance. While the majority of management
    disciplines have had research dedicated to the conceptual discussion of how to
    link a variety of organizational theories to empirically quantified research topics,
    the body of research into big data so far lacks an academic work capable of systematising
    the organizational theories supporting big data domain. The three main contributions
    of this work are: (a) it addresses the application of dozens of organizational
    theories to big data research; (b) it offers a research agenda on how to link
    organizational theories to empirical research in big data; and (c) it foresees
    promising linkages between organizational theories and the effects of big data
    on organizational performance, with the aim of contributing to further research
    in this field. This work concludes by presenting implications for researchers
    and managers, and by highlighting intrinsic limitations of the research.'
  Author: Paula {de Camargo Fiorini} and Bruno Michel {Roman Pais Seles} and Charbel
    Jose {Chiappetta Jabbour} and Enzo {Barberio Mariano} and Ana Beatriz Lopes {de
    Sousa Jabbour}
  Book_Title_Journal: International Journal of Information Management
  DOI: https://doi.org/10.1016/j.ijinfomgt.2018.07.005
  JCS_FACTOR: 14.098
  Keywords: "Big data, Big data analytics, Organizational theory, Firms\xE2\u20AC\u2122\
    \ performance, Research agenda"
  SCI_FACTOR: 2.77
  Title: 'Management theory and big data literature: From a review to a research agenda'
  Title_JCS: INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
  Title_SCI: International Journal of Information Management
  Type_Publication: article
  Year: 2018
- Abstract: Over recent years, the frequency and intensity of droughts have increased
    and there has been a large drying trend over many parts of the world. Consequently,
    drought monitoring using big data analytic has gained an explosive interest. Droughts
    stand among the most damaging natural disasters. It threatens agricultural production,
    ecological environment, and socio-economic development. For this reason, early
    warning, accurate evaluation, and efficient prediction are an emergency especially
    for the nations that are the most menaced by this danger. There are numerous emerging
    studies addressing big data and its applications in drought monitoring. In fact,
    big data handle data heterogeneity which is an additive value for the prediction
    of drought, it offers a view of the different dimensions such as the spatial distribution,
    the temporal distribution and the severity detection of this phenomenon. Big data
    analytic and drought are introduced and reviewed in this paper. Besides, this
    review includes different studies, researches and applications of big data to
    drought monitoring. Challenges related to data life cycle such as data challenges,
    data processing challenges and data infrastructure management challenges are also
    discussed. Finally, we conclude that big data analytic can be beneficial in drought
    monitoring but there is a need for statistical and artificial intelligence-based
    approaches.
  Author: Hanen Balti and Ali {Ben Abbes} and Nedra Mellouli and Imed Riadh Farah
    and Yanfang Sang and Myriam Lamolle
  Book_Title_Journal: Ecological Informatics
  DOI: https://doi.org/10.1016/j.ecoinf.2020.101136
  JCS_FACTOR: 3.142
  Keywords: Drought monitoring, Artificial intelligence, Big data, Machine learning,
    Statistical approach, Remote sensing
  SCI_FACTOR: 0.774
  Title: 'A review of drought monitoring with big data: Issues, methods, challenges
    and research directions'
  Title_JCS: Ecological Informatics
  Title_SCI: Ecological Informatics
  Type_Publication: article
  Year: 2020
- Abstract: "Data collection is an important process in the life cycle of big data\
    \ processing. It is the key part that must be completed first in all kinds of\
    \ data applications, which determines the results of data analysis and application\
    \ service quality. However, untrusted data sources and transmission links expose\
    \ the data collection process to attacks and malicious threats such as counterfeiting,\
    \ replay, and denial of service, and ultimately lead to untrustworthy data. In\
    \ order to cope with the threat of data collection process and ensure data quality,\
    \ this paper proposes trust evaluation scheme for data security collection based\
    \ on wireless sensor network, one of the data collection applications, including\
    \ direct trust, recommendation trust, link trust, and backhaul trust. Meanwhile,\
    \ in order to realize the dynamic update of the trust of the data sources, a true\
    \ data discovery and trust dynamic update mechanism based on \xCF\u2030-FCM (Weight\
    \ Fuzzy C-Mean) algorithm is proposed. The results of a large number of simulation\
    \ experiments show that the proposed scheme, model and algorithm can effectively\
    \ evaluate the trust of data sources and ensure the authenticity of the collected\
    \ data."
  Author: Denglong Lv and Shibing Zhu
  Book_Title_Journal: Computers & Security
  DOI: https://doi.org/10.1016/j.cose.2020.101937
  JCS_FACTOR: 4.438
  Keywords: Big data collection, Trust evaluation, Trust model, True data discovery,
    Wireless sensor network
  SCI_FACTOR: 0.0
  Title: Achieving secure big data collection based on trust evaluation and true data
    discovery
  Title_JCS: COMPUTERS & SECURITY
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: The prospering Big data era is emerging in the power grid. Multiple world-wide
    studies are emphasizing the big data applications in the microgrid due to the
    huge amount of produced data. Big data analytics can impact the design and applications
    towards safer, better, more profitable, and effective power grid. This paper presents
    the recognition and challenges of the big data and the microgrid. The construction
    of big data analytics is introduced. The data sources, big data opportunities,
    and enhancement areas in the microgrid like stability improvement, asset management,
    renewable energy prediction, and decision-making support are summarized. Diverse
    case studies are presented including different planning, operation control, decision
    making, load forecasting, data attacks detection, and maintenance aspects of the
    microgrid. Finally, the open challenges of big data in the microgrid are discussed.
  Author: Karim Moharm
  Book_Title_Journal: Advanced Engineering Informatics
  DOI: https://doi.org/10.1016/j.aei.2019.100945
  JCS_FACTOR: 5.603
  Keywords: Big data, Microgrid
  SCI_FACTOR: 1.107
  Title: 'State of the art in big data applications in microgrid: A review'
  Title_JCS: ADVANCED ENGINEERING INFORMATICS
  Title_SCI: Advanced Engineering Informatics
  Type_Publication: article
  Year: 2019
- Abstract: This paper draws on data from three organisational case studies and expert
    interviews to propose that persuasive practices are the precursors and enablers
    of analytical capability development. A bundle of seven practices was identified
    and observed to bridge multiple gaps between technical and non-technical colleagues
    on big data analytics (BDA) projects. The deployment of these practices varied
    according to the level of BDA maturity and featured a host of socio-material elements.
    This paper complements existing technical case studies with a fine-grained qualitative
    account of the managerial and human elements of BDA implementation. Effective
    deployment of persuasive practices potentially both embeds the benefits and mitigates
    the risks of BDA, sowing the seeds of many different forms of value.
  Author: Jeffrey Hughes and Kirstie Ball
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2020.120300
  JCS_FACTOR: 8.593
  Keywords: Big data analytics, Persuasion, Practice, Capabilities, Value
  SCI_FACTOR: 2.226
  Title: Sowing the seeds of value? Persuasive practices and the embedding of big
    data analytics
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2020
- Abstract: Climate change and environmental management are issues of global concern.
    The advent of the era of Big Data has created a new research platform for the
    assessment of environmental governance and policies. However, little is known
    about Big Data application to climate change and environmental management research.
    This paper adopts bibliometric analysis in conjunction with network analysis to
    systematically evaluate the publications on carbon emissions and environmental
    management based on Big Data and Streaming Data using R package and VOSviewer
    software. The analysis involves 274 articles after rigorous screening and includes
    citation analysis, co-citation analysis, and co-word analysis. Main findings include
    (1) Carbon emissions and environmental management based on big data and streaming
    data is an emerging multidisciplinary research topic, which has been applied in
    the fields of computer science, supply chain design, transportation, carbon price
    assessment, environmental policy evaluation, and CO2 emissions reduction. (2)
    This field has attracted the attention of nations which are major contributors
    to the world economy. In particular, European and American scholars have made
    the main contributions to this topic, and Chinese researchers have also had great
    impact. (3) The research content of this topic is primarily divided into four
    categories, including empirical studies of specific industries, air pollution
    governance, technological innovation, and low-carbon transportation. Our findings
    suggest that future research should bring greater depth of practical and modeling
    analysis to environmental policy assessment based on Big Data.
  Author: Yuan Su and Yanni Yu and Ning Zhang
  Book_Title_Journal: Science of The Total Environment
  DOI: https://doi.org/10.1016/j.scitotenv.2020.138984
  JCS_FACTOR: 7.963
  Keywords: Big data, Streaming data, Carbon emission, Environmental management, Bibliometric
    analysis, Net-work analysis
  SCI_FACTOR: 1.795
  Title: 'Carbon emissions and environmental management based on Big Data and Streaming
    Data: A bibliometric analysis'
  Title_JCS: SCIENCE OF THE TOTAL ENVIRONMENT
  Title_SCI: Science of the Total Environment
  Type_Publication: article
  Year: 2020
- Abstract: The complexity that characterises the dynamic nature of the various environmental
    factors makes it very compelling for firms to be capable of addressing the changing
    customers' needs. The current study examines the role of big data in new product
    success. We develop a qualitative research with case study approach to look at
    this. Specifically, we look at multiple cases to get in-depth understanding of
    customer agility for new product success with big data analytics. The findings
    of the study provide insight into the role of customer agility in new product
    success. This study unpacks the interconnectedness of the effective use of data
    aggregation tools, the effectiveness of data analysis tools and customer agility.
    It also explores the link between all of these factors and new product success.
    The study is reasonably telling in that it shows that the effective use of data
    aggregation and data analysis tools results in customer agility which in itself
    explains how an organisation senses and responds speedily to opportunities for
    innovation in the competitive marketing environment. The current study provides
    significant theoretical contributions by providing evidence for the role of big
    data analytics, big data aggregation tools, customer agility, organisational slack
    and environmental turbulence in new product success.
  Author: Nick Hajli and Mina Tajvidi and Ayantunji Gbadamosi and Waqar Nadeem
  Book_Title_Journal: Industrial Marketing Management
  DOI: https://doi.org/10.1016/j.indmarman.2019.09.010
  JCS_FACTOR: 6.96
  Keywords: Big data analytics, Customer agility, Effective use of data, New product
    success
  SCI_FACTOR: 2.022
  Title: Understanding market agility for new product success with big data analytics
  Title_JCS: INDUSTRIAL MARKETING MANAGEMENT
  Title_SCI: Industrial Marketing Management
  Type_Publication: article
  Year: 2020
- Abstract: Research in Big Data and analytics offers tremendous opportunities to
    utilize evidence in making decisions in many application domains. To what extent
    can the paradigms of Big Data and analytics be used in the domain of transport?
    This article reports on an outcome of a systematic review of published articles
    in the last five years that discuss Big Data concepts and applications in the
    transportation domain. The goal is to explore and understand the current research,
    opportunities, and challenges relating to the utilization of Big Data and analytics
    in transportation. The review shows the potential of Big Data and analytics to
    garner insights and improve transportation systems through the analysis of various
    forms of data obtained from traffic monitoring systems, connected vehicles, crowdsourcing,
    and social media. We discuss some platforms and software architecture for the
    transport domain, along with a wide array of storage, processing, and analytical
    techniques, and describe challenges associated with the implementation of Big
    Data and analytics. This review contributes broadly to the various ways in which
    cities can utilize Big Data in transportation to guide the creation of sustainable
    and safer traffic systems. Since research in Big Data and transportation is, by
    and large, at infancy, this article does not prescribe recommendations to the
    various challenges identified, which also constitutes the limitation of the article.
  Author: Alex Neilson and  Indratmo and Ben Daniel and Stevanus Tjandra
  Book_Title_Journal: Big Data Research
  DOI: https://doi.org/10.1016/j.bdr.2019.03.001
  JCS_FACTOR: 3.578
  Keywords: Big Data, Smart city, Intelligent transportation system, Connected vehicle,
    Road traffic safety, Vision Zero
  SCI_FACTOR: 0.565
  Title: 'Systematic Review of the Literature on Big Data in the Transportation Domain:
    Concepts and Applications'
  Title_JCS: Big Data Research
  Title_SCI: Big Data Research
  Type_Publication: article
  Year: 2019
- Abstract: Big Data is one of the recent technological advances with the strong applicability
    in almost every industry, including manufacturing. However, despite business opportunities
    offered by this technology, its adoption is still in early stage in many industries.
    Thus, this study aimed to identify and rank the significant factors influencing
    adoption of big data and in turn to predict the influence of big data adoption
    on manufacturing companies' performance using a hybrid approach of decision-making
    trial and evaluation laboratory (DEMATEL)- adaptive neuro-fuzzy inference systems
    (ANFIS). This study identified the critical adoption factors from literature review
    and categorized them into technological, organizational and environmental dimensions.
    Data was collected from 234 industrial managers who were involved in the decision-making
    process regarding IT procurement in Malaysian manufacturing companies. Research
    results showed that technological factors (perceived benefits, complexity, technology
    resources, big data quality and integration) have the highest influence on the
    big data adoption and firms' performance. This study is one of the pioneers in
    using DEMATEL-ANFIS approach in the big data adoption context. In addition to
    the academic contribution, findings of this study can hopefully assist manufacturing
    industries, big data service providers, and governments to precisely focus on
    vital factors found in this study in order to improve firm performance by adopting
    big data.
  Author: Elaheh Yadegaridehkordi and Mehdi Hourmand and Mehrbakhsh Nilashi and Liyana
    Shuib and Ali Ahani and Othman Ibrahim
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2018.07.043
  JCS_FACTOR: 8.593
  Keywords: Big data, Firm performance, Manufacturing companies, DEMATEL, ANFIS
  SCI_FACTOR: 2.226
  Title: 'Influence of big data adoption on manufacturing companies'' performance:
    An integrated DEMATEL-ANFIS approach'
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2018
- Abstract: "The rapid growth of urban populations worldwide imposes new challenges\
    \ on citizens\xE2\u20AC\u2122 daily lives, including environmental pollution,\
    \ public security, road congestion, etc. New technologies have been developed\
    \ to manage this rapid growth by developing smarter cities. Integrating the Internet\
    \ of Things (IoT) in citizens\xE2\u20AC\u2122 lives enables the innovation of\
    \ new intelligent services and applications that serve sectors around the city,\
    \ including healthcare, surveillance, agriculture, etc. IoT devices and sensors\
    \ generate large amounts of data that can be analyzed to gain valuable information\
    \ and insights that help to enhance citizens\xE2\u20AC\u2122 quality of life.\
    \ Deep Learning (DL), a new area of Artificial Intelligence (AI), has recently\
    \ demonstrated the potential for increasing the efficiency and performance of\
    \ IoT big data analytics. In this survey, we provide a review of the literature\
    \ regarding the use of IoT and DL to develop smart cities. We begin by defining\
    \ the IoT and listing the characteristics of IoT-generated big data. Then, we\
    \ present the different computing infrastructures used for IoT big data analytics,\
    \ which include cloud, fog, and edge computing. After that, we survey popular\
    \ DL models and review the recent research that employs both IoT and DL to develop\
    \ smart applications and services for smart cities. Finally, we outline the current\
    \ challenges and issues faced during the development of smart city services."
  Author: "Safa Ben Atitallah and Maha Driss and Wadii Boulila and Henda Ben Gh\xC3\
    \xA9zala"
  Book_Title_Journal: Computer Science Review
  DOI: https://doi.org/10.1016/j.cosrev.2020.100303
  JCS_FACTOR: 7.872
  Keywords: Internet of Things, Deep Learning, Smart city, Big data analytics, Review
  SCI_FACTOR: 1.646
  Title: 'Leveraging Deep Learning and IoT big data analytics to support the smart
    cities development: Review and future directions'
  Title_JCS: Computer Science Review
  Title_SCI: Computer Science Review
  Type_Publication: article
  Year: 2020
- Abstract: 'ABSTRACT

    The significance of big data analytics-powered artificial intelligence has grown
    in recent years. The literature indicates that big data analytics-powered artificial
    intelligence has the ability to enhance supply chain performance, but there is
    limited research concerning the reasons for which firms engaging in manufacturing
    activities adopt big data analytics-powered artificial intelligence. To address
    this gap, our study employs institutional theory and resource-based view theory
    to elucidate the way in which automotive firms configure tangible resources and
    workforce skills to drive technological enablement and improve sustainable manufacturing
    practices and furthermore develop circular economy capabilities. We tested the
    research hypothesis using primary data collected from 219 automotive and allied
    manufacturing companies operating in South Africa. The contribution of this work
    lies in the statistical validation of the theoretical framework, which provides
    insight regarding the role of institutional pressures on resources and their effects
    on the adoption of big data analytics-powered artificial intelligence, and how
    this affects sustainable manufacturing and circular economy capabilities under
    the moderating effects of organizational flexibility and industry dynamism.'
  Author: Surajit Bag and Jan Ham Christiaan Pretorius and Shivam Gupta and Yogesh
    K. Dwivedi
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2020.120420
  JCS_FACTOR: 8.593
  Keywords: Big data, Artificial intelligence, Industry 4.0, Circular economy, Sustainable
    manufacturing
  SCI_FACTOR: 2.226
  Title: Role of institutional pressures and resources in the adoption of big data
    analytics powered artificial intelligence, sustainable manufacturing practices
    and circular economy capabilities
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2021
- Abstract: This study examines the antecedents and influence of big data decision-making
    capabilities on decision-making quality among Chinese firms. We propose that such
    capabilities are influenced by big data management challenges such as leadership,
    talent management, technology, and organisational culture. By using primary data
    from 108 Chinese firms and utilising partial least squares, we tested the antecedents
    of big data decision-making capability and its impact on decision-making quality.
    Findings suggest that big data management challenges are the key antecedents of
    big data decision-making capability. Furthermore, the latter is vital for big
    data decision-making quality.
  Author: Saqib Shamim and Jing Zeng and Syed Muhammad Shariq and Zaheer Khan
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2018.12.003
  JCS_FACTOR: 7.555
  Keywords: Big data management, Dynamic capabilities, Big data decision-making capability,
    Decision-making quality, China
  SCI_FACTOR: 0.0
  Title: 'Role of big data management in enhancing big data decision-making capability
    and quality among Chinese firms: A dynamic capabilities view'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2019
- Abstract: This study examines the antecedents and influence of big data decision-making
    capabilities on decision-making quality among Chinese firms. We propose that such
    capabilities are influenced by big data management challenges such as leadership,
    talent management, technology, and organisational culture. By using primary data
    from 108 Chinese firms and utilising partial least squares, we tested the antecedents
    of big data decision-making capability and its impact on decision-making quality.
    Findings suggest that big data management challenges are the key antecedents of
    big data decision-making capability. Furthermore, the latter is vital for big
    data decision-making quality.
  Author: Saqib Shamim and Jing Zeng and Syed Muhammad Shariq and Zaheer Khan
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2018.12.003
  JCS_FACTOR: 7.555
  Keywords: Big data management, Dynamic capabilities, Big data decision-making capability,
    Decision-making quality, China
  SCI_FACTOR: 0.0
  Title: 'Role of big data management in enhancing big data decision-making capability
    and quality among Chinese firms: A dynamic capabilities view'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2019
- Abstract: Prior research articulated the importance of developing a big data analytics
    capability but did not show how to cultivate this development. Drawing on the
    literature on this topic, this study develops the concept of Big Data capability,
    which enhances our understanding of Big Data practice beyond that captured in
    previous literature on the concept of big data analytics capability. This study
    further highlights the strategic implications of the concept by testing its relationship
    to three strategic orientations and one aspect of organizational culture. Findings
    show that customer, entrepreneurial, and technology orientations, and developmental
    culture are important contributors to the development of Big Data capability.
  Author: Canchu Lin and Anand Kunnathur
  Book_Title_Journal: Journal of Business Research
  DOI: https://doi.org/10.1016/j.jbusres.2019.07.016
  JCS_FACTOR: 7.55
  Keywords: Big data capability, Customer orientation, Entrepreneurial orientation,
    Technology orientation, And developmental culture
  SCI_FACTOR: 2.049
  Title: Strategic orientations, developmental culture, and big data capability
  Title_JCS: JOURNAL OF BUSINESS RESEARCH
  Title_SCI: Journal of Business Research
  Type_Publication: article
  Year: 2019
- Abstract: 'In any knowledge discovery process the value of extracted knowledge is
    directly related to the quality of the data used. Big Data problems, generated
    by massive growth in the scale of data observed in recent years, also follow the
    same dictate. A common problem affecting data quality is the presence of noise,
    particularly in classification problems, where label noise refers to the incorrect
    labeling of training instances, and is known to be a very disruptive feature of
    data. However, in this Big Data era, the massive growth in the scale of the data
    poses a challenge to traditional proposals created to tackle noise, as they have
    difficulties coping with such a large amount of data. New algorithms need to be
    proposed to treat the noise in Big Data problems, providing high quality and clean
    data, also known as Smart Data. In this paper, two Big Data preprocessing approaches
    to remove noisy examples are proposed: an homogeneous ensemble and an heterogeneous
    ensemble filter, with special emphasis in their scalability and performance traits.
    The obtained results show that these proposals enable the practitioner to efficiently
    obtain a Smart Dataset from any Big Data classification problem.'
  Author: "Diego Garc\xC3\xADa-Gil and Juli\xC3\xA1n Luengo and Salvador Garc\xC3\xAD\
    a and Francisco Herrera"
  Book_Title_Journal: Information Sciences
  DOI: https://doi.org/10.1016/j.ins.2018.12.002
  JCS_FACTOR: 6.795
  Keywords: Big Data, Smart Data, Classification, Class noise, Label noise.
  SCI_FACTOR: 1.524
  Title: 'Enabling Smart Data: Noise filtering in Big Data classification'
  Title_JCS: INFORMATION SCIENCES
  Title_SCI: Information Sciences
  Type_Publication: article
  Year: 2019
- Abstract: "Big data adoption is a process through which businesses find innovative\
    \ ways to enhance productivity and predict risk to satisfy customers need more\
    \ efficiently. Despite the increase in demand and importance of big data adoption,\
    \ there is still a lack of comprehensive review and classification of the existing\
    \ studies in this area. This research aims to gain a comprehensive understanding\
    \ of the current state-of-the-art by highlighting theoretical models, the influence\
    \ factors, and the research challenges of big data adoption. By adopting a systematic\
    \ selection process, twenty studies were identified in the domain of big data\
    \ adoption and were reviewed in order to extract relevant information that answers\
    \ a set of research questions. According to the findings, Technology\xE2\u20AC\
    \u201COrganization\xE2\u20AC\u201CEnvironment and Diffusion of Innovations are\
    \ the most popular theoretical models used for big data adoption in various domains.\
    \ This research also revealed forty-two factors in technology, organization, environment,\
    \ and innovation that have a significant influence on big data adoption. Finally,\
    \ challenges found in the current research about big data adoption are represented,\
    \ and future research directions are recommended. This study is helpful for researchers\
    \ and stakeholders to take initiatives that will alleviate the challenges and\
    \ facilitate big data adoption in various fields."
  Author: Maria Ijaz Baig and Liyana Shuib and Elaheh Yadegaridehkordi
  Book_Title_Journal: Information Processing & Management
  DOI: https://doi.org/10.1016/j.ipm.2019.102095
  JCS_FACTOR: 6.222
  Keywords: "Big data adoption, Technology\xE2\u20AC\u201COrganization\xE2\u20AC\u201C\
    Environment, Diffusion of Innovations"
  SCI_FACTOR: 0.0
  Title: 'Big data adoption: State of the art and research challenges'
  Title_JCS: INFORMATION PROCESSING & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2019
- Abstract: "Big data adoption is a process through which businesses find innovative\
    \ ways to enhance productivity and predict risk to satisfy customers need more\
    \ efficiently. Despite the increase in demand and importance of big data adoption,\
    \ there is still a lack of comprehensive review and classification of the existing\
    \ studies in this area. This research aims to gain a comprehensive understanding\
    \ of the current state-of-the-art by highlighting theoretical models, the influence\
    \ factors, and the research challenges of big data adoption. By adopting a systematic\
    \ selection process, twenty studies were identified in the domain of big data\
    \ adoption and were reviewed in order to extract relevant information that answers\
    \ a set of research questions. According to the findings, Technology\xE2\u20AC\
    \u201COrganization\xE2\u20AC\u201CEnvironment and Diffusion of Innovations are\
    \ the most popular theoretical models used for big data adoption in various domains.\
    \ This research also revealed forty-two factors in technology, organization, environment,\
    \ and innovation that have a significant influence on big data adoption. Finally,\
    \ challenges found in the current research about big data adoption are represented,\
    \ and future research directions are recommended. This study is helpful for researchers\
    \ and stakeholders to take initiatives that will alleviate the challenges and\
    \ facilitate big data adoption in various fields."
  Author: Maria Ijaz Baig and Liyana Shuib and Elaheh Yadegaridehkordi
  Book_Title_Journal: Information Processing & Management
  DOI: https://doi.org/10.1016/j.ipm.2019.102095
  JCS_FACTOR: 6.222
  Keywords: "Big data adoption, Technology\xE2\u20AC\u201COrganization\xE2\u20AC\u201C\
    Environment, Diffusion of Innovations"
  SCI_FACTOR: 0.0
  Title: 'Big data adoption: State of the art and research challenges'
  Title_JCS: INFORMATION PROCESSING & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2019
- Abstract: Big Data represents a promising area for value creation and frontier research.
    The potential to extract actionable insights from Big Data has gained increasing
    attention of both academics and practitioners operating in several industries.
    Marketing domain has become from the start a field for experiments with Big Data
    approaches, even if the adoption of Big Data solutions does not always generate
    effective value for the adopters. Therefore, the gap existing between the potential
    of value creation embedded in the Big Data paradigm and the current limited exploitation
    of this value represents an area of investigation that this paper aims to explore.
    In particular, by following a systematic literature review, this study aims at
    presenting a framework that outlines the multiple value directions that the Big
    Data paradigm can generate for the adopting organizations. Eleven distinct value
    directions have been identified and then grouped in five dimensions (Informational,
    Transactional, Transformational, Strategic, Infrastructural Value), which constitute
    the pillars of the proposed framework. Finally, the framework has been also preliminarily
    applied in three case studies conducted within three Italian based companies operating
    in different industries (e-commerce, fast-moving consumer goods, and banking)
    in the final aim to see its applicability in real business scenarios.
  Author: Gianluca Elia and Gloria Polimeno and Gianluca Solazzo and Giuseppina Passiante
  Book_Title_Journal: Industrial Marketing Management
  DOI: https://doi.org/10.1016/j.indmarman.2019.08.004
  JCS_FACTOR: 6.96
  Keywords: Big data analytics, Cognitive computing, Framework, Model, Systematic
    literature review, Value creation
  SCI_FACTOR: 2.022
  Title: A multi-dimension framework for value creation through big data
  Title_JCS: INDUSTRIAL MARKETING MANAGEMENT
  Title_SCI: Industrial Marketing Management
  Type_Publication: article
  Year: 2020
- Abstract: Simulation stands out as an appropriate method for the Supply Chain Management
    (SCM) field. Nevertheless, to produce accurate simulations of Supply Chains (SCs),
    several business processes must be considered. Thus, when using real data in these
    simulation models, Big Data concepts and technologies become necessary, as the
    involved data sources generate data at increasing volume, velocity and variety,
    in what is known as a Big Data context. While developing such solution, several
    data issues were found, with simulation proving to be more efficient than traditional
    data profiling techniques in identifying them. Thus, this paper proposes the use
    of simulation as a semantic validator of the data, proposed a classification for
    such issues and quantified their impact in the volume of data used in the final
    achieved solution. This paper concluded that, while SC simulations using Big Data
    concepts and technologies are within the grasp of organizations, their data models
    still require considerable improvements, in order to produce perfect mimics of
    their SCs. In fact, it was also found that simulation can help in identifying
    and bypassing some of these issues.
  Author: "Ant\xC3\xB3nio AC Vieira and Lu\xC3\xADs MS Dias and Maribel Y Santos and\
    \ Guilherme AB Pereira and Jos\xC3\xA9 A Oliveira"
  Book_Title_Journal: Simulation Modelling Practice and Theory
  DOI: https://doi.org/10.1016/j.simpat.2019.101985
  JCS_FACTOR: 3.272
  Keywords: Simulation, Big Data, Data issues, Semantic validation, Supply chain management,
    Industry 4.0
  SCI_FACTOR: 0.554
  Title: On the use of simulation as a Big Data semantic validator for supply chain
    management
  Title_JCS: SIMULATION MODELLING PRACTICE AND THEORY
  Title_SCI: Simulation Modelling Practice and Theory
  Type_Publication: article
  Year: 2020
- Abstract: "Today, in many organizations, the debate about the difference in core\
    \ capabilities has become an important factor for market competition. Companies,\
    \ based on the field of activity, decide to strengthen some of their capabilities,\
    \ capacities, and expertise. Therefore, the focus of an organization on the strengths\
    \ and efforts to develop its sustainability will lead to a competitive advantage\
    \ in the marketplace. Due to changes in environmental factors, organizations have\
    \ focused on carbon emissions in procurement and transportation that have the\
    \ highest carbon footprint. This paper proposes a multi-objective, eco-sustainability\
    \ model for a supply chain. The objectives are to minimize overall costs, maximize\
    \ the efficiency of transportation vehicles and minimize information fraud in\
    \ the process of information sharing within supply chain elements. Big data is\
    \ considered in the amount of information exchanged between customers and other\
    \ elements of the proposed supply chain; since there are frauds in information\
    \ sharing then using big data 5Vs the model is adapted to control the cost of\
    \ information loss leading to customer dissatisfaction. Since uncertainty is inevitable\
    \ in the real environments, in this research hybrid uncertainty is considered.\
    \ Because two sources of uncertainty are considered in most of the parameters,\
    \ thus it is necessary to robustify the decision-making process. The model is\
    \ a mixed integer nonlinear program including big data for an optimal sustainable\
    \ procurement and transportation decision. A heuristic method is used to solve\
    \ the big data problem that makes use of a robust fuzzy stochastic programming\
    \ approach. The proposed model can prevent disturbances by using a scenario-based\
    \ stochastic programming approach. An effective hybrid robust fuzzy stochastic\
    \ method is also employed for controlling uncertainty in parameters and risk taking\
    \ out of outbound decisions. To solve the multi-objective model, augmented \xCE\
    \xB5-constraint method is utilized. The model performance is investigated in a\
    \ comprehensive computational study."
  Author: Hadi Gholizadeh and Hamed Fazlollahtabar and Mohammad Khalilzadeh
  Book_Title_Journal: Journal of Cleaner Production
  DOI: https://doi.org/10.1016/j.jclepro.2020.120640
  JCS_FACTOR: 9.297
  Keywords: "logistics, Robust fuzzy stochastic programming, Sustainable procurement,\
    \ Big data, Hybrid uncertainty, \xCE\xB5-Constraint"
  SCI_FACTOR: 1.937
  Title: A robust fuzzy stochastic programming for sustainable procurement and logistics
    under hybrid uncertainty using big data
  Title_JCS: Journal of Cleaner Production
  Title_SCI: Journal of Cleaner Production
  Type_Publication: article
  Year: 2020
- Abstract: Big data analytics (BDA) are gaining importance in all aspects of business
    management. This is driven by both the presence of large-scale data and management's
    desire to root decisions in data. Extant research demonstrates that supply chain
    and operations management functions are among the biggest sources and users of
    data in the company. Therefore, their decision-making processes would benefit
    from increased use of BDA technologies. However, there is still a lack of understanding
    of what determines a company's ability to build BDA capability to gain a competitive
    advantage. In this study, we attempt to answer this fundamental question by identifying
    the factors that assist a company in or inhibit it from building its BDA capability
    and maximizing its gains through BDA technologies. We base our findings on a qualitative
    analysis of data collected from field visits, interviews with senior management,
    and secondary resources. We find that, in addition to technical capacity, competitive
    landscape and intra-firm power dynamics play an important role in building BDA
    capability and using BDA technologies.
  Author: Ashish Kumar Jha and Maher A.N. Agi and Eric W.T. Ngai
  Book_Title_Journal: Decision Support Systems
  DOI: https://doi.org/10.1016/j.dss.2020.113382
  JCS_FACTOR: 5.795
  Keywords: Big data, Analytics, Capability development, Qualitative study, Supply
    chain
  SCI_FACTOR: 1.564
  Title: A note on big data analytics capability development in supply chain
  Title_JCS: DECISION SUPPORT SYSTEMS
  Title_SCI: Decision Support Systems
  Type_Publication: article
  Year: 2020
- Abstract: This paper provides a survey of big data analytics applications and associated
    implementation issues. The emphasis is placed on applications that are novel and
    have demonstrated value to the industry, as illustrated using field data and practical
    applications. The paper reflects on the lessons learned from initial implementations,
    as well as ideas that are yet to be explored. The various data science trends
    treated in the literature are outlined, while experiences from applying them in
    the electricity grid setting are emphasized to pave the way for future applications.
    The paper ends with opportunities and challenges, as well as implementation goals
    and strategies for achieving impactful outcomes.
  Author: Mladen Kezunovic and Pierre Pinson and Zoran Obradovic and Santiago Grijalva
    and Tao Hong and Ricardo Bessa
  Book_Title_Journal: Electric Power Systems Research
  DOI: https://doi.org/10.1016/j.epsr.2020.106788
  JCS_FACTOR: 3.414
  Keywords: Electricity grids, Analytics, Big data, Decision-making
  SCI_FACTOR: 0.845
  Title: Big data analytics for future electricity grids
  Title_JCS: ELECTRIC POWER SYSTEMS RESEARCH
  Title_SCI: Electric Power Systems Research
  Type_Publication: article
  Year: 2020
- Abstract: 'Advanced manufacturing is one of the core national strategies in the
    US (AMP), Germany (Industry 4.0) and China (Made-in China 2025). The emergence
    of the concept of Cyber Physical System (CPS) and big data imperatively enable
    manufacturing to become smarter and more competitive among nations. Many researchers
    have proposed new solutions with big data enabling tools for manufacturing applications
    in three directions: product, production and business. Big data has been a fast-changing
    research area with many new opportunities for applications in manufacturing. This
    paper presents a systematic literature review of the state-of-the-art of big data
    in manufacturing. Six key drivers of big data applications in manufacturing have
    been identified. The key drivers are system integration, data, prediction, sustainability,
    resource sharing and hardware. Based on the requirements of manufacturing, nine
    essential components of big data ecosystem are captured. They are data ingestion,
    storage, computing, analytics, visualization, management, workflow, infrastructure
    and security. Several research domains are identified that are driven by available
    capabilities of big data ecosystem. Five future directions of big data applications
    in manufacturing are presented from modelling and simulation to real-time big
    data analytics and cybersecurity.'
  Author: Yesheng Cui and Sami Kara and Ka C. Chan
  Book_Title_Journal: Robotics and Computer-Integrated Manufacturing
  DOI: https://doi.org/10.1016/j.rcim.2019.101861
  JCS_FACTOR: 5.666
  Keywords: Smart manufacturing, Big data, Cloud computing, Cloud manufacturing, Internet
    of things, NoSQL
  SCI_FACTOR: 1.561
  Title: 'Manufacturing big data ecosystem: A systematic literature review'
  Title_JCS: ROBOTICS AND COMPUTER-INTEGRATED MANUFACTURING
  Title_SCI: Robotics and Computer-Integrated Manufacturing
  Type_Publication: article
  Year: 2020
- Abstract: Industry 4.0 (I4.0) defines a new paradigm to produce high-quality products
    at the low cost by reacting quickly and effectively to changing demands in the
    highly volatile global markets. In Industry 4.0, the adoption of Internet of Things
    (IoT)-enabled Wireless Sensors (WSs) in the manufacturing processes, such as equipment,
    machining, assembly, material handling, inspection, etc., generates a huge volume
    of data known as Industrial Big Data (IBD). However, the reliable and efficient
    gathering and transmission of this big data from the source sensors to the floor
    inspection system for the real-time monitoring of unexpected changes in the production
    and quality control processes is the biggest challenge for Industrial Wireless
    Sensor Networks (IWSNs). This is because of the harsh nature of the indoor industrial
    environment that causes high noise, signal fading, multipath effects, heat and
    electromagnetic interference, which reduces the transmission quality and trigger
    errors in the IWSNs. Therefore, this paper proposes a novel cross-layer data gathering
    approach called CBI4.0 for active monitoring and control of manufacturing processes
    in the Industry 4.0. The key aim of the proposed CBI4.0 scheme is to exploit the
    multi-channel and multi-radio architecture of the sensor network to guarantee
    quality of service (QoS) requirements, such as higher data rates, throughput,
    and low packet loss, corrupted packets, and latency by dynamically switching between
    different frequency bands in the Multichannel Wireless Sensor Networks (MWSNs).
    By performing several simulation experiments through EstiNet 9.0 simulator, the
    performance of the proposed CBI4.0 scheme is compared against existing studies
    in the automobile Industry 4.0. The experimental outcomes show that the proposed
    scheme outperforms existing schemes and is suitable for effective control and
    monitoring of various events in the automobile Industry 4.0.
  Author: Muhammad Faheem and Rizwan Aslam Butt and Rashid Ali and Basit Raza and
    Md. Asri Ngadi and Vehbi Cagri Gungor
  Book_Title_Journal: Journal of Industrial Information Integration
  DOI: https://doi.org/10.1016/j.jii.2021.100236
  JCS_FACTOR: 10.063
  Keywords: Internet of things, Industry 4.0, Big data, Multi-channel communication,
    Wireless sensor network
  SCI_FACTOR: 2.042
  Title: 'CBI4.0: A cross-layer approach for big data gathering for active monitoring
    and maintenance in the manufacturing industry 4.0'
  Title_JCS: Journal of Industrial Information Integration
  Title_SCI: Journal of Industrial Information Integration
  Type_Publication: article
  Year: 2021
- Abstract: "The age of big data analytics is now here, with companies increasingly\
    \ investing in big data initiatives to foster innovation and outperform competition.\
    \ Nevertheless, while researchers and practitioners started to examine the shifts\
    \ that these technologies entail and their overall business value, it is still\
    \ unclear whether and under what conditions they drive innovation. To address\
    \ this gap, this study draws on the resource-based view (RBV) of the firm and\
    \ information governance theory to explore the interplay between a firm\xE2\u20AC\
    \u2122s big data analytics capabilities (BDACs) and their information governance\
    \ practices in shaping innovation capabilities. We argue that a firm\xE2\u20AC\
    \u2122s BDAC helps enhance two distinct types of innovative capabilities, incremental\
    \ and radical capabilities, and that information governance positively moderates\
    \ this relationship. To examine our research model, we analyzed survey data collected\
    \ from 175 IT and business managers. Results from partial least squares structural\
    \ equation modelling analysis reveal that BDACs have a positive and significant\
    \ effect on both incremental and radical innovative capabilities. Our analysis\
    \ also highlights the important role of information governance, as it positively\
    \ moderates the relationship between BDAC\xE2\u20AC\u2122s and a firm\xE2\u20AC\
    \u2122s radical innovative capability, while there is a nonsignificant moderating\
    \ effect for incremental innovation capabilities. Finally, we examine the effect\
    \ of environmental uncertainty conditions in our model and find that information\
    \ governance and BDACs have amplified effects under conditions of high environmental\
    \ dynamism."
  Author: Patrick Mikalef and Maria Boura and George Lekakos and John Krogstie
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2020.103361
  JCS_FACTOR: 7.555
  Keywords: Big data analytics capabilities, Information governance, Incremental innovation,
    Radical innovation, Environmental uncertainty, FIMIX-PLS
  SCI_FACTOR: 0.0
  Title: The role of information governance in big data analytics driven innovation
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: "The age of big data analytics is now here, with companies increasingly\
    \ investing in big data initiatives to foster innovation and outperform competition.\
    \ Nevertheless, while researchers and practitioners started to examine the shifts\
    \ that these technologies entail and their overall business value, it is still\
    \ unclear whether and under what conditions they drive innovation. To address\
    \ this gap, this study draws on the resource-based view (RBV) of the firm and\
    \ information governance theory to explore the interplay between a firm\xE2\u20AC\
    \u2122s big data analytics capabilities (BDACs) and their information governance\
    \ practices in shaping innovation capabilities. We argue that a firm\xE2\u20AC\
    \u2122s BDAC helps enhance two distinct types of innovative capabilities, incremental\
    \ and radical capabilities, and that information governance positively moderates\
    \ this relationship. To examine our research model, we analyzed survey data collected\
    \ from 175 IT and business managers. Results from partial least squares structural\
    \ equation modelling analysis reveal that BDACs have a positive and significant\
    \ effect on both incremental and radical innovative capabilities. Our analysis\
    \ also highlights the important role of information governance, as it positively\
    \ moderates the relationship between BDAC\xE2\u20AC\u2122s and a firm\xE2\u20AC\
    \u2122s radical innovative capability, while there is a nonsignificant moderating\
    \ effect for incremental innovation capabilities. Finally, we examine the effect\
    \ of environmental uncertainty conditions in our model and find that information\
    \ governance and BDACs have amplified effects under conditions of high environmental\
    \ dynamism."
  Author: Patrick Mikalef and Maria Boura and George Lekakos and John Krogstie
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2020.103361
  JCS_FACTOR: 7.555
  Keywords: Big data analytics capabilities, Information governance, Incremental innovation,
    Radical innovation, Environmental uncertainty, FIMIX-PLS
  SCI_FACTOR: 0.0
  Title: The role of information governance in big data analytics driven innovation
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: "Incorporating big data analytics into a particular context brings various\
    \ challenges that rest on the model or framework through which individuals or\
    \ organisations adopt big data to achieve their objectives. Although these models\
    \ have recently triggered scholars\xE2\u20AC\u2122 attention in various domains,\
    \ in-depth knowledge of using each of these models in big data research is still\
    \ blurred. This study enriches our knowledge on emerging models and theories that\
    \ shape big data analytics adoption (BDAD) research through a bibliometric analysis\
    \ of 229 studies (143 journal articles and 86 conference papers) published in\
    \ indexed sources between 2013 and 2019. As a result, twenty models on BDAD have\
    \ emerged (e.g., \xE2\u20AC\u0153Dynamic Capabilities\xE2\u20AC\x9D, \xE2\u20AC\
    \u0153Resource-Based View\xE2\u20AC\x9D, \xE2\u20AC\u0153Technology Acceptance\
    \ Model\xE2\u20AC\x9D, \xE2\u20AC\u0153Diffusion of Innovation\xE2\u20AC\x9D,\
    \ etc.). The analysis reveals that BDAD research to demonstrate attributes suggestive\
    \ of a topic at an initial stage of development as it is broadly dispersed across\
    \ different domains employs a wide range of models, some of which overlap. Most\
    \ of the applied models are generic in nature focusing on variance-based relationships\
    \ and snapshot prediction with little consensus. There is a conspicuous dearth\
    \ of process models, firm-level analysis and cultural orientation in contemporary\
    \ BDAD research. Insights of this bibliometric study could guide rigorous big\
    \ data research and practice in various contexts. The study concludes with research\
    \ implications and limitations that offer promising prospects for forthcoming\
    \ research."
  Author: Mohamed Aboelmaged and Samar Mouakket
  Book_Title_Journal: Information Processing & Management
  DOI: https://doi.org/10.1016/j.ipm.2020.102234
  JCS_FACTOR: 6.222
  Keywords: Big data analytics, Technology adoption, Literature review, Bibliometric
    analysis, Theoretical models, Adoption frameworks
  SCI_FACTOR: 0.0
  Title: 'Influencing models and determinants in big data analytics research: A bibliometric
    analysis'
  Title_JCS: INFORMATION PROCESSING & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: "Incorporating big data analytics into a particular context brings various\
    \ challenges that rest on the model or framework through which individuals or\
    \ organisations adopt big data to achieve their objectives. Although these models\
    \ have recently triggered scholars\xE2\u20AC\u2122 attention in various domains,\
    \ in-depth knowledge of using each of these models in big data research is still\
    \ blurred. This study enriches our knowledge on emerging models and theories that\
    \ shape big data analytics adoption (BDAD) research through a bibliometric analysis\
    \ of 229 studies (143 journal articles and 86 conference papers) published in\
    \ indexed sources between 2013 and 2019. As a result, twenty models on BDAD have\
    \ emerged (e.g., \xE2\u20AC\u0153Dynamic Capabilities\xE2\u20AC\x9D, \xE2\u20AC\
    \u0153Resource-Based View\xE2\u20AC\x9D, \xE2\u20AC\u0153Technology Acceptance\
    \ Model\xE2\u20AC\x9D, \xE2\u20AC\u0153Diffusion of Innovation\xE2\u20AC\x9D,\
    \ etc.). The analysis reveals that BDAD research to demonstrate attributes suggestive\
    \ of a topic at an initial stage of development as it is broadly dispersed across\
    \ different domains employs a wide range of models, some of which overlap. Most\
    \ of the applied models are generic in nature focusing on variance-based relationships\
    \ and snapshot prediction with little consensus. There is a conspicuous dearth\
    \ of process models, firm-level analysis and cultural orientation in contemporary\
    \ BDAD research. Insights of this bibliometric study could guide rigorous big\
    \ data research and practice in various contexts. The study concludes with research\
    \ implications and limitations that offer promising prospects for forthcoming\
    \ research."
  Author: Mohamed Aboelmaged and Samar Mouakket
  Book_Title_Journal: Information Processing & Management
  DOI: https://doi.org/10.1016/j.ipm.2020.102234
  JCS_FACTOR: 6.222
  Keywords: Big data analytics, Technology adoption, Literature review, Bibliometric
    analysis, Theoretical models, Adoption frameworks
  SCI_FACTOR: 0.0
  Title: 'Influencing models and determinants in big data analytics research: A bibliometric
    analysis'
  Title_JCS: INFORMATION PROCESSING & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: "The consumption data from smart meters and complex questionnaires reveals\
    \ the electricity consumers\xE2\u20AC\u2122 willingness to adapt their lifestyle\
    \ to reduce or change their behaviour in electricity usage to flatten the peak\
    \ in electricity consumption and release the stress in the power grid. Thus, the\
    \ electricity consumption can support the enforcement of tariff and demand response\
    \ strategies. Although the plethora of complex, unstructured and heterogeneous\
    \ data is collected from various devices connected to the Internet, smart meters,\
    \ plugs, sensors and complex questionnaires, there is an undoubted challenge to\
    \ handle the data flow that does not provide much information as it remains unprocessed.\
    \ Therefore, in this paper, we propose an innovative methodology that organizes\
    \ and extracts valuable information from the increasing volume of data, such as\
    \ data about the electricity consumption measured and recorded at 30\xC2\_min\
    \ intervals, as well as data collected from complex questionnaires."
  Author: "Simona-Vasilica Oprea and Adela B\xC3\xA2ra and Bogdan George Tudoric\xC4\
    \u0192 and Maria Ir\xC3\xA8ne C\xC4\u0192linoiu and Mihai Alexandru Botezatu"
  Book_Title_Journal: Computers & Electrical Engineering
  DOI: https://doi.org/10.1016/j.compeleceng.2020.106902
  JCS_FACTOR: 3.818
  Keywords: Big data, Machine learning, Smart meters, Electricity consumption, Clustering,
    Questionnaire analytics
  SCI_FACTOR: 0.0
  Title: "Insights into demand-side management with big data analytics in electricity\
    \ consumers\xE2\u20AC\u2122 behaviour"
  Title_JCS: COMPUTERS & ELECTRICAL ENGINEERING
  Title_SCI: N/A
  Type_Publication: article
  Year: 2021
- Abstract: "An accurate characterization of spatial-temporal emission patterns and\
    \ speciation of volatile organic compounds (VOCs) for multiple chemical mechanisms\
    \ is important to improving the air quality ensemble modeling. In this study,\
    \ we developed a 2017-based high-resolution (3\xC2\_km\xC2\_\xC3\u2014\xC2\_3\xC2\
    \_km) model-ready emission inventory for Guangdong Province (GD) by updating estimation\
    \ methods, emission factors, activity data, and allocation profiles. In particular,\
    \ a full-localized speciation profile dataset mapped to five chemical mechanisms\
    \ was developed to promote the determination of VOC speciation, and two dynamic\
    \ approaches based on big data were used to improve the estimation of ship emissions\
    \ and open fire biomass burning (OFBB). Compared with previous emissions, more\
    \ VOC emissions were classified as oxygenated volatile organic compound (OVOC)\
    \ species, and their contributions to the total ozone formation potential (OFP)\
    \ in the Pearl River Delta (PRD) region increased by 17%. Formaldehyde became\
    \ the largest OFP species in GD, accounting for 11.6% of the total OFP, indicating\
    \ that the model-ready emission inventory developed in this study is more reactive.\
    \ The high spatial-temporal variability of ship sources and OFBB, which were previously\
    \ underestimated, was also captured by using big data. Ship emissions during typhoon\
    \ days and holidays decreased by 23\xE2\u20AC\u201C55%. 95% of OFBB emissions\
    \ were concentrated in 9% of the GD area and 31% of the days in 2017, demonstrating\
    \ their strong spatial-temporal variability. In addition, this study revealed\
    \ that GD emissions have changed rapidly in recent years due to the leap-forward\
    \ control measures implemented, and thus, they needed to be updated regularly.\
    \ All of these updates led to a 5\xE2\u20AC\u201C17% decrease in the emission\
    \ uncertainty for most pollutants. The results of this study provide a reference\
    \ for how to reduce uncertainties in developing model-ready emission inventories."
  Author: Zhijiong Huang and Zhuangmin Zhong and Qinge Sha and Yuanqian Xu and Zhiwei
    Zhang and Lili Wu and Yuzheng Wang and Lihang Zhang and Xiaozhen Cui and MingShuang
    Tang and Bowen Shi and Chuanzeng Zheng and Zhen Li and Mingming Hu and Linlin
    Bi and Junyu Zheng and Min Yan
  Book_Title_Journal: Science of The Total Environment
  DOI: https://doi.org/10.1016/j.scitotenv.2020.144535
  JCS_FACTOR: 7.963
  Keywords: Emission inventory, Guangdong Province, Ship emissions, Big data, VOCs
    speciation
  SCI_FACTOR: 1.795
  Title: An updated model-ready emission inventory for Guangdong Province by incorporating
    big data and mapping onto multiple chemical mechanisms
  Title_JCS: SCIENCE OF THE TOTAL ENVIRONMENT
  Title_SCI: Science of the Total Environment
  Type_Publication: article
  Year: 2021
- Abstract: The access of machine learning techniques in popular programming languages
    and the exponentially expanding big data from social media, news, surveys, and
    markets provide exciting challenges and invaluable opportunities for organizations
    and individuals to explore implicit information for decision making. Nevertheless,
    the users of machine learning usually find that these sophisticated techniques
    could incur a high level of tensions caused by the selection of the appropriate
    size of the training data set among other factors. In this paper, we provide a
    systematic way of resolving such tensions by examining practical examples of predicting
    popularity and sentiment of posts on Twitter and Facebook, blogs on Mashable,
    news on Google and Yahoo, the US house survey, and Bitcoin prices. Interesting
    results show that for the case of big data, using around 20% of the full sample
    often leads to a better prediction accuracy than opting for the full sample. Our
    conclusion is found to be consistent across a series of experiments. The managerial
    implication is that using more is not necessarily the best and users need to be
    cautious about such an important sensitivity as the simplistic approach may easily
    lead to inferior solutions with potentially detrimental consequences.
  Author: Huamao Wang and Yumei Yao and Said Salhi
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2020.120175
  JCS_FACTOR: 8.593
  Keywords: Big data, Machine learning, Data size, Prediction accuracy, Social media
  SCI_FACTOR: 2.226
  Title: 'Tension in big data using machine learning: Analysis and applications'
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2020
- Abstract: "With the unprecedented increase in data all over the world, financial\
    \ sector such as companies and industries try to remain competitive by transforming\
    \ themselves into data-driven organizations. By analyzing a huge amount of financial\
    \ data, companies are able to obtain valuable information to determine their strategic\
    \ plans such as risk control, crisis management, or growth management. However,\
    \ as the amount of data increase dramatically, traditional data analytic platforms\
    \ confront with storing, managing, and analyzing difficulties. Emerging Big Data\
    \ Analytics (BDA) overcome these problems by providing decentralized and distributed\
    \ processing. In this study, we propose two new models for default prediction.\
    \ In the first model, called DPModel-1, statistical (logistic regression), and\
    \ machine learning methods (decision tree, random forest, gradient boosting) are\
    \ employed to predict company default. Derived from the first model, we propose\
    \ DPModel-2 based on graph theory. DPModel-2 also comprises new variables obtained\
    \ from the trading interactions of companies. In both models, grid search optimization\
    \ and SHapley Additive exPlanations (SHAP) value are utilized in order to determine\
    \ the best hyperparameters and make the models interpretable, respectively. By\
    \ leveraging balance sheet, credit, and invoice datasets, default prediction is\
    \ realized for about one million companies in Turkey between the years 2010\xE2\
    \u20AC\u201C2018. The default rates of companies range between 3%-6% by year.\
    \ The experimental results are conducted on a BDA platform. According to the DPModel-1\
    \ results, the highest AUC score is ensured by random forest with 0.87. In addition,\
    \ the results are improved for each technique separately by adjusting new variables\
    \ with graph theory. According to DPModel-2 results, the best AUC score is achieved\
    \ by random forest with 0.89."
  Author: "Mustafa Y\xC4\xB1ld\xC4\xB1r\xC4\xB1m and Feyza Y\xC4\xB1ld\xC4\xB1r\xC4\
    \xB1m Okay and Suat \xC3\u2013zdemir"
  Book_Title_Journal: Expert Systems with Applications
  DOI: https://doi.org/10.1016/j.eswa.2021.114840
  JCS_FACTOR: 6.954
  Keywords: Big data analytics, Graph theory, Machine learning, Default prediction,
    SHAP value
  SCI_FACTOR: 1.368
  Title: Big data analytics for default prediction using graph theory
  Title_JCS: EXPERT SYSTEMS WITH APPLICATIONS
  Title_SCI: Expert Systems with Applications
  Type_Publication: article
  Year: 2021
- Abstract: This study investigates the driving forces of a firm's assimilation of
    big data analytical intelligence (BDAI) and how the assimilation of BDAI improve
    customer relationship management (CRM) performance. Drawing on the resource-based
    view, this study argues that a firm's data-driven culture and the competitive
    pressure it faces in the industry motivate a firm's assimilation of BDAI. As a
    firm resource, BDAI enables an organization to develop superior mass-customization
    capability, which in turn positively influences its CRM performance. In addition,
    this study proposes that a firm's marketing capability can moderate the impact
    of BDAI assimilation on its mass-customization capability. Using survey data collected
    from 147 business-to-business companies, this study finds support for most of
    the hypotheses. The findings of this study uncover compelling insights about the
    dynamics involved in the process of using BDAI to improve CRM performance.
  Author: Chubing Zhang and Xinchun Wang and Annie Peng Cui and Shenghao Han
  Book_Title_Journal: Industrial Marketing Management
  DOI: https://doi.org/10.1016/j.indmarman.2020.10.012
  JCS_FACTOR: 6.96
  Keywords: Big data, Data-driven culture, Competitive pressures, Mass customization,
    Marketing capability, CRM performance
  SCI_FACTOR: 2.022
  Title: Linking big data analytical intelligence to customer relationship management
    performance
  Title_JCS: INDUSTRIAL MARKETING MANAGEMENT
  Title_SCI: Industrial Marketing Management
  Type_Publication: article
  Year: 2020
- Abstract: The evaluation, acquisition and use of newly available big data sources
    has become a major strategic and organizational challenge for airline network
    planners. We address this challenge by developing a maturity model for big data
    readiness for airline network planning. The development of the maturity model
    is grounded in literature, expert interviews and case study research involving
    nine airlines. Four airline business models are represented, namely full-service
    carriers, low-cost airlines, scheduled charter airlines and cargo airlines. The
    maturity model has been well received with seven change requests in the model
    development phase. The revised version has been evaluated as exhaustive and useful
    by airline network planners. The self-assessment of airlines revealed low to medium
    maturity for most domains. Organizational factors show the lowest average maturity,
    IT architecture the highest. Full-service carriers seem to be more mature than
    airlines with different business models.
  Author: Iris Hausladen and Maximilian Schosser
  Book_Title_Journal: Journal of Air Transport Management
  DOI: https://doi.org/10.1016/j.jairtraman.2019.101721
  JCS_FACTOR: 4.134
  Keywords: Maturity model, Network planning, Big data analytics, Airlines, Case study
  SCI_FACTOR: 1.22
  Title: Towards a maturity model for big data analytics in airline network planning
  Title_JCS: JOURNAL OF AIR TRANSPORT MANAGEMENT
  Title_SCI: Journal of Air Transport Management
  Type_Publication: article
  Year: 2020
- Abstract: As IoT-enabled manufacturing is still in its infancy, there are several
    key research gaps that need to be addressed. These gaps include the understanding
    of the characteristics of the big data generated from industrial IoT sensors,
    the challenges they present to process data analytics, as well as the specific
    opportunities that the IoT big data could bring to advance manufacturing. In this
    paper, we use an inhouse-developed IoT-enabled manufacturing testbed to study
    the characteristics of the big data generated from the testbed. Since the quality
    of the data usually has the most impact on process modeling, data veracity is
    often the most challenging characteristic of big data. To address that, we explore
    the role of feature engineering in developing effective machine learning models
    for predicting key process variables. We compare complex deep learning approaches
    to a simple statistical learning approach, with different level or extent of feature
    engineering, to explore their pros and cons for potential industrial IoT-enabled
    manufacturing applications.
  Author: Devarshi Shah and Jin Wang and Q. Peter He
  Book_Title_Journal: Computers & Chemical Engineering
  DOI: https://doi.org/10.1016/j.compchemeng.2020.106970
  JCS_FACTOR: 3.845
  Keywords: Internet-of-Things, Smart manufacturing, Big data, Data analytics, Feature
    engineering, Deep learning, Statistical learning
  SCI_FACTOR: 0.0
  Title: "Feature engineering in big data analytics for IoT-enabled smart manufacturing\
    \ \xE2\u20AC\u201C Comparison between deep learning and statistical learning"
  Title_JCS: COMPUTERS & CHEMICAL ENGINEERING
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: 'Under rapid urbanization, cities are facing many societal challenges
    that impede sustainability. Big data analytics (BDA) gives cities unprecedented
    potential to address these issues. As BDA is still a new concept, there is limited
    knowledge on how to apply BDA in a sustainability context. Thus, this study investigates
    a case using BDA for sustainability, adopting the resource orchestration perspective.
    A process model is generated, which provides novel insights into three aspects:
    data resource orchestration, BDA capability development, and big data value creation.
    This study benefits both researchers and practitioners by contributing to theoretical
    developments as well as by providing practical insights.'
  Author: Dan Zhang and Shan L. Pan and Jiaxin Yu and Wenyuan Liu
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2019.103231
  JCS_FACTOR: 7.555
  Keywords: Big data, Big data analytics, Sustainability, Air pollution, Resource
    orchestration
  SCI_FACTOR: 0.0
  Title: 'Orchestrating big data analytics capability for sustainability: A study
    of air pollution management in China'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2019
- Abstract: 'Under rapid urbanization, cities are facing many societal challenges
    that impede sustainability. Big data analytics (BDA) gives cities unprecedented
    potential to address these issues. As BDA is still a new concept, there is limited
    knowledge on how to apply BDA in a sustainability context. Thus, this study investigates
    a case using BDA for sustainability, adopting the resource orchestration perspective.
    A process model is generated, which provides novel insights into three aspects:
    data resource orchestration, BDA capability development, and big data value creation.
    This study benefits both researchers and practitioners by contributing to theoretical
    developments as well as by providing practical insights.'
  Author: Dan Zhang and Shan L. Pan and Jiaxin Yu and Wenyuan Liu
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2019.103231
  JCS_FACTOR: 7.555
  Keywords: Big data, Big data analytics, Sustainability, Air pollution, Resource
    orchestration
  SCI_FACTOR: 0.0
  Title: 'Orchestrating big data analytics capability for sustainability: A study
    of air pollution management in China'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2019
- Abstract: 'Researches about the fusion application of Big Data and blockchain have
    appeared for a long time, many information service providers have launched information
    service business based on Big Data and blockchain (hereafter, ISBD). However,
    in the green agri-food area, the ISBD application does not popularized. A vital
    reason is that many decision makers do not know how to make an optimal investment
    decision and coordinate chain members after adopting ISBD. The core of this problem
    is to study the issue of investment decision and coordination in a green agri-food
    supply chain. To solve this problem, firstly, combining with the status of Chinese
    agricultural development, we proposed a more suitable supply chain structure in
    the fusion application environment of Big Data and blockchain. Then, we chose
    a green agri-food supply chain with one producer and one retailer as research
    object and revised the demand function. Afterwards, considering the changes of
    agri-food freshness and greenness, we built and analysed the benefit models of
    producer and retailer before and after using ISBD, and then a cost-sharing and
    revenue-sharing contract was put forward to coordinate the supply chain. Findings:
    1) When the total investment cost payed by producer and retailer is in a certain
    range, using ISBD will help chain members gain more benefits. 2) If chain members
    want to gain more benefits after using ISBD, they should try their best to optimize
    costs by extracting valuable information. Results can offer a theoretical guidance
    for producer and retailer in investing in ISBD, pricing decision and supply chain
    coordination after applying ISBD.'
  Author: Pan Liu and Yue Long and Hai-Cao Song and Yan-Dong He
  Book_Title_Journal: Journal of Cleaner Production
  DOI: https://doi.org/10.1016/j.jclepro.2020.123646
  JCS_FACTOR: 9.297
  Keywords: Big data, Blockchain, Agri-food supply chain, Investment decision, Coordination
  SCI_FACTOR: 1.937
  Title: Investment decision and coordination of green agri-food supply chain considering
    information service based on blockchain and big data
  Title_JCS: Journal of Cleaner Production
  Title_SCI: Journal of Cleaner Production
  Type_Publication: article
  Year: 2020
- Abstract: 'With the development of the integrated energy Internet, energy structure
    optimization and emission reduction have led to higher requirements for developing
    various energy sources to enable coordinated and sustainable development. However,
    data-mining methods are rarely used to study the coordination of multi-energy
    generation in published research results. In this study, from the perspective
    of power industry emissions, coordinated generation of various energy sources,
    and balance of power generation and consumption, a data-mining algorithm was used
    to analyze the development of thermal power, hydropower, wind power, waste heat,
    gas, and other power sources. The chi-square automatic interaction detection tree
    (CHAID), logistic regression, and two-step clustering methods were applied. The
    results show that: a) CO2 and SO2 emissions were mainly affected by thermal power
    generation, whereas NOx emissions were jointly affected by thermal power, garbage
    power, and gas-fired power, and the emissions of various pollutants increased
    with an increase in power consumption. The optimal power-generation scheme under
    minimum emission can be obtained. b) There was a strong correlation between thermal
    power generation and residential electricity consumption, and renewable energy
    (wind energy, photovoltaic, hydropower) exhibited the highest correlation with
    the electricity consumption of the tertiary industry, which indicates that renewable
    energy generation can be promoted by managing electricity consumption in the tertiary
    industry. c) When the electricity demand of all users was small, the proportion
    of renewable energy power generation increased; in contrast, the thermal power
    generation was larger. This indicates the importance of improving the sustainable
    and stable power supply of renewable energy. This study provides a data analysis
    model for the coordinated development of multiple energies, which will contribute
    to the decision-making basis for controlling power emissions, improving the utilization
    rate of renewable energy, and optimizing the energy structure.'
  Author: Dongfang Ren and Xiaopeng Guo and Cunbin Li
  Book_Title_Journal: Journal of Cleaner Production
  DOI: https://doi.org/10.1016/j.jclepro.2021.128154
  JCS_FACTOR: 9.297
  Keywords: Multi-energy power generation, Pollutant emission, Big data analysis,
    Renewable energy generation, Thermal power
  SCI_FACTOR: 1.937
  Title: "Research on big data analysis model of multi energy power generation considering\
    \ pollutant emission\xE2\u20AC\u201DEmpirical analysis from Shanxi Province"
  Title_JCS: Journal of Cleaner Production
  Title_SCI: Journal of Cleaner Production
  Type_Publication: article
  Year: 2021
- Abstract: From the last decade, additive manufacturing (AM) has been evolving speedily
    and has revealed the great potential for energy-saving and cleaner environmental
    production due to a reduction in material and resource consumption and other tooling
    requirements. In this modern era, with the advancements in manufacturing technologies,
    academia and industry have been given more interest in smart manufacturing for
    taking benefits for making their production more sustainable and effective. In
    the present study, the significant techniques of smart manufacturing, sustainable
    manufacturing, and additive manufacturing are combined to make a unified term
    of sustainable and smart additive manufacturing (SSAM). The paper aims to develop
    framework by combining big data analytics, additive manufacturing, and sustainable
    smart manufacturing technologies which is beneficial to the additive manufacturing
    enterprises. So, a framework of big data-driven sustainable and smart additive
    manufacturing (BD-SSAM) is proposed which helped AM industry leaders to make better
    decisions for the beginning of life (BOL) stage of product life cycle. Finally,
    an application scenario of the additive manufacturing industry was presented to
    demonstrate the proposed framework. The proposed framework is implemented on the
    BOL stage of product lifecycle due to limitation of available resources and for
    fabrication of AlSi10Mg alloy components by using selective laser melting (SLM)
    technique of AM. The results indicate that energy consumption and quality of the
    product are adequately controlled which is helpful for smart sustainable manufacturing,
    emission reduction, and cleaner production.
  Author: Arfan Majeed and Yingfeng Zhang and Shan Ren and Jingxiang Lv and Tao Peng
    and Saad Waqar and Enhuai Yin
  Book_Title_Journal: Robotics and Computer-Integrated Manufacturing
  DOI: https://doi.org/10.1016/j.rcim.2020.102026
  JCS_FACTOR: 5.666
  Keywords: Big data, Additive manufacturing, Sustainable manufacturing, Smart manufacturing,
    Optimization
  SCI_FACTOR: 1.561
  Title: A big data-driven framework for sustainable and smart additive manufacturing
  Title_JCS: ROBOTICS AND COMPUTER-INTEGRATED MANUFACTURING
  Title_SCI: Robotics and Computer-Integrated Manufacturing
  Type_Publication: article
  Year: 2021
- Abstract: "In the \xE2\u20AC\u0153Internet+\xE2\u20AC\x9D era, involving third-party\
    \ Internet recycling platforms (IRPs) has revolutionized the operation models\
    \ of closed-loop supply chains (CLSCs) in China. This study explores the impact\
    \ of technological innovation, Big Data marketing and overconfidence on supply\
    \ chain member decision-making. We propose a two-stage remanufacturing CLSC dynamic\
    \ model consisting of a manufacturer, an IRP, and a supplier based on differential\
    \ game theory. By comparing the optimal decisions of each member in three scenarios,\
    \ we find that the IRP\xE2\u20AC\u2122s overconfident behavior is beneficial to\
    \ both the manufacturer and the IRP but will damage the supplier's profit. Although\
    \ a suitable cost-sharing ratio can enable the manufacturer and IRP to achieve\
    \ a \xE2\u20AC\u0153win\xE2\u20AC\u201Cwin\xE2\u20AC\x9D situation, an excessive\
    \ level of confidence will inhibit the incentives of the cost-sharing strategy,\
    \ negatively affecting the manufacturer's interests. Interestingly, a cost-sharing\
    \ contract will become inefficient under certain conditions, i.e., highly efficient\
    \ level of technological innovation, highly efficient Big Data marketing, and\
    \ a high level of overconfidence, negatively affecting the manufacturer\xE2\u20AC\
    \u2122s interests. Additionally, technological innovation efficiency and marketing\
    \ efficiency will have different effects on the IRP's recycling price. A cost-sharing\
    \ contract and the IRP\xE2\u20AC\u2122s overconfidence will prompt the IRP to\
    \ exert more efforts on technological innovation and Big Data marketing and to\
    \ significantly reduce the manufacturing costs and recycling costs for all members.\
    \ Notably, although the IRP\xE2\u20AC\u2122s overconfidence and cost-sharing strategies\
    \ may damage the supplier\xE2\u20AC\u2122s profit, the total profit of the CLSC\
    \ increases."
  Author: Zehua Xiang and Minli Xu
  Book_Title_Journal: Computers & Industrial Engineering
  DOI: https://doi.org/10.1016/j.cie.2020.106538
  JCS_FACTOR: 5.431
  Keywords: Supply chain management, Big Data marketing, Technological innovation,
    Closed-loop supply chain, Overconfidence
  SCI_FACTOR: 0.0
  Title: Dynamic game strategies of a two-stage remanufacturing closed-loop supply
    chain considering Big Data marketing, technological innovation and overconfidence
  Title_JCS: COMPUTERS & INDUSTRIAL ENGINEERING
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: The onset of the Internet of Things enables machines to be outfitted with
    always-on sensors that can provide health information to cloud-based monitoring
    systems for prognostics and health management (PHM), which greatly improves reliability
    and avoids downtime of machines and processes on the shop floor. On the other
    hand, real-time monitoring produces large amounts of data, leading to significant
    challenges for efficient and effective data transmission (from the shop floor
    to the cloud) and analysis (in the cloud). Restricted by industrial hardware capability,
    especially Internet bandwidth, most solutions approach data transmission from
    the perspective of data compression (before transmission, at local computing devices)
    coupled with data reconstruction (after transmission, in the cloud). However,
    existing data compression techniques may not adapt to domain-specific characteristics
    of data, and hence have limitations in addressing high compression ratios where
    full restoration of signal details is important for revealing machine conditions.
    This study integrates Deep Convolutional Autoencoders (DCAE) with local structure
    and physics-informed loss terms that incorporate PHM domain knowledge such as
    the importance of frequency content for machine fault diagnosis. Furthermore,
    Fault Division Autoencoder Multiplexing (FDAM) is proposed to mitigate the negative
    effects of multiple disjoint operating conditions on reconstruction fidelity.
    The proposed methods are evaluated on two case studies, and autocorrelation-based
    noise analysis provides insight into the relative performance across machine health
    and operating conditions. Results indicate that physically-informed DCAE compression
    outperforms prevalent data compression approaches, such as compressed sensing,
    Principal Component Analysis (PCA), Discrete Cosine Transform (DCT), and DCAE
    with a standard loss function. FDAM can further improve the data reconstruction
    quality for certain machine conditions.
  Author: Matthew Russell and Peng Wang
  Book_Title_Journal: Mechanical Systems and Signal Processing
  DOI: https://doi.org/10.1016/j.ymssp.2021.108709
  JCS_FACTOR: 6.823
  Keywords: Physics-informed deep learning, Prognostics and health management, Data
    compression, Big data
  SCI_FACTOR: 2.275
  Title: Physics-informed deep learning for signal compression and reconstruction
    of big data in industrial condition monitoring
  Title_JCS: MECHANICAL SYSTEMS AND SIGNAL PROCESSING
  Title_SCI: Mechanical Systems and Signal Processing
  Type_Publication: article
  Year: 2022
- Abstract: Technology has become inevitable in human life, especially the growth
    of Internet of Things (IoT), which enables communication and interaction with
    various devices. However, IoT has been proven to be vulnerable to security breaches.
    Therefore, it is necessary to develop fool proof solutions by creating new technologies
    or combining existing technologies to address the security issues. Deep learning,
    a branch of machine learning has shown promising results in previous studies for
    detection of security breaches. Additionally, IoT devices generate large volumes,
    variety, and veracity of data. Thus, when big data technologies are incorporated,
    higher performance and better data handling can be achieved. Hence, we have conducted
    a comprehensive survey on state-of-the-art deep learning, IoT security, and big
    data technologies. Further, a comparative analysis and the relationship among
    deep learning, IoT security, and big data technologies have also been discussed.
    Further, we have derived a thematic taxonomy from the comparative analysis of
    technical studies of the three aforementioned domains. Finally, we have identified
    and discussed the challenges in incorporating deep learning for IoT security using
    big data technologies and have provided directions to future researchers on the
    IoT security aspects.
  Author: Mohamed Ahzam Amanullah and Riyaz Ahamed Ariyaluran Habeeb and Fariza Hanum
    Nasaruddin and Abdullah Gani and Ejaz Ahmed and Abdul Salam Mohamed Nainar and
    Nazihah Md Akim and Muhammad Imran
  Book_Title_Journal: Computer Communications
  DOI: https://doi.org/10.1016/j.comcom.2020.01.016
  JCS_FACTOR: 3.167
  Keywords: Deep learning, Big data, IoT security
  SCI_FACTOR: 0.627
  Title: Deep learning and big data technologies for IoT security
  Title_JCS: COMPUTER COMMUNICATIONS
  Title_SCI: Computer Communications
  Type_Publication: article
  Year: 2020
- Abstract: This is the first systematic literature review concerning the interconnections
    between big data (BD) and co-innovation. It uses BD as a common perspective of
    analysis as well as a concept aggregating different research streams (open innovation,
    co-creation and collaborative innovation). The review is based on the results
    of a bibliographic coupling analysis performed with 51 peer-reviewed papers published
    before the end of 2019. Three thematic clusters were discovered, which respectively
    focused on BD as a knowledge creation enabler within co-innovation contexts, BD
    as a driver of co-innovation processes based on customer engagement, and the impact
    of BD on co-innovation within service ecosystems. The paper theoretically argues
    that the use of BD, in addition to enhancing intentional and direct collaborative
    innovation processes, allows the development of passive and unintentional co-innovation
    that can be implemented through indirect relationships between the collaborative
    actors. This study also makes eleven unique research propositions concerning further
    theoretical developments and managerial implementations in the field of BD-driven
    co-innovation.
  Author: Stefano Bresciani and Francesco Ciampi and Francesco Meli and Alberto Ferraris
  Book_Title_Journal: International Journal of Information Management
  DOI: https://doi.org/10.1016/j.ijinfomgt.2021.102347
  JCS_FACTOR: 14.098
  Keywords: Big data, Co-innovation, Open innovation, Bibliometric analysis, Literature
    review
  SCI_FACTOR: 2.77
  Title: 'Using big data for co-innovation processes: Mapping the field of data-driven
    innovation, proposing theoretical developments and providing a research agenda'
  Title_JCS: INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
  Title_SCI: International Journal of Information Management
  Type_Publication: article
  Year: 2021
- Abstract: Big data has increasingly appeared as a frontier of opportunity in enhancing
    firm performance. However, it still is in early stages of introduction and many
    enterprises are still un-decisive in its adoption. The aim of this study is to
    propose a theoretical model based on integration of Human-Organization-Technology
    fit and Technology-Organization-Environment frameworks to identify the key factors
    affecting big data adoption and its consequent impact on the firm performance.
    The significant factors are gained from the literature and the research model
    is developed. Data was collected from top managers and/or owners of SMEs hotels
    in Malaysia using online survey questionnaire. Structural Equation Modelling (SEM)
    is used to assess the developed model and Adaptive Neuro-Fuzzy Inference Systems
    (ANFIS) technique is used to prioritize adoption factors based on their importance
    levels. The results showed that relative advantage, management support, IT expertise,
    and external pressure are the most important factors in the technological, organizational,
    human, and environmental dimensions. The results further revealed that technology
    is the most important influential dimension. The outcomes of this study can assist
    the policy makers, businesses and governments to make well-informed decisions
    in adopting big data.
  Author: Elaheh Yadegaridehkordi and Mehrbakhsh Nilashi and Liyana Shuib and Mohd
    {Hairul Nizam Bin Md Nasir} and Shahla Asadi and Sarminah Samad and Nor {Fatimah
    Awang}
  Book_Title_Journal: Electronic Commerce Research and Applications
  DOI: https://doi.org/10.1016/j.elerap.2019.100921
  JCS_FACTOR: 6.014
  Keywords: Firm performance, Big data, Hotel industry, Fuzzy logic, Structural equation
    modelling
  SCI_FACTOR: 1.184
  Title: The impact of big data on firm performance in hotel industry
  Title_JCS: Electronic Commerce Research and Applications
  Title_SCI: Electronic Commerce Research and Applications
  Type_Publication: article
  Year: 2020
- Abstract: Big data has increasingly appeared as a frontier of opportunity in enhancing
    firm performance. However, it still is in early stages of introduction and many
    enterprises are still un-decisive in its adoption. The aim of this study is to
    propose a theoretical model based on integration of Human-Organization-Technology
    fit and Technology-Organization-Environment frameworks to identify the key factors
    affecting big data adoption and its consequent impact on the firm performance.
    The significant factors are gained from the literature and the research model
    is developed. Data was collected from top managers and/or owners of SMEs hotels
    in Malaysia using online survey questionnaire. Structural Equation Modelling (SEM)
    is used to assess the developed model and Adaptive Neuro-Fuzzy Inference Systems
    (ANFIS) technique is used to prioritize adoption factors based on their importance
    levels. The results showed that relative advantage, management support, IT expertise,
    and external pressure are the most important factors in the technological, organizational,
    human, and environmental dimensions. The results further revealed that technology
    is the most important influential dimension. The outcomes of this study can assist
    the policy makers, businesses and governments to make well-informed decisions
    in adopting big data.
  Author: Elaheh Yadegaridehkordi and Mehrbakhsh Nilashi and Liyana Shuib and Mohd
    {Hairul Nizam Bin Md Nasir} and Shahla Asadi and Sarminah Samad and Nor {Fatimah
    Awang}
  Book_Title_Journal: Electronic Commerce Research and Applications
  DOI: https://doi.org/10.1016/j.elerap.2019.100921
  JCS_FACTOR: 6.014
  Keywords: Firm performance, Big data, Hotel industry, Fuzzy logic, Structural equation
    modelling
  SCI_FACTOR: 1.184
  Title: The impact of big data on firm performance in hotel industry
  Title_JCS: Electronic Commerce Research and Applications
  Title_SCI: Electronic Commerce Research and Applications
  Type_Publication: article
  Year: 2020
- Abstract: "The advent and development of digital technologies have brought about\
    \ a proliferation of online consumer reviews (OCRs), i.e., real-time customers\xE2\
    \u20AC\u2122 evaluations of products, services, and brands. Increasingly, e-commerce\
    \ platforms are using them to gain insights from customer feedback. Meanwhile,\
    \ a new generation of big data analytics (BDA) companies are crowdsourcing large\
    \ volumes of OCRs by means of controlled ad hoc online experiments and advanced\
    \ machine learning (ML) techniques to forecast demand and determine the market\
    \ potential for new products in several industries. We illustrate how this process\
    \ is taking place for consumer goods companies by exploring the case of UK digital\
    \ BDA company, SoundOut. Based on an in-depth qualitative analysis, we develop\
    \ the consumer goods company innovation (CGCI) conceptual framework, which illustrates\
    \ how digital BDA firms help consumer goods companies to test new products before\
    \ they are launched on the market, and innovate. Theoretical and managerial implications\
    \ are discussed."
  Author: Marcello M. Mariani and Samuel {Fosso Wamba}
  Book_Title_Journal: Journal of Business Research
  DOI: https://doi.org/10.1016/j.jbusres.2020.09.012
  JCS_FACTOR: 7.55
  Keywords: Big data analytics, Forecasting, Innovation, Online review crowdsourcing,
    Consumer goods companies, Digital data
  SCI_FACTOR: 2.049
  Title: 'Exploring how consumer goods companies innovate in the digital age: The
    role of big data analytics companies'
  Title_JCS: JOURNAL OF BUSINESS RESEARCH
  Title_SCI: Journal of Business Research
  Type_Publication: article
  Year: 2020
- Abstract: "Life cycle assessment (LCA) and life cycle cost (LCC) are two primary\
    \ methods used to assess the environmental and economic feasibility of building\
    \ construction. An estimation of the building's life span is essential to carrying\
    \ out these methods. However, given the diverse factors that affect the building's\
    \ life span, it was estimated typically based on its main structural type. However,\
    \ different buildings have different life spans. Simply assuming that all buildings\
    \ with the same structural type follow an identical life span can cause serious\
    \ estimation errors. In this study, we collected 1,812,700 records describing\
    \ buildings built and demolished in South Korea, analysed the actual life span\
    \ of each building, and developed a building life-span prediction model using\
    \ deep-learning and traditional machine learning. The prediction models examined\
    \ in this study produced root mean square errors of 3.72\xE2\u20AC\u201C4.6 and\
    \ the coefficients of determination of 0.932\xE2\u20AC\u201C0.955. Among those\
    \ models, a deep-learning based prediction model was found the most powerful.\
    \ As anticipated, the conventional method of determining a building's life expectancy\
    \ using a discrete set of specific factors and associated assumptions of life\
    \ span did not yield realistic results. This study demonstrates that an application\
    \ of deep learning to the LCA and LCC of a building is a promising direction,\
    \ effectively guiding business planning and critical decision making throughout\
    \ the construction process."
  Author: Sukwon Ji and Bumho Lee and Mun Yong Yi
  Book_Title_Journal: Building and Environment
  DOI: https://doi.org/10.1016/j.buildenv.2021.108267
  JCS_FACTOR: 6.456
  Keywords: Building life span, Life cycle cost, Life cycle assessment, Big data,
    Machine learning, Deep neural network
  SCI_FACTOR: 1.736
  Title: 'Building life-span prediction for life cycle assessment and life cycle cost
    using machine learning: A big data approach'
  Title_JCS: BUILDING AND ENVIRONMENT
  Title_SCI: Building and Environment
  Type_Publication: article
  Year: 2021
- Abstract: Grounded in gestalt insight learning theory and organizational learning
    theory, we collected data from 280 middle and top-level managers to investigate
    the impact of each big data characteristic (i.e., data volume, data velocity,
    data variety, and data veracity) on firm innovation competency (i.e., exploitation
    competency and exploration competency), mediated through data-driven insight generation
    (i.e., descriptive insight, predictive insight, and prescriptive insight). Findings
    show that while data velocity, variety, and veracity enhance data-driven insight
    generation, data volume does not impact it. Additionally, results of the post
    hoc analysis indicate that while descriptive and predictive insights improve innovation
    competency, prescriptive insight does not affect it. These results provide interesting
    and unique theoretical and practical insights.
  Author: Maryam Ghasemaghaei and Goran Calic
  Book_Title_Journal: Journal of Business Research
  DOI: https://doi.org/10.1016/j.jbusres.2019.07.006
  JCS_FACTOR: 7.55
  Keywords: Big data characteristics, Descriptive insight, Predictive insight, Prescriptive
    insight, Innovation competency
  SCI_FACTOR: 2.049
  Title: Does big data enhance firm innovation competency? The mediating role of data-driven
    insights
  Title_JCS: JOURNAL OF BUSINESS RESEARCH
  Title_SCI: Journal of Business Research
  Type_Publication: article
  Year: 2019
- Abstract: "Analysis of data by humans can be a time-consuming activity and thus\
    \ use of sophisticated cognitive systems can be utilized to crunch this enormous\
    \ amount of data. Cognitive computing can be utilized to reduce the shortcomings\
    \ of the concerns faced during big data analytics. The aim of the study is to\
    \ provide readers a complete understanding of past, present and future directions\
    \ in the domain big data and cognitive computing. A systematic literature review\
    \ has been adopted for this study by using the Scopus, DBLP and Web of Science\
    \ databases. The work done in the field of big data and cognitive computing is\
    \ currently at the nascent stage and this is evident from the publication record.\
    \ The characteristics of cognitive computing, namely observation, interpretation,\
    \ evaluation and decision were mapped to the five V\xE2\u20AC\u2122s of big data\
    \ namely volume, variety, veracity, velocity and value. Perspectives which touch\
    \ all these parameters are yet to be widely explored in existing literature."
  Author: Shivam Gupta and Arpan Kumar Kar and Abdullah Baabdullah and Wassan A.A.
    Al-Khowaiter
  Book_Title_Journal: International Journal of Information Management
  DOI: https://doi.org/10.1016/j.ijinfomgt.2018.06.005
  JCS_FACTOR: 14.098
  Keywords: Big data, Cognitive computing, Literature review, Resource based View,
    Institutional theory
  SCI_FACTOR: 2.77
  Title: 'Big data with cognitive computing: A review for the future'
  Title_JCS: INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
  Title_SCI: International Journal of Information Management
  Type_Publication: article
  Year: 2018
- Abstract: Cloud computing is a powerful technology to perform massive-scale and
    complex computing. It eliminates the need to maintain expensive computing hardware,
    dedicated space, and software. Massive growth in the scale of data or big data
    generated through cloud computing has been observed. Addressing big data is a
    challenging and time-demanding task that requires a large computational infrastructure
    to ensure successful data processing and analysis. The rise of big data in cloud
    computing is reviewed in this study. The definition, characteristics, and classification
    of big data along with some discussions on cloud computing are introduced. The
    relationship between big data and cloud computing, big data storage systems, and
    Hadoop technology are also discussed. Furthermore, research challenges are investigated,
    with focus on scalability, availability, data integrity, data transformation,
    data quality, data heterogeneity, privacy, legal and regulatory issues, and governance.
    Lastly, open research issues that require substantial research efforts are summarized.
  Author: Ibrahim Abaker Targio Hashem and Ibrar Yaqoob and Nor Badrul Anuar and Salimah
    Mokhtar and Abdullah Gani and Samee {Ullah Khan}
  Book_Title_Journal: Information Systems
  DOI: https://doi.org/10.1016/j.is.2014.07.006
  JCS_FACTOR: 2.309
  Keywords: Big data, Cloud computing, Hadoop
  SCI_FACTOR: 0.547
  Title: "The rise of \xE2\u20AC\u0153big data\xE2\u20AC\x9D on cloud computing: Review\
    \ and open research issues"
  Title_JCS: INFORMATION SYSTEMS
  Title_SCI: Information Systems
  Type_Publication: article
  Year: 2015
- Abstract: 'In a fast growing big data era, volume and varieties of data processed
    in Internet applications drastically increase. Real-world search engines commonly
    use text classifiers with thousands of classes to improve relevance or data quality.
    These large scale classification problems lead to severe runtime performance challenges,
    so practitioners often resort to fast approximation techniques. However, the increase
    in classification speed comes at a cost, as approximations are lossy, mis-assigning
    classes relative to the original reference classification algorithm. To address
    this problem, we introduce a Lossless Pruned Naive Bayes (LPNB) classification
    algorithm tailored to real-world, big data applications with thousands of classes.
    LPNB achieves significant speed-ups by drawing on Information Retrieval (IR) techniques
    for efficient posting list traversal and pruning. We show empirically that LPNB
    can classify text up to eleven times faster than standard Naive Bayes on a real-world
    data set with 7205 classes, with larger gains extrapolated for larger taxonomies.
    In practice, the achieved acceleration is significant as it can greatly cut required
    computation time. In addition, it is lossless: the output is identical to standard
    Naive Bayes, in contrast to extant techniques such as hierarchical classification.
    The acceleration does not rely on the taxonomy structure, and it can be used for
    both hierarchical and flat taxonomies.'
  Author: Nanfei Sun and Bingjun Sun and Jian (Denny) Lin and Michael Yu-Chi Wu
  Book_Title_Journal: Big Data Research
  DOI: https://doi.org/10.1016/j.bdr.2018.05.007
  JCS_FACTOR: 3.578
  Keywords: Big data, Classification, Naive Bayes, Large-scale taxonomy, Lossless,
    Pruned
  SCI_FACTOR: 0.565
  Title: Lossless Pruned Naive Bayes for Big Data Classifications
  Title_JCS: Big Data Research
  Title_SCI: Big Data Research
  Type_Publication: article
  Year: 2018
- Abstract: 'Introduction

    Machine learning capability holds promise to inform disease models, the discovery
    and development of novel disease modifying therapeutics and prevention strategies
    in psychiatry. Herein, we provide an introduction on how machine learning/Artificial
    Intelligence (AI) may instantiate such capabilities, as well as provide rationale
    for its application to psychiatry in both research and clinical ecosystems.

    Methods

    Databases PubMed and PsycINFO were searched from 1966 to June 2016 for keywords:Big
    Data, Machine Learning, Precision Medicine, Artificial Intelligence, Mental Health,
    Mental Disease, Psychiatry, Data Mining, RDoC, and Research Domain Criteria. Articles
    selected for review were those that were determined to be aligned with the objective
    of this particular paper.

    Results

    Results indicate that AI is a viable option to build useful predictors of outcome
    while offering objective and comparable accuracy metrics, a unique opportunity,
    particularly in mental health research. The approach has also consistently brought
    notable insight into disease models through processing the vast amount of already
    available multi-domain, semi-structured medical data. The opportunity for AI in
    psychiatry, in addition to disease-model refinement, is in characterizing those
    at risk, and it is likely also relevant to personalizing and discovering therapeutics.

    Conclusions

    Machine learning currently provides an opportunity to parse disease models in
    complex, multi-factorial disease states (e.g. mental disorders) and could possibly
    inform treatment selection with existing therapies and provide bases for domain-based
    therapeutic discovery.'
  Author: Andy M.Y. Tai and Alcides Albuquerque and Nicole E. Carmona and Mehala Subramanieapillai
    and Danielle S. Cha and Margarita Sheko and Yena Lee and Rodrigo Mansur and Roger
    S. McIntyre
  Book_Title_Journal: Artificial Intelligence in Medicine
  DOI: https://doi.org/10.1016/j.artmed.2019.101704
  JCS_FACTOR: 5.326
  Keywords: Big data, Machine learning, Precision medicine, AI, Mental health, Mental
    disease, Psychiatry, Data mining, RDoC, Research domain criteria, DSM-5. Schizophrenia,
    ADHD, Alzheimer, Depression, fMRI, MRI, Algorithms, IBM Watson, Neuro networking,
    Random forests, Decision trees, Support vector machines
  SCI_FACTOR: 0.98
  Title: 'Machine learning and big data: Implications for disease modeling and therapeutic
    discovery in psychiatry'
  Title_JCS: ARTIFICIAL INTELLIGENCE IN MEDICINE
  Title_SCI: Artificial Intelligence in Medicine
  Type_Publication: article
  Year: 2019
- Abstract: 'Big Data Analytics (BDA) is increasingly becoming a trending practice
    that generates an enormous amount of data and provides a new opportunity that
    is helpful in relevant decision-making. The developments in Big Data Analytics
    provide a new paradigm and solutions for big data sources, storage, and advanced
    analytics. The BDA provide a nuanced view of big data development, and insights
    on how it can truly create value for firm and customer. This article presents
    a comprehensive, well-informed examination, and realistic analysis of deploying
    big data analytics successfully in companies. It provides an overview of the architecture
    of BDA including six components, namely: (i) data generation, (ii) data acquisition,
    (iii) data storage, (iv) advanced data analytics, (v) data visualization, and
    (vi) decision-making for value-creation. In this paper, seven V''s characteristics
    of BDA namely Volume, Velocity, Variety, Valence, Veracity, Variability, and Value
    are explored. The various big data analytics tools, techniques and technologies
    have been described. Furthermore, it presents a methodical analysis for the usage
    of Big Data Analytics in various applications such as agriculture, healthcare,
    cyber security, and smart city. This paper also highlights the previous research,
    challenges, current status, and future directions of big data analytics for various
    application platforms. This overview highlights three issues, namely (i) concepts,
    characteristics and processing paradigms of Big Data Analytics; (ii) the state-of-the-art
    framework for decision-making in BDA for companies to insight value-creation;
    and (iii) the current challenges of Big Data Analytics as well as possible future
    directions.'
  Author: Mandeep Kaur Saggi and Sushma Jain
  Book_Title_Journal: Information Processing & Management
  DOI: https://doi.org/10.1016/j.ipm.2018.01.010
  JCS_FACTOR: 6.222
  Keywords: Big data, Data analytics, Machine learning, Big data visualization, Decision-making,
    Smart agriculture, Smart city application, Value-creation, Value-discover, Value-realization
  SCI_FACTOR: 0.0
  Title: A survey towards an integration of big data analytics to big insights for
    value-creation
  Title_JCS: INFORMATION PROCESSING & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2018
- Abstract: 'Big Data Analytics (BDA) is increasingly becoming a trending practice
    that generates an enormous amount of data and provides a new opportunity that
    is helpful in relevant decision-making. The developments in Big Data Analytics
    provide a new paradigm and solutions for big data sources, storage, and advanced
    analytics. The BDA provide a nuanced view of big data development, and insights
    on how it can truly create value for firm and customer. This article presents
    a comprehensive, well-informed examination, and realistic analysis of deploying
    big data analytics successfully in companies. It provides an overview of the architecture
    of BDA including six components, namely: (i) data generation, (ii) data acquisition,
    (iii) data storage, (iv) advanced data analytics, (v) data visualization, and
    (vi) decision-making for value-creation. In this paper, seven V''s characteristics
    of BDA namely Volume, Velocity, Variety, Valence, Veracity, Variability, and Value
    are explored. The various big data analytics tools, techniques and technologies
    have been described. Furthermore, it presents a methodical analysis for the usage
    of Big Data Analytics in various applications such as agriculture, healthcare,
    cyber security, and smart city. This paper also highlights the previous research,
    challenges, current status, and future directions of big data analytics for various
    application platforms. This overview highlights three issues, namely (i) concepts,
    characteristics and processing paradigms of Big Data Analytics; (ii) the state-of-the-art
    framework for decision-making in BDA for companies to insight value-creation;
    and (iii) the current challenges of Big Data Analytics as well as possible future
    directions.'
  Author: Mandeep Kaur Saggi and Sushma Jain
  Book_Title_Journal: Information Processing & Management
  DOI: https://doi.org/10.1016/j.ipm.2018.01.010
  JCS_FACTOR: 6.222
  Keywords: Big data, Data analytics, Machine learning, Big data visualization, Decision-making,
    Smart agriculture, Smart city application, Value-creation, Value-discover, Value-realization
  SCI_FACTOR: 0.0
  Title: A survey towards an integration of big data analytics to big insights for
    value-creation
  Title_JCS: INFORMATION PROCESSING & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2018
- Abstract: 'Recently, big data (BD) has attracted researchers and practitioners due
    to its potential usefulness in decision-making processes. Big data analytics (BDA)
    is becoming increasingly popular among manufacturing companies as it helps gain
    insights and make decisions based on BD. However, there many barriers to the adoption
    of BDA in manufacturing supply chains. It is therefore necessary for manufacturing
    companies to identify and examine the nature of each barrier. Previous studies
    have mostly built conceptual frameworks for BDA in a given situation and have
    ignored examining the nature of the barriers to BDA. Due to the significance of
    both BD and BDA, this research aims to identify and examine the critical barriers
    to the adoption of BDA in manufacturing supply chains in the context of Bangladesh.
    This research explores the existing body of knowledge by examining these barriers
    using a Delphi-based analytic hierarchy process (AHP). Data were obtained from
    five Bangladeshi manufacturing companies. The findings of this research are as
    follows: (i) data-related barriers are most important, (ii) technology-related
    barriers are second, and (iii) the five most important components of these barriers
    are (a) lack of infrastructure, (b) complexity of data integration, (c) data privacy,
    (d) lack of availability of BDA tools and (e) high cost of investment. The findings
    can assist industrial managers to understand the actual nature of the barriers
    and potential benefits of using BDA and to make policy regarding BDA adoption
    in manufacturing supply chains. A sensitivity analysis was carried out to justify
    the robustness of the barrier rankings.'
  Author: Md. Abdul Moktadir and Syed Mithun Ali and Sanjoy Kumar Paul and Nagesh
    Shukla
  Book_Title_Journal: Computers & Industrial Engineering
  DOI: https://doi.org/10.1016/j.cie.2018.04.013
  JCS_FACTOR: 5.431
  Keywords: AHP, Big data analytics, Barriers to BDA, Delphi, Information and communication
    technology (ICT), Manufacturing supply chains
  SCI_FACTOR: 0.0
  Title: 'Barriers to big data analytics in manufacturing supply chains: A case study
    from Bangladesh'
  Title_JCS: COMPUTERS & INDUSTRIAL ENGINEERING
  Title_SCI: N/A
  Type_Publication: article
  Year: 2019
- Abstract: The business concept of the circular economy (CE) has gained significant
    momentum among practitioners and researchers alike. However, successful adoption
    and implementation of this paradigm of managing business remains a challenge.
    In this article, we build a case for utilizing big data analytics (BDA) as a fundamental
    basis for informed and data driven decision making in supply chain networks supporting
    CE. We view this from a stakeholder perspective and argue that a collaborative
    association among all supply chain members can positively affect CE implementation.
    We propose a model highlighting the facilitating role of big data analytics for
    achieving shared sustainability goals. The model is based on integrating thematic
    categories coming out of 10 semi-structured interviews with key position holders
    in industry. We argue that mutual support and coordination driven by a stakeholder
    perspective coupled with holistic information processing and sharing along the
    entire supply chain network can effectively create a basis for achieving the triple
    bottom line of economic, ecological and social benefits. The proposed model is
    useful for managers in that it provides a reference point for aligning activities
    with the circular economy paradigm. The conceptual model provides a theoretical
    basis for future empirical research in this domain.
  Author: "Shivam Gupta and Haozhe Chen and Benjamin T. Hazen and Sarabjot Kaur and\
    \ Ernesto D.R. {Santiba\xC3\xB1ez Gonzalez}"
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2018.06.030
  JCS_FACTOR: 8.593
  Keywords: Circular economy, Big data, Stakeholder theory, Relational view, Supply
    chain management, Sustainability
  SCI_FACTOR: 2.226
  Title: 'Circular economy and big data analytics: A stakeholder perspective'
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2019
- Abstract: Organizations are looking for ways to harness the power of big data (BD)
    to improve their decision making. Despite its significance the effects of BD on
    decision-making quality has been given scant attention in the literature. In this
    paper factors influencing decision-making based on BD are identified using a case
    study. BD is collected from different sources that have various data qualities
    and are processed by various organizational entities resulting in the creation
    of a big data chain. The veracity (manipulation, noise), variety (heterogeneity
    of data) and velocity (constantly changing data sources) amplified by the size
    of big data calls for relational and contractual governance mechanisms to ensure
    BD quality and being able to contextualize data. The case study reveals that taking
    advantage of big data is an evolutionary process in which the gradually understanding
    of the potential of big data and the routinization of processes plays a crucial
    role.
  Author: Marijn Janssen and Haiko {van der Voort} and Agung Wahyudi
  Book_Title_Journal: Journal of Business Research
  DOI: https://doi.org/10.1016/j.jbusres.2016.08.007
  JCS_FACTOR: 7.55
  Keywords: Big data, Big data analytics, Big data chain, E-government, Governance,
    Decision-making, Decision-making quality
  SCI_FACTOR: 2.049
  Title: Factors influencing big data decision-making quality
  Title_JCS: JOURNAL OF BUSINESS RESEARCH
  Title_SCI: Journal of Business Research
  Type_Publication: article
  Year: 2017
- Abstract: As one of the bottleneck technologies of electric vehicles (EVs), the
    battery hosts complex and hardly observable internal chemical reactions. Therefore,
    a precise mathematical model is crucial for the battery management system (BMS)
    to ensure the secure and stable operation of the battery in a multi-variable environment.
    First, a Cloud-based BMS (C-BMS) is established based on a database containing
    complete battery status information. Next, a data cleaning method based on machine
    learning is applied to the big data of batteries. Meanwhile, to improve the model
    stability under dynamic conditions, an F-divergence-based data distribution quality
    assessment method and a sampling-based data preprocess method is designed. Then,
    a lithium-ion battery temperature-dependent model is built based on Stacked Denoising
    Autoencoders- Extreme Learning Machine (SDAE-ELM) algorithm, and a new training
    method combined with data preprocessing is also proposed to improve the model
    accuracy. Finally, to improve reliability, a conjunction working mode between
    the C-BMS and the BMS in vehicles (V-BMS) is also proposed, providing as an applied
    case of the model. Using the battery data extracted from electric buses, the effectiveness
    and accuracy of the model are validated. The error of the estimated battery terminal
    voltage is within 2%, and the error of the estimated State of Charge (SoC) is
    within 3%.
  Author: Shuangqi Li and Hongwen He and Jianwei Li
  Book_Title_Journal: Applied Energy
  DOI: https://doi.org/10.1016/j.apenergy.2019.03.154
  JCS_FACTOR: 9.746
  Keywords: Electric vehicles, Battery energy storage, Temperature-dependent model,
    Battery management system, Big data, Deep learning
  SCI_FACTOR: 3.035
  Title: Big data driven lithium-ion battery modeling method based on SDAE-ELM algorithm
    and data pre-processing technology
  Title_JCS: APPLIED ENERGY
  Title_SCI: Applied Energy
  Type_Publication: article
  Year: 2019
- Abstract: "Although big data analytics (BDA) is considered the next \xE2\u20AC\u0153\
    frontier\xE2\u20AC\x9D in data science by creating potential business opportunities,\
    \ the way to extract those opportunities is unclear. This paper aims to understand\
    \ the antecedents of BDA value at a firm level. The authors performed a study\
    \ using a mixed methodology approach. First, by carrying out a Delphi study to\
    \ explore and rank the antecedents affecting the creation of BDA value. Based\
    \ on the Delphi results, we propose an empirically validated model supported by\
    \ a survey conducted on 175 European firms to explain the antecedents of BDA sustained\
    \ value. The results show that the proposed model explains 62% of BDA sustained\
    \ value at the firm level, where the most critical contributor is BDA use. We\
    \ provide directions for managers to support their decisions on BDA strategy definition\
    \ and refinement. For academics, we extend BDA value literature and outline some\
    \ potential research opportunities."
  Author: "Nadine C\xC3\xB4rte-Real and Pedro Ruivo and Tiago Oliveira and Ale\xC5\
    \xA1 Popovi\xC4\x8D"
  Book_Title_Journal: Journal of Business Research
  DOI: https://doi.org/10.1016/j.jbusres.2018.12.072
  JCS_FACTOR: 7.55
  Keywords: IT business value, Big data analytics (BDA), Delphi method, Mixed methodology,
    Competitive advantage
  SCI_FACTOR: 2.049
  Title: Unlocking the drivers of big data analytics value in firms
  Title_JCS: JOURNAL OF BUSINESS RESEARCH
  Title_SCI: Journal of Business Research
  Type_Publication: article
  Year: 2019
- Abstract: "Data quality assessment has gained attention in the recent years since\
    \ more and more companies and medical centers are highlighting the importance\
    \ of an automated framework to effectively manage the quality of their big data.\
    \ Data cleaning, also known as data curation, lies in the heart of the data quality\
    \ assessment and is a key aspect prior to the development of any data analytics\
    \ services. In this work, we present the objectives, functionalities and methodological\
    \ advances of an automated framework for data curation from a medical perspective.\
    \ The steps towards the development of a system for data quality assessment are\
    \ first described along with multidisciplinary data quality measures. A three-layer\
    \ architecture which realizes these steps is then presented. Emphasis is given\
    \ on the detection and tracking of inconsistencies, missing values, outliers,\
    \ and similarities, as well as, on data standardization to finally enable data\
    \ harmonization. A case study is conducted in order to demonstrate the applicability\
    \ and reliability of the proposed framework on two well-established cohorts with\
    \ clinical data related to the primary Sj\xC3\xB6gren's Syndrome (pSS). Our results\
    \ confirm the validity of the proposed framework towards the automated and fast\
    \ identification of outliers, inconsistencies, and highly-correlated and duplicated\
    \ terms, as well as, the successful matching of more than 85% of the pSS-related\
    \ medical terms in both cohorts, yielding more accurate, relevant, and consistent\
    \ clinical data."
  Author: Vasileios C. Pezoulas and Konstantina D. Kourou and Fanis Kalatzis and Themis
    P. Exarchos and Aliki Venetsanopoulou and Evi Zampeli and Saviana Gandolfo and
    Fotini Skopouli and Salvatore {De Vita} and Athanasios G. Tzioufas and Dimitrios
    I. Fotiadis
  Book_Title_Journal: Computers in Biology and Medicine
  DOI: https://doi.org/10.1016/j.compbiomed.2019.03.001
  JCS_FACTOR: 4.589
  Keywords: Big data, Data quality, Data quality assessment, Data curation, Data standardization
  SCI_FACTOR: 0.884
  Title: 'Medical data quality assessment: On the development of an automated framework
    for medical data curation'
  Title_JCS: COMPUTERS IN BIOLOGY AND MEDICINE
  Title_SCI: Computers in Biology and Medicine
  Type_Publication: article
  Year: 2019
- Abstract: Smart manufacturing has received increased attention from academia and
    industry in recent years, as it provides competitive advantage for manufacturing
    companies making industry more efficient and sustainable. As one of the most important
    technologies for smart manufacturing, big data analytics can uncover hidden knowledge
    and other useful information like relations between lifecycle decisions and process
    parameters helping industrial leaders to make more-informed business decisions
    in complex management environments. However, according to the literature, big
    data analytics and smart manufacturing were individually researched in academia
    and industry. To provide theoretical foundations for the research community to
    further develop scientific insights in applying big data analytics to smart manufacturing,
    it is necessary to summarize the existing research progress and weakness. In this
    paper, through combining the key technologies of smart manufacturing and the idea
    of ubiquitous servitization in the whole lifecycle, the term of sustainable smart
    manufacturing was coined. A comprehensive overview of big data in smart manufacturing
    was conducted, and a conceptual framework was proposed from the perspective of
    product lifecycle. The proposed framework allows analyzing potential applications
    and key advantages, and the discussion of current challenges and future research
    directions provides valuable insights for academia and industry.
  Author: Shan Ren and Yingfeng Zhang and Yang Liu and Tomohiko Sakao and Donald Huisingh
    and Cecilia M.V.B. Almeida
  Book_Title_Journal: Journal of Cleaner Production
  DOI: https://doi.org/10.1016/j.jclepro.2018.11.025
  JCS_FACTOR: 9.297
  Keywords: Big data analytics, Smart manufacturing, Servitization, Sustainable production,
    Conceptual framework, Product lifecycle
  SCI_FACTOR: 1.937
  Title: 'A comprehensive review of big data analytics throughout product lifecycle
    to support sustainable smart manufacturing: A framework, challenges and future
    research directions'
  Title_JCS: Journal of Cleaner Production
  Title_SCI: Journal of Cleaner Production
  Type_Publication: article
  Year: 2019
- Abstract: As more and more health systems have converted to the use of electronic
    health records, the amount of searchable and analyzable data is exploding. This
    includes not just provider or laboratory created data but also data collected
    by instruments, personal devices, and patients themselves, among others. This
    has led to more attention being paid to the analysis of these data to answer previously
    unaddressed questions. This is especially important given the number of therapies
    previously found to be beneficial in clinical trials that are currently being
    re-scrutinized. Because there are orders of magnitude more information contained
    in these data sets, a fundamentally different approach needs to be taken to their
    processing and analysis and the generation of knowledge. Health care and medicine
    are drivers of this phenomenon and will ultimately be the main beneficiaries.
    Concurrently, many different types of questions can now be asked using these data
    sets. Research groups have become increasingly active in mining large data sets,
    including nationwide health care databases, to learn about associations of medication
    use and various unrelated diseases such as cancer. Given the recent increase in
    research activity in this area, its promise to radically change clinical research,
    and the relative lack of widespread knowledge about its potential and advances,
    we surveyed the available literature to understand the strengths and limitations
    of these new tools. We also outline new databases and techniques that are available
    to researchers worldwide, with special focus on work pertaining to the broad and
    rapid monitoring of drug safety and secondary effects.
  Author: Ali Zarrinpar and Ting-Yuan {David Cheng} and Zhiguang Huo
  Book_Title_Journal: Journal of Surgical Research
  DOI: https://doi.org/10.1016/j.jss.2019.09.053
  JCS_FACTOR: 2.192
  Keywords: Electronic health record, Big data, Drug safety, Health care database,
    Cancer risk
  SCI_FACTOR: 0.78
  Title: What Can We Learn About Drug Safety and Other Effects in the Era of Electronic
    Health Records and Big Data That We Would Not Be Able to Learn From Classic Epidemiology?
  Title_JCS: JOURNAL OF SURGICAL RESEARCH
  Title_SCI: Journal of Surgical Research
  Type_Publication: article
  Year: 2020
- Abstract: 'Even at an early stage, diverse big data have been applied to tourism
    research and made an amazing improvement. This paper might be the first attempt
    to present a comprehensive literature review on different types of big data in
    tourism research. By data sources, the tourism-related big data fall into three
    primary categories: UGC data (generated by users), including online textual data
    and online photo data; device data (by devices), including GPS data, mobile roaming
    data, Bluetooth data, etc.; transaction data (by operations), including web search
    data, webpage visiting data, online booking data, etc. Carrying different information,
    different data types address different tourism issues. For each type, a systematical
    analysis is conducted from the perspectives of research focuses, data characteristics,
    analytic techniques, major challenges and further directions. This survey facilitates
    a thorough understanding of this sunrise research and offers valuable insights
    into its future prospects.'
  Author: Jingjing Li and Lizhi Xu and Ling Tang and Shouyang Wang and Ling Li
  Book_Title_Journal: Tourism Management
  DOI: https://doi.org/10.1016/j.tourman.2018.03.009
  JCS_FACTOR: 10.967
  Keywords: Tourism research, Big data, Literature review, Tourism management, Tourist
    behavior
  SCI_FACTOR: 3.328
  Title: 'Big data in tourism research: A literature review'
  Title_JCS: TOURISM MANAGEMENT
  Title_SCI: Tourism Management
  Type_Publication: article
  Year: 2018
- Abstract: "A central question for information systems (IS) researchers and practitioners\
    \ is if, and how, big data can help attain a competitive advantage. To address\
    \ this question, this study draws on the resource-based view, dynamic capabilities\
    \ view, and on recent literature on big data analytics, and examines the indirect\
    \ relationship between a firm\xE2\u20AC\u2122s big data analytics capability (BDAC)\
    \ and competitive performance. The study extends existing research by proposing\
    \ that BDACs enable firms to generate insight that can help strengthen their dynamic\
    \ capabilities, which, in turn, positively impact marketing and technological\
    \ capabilities. To test our proposed research model, we used survey data from\
    \ 202 chief information officers and IT managers working in Norwegian firms. By\
    \ means of partial least squares structural equation modeling, results show that\
    \ a strong BDAC can help firms build a competitive advantage. This effect is not\
    \ direct but fully mediated by dynamic capabilities, which exerts a positive and\
    \ significant effect on two types of operational capabilities: marketing and technological\
    \ capabilities. The findings suggest that IS researchers should look beyond direct\
    \ effects of big data investments and shift their attention on how a BDAC can\
    \ be leveraged to enable and support organizational capabilities."
  Author: Patrick Mikalef and John Krogstie and Ilias O. Pappas and Paul Pavlou
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2019.05.004
  JCS_FACTOR: 7.555
  Keywords: Big data analytics, Dynamic capabilities, Operational capabilities, Business
    value, Resource-based view
  SCI_FACTOR: 0.0
  Title: 'Exploring the relationship between big data analytics capability and competitive
    performance: The mediating roles of dynamic and operational capabilities'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: "A central question for information systems (IS) researchers and practitioners\
    \ is if, and how, big data can help attain a competitive advantage. To address\
    \ this question, this study draws on the resource-based view, dynamic capabilities\
    \ view, and on recent literature on big data analytics, and examines the indirect\
    \ relationship between a firm\xE2\u20AC\u2122s big data analytics capability (BDAC)\
    \ and competitive performance. The study extends existing research by proposing\
    \ that BDACs enable firms to generate insight that can help strengthen their dynamic\
    \ capabilities, which, in turn, positively impact marketing and technological\
    \ capabilities. To test our proposed research model, we used survey data from\
    \ 202 chief information officers and IT managers working in Norwegian firms. By\
    \ means of partial least squares structural equation modeling, results show that\
    \ a strong BDAC can help firms build a competitive advantage. This effect is not\
    \ direct but fully mediated by dynamic capabilities, which exerts a positive and\
    \ significant effect on two types of operational capabilities: marketing and technological\
    \ capabilities. The findings suggest that IS researchers should look beyond direct\
    \ effects of big data investments and shift their attention on how a BDAC can\
    \ be leveraged to enable and support organizational capabilities."
  Author: Patrick Mikalef and John Krogstie and Ilias O. Pappas and Paul Pavlou
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2019.05.004
  JCS_FACTOR: 7.555
  Keywords: Big data analytics, Dynamic capabilities, Operational capabilities, Business
    value, Resource-based view
  SCI_FACTOR: 0.0
  Title: 'Exploring the relationship between big data analytics capability and competitive
    performance: The mediating roles of dynamic and operational capabilities'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: Recently, patient safety and healthcare have gained high attention in
    professional and health policy-makers. This rapid growth causes generating a high
    amount of data, which is known as big data. Therefore, handling and processing
    of this data are attracted great attention. Cloud computing is one of the main
    choices for handling and processing of this type of data. But, as far as we know,
    the detailed review and deep discussion in this filed are very rare. Therefore,
    this paper reviews and discusses the recently introduced mechanisms in this field
    as well as providing a deep analysis of their applied mechanisms. Moreover, the
    drawbacks and benefits of the reviewed mechanisms have been discussed and the
    main challenges of these mechanisms are highlighted for developing more efficient
    healthcare big data processing techniques over cloud computing in the future.
  Author: Lila Rajabion and Abdusalam Abdulla Shaltooki and Masoud Taghikhah and Amirhossein
    Ghasemi and Arshad Badfar
  Book_Title_Journal: International Journal of Information Management
  DOI: https://doi.org/10.1016/j.ijinfomgt.2019.05.017
  JCS_FACTOR: 14.098
  Keywords: Cloud computing, Processing, Healthcare, Big data, Review
  SCI_FACTOR: 2.77
  Title: 'Healthcare big data processing mechanisms: The role of cloud computing'
  Title_JCS: INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
  Title_SCI: International Journal of Information Management
  Type_Publication: article
  Year: 2019
- Abstract: The landscape of mental health has undergone tremendous changes within
    the last two decades, but the research on mental health is still at the initial
    stage with substantial knowledge gaps and the lack of precise diagnosis. Nowadays,
    big data and artificial intelligence offer new opportunities for the screening
    and prediction of mental problems. In this review paper, we outline the vision
    of digital phenotyping of mental health (DPMH) by fusing the enriched data from
    ubiquitous sensors, social media and healthcare systems, and present a broad overview
    of DPMH from sensing and computing perspectives. We first conduct a systematical
    literature review and propose the research framework, which highlights the key
    aspects related with mental health, and discuss the challenges elicited by the
    enriched data for digital phenotyping. Next, five key research strands including
    affect recognition, cognitive analytics, behavioral anomaly detection, social
    analytics, and biomarker analytics are unfolded in the psychiatric context. Finally,
    we discuss various open issues and the corresponding solutions to underpin the
    digital phenotyping of mental health.
  Author: Yunji Liang and Xiaolong Zheng and Daniel D. Zeng
  Book_Title_Journal: Information Fusion
  DOI: https://doi.org/10.1016/j.inffus.2019.04.001
  JCS_FACTOR: 12.975
  Keywords: Digital phenotyping, Big data, Mental health, Data mining, Information
    fusion
  SCI_FACTOR: 2.776
  Title: A survey on big data-driven digital phenotyping of mental health
  Title_JCS: Information Fusion
  Title_SCI: Information Fusion
  Type_Publication: article
  Year: 2019
- Abstract: "The paper examines the opportunities in and possibilities arising from\
    \ big data in retailing, particularly along five major data dimensions\xE2\u20AC\
    \u201Ddata pertaining to customers, products, time, (geo-spatial) location and\
    \ channel. Much of the increase in data quality and application possibilities\
    \ comes from a mix of new data sources, a smart application of statistical tools\
    \ and domain knowledge combined with theoretical insights. The importance of theory\
    \ in guiding any systematic search for answers to retailing questions, as well\
    \ as for streamlining analysis remains undiminished, even as the role of big data\
    \ and predictive analytics in retailing is set to rise in importance, aided by\
    \ newer sources of data and large-scale correlational techniques. The Statistical\
    \ issues discussed include a particular focus on the relevance and uses of Bayesian\
    \ analysis techniques (data borrowing, updating, augmentation and hierarchical\
    \ modeling), predictive analytics using big data and a field experiment, all in\
    \ a retailing context. Finally, the ethical and privacy issues that may arise\
    \ from the use of big data in retailing are also highlighted."
  Author: Eric T. Bradlow and Manish Gangwar and Praveen Kopalle and Sudhir Voleti
  Book_Title_Journal: Journal of Retailing
  DOI: https://doi.org/10.1016/j.jretai.2016.12.004
  JCS_FACTOR: 5.245
  Keywords: Big data, Predictive analytics, Retailing, Pricing
  SCI_FACTOR: 3.184
  Title: The Role of Big Data and Predictive Analytics in Retailing
  Title_JCS: JOURNAL OF RETAILING
  Title_SCI: Journal of Retailing
  Type_Publication: article
  Year: 2017
- Abstract: With its rapid growth and increasing adoption, big data is producing a
    substantial impact in society. Its usage is opening both opportunities such as
    new business models and economic gains and risks such as privacy violations and
    discrimination. Europe is in need of a comprehensive strategy to optimise the
    use of data for a societal benefit and increase the innovation and competitiveness
    of its productive activities. In this paper, we contribute to the definition of
    this strategy with a research roadmap to capture the economic, social and ethical,
    legal and political benefits associated with the use of big data in Europe. The
    present roadmap considers the positive and negative externalities associated with
    big data, maps research and innovation topics in the areas of data management,
    processing, analytics, protection, visualisation, as well as non-technical topics,
    to the externalities they can tackle, and provides a time frame to address these
    topics in order to deliver social impact, skills development and standardisation.
    Finally, it also identifies what sectors will be most benefited by each of the
    research efforts. The goal of the roadmap is to guide European research efforts
    to develop a socially responsible big data economy, and to allow stakeholders
    to identify and meet big data challenges and proceed with a shared understanding
    of the societal impact, positive and negative externalities and concrete problems
    worth investigating in future programmes.
  Author: "Mart\xC3\xAD Cuquet and Anna Fensel"
  Book_Title_Journal: Technology in Society
  DOI: https://doi.org/10.1016/j.techsoc.2018.03.005
  JCS_FACTOR: 4.192
  Keywords: Big data, Research roadmap, Societal externalities, Skills development,
    Standardisation
  SCI_FACTOR: 0.819
  Title: 'The societal impact of big data: A research roadmap for Europe'
  Title_JCS: TECHNOLOGY IN SOCIETY
  Title_SCI: Technology in Society
  Type_Publication: article
  Year: 2018
- Abstract: The emergence of powerful software has created conditions and approaches
    for large datasets to be collected and analyzed which has led to informed decision-making
    towards tackling health issues. The objective of this study is to systematically
    review 804 scholarly publications related to big data analytics in health in order
    to identify the organizational and social values along with associated challenges.
    Key principles of Preferred Reporting Items for Systematic Reviews and Meta-Analyses
    (PRISMA) methodology were followed for conducting systematic reviews. Following
    a research path, we present the values, challenges and future directions of the
    scientific area using indicative examples from relevant published articles. The
    study reveals that one of the main values created is the development of analytical
    techniques which provides personalized health services to users and supports human
    decision-making using automated algorithms, challenging the power issues in the
    doctor-patient relationship and creating new working conditions. A main challenge
    to data analytics is data management and security when processing large volumes
    of sensitive, personal health data. Future research is directed towards the development
    of systems that will standardize and secure the process of extracting private
    healthcare datasets from relevant organizations. Our systematic literature review
    aims to provide to governments and health policy-makers a better understanding
    of how the development of a data driven strategy can improve public health and
    the functioning of healthcare organizations but also how can create challenges
    that need to be addressed in the near future to avoid societal malfunctions.
  Author: P. Galetsi and K. Katsaliaki and S. Kumar
  Book_Title_Journal: Social Science & Medicine
  DOI: https://doi.org/10.1016/j.socscimed.2019.112533
  JCS_FACTOR: 4.634
  Keywords: Systematic review, Big data analytics, Health-medicine, Decision-making,
    Organizational and societal values, Preferred reporting items for systematic reviews
    and meta-analyses
  SCI_FACTOR: 0.0
  Title: 'Values, challenges and future directions of big data analytics in healthcare:
    A systematic review'
  Title_JCS: SOCIAL SCIENCE & MEDICINE
  Title_SCI: N/A
  Type_Publication: article
  Year: 2019
- Abstract: The emergence of powerful software has created conditions and approaches
    for large datasets to be collected and analyzed which has led to informed decision-making
    towards tackling health issues. The objective of this study is to systematically
    review 804 scholarly publications related to big data analytics in health in order
    to identify the organizational and social values along with associated challenges.
    Key principles of Preferred Reporting Items for Systematic Reviews and Meta-Analyses
    (PRISMA) methodology were followed for conducting systematic reviews. Following
    a research path, we present the values, challenges and future directions of the
    scientific area using indicative examples from relevant published articles. The
    study reveals that one of the main values created is the development of analytical
    techniques which provides personalized health services to users and supports human
    decision-making using automated algorithms, challenging the power issues in the
    doctor-patient relationship and creating new working conditions. A main challenge
    to data analytics is data management and security when processing large volumes
    of sensitive, personal health data. Future research is directed towards the development
    of systems that will standardize and secure the process of extracting private
    healthcare datasets from relevant organizations. Our systematic literature review
    aims to provide to governments and health policy-makers a better understanding
    of how the development of a data driven strategy can improve public health and
    the functioning of healthcare organizations but also how can create challenges
    that need to be addressed in the near future to avoid societal malfunctions.
  Author: P. Galetsi and K. Katsaliaki and S. Kumar
  Book_Title_Journal: Social Science & Medicine
  DOI: https://doi.org/10.1016/j.socscimed.2019.112533
  JCS_FACTOR: 4.634
  Keywords: Systematic review, Big data analytics, Health-medicine, Decision-making,
    Organizational and societal values, Preferred reporting items for systematic reviews
    and meta-analyses
  SCI_FACTOR: 0.0
  Title: 'Values, challenges and future directions of big data analytics in healthcare:
    A systematic review'
  Title_JCS: SOCIAL SCIENCE & MEDICINE
  Title_SCI: N/A
  Type_Publication: article
  Year: 2019
- Abstract: The emerging Big Data integration imposes diverse challenges, compromising
    the sustainable business research practice. Heterogeneity, multi-dimensionality,
    velocity, and massive volumes that challenge Big Data paradigm may preclude the
    effective data and system integration processes. Business alignments get affected
    within and across joint ventures as enterprises attempt to adapt to changes in
    industrial environments rapidly. In the context of the Oil and Gas industry, we
    design integrated artefacts for a resilient multidimensional warehouse repository.
    With access to several decades of resource data in upstream companies, we incorporate
    knowledge-based data models with spatial-temporal dimensions in data schemas to
    minimize ambiguity in warehouse repository implementation. The design considerations
    ensure uniqueness and monotonic properties of dimensions, maintaining the connectivity
    between artefacts and achieving the business alignments. The multidimensional
    attributes envisage Big Data analysts a scope of business research with valuable
    new knowledge for decision support systems and adding further business values
    in geographic scales.
  Author: Shastri L. Nimmagadda and Torsten Reiners and Lincoln C. Wood
  Book_Title_Journal: Journal of Business Research
  DOI: https://doi.org/10.1016/j.jbusres.2018.04.029
  JCS_FACTOR: 7.55
  Keywords: Upstream business, Heterogeneous and multidimensional data, Data warehousing
    and mining, Big Data paradigm, Spatial-temporal dimensions
  SCI_FACTOR: 2.049
  Title: On big data-guided upstream business research and its knowledge management
  Title_JCS: JOURNAL OF BUSINESS RESEARCH
  Title_SCI: Journal of Business Research
  Type_Publication: article
  Year: 2018
- Abstract: Customer experience (CX) has emerged as a sustainable source of competitive
    differentiation. Recent developments in big data analytics (BDA) have exposed
    possibilities to unlock customer insights for customer experience management (CXM).
    Research at the intersection of these two fields is scarce and there is a need
    for conceptual work that (1) provides an overview of opportunities to use BDA
    for CXM and (2) guides management practice and future research. The purpose of
    this paper is therefore to develop a strategic framework for CXM based on CX insights
    resulting from BDA. Our conceptualisation is comprehensive and is particularly
    relevant for researchers and practitioners who are less familiar with the potential
    of BDA for CXM. For managers, we provide a step-by-step guide on how to kick-start
    or implement our strategic framework. For researchers, we propose some opportunities
    for future studies in this promising research area.
  Author: Maria Holmlund and Yves {Van Vaerenbergh} and Robert Ciuchita and Annika
    Ravald and Panagiotis Sarantopoulos and Francisco Villarroel Ordenes and Mohamed
    Zaki
  Book_Title_Journal: Journal of Business Research
  DOI: https://doi.org/10.1016/j.jbusres.2020.01.022
  JCS_FACTOR: 7.55
  Keywords: Customer experience, Customer experience management, Customer experience
    insight, Big data analytics
  SCI_FACTOR: 2.049
  Title: 'Customer experience management in the age of big data analytics: A strategic
    framework'
  Title_JCS: JOURNAL OF BUSINESS RESEARCH
  Title_SCI: Journal of Business Research
  Type_Publication: article
  Year: 2020
- Abstract: "Big data analytics has recently emerged as an important research area\
    \ due to the popularity of the Internet and the advent of the Web 2.0 technologies.\
    \ Moreover, the proliferation and adoption of social media applications have provided\
    \ extensive opportunities and challenges for researchers and practitioners. The\
    \ massive amount of data generated by users using social media platforms is the\
    \ result of the integration of their background details and daily activities.\
    \ This enormous volume of generated data known as \xE2\u20AC\u0153big data\xE2\
    \u20AC\x9D has been intensively researched recently. A review of the recent works\
    \ is presented to obtain a broad perspective of the social media big data analytics\
    \ research topic. We classify the literature based on important aspects. This\
    \ study also compares possible big data analytics techniques and their quality\
    \ attributes. Moreover, we provide a discussion on the applications of social\
    \ media big data analytics by highlighting the state-of-the-art techniques, methods,\
    \ and the quality attributes of various studies. Open research challenges in big\
    \ data analytics are described as well."
  Author: Norjihan Abdul Ghani and Suraya Hamid and Ibrahim Abaker {Targio Hashem}
    and Ejaz Ahmed
  Book_Title_Journal: Computers in Human Behavior
  DOI: https://doi.org/10.1016/j.chb.2018.08.039
  JCS_FACTOR: 6.829
  Keywords: Big data, Social media, Machine learning, Analytics
  SCI_FACTOR: 2.108
  Title: 'Social media big data analytics: A survey'
  Title_JCS: COMPUTERS IN HUMAN BEHAVIOR
  Title_SCI: Computers in Human Behavior
  Type_Publication: article
  Year: 2019
- Abstract: The emergence of digitally connected products and big data analytics (BDA)
    in industrial marketing has attracted academic and managerial interest in smart
    services. However, suppliers' provision of smart services and customers' adoption
    of these services have received scarce attention in the literature, demonstrating
    the need to address the changing nature of customer-supplier interactions in the
    digital era. Responding to prior research calls, this study utilizes ethnographic
    research and a storytelling lens to advance our knowledge of how stories and BDA
    can enhance customers' attitudes toward suppliers' smart services, their behavioral
    intentions and their actual adoption of smart services. The study's findings demonstrate
    that storytelling is a collective sensemaking and sensegiving process that occurs
    in interactions between customers and suppliers in which both parties contribute
    to the story development. The use of BDA in storytelling enhances customer sensemaking
    of smart services by highlighting the business value extracted from the digitized
    data of a reference customer. By synthesizing insights from servitization, storytelling,
    BDA and the customer reference literature, this study offers managers practical
    guidance regarding how to increase smart service sales. An example of a story
    used to facilitate customer adoption of a supplier's smart services in the manufacturing
    sector is provided.
  Author: Valeriia Boldosova
  Book_Title_Journal: Industrial Marketing Management
  DOI: https://doi.org/10.1016/j.indmarman.2019.12.004
  JCS_FACTOR: 6.96
  Keywords: Storytelling, Big data analytics, Smart service, Customer reference, Customer-supplier
    relationships
  SCI_FACTOR: 2.022
  Title: 'Telling stories that sell: The role of storytelling and big data analytics
    in smart service sales'
  Title_JCS: INDUSTRIAL MARKETING MANAGEMENT
  Title_SCI: Industrial Marketing Management
  Type_Publication: article
  Year: 2020
- Abstract: Today, we are undoubtedly in the era of data. Big Data Analytics (BDA)
    is no longer a perspective for all level of the organization. This is of special
    interest in the manufacturing process with their high capital intensity, time
    constraints and given the huge amount of data already captured. However, there
    is a paucity in past literature on BDA to develop better understanding of the
    capabilities and strategic implications to extract value from BDA. In that vein,
    the central aim of this paper is to develop a novel model that summarizes the
    main capabilities of BDA in the context of manufacturing process. This is carried
    out by relying on the findings of a review of the ongoing research along with
    a multiple case studies within a leading phosphate derivatives manufacturer to
    point out the capabilities of BDA in manufacturing processes and outline recommendations
    to advance research in the field. The findings will help companies to understand
    the big data analytics capabilities and its potential implications for their manufacturing
    processes and support them seeking to design more effective BDA-enabler infrastructure.
  Author: Amine Belhadi and Karim Zkik and Anass Cherrafi and Sha'ri M. Yusof and
    Said {El fezazi}
  Book_Title_Journal: Computers & Industrial Engineering
  DOI: https://doi.org/10.1016/j.cie.2019.106099
  JCS_FACTOR: 5.431
  Keywords: Big Data Analytics, Manufacturing process, Big Data Analytics capabilities,
    Business intelligence, Literature review, Multiple case study
  SCI_FACTOR: 0.0
  Title: 'Understanding Big Data Analytics for Manufacturing Processes: Insights from
    Literature Review and Multiple Case Studies'
  Title_JCS: COMPUTERS & INDUSTRIAL ENGINEERING
  Title_SCI: N/A
  Type_Publication: article
  Year: 2019
- Abstract: "Disruptive innovations are usually identified as ideas that are created\
    \ \xE2\u20AC\u02DCoutside the box\xE2\u20AC\u2122. They are expected to fundamentally\
    \ change existing business models and processes founded on technological applications.\
    \ Disruptive innovations can be challenging to define. Information technology\
    \ (IT) solutions focus on collecting, processing, and reporting different types\
    \ of data. Commonly, is the solutions are expected (in cybernetics or self-regulating\
    \ processes) to provide feedback to original processes and to steer them based\
    \ on the data. To achieve continuous improvement with regard to environmental\
    \ responsibility and profitability, new thinking and, in particular, accurate\
    \ and reliable data are needed for decision-making. Very large data storages,\
    \ known as big data, contain an increasing mass of different types of homogenous\
    \ and non-homogenous information, as well as extensive time-series. New, innovative\
    \ algorithms are required to reveal relevant information and opportunities hidden\
    \ in these data storages. Global environmental challenges and zero-emission responsible\
    \ production issues can only be solved using relevant and reliable continuous\
    \ data as the basis. The final goal should be the creation of scalable environmental\
    \ solutions based on disruptive innovations and accurate data. The aim of this\
    \ paper is to determine the explicit steps for replacing silo-based reporting\
    \ with company-wide, refined information, which enables decision-makers in all\
    \ industries the chance to make responsible choices."
  Author: "Esa H\xC3\xA4m\xC3\xA4l\xC3\xA4inen and Tommi Inkinen"
  Book_Title_Journal: Journal of Industrial Information Integration
  DOI: https://doi.org/10.1016/j.jii.2019.100105
  JCS_FACTOR: 10.063
  Keywords: Big data, Disruption, Responsible, Process industry, Economic efficiency,
    Economic geography
  SCI_FACTOR: 2.042
  Title: Industrial applications of big data in disruptive innovations supporting
    environmental reporting
  Title_JCS: Journal of Industrial Information Integration
  Title_SCI: Journal of Industrial Information Integration
  Type_Publication: article
  Year: 2019
- Abstract: "In this paper, the droplet size distributions of high-velocity airblast\
    \ atomization were analyzed. The spray measurement was performed by a Phase-Doppler\
    \ anemometer at several points and different diameters across the spray for diesel\
    \ oil, light heating oil, crude rapeseed oil, and water. The atomizing gauge pressure\
    \ and the liquid preheating temperature varied from 0.3 to 2.4\xC2\_bar and 25\
    \ to 100\xC2\_\xC2\xB0C, respectively. Approximately 400\xC2\_million individual\
    \ droplets were recorded; therefore, a big data evaluation technique was applied.\
    \ 18 of the most commonly used probability density functions (PDF) were fitted\
    \ to the histogram of each measuring point and evaluated by their relative log-likelihood.\
    \ Among the three-parameter PDFs, Generalized Extreme Value and Burr PDFs provided\
    \ the most desirable result to describe a complete drop size distribution. With\
    \ restriction to two-parameter PDFs, the Nakagami PDF unexpectedly outperformed\
    \ all the others, including Weibull (Rosin-Rammler) PDF, which is commonly used\
    \ in atomization. However, if the spray is characterized by a single value, such\
    \ as the Sauter Mean Diameter, i.e. an expected value-like parameter is of primary\
    \ importance over the distribution, Gamma PDF is the best option, used in several\
    \ papers of the atomization literature."
  Author: "Andr\xC3\xA1s Urb\xC3\xA1n and Axel Groniewsky and Milan Mal\xC3\xBD and\
    \ Viktor J\xC3\xB3zsa and Jan Jedelsk\xC3\xBD"
  Book_Title_Journal: Fuel
  DOI: https://doi.org/10.1016/j.fuel.2020.117792
  JCS_FACTOR: 6.609
  Keywords: Big data, Airblast, Rapeseed oil, PDA, Probability density function, Likelihood
  SCI_FACTOR: 1.56
  Title: 'Application of big data analysis technique on high-velocity airblast atomization:
    Searching for optimum probability density function'
  Title_JCS: FUEL
  Title_SCI: Fuel
  Type_Publication: article
  Year: 2020
- Abstract: 'According to McKinsey & Company, about a third of food produced is lost
    or wasted every year, amounting to a $940 billion economic hit. Inefficiencies
    in planting, harvesting, water use, reduced animal contributions, as well as uncertainty
    about weather, pests, consumer demand and other intangibles contribute to the
    loss. Precision Agriculture (PA) and Precision Livestock Farming (PLF) come to
    assist in optimizing agricultural and livestock production and minimizing the
    wastes and costs aforementioned. PA is a technology-enabled, data-driven approach
    to farming management that observes, measures, and analyzes the needs of individual
    fields and crops. PLF is also a technology-enabled, data-driven approach to livestock
    production management, which exploits technology to quantitatively measure the
    behavior, health and performance of animals. Big data delivered by a plethora
    of data sources related to these domains, has a multitude of payoffs including
    precision monitoring of fertilizer and fungicide levels to optimize crop yields,
    risk mitigation that results from monitoring when temperature and humidity levels
    reach dangerous levels for crops, increasing livestock production while minimizing
    the environmental footprint of livestock farming, ensuring high levels of welfare
    and health for animals, and more. By adding analytics to these sensor and image
    data, opportunities also exist to further optimize PA and PLF by having continuous
    data on how a field or the livestock is responding to a protocol. For these domains,
    two main challenges exist: 1) to exploit this multitude of data facilitating dedicated
    improvements in performance, and 2) to make available advanced infrastructure
    so as to harness the power of this information in order to benefit from the new
    insights, practices and products, efficiently time-wise, lowering responsiveness
    down to seconds so as to cater for time-critical decisions. The current paper
    aims to introduce CYBELE, a platform aspiring to safeguard that the stakeholders
    involved in the agri-food value chain (research community, SMEs, entrepreneurs,
    etc.) have integrated, unmediated access to a vast amount of very large scale
    datasets of diverse types and coming from a variety of sources, and that they
    are capable of actually generating value and extracting insights out of these
    data, by providing secure and unmediated access to large-scale High Performance
    Computing (HPC) infrastructures supporting advanced data discovery, processing,
    combination and visualization services, solving computationally-intensive challenges
    modelled as mathematical algorithms requiring very high computing power and capability.'
  Author: Konstantinos Perakis and Fenareti Lampathaki and Konstantinos Nikas and
    Yiannis Georgiou and Oskar Marko and Jarissa Maselyne
  Book_Title_Journal: Computer Networks
  DOI: https://doi.org/10.1016/j.comnet.2019.107035
  JCS_FACTOR: 4.474
  Keywords: Precision agriculture, Precision livestock farming, High performance computing,
    Big data analytics
  SCI_FACTOR: 0.798
  Title: "CYBELE \xE2\u20AC\u201C Fostering precision agriculture & livestock farming\
    \ through secure access to large-scale HPC enabled virtual industrial experimentation\
    \ environments fostering scalable big data analytics"
  Title_JCS: Computer Networks
  Title_SCI: Computer Networks
  Type_Publication: article
  Year: 2020
- Abstract: "Next-generation sequencing (NGS) is considered to be a prominent example\
    \ of \xE2\u20AC\u0153big data\xE2\u20AC\x9D because of the quantity and complexity\
    \ of data it produces and because it presents an opportunity to use powerful information\
    \ sources that could reduce clinical and health economic uncertainty at a patient\
    \ level. One obstacle to translating NGS into routine health care has been a lack\
    \ of clinical trials evaluating NGS technologies, which could be used to populate\
    \ cost-effectiveness analyses (CEAs). A key question is whether big data can be\
    \ used to partially support CEAs of NGS. This question has been brought into sharp\
    \ focus with the creation of large national sequencing initiatives. In this article\
    \ we summarize the main methodological and practical challenges of using big data\
    \ as an input into CEAs of NGS. Our focus is on the challenges of using large\
    \ observational datasets and cohort studies and linking these data to the genomic\
    \ information obtained from NGS, as is being pursued in the conduct of large genomic\
    \ sequencing initiatives. We propose potential solutions to these key challenges.\
    \ We conclude that the use of genomic big data to support and inform CEAs of NGS\
    \ technologies holds great promise. Nevertheless, health economists face substantial\
    \ challenges when using these data and must be cognizant of them before big data\
    \ can be confidently used to produce evidence on the cost-effectiveness of NGS."
  Author: Sarah Wordsworth and Brett Doble and Katherine Payne and James Buchanan
    and Deborah A. Marshall and Christopher McCabe and Dean A. Regier
  Book_Title_Journal: Value in Health
  DOI: https://doi.org/10.1016/j.jval.2018.06.016
  JCS_FACTOR: 5.725
  Keywords: Big data, cost-effectiveness, next generation sequencing
  SCI_FACTOR: 1.859
  Title: "Using \xE2\u20AC\u0153Big Data\xE2\u20AC\x9D in the Cost-Effectiveness Analysis\
    \ of Next-Generation Sequencing Technologies: Challenges and Potential Solutions"
  Title_JCS: VALUE IN HEALTH
  Title_SCI: Value in Health
  Type_Publication: article
  Year: 2018
- Abstract: "Next-generation sequencing (NGS) is considered to be a prominent example\
    \ of \xE2\u20AC\u0153big data\xE2\u20AC\x9D because of the quantity and complexity\
    \ of data it produces and because it presents an opportunity to use powerful information\
    \ sources that could reduce clinical and health economic uncertainty at a patient\
    \ level. One obstacle to translating NGS into routine health care has been a lack\
    \ of clinical trials evaluating NGS technologies, which could be used to populate\
    \ cost-effectiveness analyses (CEAs). A key question is whether big data can be\
    \ used to partially support CEAs of NGS. This question has been brought into sharp\
    \ focus with the creation of large national sequencing initiatives. In this article\
    \ we summarize the main methodological and practical challenges of using big data\
    \ as an input into CEAs of NGS. Our focus is on the challenges of using large\
    \ observational datasets and cohort studies and linking these data to the genomic\
    \ information obtained from NGS, as is being pursued in the conduct of large genomic\
    \ sequencing initiatives. We propose potential solutions to these key challenges.\
    \ We conclude that the use of genomic big data to support and inform CEAs of NGS\
    \ technologies holds great promise. Nevertheless, health economists face substantial\
    \ challenges when using these data and must be cognizant of them before big data\
    \ can be confidently used to produce evidence on the cost-effectiveness of NGS."
  Author: Sarah Wordsworth and Brett Doble and Katherine Payne and James Buchanan
    and Deborah A. Marshall and Christopher McCabe and Dean A. Regier
  Book_Title_Journal: Value in Health
  DOI: https://doi.org/10.1016/j.jval.2018.06.016
  JCS_FACTOR: 5.725
  Keywords: Big data, cost-effectiveness, next generation sequencing
  SCI_FACTOR: 1.859
  Title: "Using \xE2\u20AC\u0153Big Data\xE2\u20AC\x9D in the Cost-Effectiveness Analysis\
    \ of Next-Generation Sequencing Technologies: Challenges and Potential Solutions"
  Title_JCS: VALUE IN HEALTH
  Title_SCI: Value in Health
  Type_Publication: article
  Year: 2018
- Abstract: "Big data generated by social media stands for a valuable source of information,\
    \ which offers an excellent opportunity to mine valuable insights. Particularly,\
    \ User-generated contents such as reviews, recommendations, and users\xE2\u20AC\
    \u2122 behavior data are useful for supporting several marketing activities of\
    \ many companies. Knowing what users are saying about the products they bought\
    \ or the services they used through reviews in social media represents a key factor\
    \ for making decisions. Sentiment analysis is one of the fundamental tasks in\
    \ Natural Language Processing. Although deep learning for sentiment analysis has\
    \ achieved great success and allowed several firms to analyze and extract relevant\
    \ information from their textual data, but as the volume of data grows, a model\
    \ that runs in a traditional environment cannot be effective, which implies the\
    \ importance of efficient distributed deep learning models for social Big Data\
    \ analytics. Besides, it is known that social media analysis is a complex process,\
    \ which involves a set of complex tasks. Therefore, it is important to address\
    \ the challenges and issues of social big data analytics and enhance the performance\
    \ of deep learning techniques in terms of classification accuracy to obtain better\
    \ decisions. In this paper, we propose an approach for sentiment analysis, which\
    \ is devoted to adopting fastText with Recurrent neural network variants to represent\
    \ textual data efficiently. Then, it employs the new representations to perform\
    \ the classification task. Its main objective is to enhance the performance of\
    \ well-known Recurrent Neural Network (RNN) variants in terms of classification\
    \ accuracy and handle large scale data. In addition, we propose a distributed\
    \ intelligent system for real-time social big data analytics. It is designed to\
    \ ingest, store, process, index, and visualize the huge amount of information\
    \ in real-time. The proposed system adopts distributed machine learning with our\
    \ proposed method for enhancing decision-making processes. Extensive experiments\
    \ conducted on two benchmark data sets demonstrate that our proposal for sentiment\
    \ analysis outperforms well-known distributed recurrent neural network variants\
    \ (i.e., Long Short-Term Memory (LSTM), Bidirectional Long Short-Term Memory (BiLSTM),\
    \ and Gated Recurrent Unit (GRU)). Specifically, we tested the efficiency of our\
    \ approach using the three different deep learning models. The results show that\
    \ our proposed approach is able to enhance the performance of the three models.\
    \ The current work can provide several benefits for researchers and practitioners\
    \ who want to collect, handle, analyze and visualize several sources of information\
    \ in real-time. Also, it can contribute to a better understanding of public opinion\
    \ and user behaviors using our proposed system with the improved variants of the\
    \ most powerful distributed deep learning and machine learning algorithms. Furthermore,\
    \ it is able to increase the classification accuracy of several existing works\
    \ based on RNN models for sentiment analysis."
  Author: Badr {Ait Hammou} and Ayoub {Ait Lahcen} and Salma Mouline
  Book_Title_Journal: Information Processing & Management
  DOI: https://doi.org/10.1016/j.ipm.2019.102122
  JCS_FACTOR: 6.222
  Keywords: Big data, FastText, Recurrent neural networks, LSTM, BiLSTM, GRU, Natural
    language processing, Sentiment analysis, Social big data analytics
  SCI_FACTOR: 0.0
  Title: Towards a real-time processing framework based on improved distributed recurrent
    neural network variants with fastText for social big data analytics
  Title_JCS: INFORMATION PROCESSING & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: "Big data generated by social media stands for a valuable source of information,\
    \ which offers an excellent opportunity to mine valuable insights. Particularly,\
    \ User-generated contents such as reviews, recommendations, and users\xE2\u20AC\
    \u2122 behavior data are useful for supporting several marketing activities of\
    \ many companies. Knowing what users are saying about the products they bought\
    \ or the services they used through reviews in social media represents a key factor\
    \ for making decisions. Sentiment analysis is one of the fundamental tasks in\
    \ Natural Language Processing. Although deep learning for sentiment analysis has\
    \ achieved great success and allowed several firms to analyze and extract relevant\
    \ information from their textual data, but as the volume of data grows, a model\
    \ that runs in a traditional environment cannot be effective, which implies the\
    \ importance of efficient distributed deep learning models for social Big Data\
    \ analytics. Besides, it is known that social media analysis is a complex process,\
    \ which involves a set of complex tasks. Therefore, it is important to address\
    \ the challenges and issues of social big data analytics and enhance the performance\
    \ of deep learning techniques in terms of classification accuracy to obtain better\
    \ decisions. In this paper, we propose an approach for sentiment analysis, which\
    \ is devoted to adopting fastText with Recurrent neural network variants to represent\
    \ textual data efficiently. Then, it employs the new representations to perform\
    \ the classification task. Its main objective is to enhance the performance of\
    \ well-known Recurrent Neural Network (RNN) variants in terms of classification\
    \ accuracy and handle large scale data. In addition, we propose a distributed\
    \ intelligent system for real-time social big data analytics. It is designed to\
    \ ingest, store, process, index, and visualize the huge amount of information\
    \ in real-time. The proposed system adopts distributed machine learning with our\
    \ proposed method for enhancing decision-making processes. Extensive experiments\
    \ conducted on two benchmark data sets demonstrate that our proposal for sentiment\
    \ analysis outperforms well-known distributed recurrent neural network variants\
    \ (i.e., Long Short-Term Memory (LSTM), Bidirectional Long Short-Term Memory (BiLSTM),\
    \ and Gated Recurrent Unit (GRU)). Specifically, we tested the efficiency of our\
    \ approach using the three different deep learning models. The results show that\
    \ our proposed approach is able to enhance the performance of the three models.\
    \ The current work can provide several benefits for researchers and practitioners\
    \ who want to collect, handle, analyze and visualize several sources of information\
    \ in real-time. Also, it can contribute to a better understanding of public opinion\
    \ and user behaviors using our proposed system with the improved variants of the\
    \ most powerful distributed deep learning and machine learning algorithms. Furthermore,\
    \ it is able to increase the classification accuracy of several existing works\
    \ based on RNN models for sentiment analysis."
  Author: Badr {Ait Hammou} and Ayoub {Ait Lahcen} and Salma Mouline
  Book_Title_Journal: Information Processing & Management
  DOI: https://doi.org/10.1016/j.ipm.2019.102122
  JCS_FACTOR: 6.222
  Keywords: Big data, FastText, Recurrent neural networks, LSTM, BiLSTM, GRU, Natural
    language processing, Sentiment analysis, Social big data analytics
  SCI_FACTOR: 0.0
  Title: Towards a real-time processing framework based on improved distributed recurrent
    neural network variants with fastText for social big data analytics
  Title_JCS: INFORMATION PROCESSING & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: 'Remanufacturing is deemed to be an effective method for recycling resources,
    achieving sustainable production. However, little importance of remanufacturing
    has been attached in PLM. Surely, there are many problems in implementation of
    the remanufacturing strategy, such as inability to effectively reduce uncertainty,
    lack of product multi-life-cycle remanufacturing process tracking management,
    lack of smart enabling technology application in the full lifecycle that focusing
    on multi-life-cycle remanufacturing. After analyzing the reasons, through integrating
    smart enabling technologies, a new PLM paradigm focusing on the multi-life-cycle
    remanufacturing process: Big Data driven Hierarchical Digital Twin Predictive
    Remanufacturing (BDHDTPREMfg) is proposed. And the definition of BDHDTPREMfg is
    proposed. A big data driven layered architecture and the hierarchical CPS-Digital-Twin(CPSDT)
    reconfiguration control mechanism of BDHDTPREMfg are respectively developed. Then,
    this paper presents an application scenario of BDHDTPREMfg to validate the feasibility
    and effectiveness. Based on the above application analysis, the benefits of penetrating
    BDHDTPREMfg into the entire lifecycle are demonstrated. The summary of this paper
    and future research work is discussed in the end.'
  Author: Yankai Wang and Shilong Wang and Bo Yang and Lingzi Zhu and Feng Liu
  Book_Title_Journal: Journal of Cleaner Production
  DOI: https://doi.org/10.1016/j.jclepro.2019.119299
  JCS_FACTOR: 9.297
  Keywords: multi-life-cycle remanufacturing, Sustainable products, Big data, CPS-Digital-twin(CPSDT),
    IoT-cloud, Reconfiguration
  SCI_FACTOR: 1.937
  Title: 'Big data driven Hierarchical Digital Twin Predictive Remanufacturing paradigm:
    Architecture, control mechanism, application scenario and benefits'
  Title_JCS: Journal of Cleaner Production
  Title_SCI: Journal of Cleaner Production
  Type_Publication: article
  Year: 2020
- Abstract: 'Drawing on a revelatory case study, we identify four big data analytics
    (BDA) actualization mechanisms: (1) enhancing, (2) constructing, (3) coordinating,
    and (4) integrating, which manifest in actions on three socio-technical system
    levels, i.e., the structure, actor, and technology levels. We investigate the
    actualization of four BDA affordances at an automotive manufacturing company,
    i.e., establishing customer-centric marketing, provisioning vehicle-data-driven
    services, data-driven vehicle developing, and optimizing production processes.
    This study introduces a theoretical perspective to BDA research that explains
    how organizational actions contribute to actualizing BDA affordances. We further
    provide practical implications that can help guide practitioners in BDA adoption.'
  Author: Christian Dremel and Matthias M. Herterich and Jochen Wulf and Jan {vom
    Brocke}
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2018.10.007
  JCS_FACTOR: 7.555
  Keywords: Big data analytics, Affordance theory, Socio-technical approach, Organizational
    transformation, Organizational benefits, Affordance actualization
  SCI_FACTOR: 0.0
  Title: 'Actualizing big data analytics affordances: A revelatory case study'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: 'Drawing on a revelatory case study, we identify four big data analytics
    (BDA) actualization mechanisms: (1) enhancing, (2) constructing, (3) coordinating,
    and (4) integrating, which manifest in actions on three socio-technical system
    levels, i.e., the structure, actor, and technology levels. We investigate the
    actualization of four BDA affordances at an automotive manufacturing company,
    i.e., establishing customer-centric marketing, provisioning vehicle-data-driven
    services, data-driven vehicle developing, and optimizing production processes.
    This study introduces a theoretical perspective to BDA research that explains
    how organizational actions contribute to actualizing BDA affordances. We further
    provide practical implications that can help guide practitioners in BDA adoption.'
  Author: Christian Dremel and Matthias M. Herterich and Jochen Wulf and Jan {vom
    Brocke}
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2018.10.007
  JCS_FACTOR: 7.555
  Keywords: Big data analytics, Affordance theory, Socio-technical approach, Organizational
    transformation, Organizational benefits, Affordance actualization
  SCI_FACTOR: 0.0
  Title: 'Actualizing big data analytics affordances: A revelatory case study'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: Cities worldwide are attempting to transform themselves into smart cities.
    Recent cases and studies show that a key factor in this transformation is the
    use of urban big data from stakeholders and physical objects in cities. However,
    the knowledge and framework for data use for smart cities remain relatively unknown.
    This paper reports findings from an analysis of various use cases of big data
    in cities worldwide and the authors' four projects with government organizations
    toward developing smart cities. Specifically, this paper classifies the urban
    data use cases into four reference models and identifies six challenges in transforming
    data into information for smart cities. Furthermore, building upon the relevant
    literature, this paper proposes five considerations for addressing the challenges
    in implementing the reference models in real-world applications. The reference
    models, challenges, and considerations collectively form a framework for data
    use for smart cities. This paper will contribute to urban planning and policy
    development in the modern data-rich economy.
  Author: Chiehyeon Lim and Kwang-Jae Kim and Paul P. Maglio
  Book_Title_Journal: Cities
  DOI: https://doi.org/10.1016/j.cities.2018.04.011
  JCS_FACTOR: 5.835
  Keywords: Smart city, Big data, Reference model, Challenge, Consideration
  SCI_FACTOR: 1.771
  Title: 'Smart cities with big data: Reference models, challenges, and considerations'
  Title_JCS: CITIES
  Title_SCI: Cities
  Type_Publication: article
  Year: 2018
- Abstract: Big data analytics has been widely regarded as a breakthrough technological
    development in academic and business communities. Despite the growing number of
    firms that are launching big data initiatives, there is still limited understanding
    on how firms translate the potential of such technologies into business value.
    The literature argues that to leverage big data analytics and realize performance
    gains, firms must develop strong big data analytics capabilities. Nevertheless,
    most studies operate under the assumption that there is limited heterogeneity
    in the way firms build their big data analytics capabilities and that related
    resources are of similar importance regardless of context. This paper draws on
    complexity theory and investigates the configurations of resources and contextual
    factors that lead to performance gains from big data analytics investments. Our
    empirical investigation followed a mixed methods approach using survey data from
    175 chief information officers and IT managers working in Greek firms, and three
    case studies to show that depending on the context, big data analytics resources
    differ in significance when considering performance gains. Applying a fuzzy-set
    qualitative comparative analysis (fsQCA) method on the quantitative data, we show
    that there are four different patterns of elements surrounding big data analytics
    that lead to high performance. Outcomes of the three case studies highlight the
    inter-relationships between these elements and outline challenges that organizations
    face when orchestrating big data analytics resources.
  Author: Patrick Mikalef and Maria Boura and George Lekakos and John Krogstie
  Book_Title_Journal: Journal of Business Research
  DOI: https://doi.org/10.1016/j.jbusres.2019.01.044
  JCS_FACTOR: 7.55
  Keywords: Big data analytics, Complexity theory, fsQCA, Business value, Mixed-method,
    Environmental uncertainty
  SCI_FACTOR: 2.049
  Title: 'Big data analytics and firm performance: Findings from a mixed-method approach'
  Title_JCS: JOURNAL OF BUSINESS RESEARCH
  Title_SCI: Journal of Business Research
  Type_Publication: article
  Year: 2019
- Abstract: The advent of connected devices and omnipresence of Internet have paved
    way for intruders to attack networks, which leads to cyber-attack, financial loss,
    information theft in healthcare, and cyber war. Hence, network security analytics
    has become an important area of concern and has gained intensive attention among
    researchers, off late, specifically in the domain of anomaly detection in network,
    which is considered crucial for network security. However, preliminary investigations
    have revealed that the existing approaches to detect anomalies in network are
    not effective enough, particularly to detect them in real time. The reason for
    the inefficacy of current approaches is mainly due the amassment of massive volumes
    of data though the connected devices. Therefore, it is crucial to propose a framework
    that effectively handles real time big data processing and detect anomalies in
    networks. In this regard, this paper attempts to address the issue of detecting
    anomalies in real time. Respectively, this paper has surveyed the state-of-the-art
    real-time big data processing technologies related to anomaly detection and the
    vital characteristics of associated machine learning algorithms. This paper begins
    with the explanation of essential contexts and taxonomy of real-time big data
    processing, anomalous detection, and machine learning algorithms, followed by
    the review of big data processing technologies. Finally, the identified research
    challenges of real-time big data processing in anomaly detection are discussed.
  Author: Riyaz Ahamed {Ariyaluran Habeeb} and Fariza Nasaruddin and Abdullah Gani
    and Ibrahim Abaker {Targio Hashem} and Ejaz Ahmed and Muhammad Imran
  Book_Title_Journal: International Journal of Information Management
  DOI: https://doi.org/10.1016/j.ijinfomgt.2018.08.006
  JCS_FACTOR: 14.098
  Keywords: Real-time, Big data processing, Anomaly detection and machine learning
    algorithms
  SCI_FACTOR: 2.77
  Title: 'Real-time big data processing for anomaly detection: A Survey'
  Title_JCS: INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
  Title_SCI: International Journal of Information Management
  Type_Publication: article
  Year: 2019
- Abstract: 'In recent years, the Internet of Things (IoT) has emerged as a new opportunity.
    Thus, all devices such as smartphones, transportation facilities, public services,
    and home appliances are used as data creator devices. All the electronic devices
    around us help our daily life. Devices such as wrist watches, emergency alarms,
    and garage doors and home appliances such as refrigerators, microwaves, air conditioning,
    and water heaters are connected to an IoT network and controlled remotely. Methods
    such as big data and data mining can be used to improve the efficiency of IoT
    and storage challenges of a large data volume and the transmission, analysis,
    and processing of the data volume on the IoT. The aim of this study is to investigate
    the research done on IoT using big data as well as data mining methods to identify
    subjects that must be emphasized more in current and future research paths. This
    article tries to achieve the goal by following the conference and journal articles
    published on IoT-big data and also IoT-data mining areas between 2010 and August
    2017. In order to examine these articles, the combination of Systematic Mapping
    and literature review was used to create an intended review article. In this research,
    44 articles were studied. These articles are divided into three categories: Architecture
    & Platform, framework, and application. In this research, a summary of the methods
    used in the area of IoT-big data and IoT-data mining is presented in three categories
    to provide a starting point for researchers in the future.'
  Author: Shabnam Shadroo and Amir Masoud Rahmani
  Book_Title_Journal: Computer Networks
  DOI: https://doi.org/10.1016/j.comnet.2018.04.001
  JCS_FACTOR: 4.474
  Keywords: Internet of things, Systematic survey, Big data, Data mining
  SCI_FACTOR: 0.798
  Title: Systematic survey of big data and data mining in internet of things
  Title_JCS: Computer Networks
  Title_SCI: Computer Networks
  Type_Publication: article
  Year: 2018
- Abstract: 'Background

    The application of Big Data analytics in healthcare has immense potential for
    improving the quality of care, reducing waste and error, and reducing the cost
    of care.

    Purpose

    This systematic review of literature aims to determine the scope of Big Data analytics
    in healthcare including its applications and challenges in its adoption in healthcare.
    It also intends to identify the strategies to overcome the challenges.

    Data sources

    A systematic search of the articles was carried out on five major scientific databases:
    ScienceDirect, PubMed, Emerald, IEEE Xplore and Taylor & Francis. The articles
    on Big Data analytics in healthcare published in English language literature from
    January 2013 to January 2018 were considered.

    Study selection

    Descriptive articles and usability studies of Big Data analytics in healthcare
    and medicine were selected.

    Data extraction

    Two reviewers independently extracted information on definitions of Big Data analytics;
    sources and applications of Big Data analytics in healthcare; challenges and strategies
    to overcome the challenges in healthcare.

    Results

    A total of 58 articles were selected as per the inclusion criteria and analyzed.
    The analyses of these articles found that: (1) researchers lack consensus about
    the operational definition of Big Data in healthcare; (2) Big Data in healthcare
    comes from the internal sources within the hospitals or clinics as well external
    sources including government, laboratories, pharma companies, data aggregators,
    medical journals etc.; (3) natural language processing (NLP) is most widely used
    Big Data analytical technique for healthcare and most of the processing tools
    used for analytics are based on Hadoop; (4) Big Data analytics finds its application
    for clinical decision support; optimization of clinical operations and reduction
    of cost of care (5) major challenge in adoption of Big Data analytics is non-availability
    of evidence of its practical benefits in healthcare.

    Conclusion

    This review study unveils that there is a paucity of information on evidence of
    real-world use of Big Data analytics in healthcare. This is because, the usability
    studies have considered only qualitative approach which describes potential benefits
    but does not take into account the quantitative study. Also, majority of the studies
    were from developed countries which brings out the need for promotion of research
    on Healthcare Big Data analytics in developing countries.'
  Author: Nishita Mehta and Anil Pandit
  Book_Title_Journal: International Journal of Medical Informatics
  DOI: https://doi.org/10.1016/j.ijmedinf.2018.03.013
  JCS_FACTOR: 4.046
  Keywords: Big data, Analytics, Healthcare, Predictive analytics, Evidence-based
    medicine
  SCI_FACTOR: 1.124
  Title: 'Concurrence of big data analytics and healthcare: A systematic review'
  Title_JCS: INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS
  Title_SCI: International Journal of Medical Informatics
  Type_Publication: article
  Year: 2018
- Abstract: Big Data is dominating the landscape as data originated in many sources
    keeps piling up. Information Technology (IT) business companies are making tremendous
    efforts to keep the pace with this wave of innovative technologies. This study
    aims to identify how the different IT companies are aligned with emerging Big
    Data technologies. The approach consisted in analyzing 11,505 news published between
    2013 and 2016 and aggregated through Google News. The companies were categorized
    according to their position in the 2017 Gartner Magic Quadrant for advanced analytics.
    A text mining and topic modeling procedure assisted in summarizing the main findings.
    Leaders dominated a large fraction of the published news. Challengers are making
    a significant effort in investing in predictive analytics, overlooking other technologies
    such as those related to data preparation and integration. The results helped
    to shed light on the emerging field of Big Data from a corporate perspective.
  Author: "Jo\xC3\xA3o Canito and Pedro Ramos and S\xC3\xA9rgio Moro and Paulo Rita"
  Book_Title_Journal: Computers in Industry
  DOI: https://doi.org/10.1016/j.compind.2018.03.018
  JCS_FACTOR: 7.635
  Keywords: Big data companies, Big data technologies, Online news, Gartner magic
    quadrant
  SCI_FACTOR: 1.432
  Title: Unfolding the relations between companies and technologies under the Big
    Data umbrella
  Title_JCS: COMPUTERS IN INDUSTRY
  Title_SCI: Computers in Industry
  Type_Publication: article
  Year: 2018
- Abstract: Big data has caused the scientific community to re-examine the scientific
    research methodologies and has triggered a revolution in scientific thinking.
    As a branch of scientific research, production safety management is also exploring
    methods to take advantage of big data. This research aims to provide a theoretical
    basis for promoting the application of big data in production safety management.
    First, four different types of production safety management paradigms were identified,
    namely small-data-based, static-oriented, interpretation-based and causal-oriented
    paradigm, and the challenges to these paradigms in the presence of big data were
    introduced. Second, the opportunities of employing big data in production safety
    management were identified from four aspects, including better predict the future
    production safety phenomena, promote production safety management highlight relevance,
    achieve the balance between deductive and inductive approaches and promote the
    interdisciplinary development of production safety management. Third, the paradigm
    shifting trend of production safety management was concluded, and the discipline
    foundation of the new paradigm was considered as the integration of data science,
    production management and safety science. Fourth, a new big-data-driven production
    safety management paradigm was developed, which consists of the logical line of
    production safety management, the macro-meso-micro data spectrum, the key big
    data analytics, and the four-dimensional morphology. At last, the strengths (e.g.,
    supporting better-informed safety description, safety inquisition, safety prediction)
    and future research direction (e.g., theory research focuses on safety-related
    data mining/capturing/cleansing) of the new paradigm were discussed. The research
    results not only can provide theoretical and practical basis for big-data-driven
    production safety management, but also can offer advice to managerial consideration
    and scholarly investigation.
  Author: Lang Huang and Chao Wu and Bing Wang
  Book_Title_Journal: Journal of Cleaner Production
  DOI: https://doi.org/10.1016/j.jclepro.2019.05.245
  JCS_FACTOR: 9.297
  Keywords: Big data, Production safety management, Big-data-driven, Challenges, Opportunities
  SCI_FACTOR: 1.937
  Title: 'Challenges, opportunities and paradigm of applying big data to production
    safety management: From a theoretical perspective'
  Title_JCS: Journal of Cleaner Production
  Title_SCI: Journal of Cleaner Production
  Type_Publication: article
  Year: 2019
- Abstract: Energy economy models are central to decision making on energy and climate
    issues in the 21st century, such as informing the design of deep decarbonisation
    strategies under the Paris Agreement. Designing policies that are aimed at achieving
    such radical transitions in the energy system will require ever more in-depth
    modelling of end-use demand, efficiency and fuel switching, as well as an increasing
    need for regional, sectoral, and agent disaggregation to capture technological,
    jurisdictional and policy detail. Building and using these models entails complex
    trade-offs between the level of detail, the size of the system boundary, and the
    available computing resources. The availability of data to characterise key energy
    system sectors and interactions is also a key driver of model structure and parameterisation,
    and there are many blind spots and design compromises that are caused by data
    scarcity. We may soon, however, live in a world of data abundance, potentially
    enabling previously impossible levels of resolution and coverage in energy economy
    models. But while big data concepts and platforms have already begun to be used
    in a number of selected energy research applications, their potential to improve
    or even completely revolutionise energy economy modelling has been almost completely
    overlooked in the existing literature. In this paper, we explore the challenges
    and possibilities of this emerging frontier. We identify critical gaps and opportunities
    for the field, as well as developing foundational concepts for guiding the future
    application of big data to energy economy modelling, with reference to the existing
    literature on decision making under uncertainty, scenario analysis and the philosophy
    of science.
  Author: Francis G.N. Li and Chris Bataille and Steve Pye and Aidan O'Sullivan
  Book_Title_Journal: Applied Energy
  DOI: https://doi.org/10.1016/j.apenergy.2019.02.002
  JCS_FACTOR: 9.746
  Keywords: Energy modelling, Climate policy, Energy policy, Decarbonisation, Energy
    data, Big data
  SCI_FACTOR: 3.035
  Title: 'Prospects for energy economy modelling with big data: Hype, eliminating
    blind spots, or revolutionising the state of the art?'
  Title_JCS: APPLIED ENERGY
  Title_SCI: Applied Energy
  Type_Publication: article
  Year: 2019
- Abstract: empty
  Author: Daniel I. McIsaac
  Book_Title_Journal: British Journal of Anaesthesia
  DOI: https://doi.org/10.1016/j.bja.2020.01.012
  JCS_FACTOR: 9.166
  Keywords: big data, enhanced recovery, epidemiology, orthopedic surgery, postoperative
    outcome, study design
  SCI_FACTOR: 2.589
  Title: 'Real-world evaluation of enhanced recovery after surgery: big data under
    the microscope'
  Title_JCS: BRITISH JOURNAL OF ANAESTHESIA
  Title_SCI: British Journal of Anaesthesia
  Type_Publication: article
  Year: 2020
- Abstract: The term big data is currently a buzzword in social science, however its
    precise meaning is ambiguous. In this paper we focus on administrative data which
    is a distinctive form of big data. Exciting new opportunities for social science
    research will be afforded by new administrative data resources, but these are
    currently under appreciated by the research community. The central aim of this
    paper is to discuss the challenges associated with administrative data. We emphasise
    that it is critical for researchers to carefully consider how administrative data
    has been produced. We conclude that administrative datasets have the potential
    to contribute to the development of high-quality and impactful social science
    research, and should not be overlooked in the emerging field of big data.
  Author: Roxanne Connelly and Christopher J. Playford and Vernon Gayle and Chris
    Dibben
  Book_Title_Journal: Social Science Research
  DOI: https://doi.org/10.1016/j.ssresearch.2016.04.015
  JCS_FACTOR: 2.322
  Keywords: Big data, Administrative data, Data management, Data quality, Data access
  SCI_FACTOR: 1.042
  Title: The role of administrative data in the big data revolution in social science
    research
  Title_JCS: SOCIAL SCIENCE RESEARCH
  Title_SCI: Social Science Research
  Type_Publication: article
  Year: 2016
- Abstract: "As spatial technology has evolved and become integrated in to archaeology,\
    \ we face a new set of challenges posed by the sheer size and complexity of data\
    \ we use and produce. In this paper I discuss the prospects and problems of Geospatial\
    \ Big Data (GBD) \xE2\u20AC\u201C broadly defined as data sets with locational\
    \ information that exceed the capacity of widely available hardware, software,\
    \ and/or human resources. While the datasets we create today remain within available\
    \ resources, we nonetheless face the same challenges as many other fields that\
    \ use and create GBD, especially in apprehensions over data quality and privacy.\
    \ After reviewing the kinds of archaeological geospatial data currently available\
    \ I discuss the near future of GBD in writing culture histories, making decisions,\
    \ and visualizing the past. I use a case study from New Zealand to argue for the\
    \ value of taking a data quantity-in-use approach to GBD and requiring applications\
    \ of GBD in archaeology be regularly accompanied by a Standalone Quality Report."
  Author: Mark D. McCoy
  Book_Title_Journal: Journal of Archaeological Science
  DOI: https://doi.org/10.1016/j.jas.2017.06.003
  JCS_FACTOR: 3.216
  Keywords: Geospatial, Big Data, Spatial technology, Cyberinfrastructure, Data science
  SCI_FACTOR: 1.572
  Title: 'Geospatial Big Data and archaeology: Prospects and problems too great to
    ignore'
  Title_JCS: JOURNAL OF ARCHAEOLOGICAL SCIENCE
  Title_SCI: Journal of Archaeological Science
  Type_Publication: article
  Year: 2017
- Abstract: "As spatial technology has evolved and become integrated in to archaeology,\
    \ we face a new set of challenges posed by the sheer size and complexity of data\
    \ we use and produce. In this paper I discuss the prospects and problems of Geospatial\
    \ Big Data (GBD) \xE2\u20AC\u201C broadly defined as data sets with locational\
    \ information that exceed the capacity of widely available hardware, software,\
    \ and/or human resources. While the datasets we create today remain within available\
    \ resources, we nonetheless face the same challenges as many other fields that\
    \ use and create GBD, especially in apprehensions over data quality and privacy.\
    \ After reviewing the kinds of archaeological geospatial data currently available\
    \ I discuss the near future of GBD in writing culture histories, making decisions,\
    \ and visualizing the past. I use a case study from New Zealand to argue for the\
    \ value of taking a data quantity-in-use approach to GBD and requiring applications\
    \ of GBD in archaeology be regularly accompanied by a Standalone Quality Report."
  Author: Mark D. McCoy
  Book_Title_Journal: Journal of Archaeological Science
  DOI: https://doi.org/10.1016/j.jas.2017.06.003
  JCS_FACTOR: 3.216
  Keywords: Geospatial, Big Data, Spatial technology, Cyberinfrastructure, Data science
  SCI_FACTOR: 1.572
  Title: 'Geospatial Big Data and archaeology: Prospects and problems too great to
    ignore'
  Title_JCS: JOURNAL OF ARCHAEOLOGICAL SCIENCE
  Title_SCI: Journal of Archaeological Science
  Type_Publication: article
  Year: 2017
- Abstract: "With an exponential increase in the provisioning of multimedia devices\
    \ over the Internet of Things (IoT), a significant amount of multimedia data (also\
    \ referred to as multimedia big data \xE2\u20AC\u201C MMBD) is being generated.\
    \ Current research and development activities focus on scalar sensor data based\
    \ IoT or general MMBD and overlook the complexity of facilitating MMBD over IoT.\
    \ This paper examines the unique nature and complexity of MMBD computing for IoT\
    \ applications and develops a comprehensive taxonomy for MMBD abstracted into\
    \ a novel process model reflecting MMBD over IoT. This process model addresses\
    \ a number of research challenges associated with MMBD, such as scalability, accessibility,\
    \ reliability, heterogeneity, and Quality of Service (QoS) requirements. A case\
    \ study is presented to demonstrate the process model."
  Author: Aparna Kumari and Sudeep Tanwar and Sudhanshu Tyagi and Neeraj Kumar and
    Michele Maasberg and Kim-Kwang Raymond Choo
  Book_Title_Journal: Journal of Network and Computer Applications
  DOI: https://doi.org/10.1016/j.jnca.2018.09.014
  JCS_FACTOR: 6.281
  Keywords: Multimedia big data, Data acquisition, Data representation, Data reduction,
    Data analysis, Data security and privacy, System intelligence, Distributed system,
    Social media
  SCI_FACTOR: 1.145
  Title: 'Multimedia big data computing and Internet of Things applications: A taxonomy
    and process model'
  Title_JCS: JOURNAL OF NETWORK AND COMPUTER APPLICATIONS
  Title_SCI: Journal of Network and Computer Applications
  Type_Publication: article
  Year: 2018
- Abstract: "Clustering technique plays a critical role in data mining, and has received\
    \ great success to solve application problems like community analysis, image retrieval,\
    \ personalized recommendation, activity prediction, etc. This paper first reviews\
    \ the traditional clustering and the emerging multiple clustering methods, respectively.\
    \ Although the existing methods have superior performance on some small or certain\
    \ datasets, they fall short when clustering is performed on CPSS big data because\
    \ of the high cost of computation and storage. With the powerful cloud computing,\
    \ this challenge can be effectively addressed, but it brings enormous threat to\
    \ individual or company\xE2\u20AC\u2122s privacy. Currently, privacy preserving\
    \ data mining has attracted widespread attention in academia. Compared to other\
    \ reviews, this paper focuses on privacy preserving clustering technique, guiding\
    \ a detailed overview and discussion. Specifically, we introduce a novel privacy-preserving\
    \ tensor-based multiple clustering, propose a privacy-preserving tensor-based\
    \ multiple clustering analytic and service framework, and give an illustrated\
    \ case study on the public transportation dataset. Furthermore, we indicate the\
    \ remaining challenges of privacy preserving clustering and discuss the future\
    \ significant research in this area."
  Author: Yaliang Zhao and Samwel K. Tarus and Laurence T. Yang and Jiayu Sun and
    Yunfei Ge and Jinke Wang
  Book_Title_Journal: Information Sciences
  DOI: https://doi.org/10.1016/j.ins.2019.10.019
  JCS_FACTOR: 6.795
  Keywords: CPSS, Big data, Cloud computing, Privacy preserving, Clustering
  SCI_FACTOR: 1.524
  Title: 'Privacy-preserving clustering for big data in cyber-physical-social systems:
    Survey and perspectives'
  Title_JCS: INFORMATION SCIENCES
  Title_SCI: Information Sciences
  Type_Publication: article
  Year: 2020
- Abstract: 'Context

    Big Data Cybersecurity Analytics (BDCA) systems leverage big data technologies
    for analyzing security events data to protect organizational networks, computers,
    and data from cyber attacks.

    Objective

    We aimed at identifying the most frequently reported quality attributes and architectural
    tactics for BDCA systems.

    Method

    We used Systematic Literature Review (SLR) method for reviewing 74 papers.

    Result

    Our findings are twofold: (i) identification of 12 most frequently reported quality
    attributes for BDCA systems; and (ii) identification and codification of 17 architectural
    tactics for addressing the identified quality attributes. The identified tactics
    include six performance tactics, four accuracy tactics, two scalability tactics,
    three reliability tactics, and one security and usability tactic each.

    Conclusion

    Our study reveals that in the context of BDCA (a) performance, accuracy and scalability
    are the most important quality concerns (b) data analytics is the most critical
    architectural component (c) despite the significance of interoperability, modifiability,
    adaptability, generality, stealthiness, and privacy assurance, these quality attributes
    lack explicit architectural support (d) empirical investigation is required to
    evaluate the impact of the codified tactics and explore the quality trade-offs
    and dependencies among the tactics and (e) the reported tactics need to be modelled
    using a standardized modelling language such as UML.'
  Author: Faheem Ullah and Muhammad {Ali Babar}
  Book_Title_Journal: Journal of Systems and Software
  DOI: https://doi.org/10.1016/j.jss.2019.01.051
  JCS_FACTOR: 2.829
  Keywords: Big data, Cybersecurity, Quality attribute, Architectural tactic
  SCI_FACTOR: 0.642
  Title: 'Architectural Tactics for Big Data Cybersecurity Analytics Systems: A Review'
  Title_JCS: JOURNAL OF SYSTEMS AND SOFTWARE
  Title_SCI: Journal of Systems and Software
  Type_Publication: article
  Year: 2019
- Abstract: Deep learning, as one of the most currently remarkable machine learning
    techniques, has achieved great success in many applications such as image analysis,
    speech recognition and text understanding. It uses supervised and unsupervised
    strategies to learn multi-level representations and features in hierarchical architectures
    for the tasks of classification and pattern recognition. Recent development in
    sensor networks and communication technologies has enabled the collection of big
    data. Although big data provides great opportunities for a broad of areas including
    e-commerce, industrial control and smart medical, it poses many challenging issues
    on data mining and information processing due to its characteristics of large
    volume, large variety, large velocity and large veracity. In the past few years,
    deep learning has played an important role in big data analytic solutions. In
    this paper, we review the emerging researches of deep learning models for big
    data feature learning. Furthermore, we point out the remaining challenges of big
    data deep learning and discuss the future topics.
  Author: Qingchen Zhang and Laurence T. Yang and Zhikui Chen and Peng Li
  Book_Title_Journal: Information Fusion
  DOI: https://doi.org/10.1016/j.inffus.2017.10.006
  JCS_FACTOR: 12.975
  Keywords: Deep learning, Big data, Stacked auto-encoders, Deep belief networks,
    Convolutional neural networks, Recurrent neural networks
  SCI_FACTOR: 2.776
  Title: A survey on deep learning for big data
  Title_JCS: Information Fusion
  Title_SCI: Information Fusion
  Type_Publication: article
  Year: 2018
- Abstract: 'The era of Big Data has arrived along with large volume, complex and
    growing data generated by many distinct sources. Nowadays, nearly every aspect
    of the modern society is impacted by Big Data, involving medical, health care,
    business, management and government. It has been receiving growing attention of
    researches from many disciplines including natural sciences, life sciences, engineering
    and even art & humanities. It also leads to new research paradigms and ways of
    thinking on the path of development. Lots of developed and under-developing tools
    improve our ability to make more felicitous decisions than what we have made ever
    before. This paper presents an overview on Big Data including four issues, namely:
    (i) concepts, characteristics and processing paradigms of Big Data; (ii) the state-of-the-art
    techniques for decision making in Big Data; (iii) felicitous decision making applications
    of Big Data in social science; and (iv) the current challenges of Big Data as
    well as possible future directions.'
  Author: Hai Wang and Zeshui Xu and Hamido Fujita and Shousheng Liu
  Book_Title_Journal: Information Sciences
  DOI: https://doi.org/10.1016/j.ins.2016.07.007
  JCS_FACTOR: 6.795
  Keywords: Big Data, Data deluge, Decision making, Data analysis, Data-intensive
    applications, Computational social science
  SCI_FACTOR: 1.524
  Title: 'Towards felicitous decision making: An overview on challenges and trends
    of Big Data'
  Title_JCS: INFORMATION SCIENCES
  Title_SCI: Information Sciences
  Type_Publication: article
  Year: 2016
- Abstract: "Purpose\nBig data is increasingly becoming a major organizational enterprise\
    \ force to reckon with in this global era for all sizes of industries. It is a\
    \ trending new enterprise system or platform which seemingly offers more features\
    \ for acquiring, storing and analysing voluminous generated data from various\
    \ sources to obtain value-additions. However, current research reveals that there\
    \ is limited agreement regarding the performance of \xE2\u20AC\u0153big data.\xE2\
    \u20AC\x9D Therefore, this paper attempts to thoroughly investigate \xE2\u20AC\
    \u0153big data,\xE2\u20AC\x9D its application and analysis in operations or supply-chain\
    \ management, as well as the trends and perspectives in this research area. This\
    \ paper is organized in the form of a literature review, discussing the main issues\
    \ of \xE2\u20AC\u0153big data\xE2\u20AC\x9D and its extension into \xE2\u20AC\u0153\
    big data II\xE2\u20AC\x9D/IoT\xE2\u20AC\u201Cvalue-adding perspectives by proposing\
    \ a value-adding framework.\nMethodology/research approach\nThe research approach\
    \ employed is a comprehensive literature review. About 100 or more peer-reviewed\
    \ journal articles/conference proceedings as well as industrial white papers are\
    \ reviewed. Harzing Publish or Perish software was employed to investigate and\
    \ critically analyse the trends and perspectives of \xE2\u20AC\u0153big data\xE2\
    \u20AC\x9D applications between 2010 and 2015.\nFindings/results\nThe four main\
    \ attributes or factors identified with \xE2\u20AC\u0153big data\xE2\u20AC\x9D\
    \ include \xE2\u20AC\u201C big data development sources (Variety \xE2\u20AC\u201C\
    \ V1), big data acquisition (Velocity \xE2\u20AC\u201C V2), big data storage (Volume\
    \ \xE2\u20AC\u201C V3), and finally big data analysis (Veracity \xE2\u20AC\u201C\
    \ V4). However, the study of \xE2\u20AC\u0153big data\xE2\u20AC\x9D has evolved\
    \ and expanded a lot based on its application and implementation processes in\
    \ specific industries in order to create value (Value-adding \xE2\u20AC\u201C\
    \ V5) \xE2\u20AC\u201C \xE2\u20AC\u0153Big Data cloud computing perspective/Internet\
    \ of Things (IoT)\xE2\u20AC\x9D. Hence, the four Vs of \xE2\u20AC\u0153big data\xE2\
    \u20AC\x9D is now expanded into five Vs.\nOriginality/value of research\nThis\
    \ paper presents original literature review research discussing \xE2\u20AC\u0153\
    big data\xE2\u20AC\x9D issues, trends and perspectives in operations/supply-chain\
    \ management in order to propose \xE2\u20AC\u0153Big data II\xE2\u20AC\x9D (IoT\
    \ \xE2\u20AC\u201C Value-adding) framework. This proposed framework is supposed\
    \ or assumed to be an extension of \xE2\u20AC\u0153big data\xE2\u20AC\x9D in a\
    \ value-adding perspective, thus proposing that \xE2\u20AC\u0153big data\xE2\u20AC\
    \x9D be explored thoroughly in order to enable industrial managers and businesses\
    \ executives to make pre-informed strategic operational and management decisions\
    \ for increased return-on-investment (ROI). It could also empower organizations\
    \ with a value-adding stream of information to have a competitive edge over their\
    \ competitors."
  Author: Richard Addo-Tenkorang and Petri T. Helo
  Book_Title_Journal: Computers & Industrial Engineering
  DOI: https://doi.org/10.1016/j.cie.2016.09.023
  JCS_FACTOR: 5.431
  Keywords: "Big data \xE2\u20AC\u201C applications and analysis, Internet of Things\
    \ (IoT), Cloud computing, Master database management, Operations/supply-chain\
    \ management"
  SCI_FACTOR: 0.0
  Title: 'Big data applications in operations/supply-chain management: A literature
    review'
  Title_JCS: COMPUTERS & INDUSTRIAL ENGINEERING
  Title_SCI: N/A
  Type_Publication: article
  Year: 2016
- Abstract: empty
  Author: Steven H. Shaha and Zain Sayeed and Afshin A. Anoushiravani and Mouhanad
    M. El-Othmani and Khaled J. Saleh
  Book_Title_Journal: Orthopedic Clinics of North America
  DOI: https://doi.org/10.1016/j.ocl.2016.05.009
  JCS_FACTOR: 2.472
  Keywords: "Big data, Comparative effectiveness, Orthopedics, Total joint arthroplasty,\
    \ Administrative\xC2\_database, Clinical database"
  SCI_FACTOR: 1.177
  Title: 'Big Data, Big Problems: Incorporating Mission, Values, and Culture in Provider
    Affiliations'
  Title_JCS: ORTHOPEDIC CLINICS OF NORTH AMERICA
  Title_SCI: Orthopedic Clinics of North America
  Type_Publication: article
  Year: 2016
- Abstract: The Data Big Bang that the development of the ICTs has raised is providing
    us with a stream of fresh and digitized data related to how people, companies
    and other organizations interact. To turn these data into knowledge about the
    underlying behavior of the social and economic agents, organizations and researchers
    must deal with such amount of unstructured and heterogeneous data. Succeeding
    in this task requires to carefully plan and organize the whole process of data
    analysis taking into account the particularities of the social and economic analyses,
    which include the wide variety of heterogeneous sources of information and a strict
    governance policy. Grounded on the data lifecycle approach, this paper develops
    a Big Data architecture that properly integrates most of the non-traditional information
    sources and data analysis methods in order to provide a specifically designed
    system for forecasting social and economic behaviors, trends and changes.
  Author: Desamparados Blazquez and Josep Domenech
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2017.07.027
  JCS_FACTOR: 8.593
  Keywords: Big Data architecture, Forecasting, Nowcasting, Data lifecycle, Socio-economic
    data, Non-traditional data sources, Non-traditional analysis methods
  SCI_FACTOR: 2.226
  Title: Big Data sources and methods for social and economic analyses
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2018
- Abstract: This paper investigates big data analytics research and application in
    supply chain management between 2010 and 2016 and provides insights to industries.
    In recent years, the amount of data produced from end-to-end supply chain management
    practices has increased exponentially. Moreover, in current competitive environment
    supply chain professionals are struggling in handling the huge data. They are
    surveying new techniques to investigate how data are produced, captured, organized
    and analyzed to give valuable insights to industries. Big Data analytics is one
    of the best techniques which can help them in overcoming their problem. Realizing
    the promising benefits of big data analytics in the supply chain has motivated
    us to write a review on the importance/impact of big data analytics and its application
    in supply chain management. First, we discuss big data analytics individually,
    and then we discuss the role of big data analytics in supply chain management
    (supply chain analytics). Current research and application are also explored.
    Finally, we outline the insights to industries. Observations and insights from
    this paper could provide the guideline for academia and practitioners in implementing
    big data analytics in different aspects of supply chain management.
  Author: Sunil Tiwari and H.M. Wee and Yosef Daryanto
  Book_Title_Journal: Computers & Industrial Engineering
  DOI: https://doi.org/10.1016/j.cie.2017.11.017
  JCS_FACTOR: 5.431
  Keywords: Big data analytics, Supply chain management, Big data application
  SCI_FACTOR: 0.0
  Title: 'Big data analytics in supply chain management between 2010 and 2016: Insights
    to industries'
  Title_JCS: COMPUTERS & INDUSTRIAL ENGINEERING
  Title_SCI: N/A
  Type_Publication: article
  Year: 2018
- Abstract: 'To date, health care industry has not fully grasped the potential benefits
    to be gained from big data analytics. While the constantly growing body of academic
    research on big data analytics is mostly technology oriented, a better understanding
    of the strategic implications of big data is urgently needed. To address this
    lack, this study examines the historical development, architectural design and
    component functionalities of big data analytics. From content analysis of 26 big
    data implementation cases in healthcare, we were able to identify five big data
    analytics capabilities: analytical capability for patterns of care, unstructured
    data analytical capability, decision support capability, predictive capability,
    and traceability. We also mapped the benefits driven by big data analytics in
    terms of information technology (IT) infrastructure, operational, organizational,
    managerial and strategic areas. In addition, we recommend five strategies for
    healthcare organizations that are considering to adopt big data analytics technologies.
    Our findings will help healthcare organizations understand the big data analytics
    capabilities and potential benefits and support them seeking to formulate more
    effective data-driven analytics strategies.'
  Author: Yichuan Wang and LeeAnn Kung and Terry Anthony Byrd
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2015.12.019
  JCS_FACTOR: 8.593
  Keywords: Big data analytics, Big data analytics architecture, Big data analytics
    capabilities, Business value of information technology (IT), Health care
  SCI_FACTOR: 2.226
  Title: 'Big data analytics: Understanding its capabilities and potential benefits
    for healthcare organizations'
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2018
- Abstract: In the current scenario, sustainable auditing, for example roundtable
    of sustainable palm oil (RSPO), requires a huge amount of data to be manually
    collected and entered into paper forms by farmers. Such systems are inherently
    inefficient, time-consuming, and, prone to errors. Researchers have proposed Big
    Data Analytics (BDA) based framework for next-generation smart sustainable auditing
    systems. Though theoretically feasible, real-life implementation of such frameworks
    is extremely difficult. Thus, this paper aims to identify the critical barriers
    that hinder the application of BDA based smart sustainable auditing system. It
    also aims to explore the dynamic interrelations among the barriers. We applied
    Interpretive Structural Modelling (ISM) approach to develop the model that extrapolates
    BDA adoption barriers and their relationships. The proposed model illustrates
    how barriers are spread over various levels and how specific barriers impact other
    barriers through direct and/or transitive links. This study provides practitioners
    with a roadmap to prioritise the interventions to facilitate the adoption of BDA
    in the sustainable auditing systems. Insights of this study could be used by academics
    to enhance understanding of the barriers to BDA applications.
  Author: Manish Shukla and Lana Mattar
  Book_Title_Journal: Computers & Industrial Engineering
  DOI: https://doi.org/10.1016/j.cie.2018.04.055
  JCS_FACTOR: 5.431
  Keywords: Big Data Analytics, Sustainable auditing systems, Barriers, RSPO, Interpretive
    Structural Modelling
  SCI_FACTOR: 0.0
  Title: 'Next generation smart sustainable auditing systems using Big Data Analytics:
    Understanding the interaction of critical barriers'
  Title_JCS: COMPUTERS & INDUSTRIAL ENGINEERING
  Title_SCI: N/A
  Type_Publication: article
  Year: 2019
- Abstract: The rapid growth of emerging applications and the evolution of cloud computing
    technologies have significantly enhanced the capability to generate vast amounts
    of data. Thus, it has become a great challenge in this big data era to manage
    such voluminous amount of data. The recent advancements in big data techniques
    and technologies have enabled many enterprises to handle big data efficiently.
    However, these advances in techniques and technologies have not yet been studied
    in detail and a comprehensive survey of this domain is still lacking. With focus
    on big data management, this survey aims to investigate feasible techniques of
    managing big data by emphasizing on storage, pre-processing, processing and security.
    Moreover, the critical aspects of these techniques are analyzed by devising a
    taxonomy in order to identify the problems and proposals made to alleviate these
    problems. Furthermore, big data management techniques are also summarized. Finally,
    several future research directions are presented.
  Author: Aisha Siddiqa and Ibrahim Abaker Targio Hashem and Ibrar Yaqoob and Mohsen
    Marjani and Shahabuddin Shamshirband and Abdullah Gani and Fariza Nasaruddin
  Book_Title_Journal: Journal of Network and Computer Applications
  DOI: https://doi.org/10.1016/j.jnca.2016.04.008
  JCS_FACTOR: 6.281
  Keywords: Big data management, Storage, Big data, Processing, Security
  SCI_FACTOR: 1.145
  Title: 'A survey of big data management: Taxonomy and state-of-the-art'
  Title_JCS: JOURNAL OF NETWORK AND COMPUTER APPLICATIONS
  Title_SCI: Journal of Network and Computer Applications
  Type_Publication: article
  Year: 2016
- Abstract: "This study seeks to understand big data ecology, how it is perceived\
    \ by different stakeholders, the potential value and challenges, and the implications\
    \ for the private sector and public organizations, as well as for policy makers.\
    \ With Normalization Process Theory in place, this study conducts socio-technical\
    \ evaluation on the big data phenomenon to understand the developmental processes\
    \ through which new practices of thinking and enacting are implemented, embedded,\
    \ and integrated in South Korea. It also undertakes empirical analyses of user\
    \ modeling to explore the factors influencing users\xD7\xB3 adoption of big data\
    \ by integrating cognitive motivations as well as user values as the primary determining\
    \ factors. Based on the qualitative and quantitative findings, this study concludes\
    \ that big data should be developed with user-centered ideas and that users should\
    \ be the focus of big data design."
  Author: Dong-Hee Shin
  Book_Title_Journal: Telecommunications Policy
  DOI: https://doi.org/10.1016/j.telpol.2015.03.007
  JCS_FACTOR: 3.036
  Keywords: Big data, Data ecosystem, Normalization, Normalization process theory,
    Big data user, Big data user experience
  SCI_FACTOR: 0.84
  Title: 'Demystifying big data: Anatomy of big data developmental process'
  Title_JCS: TELECOMMUNICATIONS POLICY
  Title_SCI: Telecommunications Policy
  Type_Publication: article
  Year: 2016
- Abstract: "This study seeks to understand big data ecology, how it is perceived\
    \ by different stakeholders, the potential value and challenges, and the implications\
    \ for the private sector and public organizations, as well as for policy makers.\
    \ With Normalization Process Theory in place, this study conducts socio-technical\
    \ evaluation on the big data phenomenon to understand the developmental processes\
    \ through which new practices of thinking and enacting are implemented, embedded,\
    \ and integrated in South Korea. It also undertakes empirical analyses of user\
    \ modeling to explore the factors influencing users\xD7\xB3 adoption of big data\
    \ by integrating cognitive motivations as well as user values as the primary determining\
    \ factors. Based on the qualitative and quantitative findings, this study concludes\
    \ that big data should be developed with user-centered ideas and that users should\
    \ be the focus of big data design."
  Author: Dong-Hee Shin
  Book_Title_Journal: Telecommunications Policy
  DOI: https://doi.org/10.1016/j.telpol.2015.03.007
  JCS_FACTOR: 3.036
  Keywords: Big data, Data ecosystem, Normalization, Normalization process theory,
    Big data user, Big data user experience
  SCI_FACTOR: 0.84
  Title: 'Demystifying big data: Anatomy of big data developmental process'
  Title_JCS: TELECOMMUNICATIONS POLICY
  Title_SCI: Telecommunications Policy
  Type_Publication: article
  Year: 2016
- Abstract: "Machine-to-Machine (M2M) communication relies on the physical objects\
    \ (e.g., satellites, sensors, and so forth) interconnected with each other, creating\
    \ mesh of machines producing massive volume of data about large geographical area\
    \ (e.g., living and non-living environment). Thus, the M2M is an ideal example\
    \ of Big Data. On the contrary, the M2M platforms that handle Big Data might perform\
    \ poorly or not according to the goals of their operator (in term of cost, database\
    \ utilization, data quality, processing and computational efficiency, analysis\
    \ and feature extraction applications). Therefore, to address the aforementioned\
    \ needs, we propose a new effective, memory and processing efficient system architecture\
    \ for Big Data in M2M, which, unlike other previous proposals, does not require\
    \ whole set of data to be processed (including raw data sets), and to be kept\
    \ in the main memory. Our designed system architecture exploits divide-and-conquer\
    \ approach and data block-wise vertical representation of the database follows\
    \ a particular petitionary strategy, which formalizes the problem of feature extraction\
    \ applications. The architecture goes from physical objects to the processing\
    \ servers, where Big Data set is first transformed into a several data blocks\
    \ that can be quickly processed, then it classifies and reorganizes these data\
    \ blocks from the same source. In addition, the data blocks are aggregated in\
    \ a sequential manner based on a machine ID, and equally partitions the data using\
    \ fusion algorithm. Finally, the results are stored in a server that helps the\
    \ users in making decision. The feasibility and efficiency of the proposed system\
    \ architecture are implemented on Hadoop single node setup on UBUNTU 14.04 LTS\
    \ core\xE2\u201E\xA2i5 machine with 3.2GHz processor and 4GB memory. The results\
    \ show that the proposed system architecture efficiently extract various features\
    \ (such as River) from the massive volume of satellite data."
  Author: Awais Ahmad and Anand Paul and M. Mazhar Rathore
  Book_Title_Journal: Neurocomputing
  DOI: https://doi.org/10.1016/j.neucom.2015.04.109
  JCS_FACTOR: 5.719
  Keywords: M2M, Big Data, Divide-and-conquer, Data fusion domain
  SCI_FACTOR: 1.085
  Title: An efficient divide-and-conquer approach for big data analytics in machine-to-machine
    communication
  Title_JCS: NEUROCOMPUTING
  Title_SCI: Neurocomputing
  Type_Publication: article
  Year: 2016
- Abstract: "Background\nIn recent years, the literature associated with healthcare\
    \ big data has grown rapidly, but few studies have used bibliometrics and a visualization\
    \ approach to conduct deep mining and reveal a panorama of the healthcare big\
    \ data field.\nMethods\nTo explore the foundational knowledge and research hotspots\
    \ of big data research in the field of healthcare informatics, this study conducted\
    \ a series of bibliometric analyses on the related literature, including papers\xE2\
    \u20AC\u2122 production trends in the field and the trend of each paper\xE2\u20AC\
    \u2122s co-author number, the distribution of core institutions and countries,\
    \ the core literature distribution, the related information of prolific authors\
    \ and innovation paths in the field, a keyword co-occurrence analysis, and research\
    \ hotspots and trends for the future.\nResults\nBy conducting a literature content\
    \ analysis and structure analysis, we found the following: (a) In the early stage,\
    \ researchers from the United States, the People\xE2\u20AC\u2122s Republic of\
    \ China, the United Kingdom, and Germany made the most contributions to the literature\
    \ associated with healthcare big data research and the innovation path in this\
    \ field. (b) The innovation path in healthcare big data consists of three stages:\
    \ the disease early detection, diagnosis, treatment, and prognosis phase, the\
    \ life and health promotion phase, and the nursing phase. (c) Research hotspots\
    \ are mainly concentrated in three dimensions: the disease dimension (e.g., epidemiology,\
    \ breast cancer, obesity, and diabetes), the technical dimension (e.g., data mining\
    \ and machine learning), and the health service dimension (e.g., customized service\
    \ and elderly nursing).\nConclusion\nThis study will provide scholars in the healthcare\
    \ informatics community with panoramic knowledge of healthcare big data research,\
    \ as well as research hotspots and future research directions."
  Author: Dongxiao Gu and Jingjing Li and Xingguo Li and Changyong Liang
  Book_Title_Journal: International Journal of Medical Informatics
  DOI: https://doi.org/10.1016/j.ijmedinf.2016.11.006
  JCS_FACTOR: 4.046
  Keywords: Big data, Healthcare informatics, Bibliometrics, Knowledge structure,
    Knowledge management
  SCI_FACTOR: 1.124
  Title: Visualizing the knowledge structure and evolution of big data research in
    healthcare informatics
  Title_JCS: INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS
  Title_SCI: International Journal of Medical Informatics
  Type_Publication: article
  Year: 2017
- Abstract: "People, devices, infrastructures and sensors can constantly communicate\
    \ exchanging data and generating new data that trace many of these exchanges.\
    \ This leads to vast volumes of data collected at ever increasing velocities and\
    \ of different variety, a phenomenon currently known as Big Data. In particular,\
    \ recent developments in Information and Communications Technologies are pushing\
    \ the fourth industrial revolution, Industry 4.0, being data generated by several\
    \ sources like machine controllers, sensors, manufacturing systems, among others.\
    \ Joining volume, variety and velocity of data, with Industry 4.0, makes the opportunity\
    \ to enhance sustainable innovation in the Factories of the Future. In this, the\
    \ collection, integration, storage, processing and analysis of data is a key challenge,\
    \ being Big Data systems needed to link all the entities and data needs of the\
    \ factory. Thereby, this paper addresses this key challenge, proposing and implementing\
    \ a Big Data Analytics architecture, using a multinational organisation (Bosch\
    \ Car Multimedia \xE2\u20AC\u201C Braga) as a case study. In this work, all the\
    \ data lifecycle, from collection to analysis, is handled, taking into consideration\
    \ the different data processing speeds that can exist in the real environment\
    \ of a factory (batch or stream)."
  Author: "Maribel Yasmina Santos and Jorge {Oliveira e S\xC3\xA1} and Carina Andrade\
    \ and Francisca {Vale Lima} and Eduarda Costa and Carlos Costa and Bruno Martinho\
    \ and Jo\xC3\xA3o Galv\xC3\xA3o"
  Book_Title_Journal: International Journal of Information Management
  DOI: https://doi.org/10.1016/j.ijinfomgt.2017.07.012
  JCS_FACTOR: 14.098
  Keywords: Big Data, Industry 4.0, Big Data analytics, Big Data architecture, Bosch
  SCI_FACTOR: 2.77
  Title: A Big Data system supporting Bosch Braga Industry 4.0 strategy
  Title_JCS: INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
  Title_SCI: International Journal of Information Management
  Type_Publication: article
  Year: 2017
- Abstract: "A group of researchers, consultants, software developers, and transit\
    \ agencies convened in Santiago, Chile over 3 days as part of the Thredbo workshop\
    \ titled \xE2\u20AC\u0153Harnessing Big Data\xE2\u20AC\x9D, to present their recent\
    \ research and discuss the state of practice, state of the art, and future directions\
    \ of big data in public transportation. This report documents their discussion.\
    \ The key conclusion of the workshop is that, although much progress has been\
    \ made in utilizing big data to improve transportation planning and operations,\
    \ much remains to be done, both in terms of developing further analysis tools\
    \ and use cases of big data, and of disseminating best practices so that they\
    \ are adopted across the industry."
  Author: "Gabriel E. S\xC3\xA1nchez-Mart\xC3\xADnez and Marcela Munizaga"
  Book_Title_Journal: Research in Transportation Economics
  DOI: https://doi.org/10.1016/j.retrec.2016.10.008
  JCS_FACTOR: 2.627
  Keywords: Big data, Measurement, Implementation challenges, Analysis tools, Transit
    best practices
  SCI_FACTOR: 1.019
  Title: 'Workshop 5 report: Harnessing big data'
  Title_JCS: Research in Transportation Economics
  Title_SCI: Research in Transportation Economics
  Type_Publication: article
  Year: 2016
- Abstract: 'Big data is an important driver of disruptive innovation that may increase
    organizations'' competitive advantage. To create innovative data combinations
    and decrease investments, big data is often shared among organizations, crossing
    organizational boundaries. However, these big data collaborations need to balance
    disruptive innovation and compliance to a strict data protection regime in the
    EU. This paper investigates how inter-organizational big data collaborations arrange
    and govern their activities in the context of this dilemma. We conceptualize big
    data as inter-organizational systems and build on IS and Organization Theory literature
    to develop four archetypical governance arrangements: Market, Hierarchy, Bazaar
    and Network. Subsequently, these arrangements are investigated in four big data
    collaboration use cases. The contributions of this study to literature are threefold.
    First, we conceptualize the organization behind big data collaborations as IOS
    governance. Second, we show that the choice for an inter-organizational governance
    arrangement highly depends on the institutional pressure from regulation and the
    type of data that is shared. In this way, we contribute to the limited body of
    research on the antecedents of IOS governance. Last, we highlight with four use
    cases how the principles of big data, specifically data maximization, clash with
    the principles of EU data protection regulation. Practically, our study provides
    guidelines for IT and innovation managers how to arrange and govern the sharing
    of data among multiple organizations.'
  Author: Tijs {van den Broek} and Anne Fleur {van Veenstra}
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2017.09.040
  JCS_FACTOR: 8.593
  Keywords: Disruptive innovation, Data protection regulation, Big data, Governance,
    Inter-organizational collaboration
  SCI_FACTOR: 2.226
  Title: 'Governance of big data collaborations: How to balance regulatory compliance
    and disruptive innovation'
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2018
- Abstract: "Background\nBuilding cancer risk models from real-world data requires\
    \ overcoming challenges in data preprocessing, efficient representation, and computational\
    \ performance. We present a case study of a cloud-based approach to learning from\
    \ de-identified electronic health record data and demonstrate its effectiveness\
    \ for melanoma risk prediction.\nMethods\nWe used a hybrid distributed and non-distributed\
    \ approach to computing in the cloud: distributed processing with Apache Spark\
    \ for data preprocessing and labeling, and non-distributed processing for machine\
    \ learning model training with scikit-learn. Moreover, we explored the effects\
    \ of sampling the training dataset to improve computational performance. Risk\
    \ factors were evaluated using regression weights as well as tree SHAP values.\n\
    Results\nAmong 4,061,172 patients who did not have melanoma through the 2016 calendar\
    \ year, 10,129 were diagnosed with melanoma within one year. A gradient-boosted\
    \ classifier achieved the best predictive performance with cross-validation (AUC\xE2\
    \u20AC\xAF=\xE2\u20AC\xAF0.799, Sensitivity\xE2\u20AC\xAF=\xE2\u20AC\xAF0.753,\
    \ Specificity\xE2\u20AC\xAF=\xE2\u20AC\xAF0.688). Compared to a model built on\
    \ the original data, a dataset two orders of magnitude smaller could achieve statistically\
    \ similar or better performance with less than 1% of the training time and cost.\n\
    Conclusions\nWe produced a model that can effectively predict melanoma risk for\
    \ a diverse dermatology population in the U.S. by using hybrid computing infrastructure\
    \ and data sampling. For this de-identified clinical dataset, sampling approaches\
    \ significantly shortened the time for model building while retaining predictive\
    \ accuracy, allowing for more rapid machine learning model experimentation on\
    \ familiar computing machinery. A large number of risk factors (>300) were required\
    \ to produce the best model."
  Author: Aaron N. Richter and Taghi M. Khoshgoftaar
  Book_Title_Journal: Computers in Biology and Medicine
  DOI: https://doi.org/10.1016/j.compbiomed.2019.04.039
  JCS_FACTOR: 4.589
  Keywords: Big data, Cloud computing, Machine learning, Electronic health records,
    Early detection of cancer
  SCI_FACTOR: 0.884
  Title: 'Efficient learning from big data for cancer risk modeling: A case study
    with melanoma'
  Title_JCS: COMPUTERS IN BIOLOGY AND MEDICINE
  Title_SCI: Computers in Biology and Medicine
  Type_Publication: article
  Year: 2019
- Abstract: Big data is a potential research area receiving considerable attention
    from academia and IT communities. In the digital world, the amounts of data generated
    and stored have expanded within a short period of time. Consequently, this fast
    growing rate of data has created many challenges. In this paper, we use structuralism
    and functionalism paradigms to analyze the origins of big data applications and
    its current trends. This paper presents a comprehensive discussion on state-of-the-art
    big data technologies based on batch and stream data processing. Moreover, strengths
    and weaknesses of these technologies are analyzed. This study also discusses big
    data analytics techniques, processing methods, some reported case studies from
    different vendors, several open research challenges, and the opportunities brought
    about by big data. The similarities and differences of these techniques and technologies
    based on important parameters are also investigated. Emerging technologies are
    recommended as a solution for big data problems.
  Author: Ibrar Yaqoob and Ibrahim Abaker Targio Hashem and Abdullah Gani and Salimah
    Mokhtar and Ejaz Ahmed and Nor Badrul Anuar and Athanasios V. Vasilakos
  Book_Title_Journal: International Journal of Information Management
  DOI: https://doi.org/10.1016/j.ijinfomgt.2016.07.009
  JCS_FACTOR: 14.098
  Keywords: Big data, Parallel and distributed computing, Cloud computing, Internet
    of things, Social media, Analytics
  SCI_FACTOR: 2.77
  Title: 'Big data: From beginning to future'
  Title_JCS: INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
  Title_SCI: International Journal of Information Management
  Type_Publication: article
  Year: 2016
- Abstract: "The ability to process large amounts of data and to extract useful insights\
    \ from data has revolutionised society. This phenomenon\xE2\u20AC\u201Ddubbed\
    \ as Big Data\xE2\u20AC\u201Dhas applications for a wide assortment of industries,\
    \ including the construction industry. The construction industry already deals\
    \ with large volumes of heterogeneous data; which is expected to increase exponentially\
    \ as technologies such as sensor networks and the Internet of Things are commoditised.\
    \ In this paper, we present a detailed survey of the literature, investigating\
    \ the application of Big Data techniques in the construction industry. We reviewed\
    \ related works published in the databases of American Association of Civil Engineers\
    \ (ASCE), Institute of Electrical and Electronics Engineers (IEEE), Association\
    \ of Computing Machinery (ACM), and Elsevier Science Direct Digital Library. While\
    \ the application of data analytics in the construction industry is not new, the\
    \ adoption of Big Data technologies in this industry remains at a nascent stage\
    \ and lags the broad uptake of these technologies in other fields. To the best\
    \ of our knowledge, there is currently no comprehensive survey of Big Data techniques\
    \ in the context of the construction industry. This paper fills the void and presents\
    \ a wide-ranging interdisciplinary review of literature of fields such as statistics,\
    \ data mining and warehousing, machine learning, and Big Data Analytics in the\
    \ context of the construction industry. We discuss the current state of adoption\
    \ of Big Data in the construction industry and discuss the future potential of\
    \ such technologies across the multiple domain-specific sub-areas of the construction\
    \ industry. We also propose open issues and directions for future work along with\
    \ potential pitfalls associated with Big Data adoption in the industry."
  Author: Muhammad Bilal and Lukumon O. Oyedele and Junaid Qadir and Kamran Munir
    and Saheed O. Ajayi and Olugbenga O. Akinade and Hakeem A. Owolabi and Hafiz A.
    Alaka and Maruf Pasha
  Book_Title_Journal: Advanced Engineering Informatics
  DOI: https://doi.org/10.1016/j.aei.2016.07.001
  JCS_FACTOR: 5.603
  Keywords: Big Data Engineering, Big Data Analytics, Construction industry, Machine
    learning
  SCI_FACTOR: 1.107
  Title: 'Big Data in the construction industry: A review of present status, opportunities,
    and future trends'
  Title_JCS: ADVANCED ENGINEERING INFORMATICS
  Title_SCI: Advanced Engineering Informatics
  Type_Publication: article
  Year: 2016
- Abstract: As society continues its rapid change to a digitized individual, corporate,
    and government environment it is prudent for researchers to investigate the zeitgeist
    of the global citizenry. The technological changes brought about by big data analytics
    are changing the way we gather and view data. This big data analytics sentiment
    research examines how Chinese and American respondents may view big data collection
    and analytics differently. The paper follows with an analysis of reported attitudes
    toward possible viewpoints from each country on various big data analytics topics
    ranging from individual to business and governmental foci. Hofstede's cultural
    dimensions are used to inform and frame our research hypotheses. Findings suggest
    that Chinese and American perspectives differ on individual data values, with
    the Chinese being more open to data collection and analytic techniques targeted
    toward individuals. Furthermore, support is found that US respondents have a more
    favorable view of businesses' use of data analytics. Finally, there is a strong
    difference in the attitudes toward governmental use of data, where US respondents
    do not favor governmental big data analytics usage and the Chinese respondents
    indicated a greater acceptance of governmental data usage. These findings are
    helpful in better understanding appropriate technological change and adoption
    from a societal perspective. Specifically, this research provides insights for
    corporate business and government entities suggesting how they might adjust their
    approach to big data collection and management in order to better support and
    sustain their organization's services and products.
  Author: Ryan C. LaBrie and Gerhard H. Steinke and Xiangmin Li and Joseph A. Cazier
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2017.06.029
  JCS_FACTOR: 8.593
  Keywords: Big data ethics, Business data usage, Corporate data collection, Government
    data usage, Technology ethics, US-China similarities, US-China differences
  SCI_FACTOR: 2.226
  Title: 'Big data analytics sentiment: US-China reaction to data collection by business
    and government'
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2018
- Abstract: Although big data analytics have tremendous benefits for healthcare organizations,
    extant research has paid insufficient attention to the exploration of its business
    value. In order to bridge this knowledge gap, this study proposes a big data analytics-enabled
    business value model in which we use the resource-based theory (RBT) and capability
    building view to explain how big data analytics capabilities can be developed
    and what potential benefits can be obtained by these capabilities in the health
    care industries. Using this model, we investigate 109 case descriptions, covering
    63 healthcare organizations to explore the causal relationships between the big
    data analytics capabilities and business value and the path-to-value chains for
    big data analytics success. Our findings provide new insights to healthcare practitioners
    on how to constitute big data analytics capabilities for business transformation
    and offer an empirical basis that can stimulate a more detailed investigation
    of big data analytics implementation.
  Author: Yichuan Wang and Nick Hajli
  Book_Title_Journal: Journal of Business Research
  DOI: https://doi.org/10.1016/j.jbusres.2016.08.002
  JCS_FACTOR: 7.55
  Keywords: Big data analytics, Business value, Capability building view, Resource-based
    theory, Information technology source management, Health care industries
  SCI_FACTOR: 2.049
  Title: Exploring the path to big data analytics success in healthcare
  Title_JCS: JOURNAL OF BUSINESS RESEARCH
  Title_SCI: Journal of Business Research
  Type_Publication: article
  Year: 2017
- Abstract: "Big Data analytics in national security, law enforcement and the fight\
    \ against fraud have the potential to reap great benefits for states, citizens\
    \ and society but require extra safeguards to protect citizens' fundamental rights.\
    \ This involves a crucial shift in emphasis from regulating Big Data collection\
    \ to regulating the phases of analysis and use. In order to benefit from the use\
    \ of Big Data analytics in the field of security, a framework has to be developed\
    \ that adds new layers of protection for fundamental rights and safeguards against\
    \ erroneous and malicious use. Additional regulation is needed at the levels of\
    \ analysis and use, and the oversight regime is in need of strengthening. At the\
    \ level of analysis \xE2\u20AC\u201C the algorithmic heart of Big Data processes\
    \ \xE2\u20AC\u201C a duty of care should be introduced that is part of an internal\
    \ audit and external review procedure. Big Data projects should also be subject\
    \ to a sunset clause. At the level of use, profiles and (semi-) automated decision-making\
    \ should be regulated more tightly. Moreover, the responsibility of the data processing\
    \ party for accuracy of analysis \xE2\u20AC\u201C and decisions taken on its basis\
    \ \xE2\u20AC\u201C should be anchored in legislation. The general and security-specific\
    \ oversight functions should be strengthened in terms of technological expertise,\
    \ access and resources. The possibilities for judicial review should be expanded\
    \ to stimulate the development of case law."
  Author: Dennis Broeders and Erik Schrijvers and Bart {van der Sloot} and Rosamunde
    {van Brakel} and Josta {de Hoog} and Ernst {Hirsch Ballin}
  Book_Title_Journal: Computer Law & Security Review
  DOI: https://doi.org/10.1016/j.clsr.2017.03.002
  JCS_FACTOR: 2.98
  Keywords: Big Data, Security, Data protection, Privacy, Regulation, Fraud, Policing,
    Surveillance, Algorithmic accountability, the Netherlands
  SCI_FACTOR: 0.0
  Title: 'Big Data and security policies: Towards a framework for regulating the phases
    of analytics and use of Big Data'
  Title_JCS: Computer Law & Security Review
  Title_SCI: N/A
  Type_Publication: article
  Year: 2017
- Abstract: Big data represents a new technology paradigm for data that are generated
    at high velocity and high volume, and with high variety. Big data is envisioned
    as a game changer capable of revolutionizing the way businesses operate in many
    industries. This article introduces an integrated view of big data, traces the
    evolution of big data over the past 20 years, and discusses data analytics essential
    for processing various structured and unstructured data. This article illustrates
    the application of data analytics using merchant review data. The impacts of big
    data on key business performances are then evaluated. Finally, six technical and
    managerial challenges are discussed.
  Author: In Lee
  Book_Title_Journal: Business Horizons
  DOI: https://doi.org/10.1016/j.bushor.2017.01.004
  JCS_FACTOR: 6.361
  Keywords: Big data, Internet of things, Data analytics, Sentiment analysis, Social
    network analysis, Web analytics
  SCI_FACTOR: 2.174
  Title: 'Big data: Dimensions, evolution, impacts, and challenges'
  Title_JCS: BUSINESS HORIZONS
  Title_SCI: Business Horizons
  Type_Publication: article
  Year: 2017
- Abstract: "Consumer analytics is at the epicenter of a Big Data revolution. Technology\
    \ helps capture rich and plentiful data on consumer phenomena in real time. Thus,\
    \ unprecedented volume, velocity, and variety of primary data, Big Data, are available\
    \ from individual consumers. To better understand the impact of Big Data on various\
    \ marketing activities, enabling firms to better exploit its benefits, a conceptual\
    \ framework that builds on resource-based theory is proposed. Three resources\xE2\
    \u20AC\u201Dphysical, human, and organizational capital\xE2\u20AC\u201Dmoderate\
    \ the following: (1) the process of collecting and storing evidence of consumer\
    \ activity as Big Data, (2) the process of extracting consumer insight from Big\
    \ Data, and (3) the process of utilizing consumer insight to enhance dynamic/adaptive\
    \ capabilities. Furthermore, unique resource requirements for firms to benefit\
    \ from Big Data are discussed."
  Author: Sunil Erevelles and Nobuyuki Fukawa and Linda Swayne
  Book_Title_Journal: Journal of Business Research
  DOI: https://doi.org/10.1016/j.jbusres.2015.07.001
  JCS_FACTOR: 7.55
  Keywords: Big Data, Consumer analytics, Consumer insights, Resource-based theory,
    Induction, Ignorance
  SCI_FACTOR: 2.049
  Title: Big Data consumer analytics and the transformation of marketing
  Title_JCS: JOURNAL OF BUSINESS RESEARCH
  Title_SCI: Journal of Business Research
  Type_Publication: article
  Year: 2016
- Abstract: A big data analytics-enabled transformation model based on practice-based
    view is developed, which reveals the causal relationships among big data analytics
    capabilities, IT-enabled transformation practices, benefit dimensions, and business
    values. This model was then tested in healthcare setting. By analyzing big data
    implementation cases, we sought to understand how big data analytics capabilities
    transform organizational practices, thereby generating potential benefits. In
    addition to conceptually defining four big data analytics capabilities, the model
    offers a strategic view of big data analytics. Three significant path-to-value
    chains were identified for healthcare organizations by applying the model, which
    provides practical insights for managers.
  Author: Yichuan Wang and LeeAnn Kung and William Yu Chung Wang and Casey G. Cegielski
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2017.04.001
  JCS_FACTOR: 7.555
  Keywords: Big data analytics, IT-enabled transformation, Practice-based view, Business
    value of IT, Healthcare, Content analysis
  SCI_FACTOR: 0.0
  Title: 'An integrated big data analytics-enabled transformation model: Application
    to health care'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2018
- Abstract: A big data analytics-enabled transformation model based on practice-based
    view is developed, which reveals the causal relationships among big data analytics
    capabilities, IT-enabled transformation practices, benefit dimensions, and business
    values. This model was then tested in healthcare setting. By analyzing big data
    implementation cases, we sought to understand how big data analytics capabilities
    transform organizational practices, thereby generating potential benefits. In
    addition to conceptually defining four big data analytics capabilities, the model
    offers a strategic view of big data analytics. Three significant path-to-value
    chains were identified for healthcare organizations by applying the model, which
    provides practical insights for managers.
  Author: Yichuan Wang and LeeAnn Kung and William Yu Chung Wang and Casey G. Cegielski
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2017.04.001
  JCS_FACTOR: 7.555
  Keywords: Big data analytics, IT-enabled transformation, Practice-based view, Business
    value of IT, Healthcare, Content analysis
  SCI_FACTOR: 0.0
  Title: 'An integrated big data analytics-enabled transformation model: Application
    to health care'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2018
- Abstract: "Context: Big Data systems are a class of software systems that ingest,\
    \ store, process and serve massive amounts of heterogeneous data, from multiple\
    \ sources. Despite their undisputed impact in current society, their engineering\
    \ is still in its infancy and companies find it difficult to adopt them due to\
    \ their inherent complexity. Existing attempts to provide architectural guidelines\
    \ for their engineering fail to take into account important Big Data characteristics,\
    \ such as the management, evolution and quality of the data. Objective: In this\
    \ paper, we follow software engineering principles to refine the \xCE\xBB-architecture,\
    \ a reference model for Big Data systems, and use it as seed to create Bolster,\
    \ a software reference architecture (SRA) for semantic-aware Big Data systems.\
    \ Method: By including a new layer into the \xCE\xBB-architecture, the Semantic\
    \ Layer, Bolster\xC2\_is capable of handling the most representative Big Data\
    \ characteristics (i.e., Volume, Velocity, Variety, Variability and Veracity).\
    \ Results: We present the successful implementation of Bolster\xC2\_in three industrial\
    \ projects, involving five organizations. The validation results show high level\
    \ of agreement among practitioners from all organizations with respect to standard\
    \ quality factors. Conclusion: As an SRA, Bolster\xC2\_allows organizations to\
    \ design concrete architectures tailored to their specific needs. A distinguishing\
    \ feature is that it provides semantic-awareness in Big Data Systems. These are\
    \ Big Data system implementations that have components to simplify data definition\
    \ and exploitation. In particular, they leverage metadata (i.e., data describing\
    \ data) to enable (partial) automation of data exploitation and to aid the user\
    \ in their decision making processes. This simplification supports the differentiation\
    \ of responsibilities into cohesive roles enhancing data governance."
  Author: "Sergi Nadal and Victor Herrero and Oscar Romero and Alberto Abell\xC3\xB3\
    \ and Xavier Franch and Stijn Vansummeren and Danilo Valerio"
  Book_Title_Journal: Information and Software Technology
  DOI: https://doi.org/10.1016/j.infsof.2017.06.001
  JCS_FACTOR: 2.73
  Keywords: Big Data, Software reference architecture, Semantic-aware, Data management,
    Data analysis
  SCI_FACTOR: 0.606
  Title: A software reference architecture for semantic-aware Big Data systems
  Title_JCS: INFORMATION AND SOFTWARE TECHNOLOGY
  Title_SCI: Information and Software Technology
  Type_Publication: article
  Year: 2017
- Abstract: The explosive growth in the number of devices connected to the Internet
    of Things (IoT) and the exponential increase in data consumption only reflect
    how the growth of big data perfectly overlaps with that of IoT. The management
    of big data in a continuously expanding network gives rise to non-trivial concerns
    regarding data collection efficiency, data processing, analytics, and security.
    To address these concerns, researchers have examined the challenges associated
    with the successful deployment of IoT. Despite the large number of studies on
    big data, analytics, and IoT, the convergence of these areas creates several opportunities
    for flourishing big data and analytics for IoT systems. In this paper, we explore
    the recent advances in big data analytics for IoT systems as well as the key requirements
    for managing big data and for enabling analytics in an IoT environment. We taxonomized
    the literature based on important parameters. We identify the opportunities resulting
    from the convergence of big data, analytics, and IoT as well as discuss the role
    of big data analytics in IoT applications. Finally, several open challenges are
    presented as future research directions.
  Author: Ejaz Ahmed and Ibrar Yaqoob and Ibrahim Abaker Targio Hashem and Imran Khan
    and Abdelmuttlib Ibrahim Abdalla Ahmed and Muhammad Imran and Athanasios V. Vasilakos
  Book_Title_Journal: Computer Networks
  DOI: https://doi.org/10.1016/j.comnet.2017.06.013
  JCS_FACTOR: 4.474
  Keywords: Internet of Things, Big data, Analytics, Distributed computing, Smart
    city
  SCI_FACTOR: 0.798
  Title: The role of big data analytics in Internet of Things
  Title_JCS: Computer Networks
  Title_SCI: Computer Networks
  Type_Publication: article
  Year: 2017
- Abstract: Recently, there has been a shifting focus of organizations and governments
    towards digitization of academic and technical documents, adding a new facet to
    the concept of digital libraries. The volume, variety and velocity of this generated
    data, satisfies the big data definition, as a result of which, this scholarly
    reserve is popularly referred to as big scholarly data. In order to facilitate
    data analytics for big scholarly data, architectures and services for the same
    need to be developed. The evolving nature of research problems has made them essentially
    interdisciplinary. As a result, there is a growing demand for scholarly applications
    like collaborator discovery, expert finding and research recommendation systems,
    in addition to several others. This research paper investigates the current trends
    and identifies the existing challenges in development of a big scholarly data
    platform, with specific focus on directions for future research and maps them
    to the different phases of the big data lifecycle.
  Author: Samiya Khan and Xiufeng Liu and Kashish A. Shakil and Mansaf Alam
  Book_Title_Journal: Information Processing & Management
  DOI: https://doi.org/10.1016/j.ipm.2017.03.006
  JCS_FACTOR: 6.222
  Keywords: Scholarly data, Big data, Cloud-based big data analytics, Big scholarly
    data, Big data platform, Scholarly applications
  SCI_FACTOR: 0.0
  Title: 'A survey on scholarly data: From big data perspective'
  Title_JCS: INFORMATION PROCESSING & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2017
- Abstract: Recently, there has been a shifting focus of organizations and governments
    towards digitization of academic and technical documents, adding a new facet to
    the concept of digital libraries. The volume, variety and velocity of this generated
    data, satisfies the big data definition, as a result of which, this scholarly
    reserve is popularly referred to as big scholarly data. In order to facilitate
    data analytics for big scholarly data, architectures and services for the same
    need to be developed. The evolving nature of research problems has made them essentially
    interdisciplinary. As a result, there is a growing demand for scholarly applications
    like collaborator discovery, expert finding and research recommendation systems,
    in addition to several others. This research paper investigates the current trends
    and identifies the existing challenges in development of a big scholarly data
    platform, with specific focus on directions for future research and maps them
    to the different phases of the big data lifecycle.
  Author: Samiya Khan and Xiufeng Liu and Kashish A. Shakil and Mansaf Alam
  Book_Title_Journal: Information Processing & Management
  DOI: https://doi.org/10.1016/j.ipm.2017.03.006
  JCS_FACTOR: 6.222
  Keywords: Scholarly data, Big data, Cloud-based big data analytics, Big scholarly
    data, Big data platform, Scholarly applications
  SCI_FACTOR: 0.0
  Title: 'A survey on scholarly data: From big data perspective'
  Title_JCS: INFORMATION PROCESSING & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2017
- Abstract: Big data has now become a strong focus of global interest that is increasingly
    attracting the attention of academia, industry, government and other organizations.
    Big data can be situated in the disciplinary area of traditional geospatial data
    handling theory and methods. The increasing volume and varying format of collected
    geospatial big data presents challenges in storing, managing, processing, analyzing,
    visualizing and verifying the quality of data. This has implications for the quality
    of decisions made with big data. Consequently, this position paper of the International
    Society for Photogrammetry and Remote Sensing (ISPRS) Technical Commission II
    (TC II) revisits the existing geospatial data handling methods and theories to
    determine if they are still capable of handling emerging geospatial big data.
    Further, the paper synthesises problems, major issues and challenges with current
    developments as well as recommending what needs to be developed further in the
    near future.
  Author: "Songnian Li and Suzana Dragicevic and Francesc Ant\xC3\xB3n Castro and\
    \ Monika Sester and Stephan Winter and Arzu Coltekin and Christopher Pettit and\
    \ Bin Jiang and James Haworth and Alfred Stein and Tao Cheng"
  Book_Title_Journal: ISPRS Journal of Photogrammetry and Remote Sensing
  DOI: https://doi.org/10.1016/j.isprsjprs.2015.10.012
  JCS_FACTOR: 8.979
  Keywords: Big data, Geospatial, Data handling, Analytics, Spatial modeling, Review
  SCI_FACTOR: 2.96
  Title: 'Geospatial big data handling theory and methods: A review and research challenges'
  Title_JCS: ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
  Title_SCI: ISPRS Journal of Photogrammetry and Remote Sensing
  Type_Publication: article
  Year: 2016
- Abstract: Real-time monitoring of cloud resources is crucial for a variety of tasks
    such as performance analysis, workload management, capacity planning and fault
    detection. Applications producing big data make the monitoring task very difficult
    at high sampling frequencies because of high computational and communication overheads
    in collecting, storing, and managing information. We present an adaptive algorithm
    for monitoring big data applications that adapts the intervals of sampling and
    frequency of updates to data characteristics and administrator needs. Adaptivity
    allows us to limit computational and communication costs and to guarantee high
    reliability in capturing relevant load changes. Experimental evaluations performed
    on a large testbed show the ability of the proposed adaptive algorithm to reduce
    resource utilization and communication overhead of big data monitoring without
    penalizing the quality of data, and demonstrate our improvements to the state
    of the art.
  Author: Mauro Andreolini and Michele Colajanni and Marcello Pietri and Stefania
    Tosi
  Book_Title_Journal: Journal of Parallel and Distributed Computing
  DOI: https://doi.org/10.1016/j.jpdc.2014.08.007
  JCS_FACTOR: 3.734
  Keywords: Adaptivity, Monitoring, Cloud computing, Big data, Scalability
  SCI_FACTOR: 0.638
  Title: Adaptive, scalable and reliable monitoring of big data on clouds
  Title_JCS: JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING
  Title_SCI: Journal of Parallel and Distributed Computing
  Type_Publication: article
  Year: 2015
- Abstract: Research on the adoption of systems for big data analytics has drawn enormous
    attention in Information Systems research. This study extends big data analytics
    adoption research by examining the effects of system characteristics on the attitude
    of managers towards the usage of big data analytics systems. A research model
    has been proposed in this study based on an extensive review of literature pertaining
    to the Technology Acceptance Model, with further validation by a survey of 150
    big data analytics users. Results of this survey confirm that characteristics
    of the big data analytics system have significant direct and indirect effects
    on belief in the benefits of big data analytics systems and perceived usefulness,
    attitude and adoption. Moreover, there are mediation effects that exist among
    the system characteristics, benefits of big data analytics systems, perceived
    usefulness and the attitude towards using big data analytics system. This study
    expands the existing body of knowledge on the adoption of big data analytics systems,
    and benefits big data analytics providers and vendors while helping in the formulation
    of their business models.
  Author: Surabhi Verma and Som Sekhar Bhattacharyya and Saurav Kumar
  Book_Title_Journal: Information Processing & Management
  DOI: https://doi.org/10.1016/j.ipm.2018.01.004
  JCS_FACTOR: 6.222
  Keywords: Technology acceptance model, Big data analytics system, System quality,
    Information quality
  SCI_FACTOR: 0.0
  Title: An extension of the technology acceptance model in the big data analytics
    system implementation environment
  Title_JCS: INFORMATION PROCESSING & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2018
- Abstract: Research on the adoption of systems for big data analytics has drawn enormous
    attention in Information Systems research. This study extends big data analytics
    adoption research by examining the effects of system characteristics on the attitude
    of managers towards the usage of big data analytics systems. A research model
    has been proposed in this study based on an extensive review of literature pertaining
    to the Technology Acceptance Model, with further validation by a survey of 150
    big data analytics users. Results of this survey confirm that characteristics
    of the big data analytics system have significant direct and indirect effects
    on belief in the benefits of big data analytics systems and perceived usefulness,
    attitude and adoption. Moreover, there are mediation effects that exist among
    the system characteristics, benefits of big data analytics systems, perceived
    usefulness and the attitude towards using big data analytics system. This study
    expands the existing body of knowledge on the adoption of big data analytics systems,
    and benefits big data analytics providers and vendors while helping in the formulation
    of their business models.
  Author: Surabhi Verma and Som Sekhar Bhattacharyya and Saurav Kumar
  Book_Title_Journal: Information Processing & Management
  DOI: https://doi.org/10.1016/j.ipm.2018.01.004
  JCS_FACTOR: 6.222
  Keywords: Technology acceptance model, Big data analytics system, System quality,
    Information quality
  SCI_FACTOR: 0.0
  Title: An extension of the technology acceptance model in the big data analytics
    system implementation environment
  Title_JCS: INFORMATION PROCESSING & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2018
- Abstract: 'It is clear that big data has numerous potential impacts in many fields.
    However, few papers discussed its applications in the field of safety science
    research. Additionally, there exist many problems that cannot be ignored when
    big data is applied to safety science, most outstanding of which is lack of universal
    supporting theory that guides how to apply big data to safety science research
    like methods, principles and approaches, etc. In other terms, it is not enough
    for big data to be viewed asa strong enabler for safety science applications mainly
    due to lack of universal and basic theory from the perspective of safety science.
    Considering the above analyzes, the two key objectives of this paper are: (1)
    to propose the connotation of safety big data (SBD) and its applying rules, methods
    and principles, and (2) to put forward some application prospects and challenges
    of big data to safety science research seen from theoretical research. First,
    by comparing SBD and traditional safety small data (SSD) from four aspects including
    theoretical research, typical research method, specific analysis method and processing
    mode, this paper puts forward the definition and connotation of SBD. Subsequently
    this paper further summarizes and extracts the application rules and methods of
    SBD. And then nine principles of SBD are explored and their relationship and application
    are addressed from the view of theory architecture and working framework in data
    processing flow. At last, this paper also discusses the potential applications
    and some hot issues of SBD. Overall, this paper will play an essential role in
    supporting the application of SBD. In addition, it will fill in the theory gaps
    in the field of SBD beyond traditional safety statistics, and further enriches
    the contents of safety science.'
  Author: Qiumei Ouyang and Chao Wu and Lang Huang
  Book_Title_Journal: Safety Science
  DOI: https://doi.org/10.1016/j.ssci.2017.08.012
  JCS_FACTOR: 4.877
  Keywords: Safety big data (SBD), Safety small data (SSD), Safety science, Big data
    application, Method, Principle, Prospect and challenge
  SCI_FACTOR: 1.178
  Title: Methodologies, principles and prospects of applying big data in safety science
    research
  Title_JCS: SAFETY SCIENCE
  Title_SCI: Safety Science
  Type_Publication: article
  Year: 2018
- Abstract: A theoretical framework for big data analytics-enabled customer agility
    and responsiveness was developed from extant IS research. In on-demand service
    environments, customer agility involves dynamic capabilities in sensing and responding
    to citizens. Using this framework, a case study examined a large city government's
    311 on-demand services which had leveraged big data analytics. While we found
    the localized big data analytics use by some of the 22 departments for enhanced
    customer agility and on-demand 311 services, city-wide systemic change in on-demand
    service delivery through big data analytics use was not evident. From the case
    study we identified key institutional mechanisms for linking customer agility
    to public value creation through 311 services. We posit how systemic use of big
    data analytics embedded into critical processes enables the government to co-create
    public values with citizens through 311 on-demand services, indicating the importance
    of creating a culture of analytics driven by strong political leadership.
  Author: Akemi Takeoka Chatfield and Christopher G. Reddick
  Book_Title_Journal: Government Information Quarterly
  DOI: https://doi.org/10.1016/j.giq.2017.11.002
  JCS_FACTOR: 7.279
  Keywords: On-demand services, Customer agility, Systemic use, Big data, Big data
    analytics, IT assimilation, Process-level strategic alignment, Digital infrastructures,
    311 services, Government
  SCI_FACTOR: 2.121
  Title: 'Customer agility and responsiveness through big data analytics for public
    value creation: A case study of Houston 311 on-demand services'
  Title_JCS: GOVERNMENT INFORMATION QUARTERLY
  Title_SCI: Government Information Quarterly
  Type_Publication: article
  Year: 2018
- Abstract: "Safety data and information are the most valuable assets for organizations\xE2\
    \u20AC\u2122 safety decision-making (SDM), especially in the era of big data (BD).\
    \ In this study, a conceptual framework for SDM based on BD, known as BD-driven\
    \ SDM, was developed and its detailed structure and elements as well as strategies\
    \ were presented. Other theoretical and practical contributions include: (a) the\
    \ description of the meta-process and interdisciplinary research area of BD-driven\
    \ SDM, (b) the design of six types of general analytics and five types of special\
    \ analytics for SBD mining according to different requirements of safety management\
    \ applications, (c) the analysis of influencing factors of BD-driven SDM, and\
    \ (d) the discussion of advantages and limitations in this research as well as\
    \ suggestions for future research. The results obtained from this study are of\
    \ important implications for research and practice on BD-driven SDM."
  Author: Lang Huang and Chao Wu and Bing Wang and Qiumei Ouyang
  Book_Title_Journal: Safety Science
  DOI: https://doi.org/10.1016/j.ssci.2018.05.012
  JCS_FACTOR: 4.877
  Keywords: Big data (BD), Safety big data (SBD), Safety decision-making (SDM), Safety
    insight (SI), Data-driven
  SCI_FACTOR: 1.178
  Title: 'Big-data-driven safety decision-making: A conceptual framework and its influencing
    factors'
  Title_JCS: SAFETY SCIENCE
  Title_SCI: Safety Science
  Type_Publication: article
  Year: 2018
- Abstract: 'Background

    Big data and cutting-edge analytic methods in nursing research challenge nurse
    scientists to extend the data sources and analytic methods used for discovering
    and translating knowledge.

    Purpose

    The purpose of this study was to identify, analyze, and synthesize exemplars of
    big data nursing research applied to practice and disseminated in key nursing
    informatics, general biomedical informatics, and nursing research journals.

    Methods

    A literature review of studies published between 2009 and 2015. There were 650
    journal articles identified in 17 key nursing informatics, general biomedical
    informatics, and nursing research journals in the Web of Science database. After
    screening for inclusion and exclusion criteria, 17 studies published in 18 articles
    were identified as big data nursing research applied to practice.

    Discussion

    Nurses clearly are beginning to conduct big data research applied to practice.
    These studies represent multiple data sources and settings. Although numerous
    analytic methods were used, the fundamental issue remains to define the types
    of analyses consistent with big data analytic methods.

    Conclusion

    There are needs to increase the visibility of big data and data science research
    conducted by nurse scientists, further examine the use of state of the science
    in data analytics, and continue to expand the availability and use of a variety
    of scientific, governmental, and industry data resources. A major implication
    of this literature review is whether nursing faculty and preparation of future
    scientists (PhD programs) are prepared for big data and data science.'
  Author: Bonnie L. Westra and Martha Sylvia and Elizabeth F. Weinfurter and Lisiane
    Pruinelli and Jung In Park and Dianna Dodd and Gail M. Keenan and Patricia Senk
    and Rachel L. Richesson and Vicki Baukner and Christopher Cruz and Grace Gao and
    Luann Whittenburg and Connie W. Delaney
  Book_Title_Journal: Nursing Outlook
  DOI: https://doi.org/10.1016/j.outlook.2016.11.021
  JCS_FACTOR: 3.25
  Keywords: Big data, Data science, Nursing informatics, Nursing research, Nurse scientist
  SCI_FACTOR: 0.953
  Title: 'Big data science: A literature review of nursing research exemplars'
  Title_JCS: NURSING OUTLOOK
  Title_SCI: Nursing Outlook
  Type_Publication: article
  Year: 2017
- Abstract: 'Background

    Big data and cutting-edge analytic methods in nursing research challenge nurse
    scientists to extend the data sources and analytic methods used for discovering
    and translating knowledge.

    Purpose

    The purpose of this study was to identify, analyze, and synthesize exemplars of
    big data nursing research applied to practice and disseminated in key nursing
    informatics, general biomedical informatics, and nursing research journals.

    Methods

    A literature review of studies published between 2009 and 2015. There were 650
    journal articles identified in 17 key nursing informatics, general biomedical
    informatics, and nursing research journals in the Web of Science database. After
    screening for inclusion and exclusion criteria, 17 studies published in 18 articles
    were identified as big data nursing research applied to practice.

    Discussion

    Nurses clearly are beginning to conduct big data research applied to practice.
    These studies represent multiple data sources and settings. Although numerous
    analytic methods were used, the fundamental issue remains to define the types
    of analyses consistent with big data analytic methods.

    Conclusion

    There are needs to increase the visibility of big data and data science research
    conducted by nurse scientists, further examine the use of state of the science
    in data analytics, and continue to expand the availability and use of a variety
    of scientific, governmental, and industry data resources. A major implication
    of this literature review is whether nursing faculty and preparation of future
    scientists (PhD programs) are prepared for big data and data science.'
  Author: Bonnie L. Westra and Martha Sylvia and Elizabeth F. Weinfurter and Lisiane
    Pruinelli and Jung In Park and Dianna Dodd and Gail M. Keenan and Patricia Senk
    and Rachel L. Richesson and Vicki Baukner and Christopher Cruz and Grace Gao and
    Luann Whittenburg and Connie W. Delaney
  Book_Title_Journal: Nursing Outlook
  DOI: https://doi.org/10.1016/j.outlook.2016.11.021
  JCS_FACTOR: 3.25
  Keywords: Big data, Data science, Nursing informatics, Nursing research, Nurse scientist
  SCI_FACTOR: 0.953
  Title: 'Big data science: A literature review of nursing research exemplars'
  Title_JCS: NURSING OUTLOOK
  Title_SCI: Nursing Outlook
  Type_Publication: article
  Year: 2017
- Abstract: In recent years, big data has emerged as one of the prominent buzzwords
    in business and management. In spite of the mounting body of research on big data
    across the social science disciplines, scholars have offered little synthesis
    on the current state of knowledge. To take stock of academic research that contributes
    to the big data revolution, this paper tracks scholarly work's perspectives on
    big data in the management domain over the past decade. We identify key themes
    emerging in management studies and develop an integrated framework to link the
    multiple streams of research in fields of organisation, operations, marketing,
    information management and other relevant areas. Our analysis uncovers a growing
    awareness of big data's business values and managerial changes led by data-driven
    approach. Stemming from the review is the suggestion for research that both structured
    and unstructured big data should be harnessed to advance understanding of big
    data value in informing organisational decisions and enhancing firm competitiveness.
    To discover the full value, firms need to formulate and implement a data-driven
    strategy. In light of these, the study identifies and outlines the implications
    and directions for future research.
  Author: Jie Sheng and Joseph Amankwah-Amoah and Xiaojun Wang
  Book_Title_Journal: International Journal of Production Economics
  DOI: https://doi.org/10.1016/j.ijpe.2017.06.006
  JCS_FACTOR: 7.885
  Keywords: Big data, Management research, Literature review
  SCI_FACTOR: 2.406
  Title: A multidisciplinary perspective of big data in management research
  Title_JCS: INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS
  Title_SCI: International Journal of Production Economics
  Type_Publication: article
  Year: 2017
- Abstract: 'Big Data has emerged as a significant area of study for both practitioners
    and researchers. Big Data is a term for massive data sets with large structure.
    In 2012, Big Data passed the top of the Gartner Hype Cycle, attesting the maturity
    level of this technology and its applications. The aim of this paper is to examine
    how do researchers grasp the big data concept? We will answer the following questions:
    How many research papers are produced? What is the annual trend of publications?
    What are the hot topics in big data research? What are the most investigated big
    data topics? Why the research is performed? What are the most frequently obtained
    research artefacts? What does big data research produces? Who are the active authors?
    Which journals include papers on Big Data? What are the active disciplines? For
    this purpose, we provide a framework identifying existing and emerging research
    areas of Big Data. This framework is based on eight dimensions, including the
    SMACIT (Social Mobile Analytics Cloud Internet of Things) perspective. Current
    and past research in Big Data are analyzed using a systematic mapping study of
    publications based on more than a decade of related academic publications. The
    results have shown that significant contributions have been made by the research
    community, attested by a continuous increase in the number of scientific publications
    that address Big Data. We found that researchers are increasingly involved in
    research combining Big Data and Analytics, Cloud, Internet of things, mobility
    or social media. As for quality objectives, besides an interest in performance,
    other topics as scalability is emerging. Moreover, security and quality aspects
    become important. Researchers on Big Data provide more algorithms, frameworks,
    and architectures than other artifacts. Finally, application domains such as earth,
    energy, medicine, ecology, marketing, and health attract more attention from researchers
    on big data. A complementary content analysis on a subset of papers sheds some
    light on the evolving field of big data research.'
  Author: Jacky Akoka and Isabelle Comyn-Wattiau and Nabil Laoufi
  Book_Title_Journal: Computer Standards & Interfaces
  DOI: https://doi.org/10.1016/j.csi.2017.01.004
  JCS_FACTOR: 2.487
  Keywords: Big Data, Systematic mapping study, Framework, Artefact, Usage, Analytics
  SCI_FACTOR: 0.0
  Title: "Research on Big Data \xE2\u20AC\u201C A systematic mapping study"
  Title_JCS: COMPUTER STANDARDS & INTERFACES
  Title_SCI: N/A
  Type_Publication: article
  Year: 2017
- Abstract: The construction of medical big data includes several problems that need
    to be solved, such as integration and data sharing of many heterogeneous information
    systems, efficient processing and analysis of large-scale medical data with complex
    structure or low degree of structure, and narrow application range of medical
    data. Therefore, medical big data construction is not only a simple collection
    and application of medical data but also a complex systematic project. This paper
    introduces China's experience in the construction of a regional medical big data
    ecosystem, including the overall goal of the project; establishment of policies
    to encourage data sharing; handling the relationship between personal privacy,
    information security, and information availability; establishing a cooperation
    mechanism between agencies; designing a polycentric medical data acquisition system;
    and establishing a large data centre. From the experience gained from one of China's
    earliest established medical big data projects, we outline the challenges encountered
    during its development and recommend approaches to overcome these challenges to
    design medical big data projects in China more rationally. Clear and complete
    top-level design of a project requires to be planned in advance and considered
    carefully. It is essential to provide a culture of information sharing and to
    facilitate the opening of data, and changes in ideas and policies need the guidance
    of the government. The contradiction between data sharing and data security must
    be handled carefully, that is not to say data openness could be abandoned. The
    construction of medical big data involves many institutions, and high-level management
    and cooperation can significantly improve efficiency and promote innovation. Compared
    with infrastructure construction, it is more challenging and time-consuming to
    develop appropriate data standards, data integration tools and data mining tools.
  Author: Bei Li and Jianbin Li and Yuqiao Jiang and Xiaoyun Lan
  Book_Title_Journal: Journal of Biomedical Informatics
  DOI: https://doi.org/10.1016/j.jbi.2019.103149
  JCS_FACTOR: 6.317
  Keywords: Medical big data, Data sharing, Information security, Cooperation mechanism,
    Medical data acquisition, Medical data centre
  SCI_FACTOR: 1.057
  Title: "Experience and reflection from China\xE2\u20AC\u2122s Xiangya medical big\
    \ data project"
  Title_JCS: JOURNAL OF BIOMEDICAL INFORMATICS
  Title_SCI: Journal of Biomedical Informatics
  Type_Publication: article
  Year: 2019
- Abstract: Energy efficiency of inland ships is significantly influenced by navigational
    environment, including wind speed and direction as well as water depth and speed.
    The complexity of the inland navigational environment makes it rather difficult
    to determine the optimal speeds under different environmental conditions to achieve
    the best energy efficiency. Route division according to the characteristics of
    these environmental factors could provide a good solution for the optimization
    of ship engine speed under different navigational environments. In this paper,
    the distributed parallel k-means clustering algorithm is adopted to achieve an
    elaborate route division by analyzing the corresponding environmental factors
    based on a self-developed big data analytics platform. Subsequently, a ship energy
    efficiency optimization model considering multiple environmental factors is established
    through analyzing the energy transfer among hull, propeller and main engine. Then,
    decisions are made concerning the optimal engine speeds in different segments
    along the path. Finally, a case study on the Yangtze River is performed to validate
    the present optimization method. The results show that the proposed method can
    effectively reduce energy consumption and CO2 emissions of ships.
  Author: Xinping Yan and Kai Wang and Yupeng Yuan and Xiaoli Jiang and Rudy R. Negenborn
  Book_Title_Journal: Ocean Engineering
  DOI: https://doi.org/10.1016/j.oceaneng.2018.08.050
  JCS_FACTOR: 3.795
  Keywords: Ship energy efficiency, Speed optimization, Big data analysis, Parallel
    k-means algorithm, Hadoop
  SCI_FACTOR: 1.321
  Title: 'Energy-efficient shipping: An application of big data analysis for optimizing
    engine speed of inland ships considering multiple environmental factors'
  Title_JCS: OCEAN ENGINEERING
  Title_SCI: Ocean Engineering
  Type_Publication: article
  Year: 2018
- Abstract: In recent years, the rapid development of Internet, Internet of Things,
    and Cloud Computing have led to the explosive growth of data in almost every industry
    and business area. Big data has rapidly developed into a hot topic that attracts
    extensive attention from academia, industry, and governments around the world.
    In this position paper, we first briefly introduce the concept of big data, including
    its definition, features, and value. We then identify from different perspectives
    the significance and opportunities that big data brings to us. Next, we present
    representative big data initiatives all over the world. We describe the grand
    challenges (namely, data complexity, computational complexity, and system complexity),
    as well as possible solutions to address these challenges. Finally, we conclude
    the paper by presenting several suggestions on carrying out big data projects.
  Author: Xiaolong Jin and Benjamin W. Wah and Xueqi Cheng and Yuanzhuo Wang
  Book_Title_Journal: Big Data Research
  DOI: https://doi.org/10.1016/j.bdr.2015.01.006
  JCS_FACTOR: 3.578
  Keywords: Big data, Data complexity, Computational complexity, System complexity
  SCI_FACTOR: 0.565
  Title: Significance and Challenges of Big Data Research
  Title_JCS: Big Data Research
  Title_SCI: Big Data Research
  Type_Publication: article
  Year: 2015
- Abstract: Today, big data processing has become a challenging task due to the amount
    of data collected using various sensors increasingly significantly. To build knowledge
    and predict the data, traditional data mining methods calculate all numerical
    attributes into the memory simultaneously. The data stream method is a solution
    for processing and calculating data. The method streams incrementally in batch
    form; therefore, infrastructure memory is sufficient to develop knowledge. The
    existing method for data stream prediction is FIMT-DD (Fast Incremental Model
    Tree-Drift Detection). Using this method, knowledge is developed in tree form
    for every instance. In this paper, enhanced FIMT-DD is proposed using ARDEV (Average
    Restrain Divider of Evaluation Value). ARDEV utilizes the Chernoff bound approach
    with error evaluation, improvement in learning rate, modification of perceptron
    rule calculation, and utilization of activation function. Standard FIMT-DD separates
    the tree formation process and perceptron prediction. The proposed method evaluates
    and connects the development of the tree for knowledge formation and the perceptron
    rule for prediction. The prediction accuracy of the proposed method is measured
    using MAE, RMSE and MAPE. From the experiment performed, the utilization of ARDEV
    enhancement shows significant improvement in terms of accuracy prediction. Statistically,
    the overall accuracy prediction improvement is approximately 6.99 % compared to
    standard FIMT-DD with a traffic dataset.
  Author: Ari Wibisono and Devvi Sarwinda
  Book_Title_Journal: Knowledge-Based Systems
  DOI: https://doi.org/10.1016/j.knosys.2019.03.019
  JCS_FACTOR: 8.038
  Keywords: ARDEV, Big data prediction, FIMT-DD, Tree regression
  SCI_FACTOR: 1.587
  Title: Average Restrain Divider of Evaluation Value (ARDEV) in data stream algorithm
    for big data prediction
  Title_JCS: KNOWLEDGE-BASED SYSTEMS
  Title_SCI: Knowledge-Based Systems
  Type_Publication: article
  Year: 2019
- Abstract: "Electric power systems are taking drastic advances in deployment of information\
    \ and communication technologies; numerous new measurement devices are installed\
    \ in forms of advanced metering infrastructure, distributed energy resources (DER)\
    \ monitoring systems, high frequency synchronized wide-area awareness systems\
    \ that with great speed are generating immense volume of energy data. However,\
    \ it is still questioned that whether the today\xE2\u20AC\u2122s power system\
    \ data, the structures and the tools being developed are indeed aligned with the\
    \ pillars of the big data science. Further, several requirements and especial\
    \ features of power systems and energy big data call for customized methods and\
    \ platforms. This paper provides an assessment of the distinguished aspects in\
    \ big data analytics developments in the domain of power systems. We perform several\
    \ taxonomy of the existing and the missing elements in the structures and methods\
    \ associated with big data analytics in power systems. We also provide a holistic\
    \ outline, classifications, and concise discussions on the technical approaches,\
    \ research opportunities, and application areas for energy big data analytics."
  Author: Hossein Akhavan-Hejazi and Hamed Mohsenian-Rad
  Book_Title_Journal: Energy Reports
  DOI: https://doi.org/10.1016/j.egyr.2017.11.002
  JCS_FACTOR: 6.87
  Keywords: Energy, Big data analytics, Internet of energy, Smart grid
  SCI_FACTOR: 1.199
  Title: 'Power systems big data analytics: An assessment of paradigm shift barriers
    and prospects'
  Title_JCS: Energy Reports
  Title_SCI: Energy Reports
  Type_Publication: article
  Year: 2018
- Abstract: Big data has the potential to revolutionize the art of management. Despite
    the high operational and strategic impacts, there is a paucity of empirical research
    to assess the business value of big data. Drawing on a systematic review and case
    study findings, this paper presents an interpretive framework that analyzes the
    definitional perspectives and the applications of big data. The paper also provides
    a general taxonomy that helps broaden the understanding of big data and its role
    in capturing business value. The synthesis of the diverse concepts within the
    literature on big data provides deeper insights into achieving value through big
    data strategy and implementation.
  Author: Samuel {Fosso Wamba} and Shahriar Akter and Andrew Edwards and Geoffrey
    Chopin and Denis Gnanzou
  Book_Title_Journal: International Journal of Production Economics
  DOI: https://doi.org/10.1016/j.ijpe.2014.12.031
  JCS_FACTOR: 7.885
  Keywords: "\xE2\u20AC\u02DCBig data\xE2\u20AC\u2122, Analytics, Business value,\
    \ Issues, Case study, Emergency services, Literature review"
  SCI_FACTOR: 2.406
  Title: "How \xE2\u20AC\u02DCbig data\xE2\u20AC\u2122 can make big impact: Findings\
    \ from a systematic review and a longitudinal case study"
  Title_JCS: INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS
  Title_SCI: International Journal of Production Economics
  Type_Publication: article
  Year: 2015
- Abstract: Driven by the innovative improvement of information and communication
    technologies (ICTs) and their applications into manufacturing industry, the big
    data era in manufacturing is correspondingly arising, and the developing data
    mining techniques (DMTs) pave the way for pursuing the aims of smart production
    with the real-time, dynamic, self-adaptive and precise control. However, lots
    of factors in the ever-changing environment of manufacturing industry, such as,
    various of complex production processes, larger scale and uncertainties, more
    complicated constrains, coupling of operational performance, and so on, make production
    management face with more and more big challenges. The dynamic inflow of a large
    number of raw data which is collected from the physical manufacturing sites or
    generated in various related information systems, caused the heavy information
    overload problems. Indeed, most of traditional DMTs are not yet sufficient to
    process such big data for smart production management. Therefore, this paper reviews
    the development of DMTs in the big data era, and makes discussion on the applications
    of DMTs in production management, by selecting and analyzing the relevant papers
    since 2010. In the meantime, we point out limitations and put forward some suggestions
    about the smartness and further applications of DMTs used in production management.
  Author: Ying Cheng and Ken Chen and Hemeng Sun and Yongping Zhang and Fei Tao
  Book_Title_Journal: Journal of Industrial Information Integration
  DOI: https://doi.org/10.1016/j.jii.2017.08.001
  JCS_FACTOR: 10.063
  Keywords: Big data, Data mining techniques (DMTs), Production management, Smart
    manufacturing, Statistical analysis, Knowledge discovery
  SCI_FACTOR: 2.042
  Title: Data and knowledge mining with big data towards smart production
  Title_JCS: Journal of Industrial Information Integration
  Title_SCI: Journal of Industrial Information Integration
  Type_Publication: article
  Year: 2018
- Abstract: "Data management tools and analytics have provided managers with the opportunity\
    \ to contemplate inventory performance as an ongoing activity by no longer examining\
    \ only data agglomerated from ERP systems, but also, considering internet information\
    \ derived from customers\xE2\u20AC\u2122 online buying behaviour. The realisation\
    \ of this complex relationship has increased interest in business intelligence\
    \ through data and text mining of structured, semi-structured and unstructured\
    \ data, commonly referred to as \xE2\u20AC\u0153big data\xE2\u20AC\x9D to uncover\
    \ underlying patterns which might explain customer behaviour and improve the response\
    \ to demand volatility. This paper explores how sales structured data can be used\
    \ in conjunction with non-structured customer data to improve inventory management\
    \ either in terms of forecasting or treating some inventory as \xE2\u20AC\u0153\
    top-selling\xE2\u20AC\x9D based on specific customer tendency to acquire more\
    \ information through the internet. A medical condition is considered - namely\
    \ pain - by examining 129 weeks of sales data regarding analgesics and information\
    \ seeking data by customers through Google, online newspapers and YouTube. In\
    \ order to facilitate our study we consider a VARX model with non-structured data\
    \ as exogenous to obtain the best estimation and we perform tests against several\
    \ univariate models in terms of best fit performance and forecasting."
  Author: Christos I. Papanagnou and Omeiza Matthews-Amune
  Book_Title_Journal: Computers & Operations Research
  DOI: https://doi.org/10.1016/j.cor.2017.08.009
  JCS_FACTOR: 4.008
  Keywords: Retail pharmacy, Data mining, Time series, Forecasting, Big data, Demand
    uncertainty
  SCI_FACTOR: 0.0
  Title: Coping with demand volatility in retail pharmacies with the aid of big data
    exploration
  Title_JCS: COMPUTERS & OPERATIONS RESEARCH
  Title_SCI: N/A
  Type_Publication: article
  Year: 2018
- Abstract: "It is already true that Big Data has drawn huge attention from researchers\
    \ in information sciences, policy and decision makers in governments and enterprises.\
    \ As the speed of information growth exceeds Moore\xE2\u20AC\u2122s Law at the\
    \ beginning of this new century, excessive data is making great troubles to human\
    \ beings. However, there are so much potential and highly useful values hidden\
    \ in the huge volume of data. A new scientific paradigm is born as data-intensive\
    \ scientific discovery (DISD), also known as Big Data problems. A large number\
    \ of fields and sectors, ranging from economic and business activities to public\
    \ administration, from national security to scientific researches in many areas,\
    \ involve with Big Data problems. On the one hand, Big Data is extremely valuable\
    \ to produce productivity in businesses and evolutionary breakthroughs in scientific\
    \ disciplines, which give us a lot of opportunities to make great progresses in\
    \ many fields. There is no doubt that the future competitions in business productivity\
    \ and technologies will surely converge into the Big Data explorations. On the\
    \ other hand, Big Data also arises with many challenges, such as difficulties\
    \ in data capture, data storage, data analysis and data visualization. This paper\
    \ is aimed to demonstrate a close-up view about Big Data, including Big Data applications,\
    \ Big Data opportunities and challenges, as well as the state-of-the-art techniques\
    \ and technologies we currently adopt to deal with the Big Data problems. We also\
    \ discuss several underlying methodologies to handle the data deluge, for example,\
    \ granular computing, cloud computing, bio-inspired computing, and quantum computing."
  Author: C.L. {Philip Chen} and Chun-Yang Zhang
  Book_Title_Journal: Information Sciences
  DOI: https://doi.org/10.1016/j.ins.2014.01.015
  JCS_FACTOR: 6.795
  Keywords: Big Data, Data-intensive computing, e-Science, Parallel and distributed
    computing, Cloud computing
  SCI_FACTOR: 1.524
  Title: 'Data-intensive applications, challenges, techniques and technologies: A
    survey on Big Data'
  Title_JCS: INFORMATION SCIENCES
  Title_SCI: Information Sciences
  Type_Publication: article
  Year: 2014
- Abstract: "Numerous approaches are available for improving governance of the child\
    \ welfare system, all of which require longitudinal data reporting on child welfare\
    \ clients. A substantial amount of agency administrative information \xE2\u20AC\
    \u201C big data \xE2\u20AC\u201C can be transformed into knowledge for policy\
    \ and management actions through a rigorous information generation process. Important\
    \ properties of the information generation process are that it must generate accurate,\
    \ timely information while protecting the confidentiality of the clients. In addition,\
    \ it must be extensible to serve an ever-changing policy and technology environment.\
    \ Knowledge discovery and data mining (KDD), aka data science, is a method developed\
    \ in the private sector to mine consumer data and can be used in public settings\
    \ to support evidence based governance. KDD consists of a rigorous 5-step process\
    \ that includes a Web-based end-user interface. The relationship between KDD and\
    \ governance is a continuous feedback cycle that enables ongoing development of\
    \ new information and knowledge as stakeholders identify emerging needs. In this\
    \ paper, we synthesis the different frameworks for utilizing big data for public\
    \ governance, introduce the KDD process, describe the nature of big data in child\
    \ welfare, and then present an updated KDD architecture that can support these\
    \ frameworks to utilize big data for governance. We also demonstrate the role\
    \ KDD plays in child welfare management through 2 case studies. We conclude with\
    \ a discussion on implications for agency\xE2\u20AC\u201Cuniversity partnerships\
    \ and research-to-practice."
  Author: Hye-Chung Kum and C. {Joy Stewart} and Roderick A. Rose and Dean F. Duncan
  Book_Title_Journal: Children and Youth Services Review
  DOI: https://doi.org/10.1016/j.childyouth.2015.09.014
  JCS_FACTOR: 2.393
  Keywords: Big data, Evidence based governance, Knowledge discovery and data mining
    (KDD), Data science, Population informatics, Policy informatics, Academic government
    partnership, Administrative data
  SCI_FACTOR: 0.816
  Title: Using big data for evidence based governance in child welfare
  Title_JCS: CHILDREN AND YOUTH SERVICES REVIEW
  Title_SCI: Children and Youth Services Review
  Type_Publication: article
  Year: 2015
- Abstract: "The upstream oil and gas industry has been contending with massive data\
    \ sets and monolithic files for many years, but \xE2\u20AC\u0153Big Data\xE2\u20AC\
    \x9D is a relatively new concept that has the potential to significantly re-shape\
    \ the industry. Despite the impressive amount of value that is being realized\
    \ by Big Data technologies in other parts of the marketplace, however, much of\
    \ the data collected within the oil and gas sector tends to be discarded, ignored,\
    \ or analyzed in a very cursory way. This viewpoint examines existing data management\
    \ practices in the upstream oil and gas industry, and compares them to practices\
    \ and philosophies that have emerged in organizations that are leading the way\
    \ in Big Data. The comparison shows that, in companies that are widely considered\
    \ to be leaders in Big Data analytics, data is regarded as a valuable asset\xE2\
    \u20AC\u201Dbut this is usually not true within the oil and gas industry insofar\
    \ as data is frequently regarded there as descriptive information about a physical\
    \ asset rather than something that is valuable in and of itself. The paper then\
    \ discusses how the industry could potentially extract more value from data, and\
    \ concludes with a series of policy-related questions to this end."
  Author: Robert K. Perrons and Jesse W. Jensen
  Book_Title_Journal: Energy Policy
  DOI: https://doi.org/10.1016/j.enpol.2015.02.020
  JCS_FACTOR: 6.142
  Keywords: Big data, Oil and gas, Information technologies, Data
  SCI_FACTOR: 2.093
  Title: "Data as an asset: What the oil and gas sector can learn from other industries\
    \ about \xE2\u20AC\u0153Big Data\xE2\u20AC\x9D"
  Title_JCS: ENERGY POLICY
  Title_SCI: Energy Policy
  Type_Publication: article
  Year: 2015
- Abstract: "The upstream oil and gas industry has been contending with massive data\
    \ sets and monolithic files for many years, but \xE2\u20AC\u0153Big Data\xE2\u20AC\
    \x9D is a relatively new concept that has the potential to significantly re-shape\
    \ the industry. Despite the impressive amount of value that is being realized\
    \ by Big Data technologies in other parts of the marketplace, however, much of\
    \ the data collected within the oil and gas sector tends to be discarded, ignored,\
    \ or analyzed in a very cursory way. This viewpoint examines existing data management\
    \ practices in the upstream oil and gas industry, and compares them to practices\
    \ and philosophies that have emerged in organizations that are leading the way\
    \ in Big Data. The comparison shows that, in companies that are widely considered\
    \ to be leaders in Big Data analytics, data is regarded as a valuable asset\xE2\
    \u20AC\u201Dbut this is usually not true within the oil and gas industry insofar\
    \ as data is frequently regarded there as descriptive information about a physical\
    \ asset rather than something that is valuable in and of itself. The paper then\
    \ discusses how the industry could potentially extract more value from data, and\
    \ concludes with a series of policy-related questions to this end."
  Author: Robert K. Perrons and Jesse W. Jensen
  Book_Title_Journal: Energy Policy
  DOI: https://doi.org/10.1016/j.enpol.2015.02.020
  JCS_FACTOR: 6.142
  Keywords: Big data, Oil and gas, Information technologies, Data
  SCI_FACTOR: 2.093
  Title: "Data as an asset: What the oil and gas sector can learn from other industries\
    \ about \xE2\u20AC\u0153Big Data\xE2\u20AC\x9D"
  Title_JCS: ENERGY POLICY
  Title_SCI: Energy Policy
  Type_Publication: article
  Year: 2015
- Abstract: 'From the viewpoint of big data as a socio-technical phenomenon, this
    study examines the associated assumptions and biases critically and contextually.
    The research analyzes the big data phenomenon from a socio-technical systems theory
    perspective: cultural, technological, and scholarly phenomena that rest on the
    interplay of technology, analysis, and mythology provoking extensive utopian and
    dystopian rhetoric. It examines the development of big data by reviewing this
    theory, identifying key components of the big data ecosystem, and explaining how
    these components are likely to evolve over time. Despite extensive investment
    and proactive drive, uncertainty exists concerning the evolution of big data and
    the impact on the new information milieu. Significant concerns recently addressed
    are in the areas of privacy, data quality, access, curation, preservation, and
    use. This study provides insight into these challenges and opportunities through
    the lens of a socio-technical analysis of big data development, which includes
    social dynamics, political discourse, and technological choices inherent in the
    design and development of next-generation ICT ecology. The policy implications
    of big data are addressed using Korean information initiatives to highlight key
    considerations as the country progresses in this new ecology era.'
  Author: Dong-Hee Shin and Min Jae Choi
  Book_Title_Journal: Telematics and Informatics
  DOI: https://doi.org/10.1016/j.tele.2014.09.006
  JCS_FACTOR: 6.182
  Keywords: Big data, Data ecosystem, Ecology, South Korea, Socio-technical perspective,
    Big data policy, Big data for development
  SCI_FACTOR: 1.567
  Title: 'Ecological views of big data: Perspectives and issues'
  Title_JCS: TELEMATICS AND INFORMATICS
  Title_SCI: Telematics and Informatics
  Type_Publication: article
  Year: 2015
- Abstract: "While there is a general recognition that breakthrough innovation is\
    \ non-linear and requires an alignment between producers (supply) and users (demand),\
    \ there is still a need for strategic intelligence about the emerging supply chains\
    \ of new technological innovations. This technology delivery system (TDS) is an\
    \ updated form of the TDS model and provides a promising chain-link approach to\
    \ the supply side of innovation. Building on early research into supply-side TDS\
    \ studies, we present a systematic approach to building a TDS model that includes\
    \ four phases: (1) identifying the macroeconomic and policy environment, including\
    \ market competition, financial investment, and industrial policy; (2) specifying\
    \ the key public and private institutions; (3) addressing the core technical complements\
    \ and their owners, then tracing their interactions through information linkages\
    \ and technology transfers; and (4) depicting the market prospects and evaluating\
    \ the potential profound influences on technological change and social developments.\
    \ Our TDS methodology is illustrated using the field of Big Data & Analytics (\xE2\
    \u20AC\u0153BDA\xE2\u20AC\x9D)."
  Author: Ying Huang and Alan L. Porter and Scott W. Cunningham and Douglas K.R. Robinson
    and Jianhua Liu and Donghua Zhu
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2017.09.012
  JCS_FACTOR: 8.593
  Keywords: Technology delivery system, Tech mining, Emerging technology, Big Data,
    Technology assessment, Impact assessment
  SCI_FACTOR: 2.226
  Title: 'A technology delivery system for characterizing the supply side of technology
    emergence: Illustrated for Big Data & Analytics'
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2018
- Abstract: Value creation is a major sustainability factor for enterprises, in addition
    to profit maximization and revenue generation. Modern enterprises collect big
    data from various inbound and outbound data sources. The inbound data sources
    handle data generated from the results of business operations, such as manufacturing,
    supply chain management, marketing, and human resource management, among others.
    Outbound data sources handle customer-generated data which are acquired directly
    or indirectly from customers, market analysis, surveys, product reviews, and transactional
    histories. However, cloud service utilization costs increase because of big data
    analytics and value creation activities for enterprises and customers. This article
    presents a novel concept of big data reduction at the customer end in which early
    data reduction operations are performed to achieve multiple objectives, such as
    (a) lowering the service utilization cost, (b) enhancing the trust between customers
    and enterprises, (c) preserving privacy of customers, (d) enabling secure data
    sharing, and (e) delegating data sharing control to customers. We also propose
    a framework for early data reduction at customer end and present a business model
    for end-to-end data reduction in enterprise applications. The article further
    presents a business model canvas and maps the future application areas with its
    nine components. Finally, the article discusses the technology adoption challenges
    for value creation through big data reduction in enterprise applications.
  Author: Muhammad Habib ur Rehman and Victor Chang and Aisha Batool and Teh Ying
    Wah
  Book_Title_Journal: International Journal of Information Management
  DOI: https://doi.org/10.1016/j.ijinfomgt.2016.05.013
  JCS_FACTOR: 14.098
  Keywords: Sustainable enterprises, Value creation, Big data analytics, Data reduction,
    Business model
  SCI_FACTOR: 2.77
  Title: Big data reduction framework for value creation in sustainable enterprises
  Title_JCS: INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
  Title_SCI: International Journal of Information Management
  Type_Publication: article
  Year: 2016
- Abstract: With the significant increase in the volume, variety, velocity and veracity
    of data generated, collected and transmitted through computing and networking
    systems, it is of little surprise that big data analysis and processing is the
    subject of focus from enterprise, academia and government. Outsourcing is one
    popular solution considered in big data processing, although security and privacy
    are two key concerns often attributed to the underutilization of outsourcing and
    other promising big data analysis and processing technologies. In this paper,
    we survey the state-of-the-art literature on cryptographic solutions designed
    to ensure the security and/or privacy in big data outsourcing. For example, we
    provide concrete examples to explain how these cryptographic solutions can be
    deployed. We summarize the existing state-of-play before discussing research opportunities.
  Author: Zhe Liu and Kim-Kwang Raymond Choo and Minghao Zhao
  Book_Title_Journal: Computers & Security
  DOI: https://doi.org/10.1016/j.cose.2016.12.006
  JCS_FACTOR: 4.438
  Keywords: Big data analysis, Privacy-preserving, Outsourced big data, Oblivious
    RAM, Security, Practical-oriented, Secure query
  SCI_FACTOR: 0.0
  Title: 'Practical-oriented protocols for privacy-preserving outsourced big data
    analysis: Challenges and future research directions'
  Title_JCS: COMPUTERS & SECURITY
  Title_SCI: N/A
  Type_Publication: article
  Year: 2017
- Abstract: Online user-generated content is playing a progressively important role
    as information source for social scientists seeking for digging out value. Advances
    procedures and technologies to enable the capture, storage, management, and analysis
    of the data make possible to exploit increasing amounts of data generated directly
    by users. In that regard, Big Data is gaining meaning into social science from
    quantitative datasets side, which differs from traditional social science where
    collecting data has always been hard, time consuming, and resource intensive.
    Hence, the emergent field of computational social science is broadening researchers'
    perspectives. However, it also requires a multidisciplinary approach involving
    several and different knowledge areas. This paper outlines an architectural framework
    and methodology to collect Big Data from an electronic Word-of-Mouth (eWOM) website
    containing user-generated content. Although the paper is written from the social
    science perspective, it must be also considered together with other complementary
    disciplines such as data accessing and computing.
  Author: "M. Olmedilla and M.R. Mart\xC3\xADnez-Torres and S.L. Toral"
  Book_Title_Journal: Computer Standards & Interfaces
  DOI: https://doi.org/10.1016/j.csi.2016.02.003
  JCS_FACTOR: 2.487
  Keywords: Big Data, User-generated content, e-Social science, Computing, Data gathering
  SCI_FACTOR: 0.0
  Title: 'Harvesting Big Data in social science: A methodological approach for collecting
    online user-generated content'
  Title_JCS: COMPUTER STANDARDS & INTERFACES
  Title_SCI: N/A
  Type_Publication: article
  Year: 2016
- Abstract: "Servitization has become a pervasive business strategy among manufacturers,\
    \ enabling them to undergird their competitive advantage. However, it has at least\
    \ one weakness. While it is used worldwide also in economies with lower production\
    \ costs, services in manufacturing are slowly becoming commoditized and will become\
    \ a necessary, though not sufficient, condition for reaching an above average\
    \ competitive advantage. Consequently, in this article we propose a new basis\
    \ for competitive advantage for manufacturing enterprises called a Big Data Strategy\
    \ in servitization. We scrutinize how manufacturers can exploit the opportunity\
    \ arising from combined Big Data and servitization. Therefore, the concept of\
    \ a Big Data Strategy framework in servitization is proposed. The findings are\
    \ benchmarked against established frameworks in the Big Data and servitization\
    \ literature. Its impact on competitive advantage is assessed through three theoretical\
    \ perspectives that increase the validity of the results. The main finding is\
    \ that, through the proposed strategy, new revenue streams can be created, while\
    \ opening the possibility to decrease prices for product\xE2\u20AC\u201Cservices.\
    \ Through the proposed strategy manufacturers can differentiate themselves from\
    \ the ones that are already servitizing. This article introduces the possibility\
    \ of influencing the most important of the five \xE2\u20AC\u0153Vs\xE2\u20AC\x9D\
    \ in Big Data\xE2\u20AC\u201CValue, in addition to the other four \xE2\u20AC\u0153\
    Vs\xE2\u20AC\x9D\xE2\u20AC\u201DVolume, Variety, Velocity and Verification. As\
    \ in regards to servitization, the article adds a third layer of added value\xE2\
    \u20AC\u201D \xE2\u20AC\u0153information\xE2\u20AC\x9D, beside the two existing\
    \ ones: product and service. The results have strategic implications for managers."
  Author: David Opresnik and Marco Taisch
  Book_Title_Journal: International Journal of Production Economics
  DOI: https://doi.org/10.1016/j.ijpe.2014.12.036
  JCS_FACTOR: 7.885
  Keywords: Servitization, Big Data, Manufacturing, Competitive advantage, Value,
    Information
  SCI_FACTOR: 2.406
  Title: The value of Big Data in servitization
  Title_JCS: INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS
  Title_SCI: International Journal of Production Economics
  Type_Publication: article
  Year: 2015
- Abstract: This survey presents the concept of Big Data. Firstly, a definition and
    the features of Big Data are given. Secondly, the different steps for Big Data
    data processing and the main problems encountered in big data management are described.
    Next, a general overview of an architecture for handling it is depicted. Then,
    the problem of merging Big Data architecture in an already existing information
    system is discussed. Finally this survey tackles semantics (reasoning, coreference
    resolution, entity linking, information extraction, consolidation, paraphrase
    resolution, ontology alignment) in the Big Data context.
  Author: Cheikh {Kacfah Emani} and Nadine Cullot and Christophe Nicolle
  Book_Title_Journal: Computer Science Review
  DOI: https://doi.org/10.1016/j.cosrev.2015.05.002
  JCS_FACTOR: 7.872
  Keywords: Big data, Hadoop, Reasoning, Coreference resolution, Entity linking, Information
    extraction, Ontology alignment
  SCI_FACTOR: 1.646
  Title: 'Understandable Big Data: A survey'
  Title_JCS: Computer Science Review
  Title_SCI: Computer Science Review
  Type_Publication: article
  Year: 2015
- Abstract: "Big data has become an important issue for a large number of research\
    \ areas such as data mining, machine learning, computational intelligence, information\
    \ fusion, the semantic Web, and social networks. The rise of different big data\
    \ frameworks such as Apache Hadoop and, more recently, Spark, for massive data\
    \ processing based on the MapReduce paradigm has allowed for the efficient utilisation\
    \ of data mining methods and machine learning algorithms in different domains.\
    \ A number of libraries such as Mahout and SparkMLib have been designed to develop\
    \ new efficient applications based on machine learning algorithms. The combination\
    \ of big data technologies and traditional machine learning algorithms has generated\
    \ new and interesting challenges in other areas as social media and social networks.\
    \ These new challenges are focused mainly on problems such as data processing,\
    \ data storage, data representation, and how data can be used for pattern mining,\
    \ analysing user behaviours, and visualizing and tracking data, among others.\
    \ In this paper, we present a revision of the new methodologies that is designed\
    \ to allow for efficient data mining and information fusion from social media\
    \ and of the new applications and frameworks that are currently appearing under\
    \ the \xE2\u20AC\u0153umbrella\xE2\u20AC\x9D of the social networks, social media\
    \ and big data paradigms."
  Author: Gema Bello-Orgaz and Jason J. Jung and David Camacho
  Book_Title_Journal: Information Fusion
  DOI: https://doi.org/10.1016/j.inffus.2015.08.005
  JCS_FACTOR: 12.975
  Keywords: Big data, Data mining, Social media, Social networks, Social-based frameworks
    and applications
  SCI_FACTOR: 2.776
  Title: 'Social big data: Recent achievements and new challenges'
  Title_JCS: Information Fusion
  Title_SCI: Information Fusion
  Type_Publication: article
  Year: 2016
- Abstract: "Today, firms can access to big data (tweets, videos, click streams, and\
    \ other unstructured sources) to extract new ideas or understanding about their\
    \ products, customers, and markets. Thus, managers increasingly view data as an\
    \ important driver of innovation and a significant source of value creation and\
    \ competitive advantage. To get the most out of the big data (in combination with\
    \ a firm\xD7\xB3s existing data), a more sophisticated way of handling, managing,\
    \ analysing and interpreting data is necessary. However, there is a lack of data\
    \ analytics techniques to assist firms to capture the potential of innovation\
    \ afforded by data and to gain competitive advantage. This research aims to address\
    \ this gap by developing and testing an analytic infrastructure based on the deduction\
    \ graph technique. The proposed approach provides an analytic infrastructure for\
    \ firms to incorporate their own competence sets with other firms. Case studies\
    \ results indicate that the proposed data analytic approach enable firms to utilise\
    \ big data to gain competitive advantage by enhancing their supply chain innovation\
    \ capabilities."
  Author: Kim Hua Tan and YuanZhu Zhan and Guojun Ji and Fei Ye and Chingter Chang
  Book_Title_Journal: International Journal of Production Economics
  DOI: https://doi.org/10.1016/j.ijpe.2014.12.034
  JCS_FACTOR: 7.885
  Keywords: Big data, Analytic infrastructure, Competence set, Deduction graph, Supply
    chain innovation
  SCI_FACTOR: 2.406
  Title: 'Harvesting big data to enhance supply chain innovation capabilities: An
    analytic infrastructure based on deduction graph'
  Title_JCS: INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS
  Title_SCI: International Journal of Production Economics
  Type_Publication: article
  Year: 2015
- Abstract: Deep learning methods are extensively applied to various fields of science
    and engineering such as speech recognition, image classifications, and learning
    methods in language processing. Similarly, traditional data processing techniques
    have several limitations of processing large amount of data. In addition, Big
    Data analytics requires new and sophisticated algorithms based on machine and
    deep learning techniques to process data in real-time with high accuracy and efficiency.
    However, recently, research incorporated various deep learning techniques with
    hybrid learning and training mechanisms of processing data with high speed. Most
    of these techniques are specific to scenarios and based on vector space thus,
    shows poor performance in generic scenarios and learning features in big data.
    In addition, one of the reason of such failure is high involvement of humans to
    design sophisticated and optimized algorithms based on machine and deep learning
    techniques. In this article, we bring forward an approach of comparing various
    deep learning techniques for processing huge amount of data with different number
    of neurons and hidden layers. The comparative study shows that deep learning techniques
    can be built by introducing a number of methods in combination with supervised
    and unsupervised training techniques.
  Author: Bilal Jan and Haleem Farman and Murad Khan and Muhammad Imran and Ihtesham
    Ul Islam and Awais Ahmad and Shaukat Ali and Gwanggil Jeon
  Book_Title_Journal: Computers & Electrical Engineering
  DOI: https://doi.org/10.1016/j.compeleceng.2017.12.009
  JCS_FACTOR: 3.818
  Keywords: Big data, Deep learning, Deep belief networks, Convolutional Neural Networks
  SCI_FACTOR: 0.0
  Title: 'Deep learning in big data Analytics: A comparative study'
  Title_JCS: COMPUTERS & ELECTRICAL ENGINEERING
  Title_SCI: N/A
  Type_Publication: article
  Year: 2019
- Abstract: In January 2017 the Consultative Committee of Convention 108 adopted its
    Guidelines on the Protection of Individuals with Regard to the Processing of Personal
    Data in a World of Big Data. These are the first guidelines on data protection
    provided by an international body which specifically address the issues surrounding
    big data applications. This article examines the main provisions of these Guidelines
    and highlights the approach adopted by the Consultative Committee, which contextualises
    the traditional principles of data protection in the big data scenario and also
    takes into account the challenges of the big data paradigm. The analysis of the
    different provisions adopted focuses primarily on the core of the Guidelines namely
    the risk assessment procedure. Moreover, the article discusses the novel solutions
    provided by the Guidelines with regard to the data subject's informed consent,
    the by-design approach, anonymization, and the role of the human factor in big
    data-supported decisions. This critical analysis of the Guidelines introduces
    a broader reflection on the divergent approaches of the Council of Europe and
    the European Union to regulating data processing. Where the principle-based model
    of the Council of Europe differs from the approach adopted by the EU legislator
    in the detailed Regulation (EU) 2016/679. In the light of this, the provisions
    of the Guidelines and their attempt to address the major challenges of the new
    big data paradigm set the stage for concluding remarks about the most suitable
    regulatory model to deal with the different issues posed by the development of
    technology.
  Author: Alessandro Mantelero
  Book_Title_Journal: Computer Law & Security Review
  DOI: https://doi.org/10.1016/j.clsr.2017.05.011
  JCS_FACTOR: 2.98
  Keywords: Big data, Data protection, Council of Europe, Risk assessment, Data protection
    by design, Consent, Data anonymization, Open data, Algorithms
  SCI_FACTOR: 0.0
  Title: Regulating big data. The guidelines of the Council of Europe in the context
    of the European data protection framework
  Title_JCS: Computer Law & Security Review
  Title_SCI: N/A
  Type_Publication: article
  Year: 2017
- Abstract: "The recent interest in big data has led many companies to develop big\
    \ data analytics capability (BDAC) in order to enhance firm performance (FPER).\
    \ However, BDAC pays off for some companies but not for others. It appears that\
    \ very few have achieved a big impact through big data. To address this challenge,\
    \ this study proposes a BDAC model drawing on the resource-based theory (RBT)\
    \ and the entanglement view of sociomaterialism. The findings show BDAC as a hierarchical\
    \ model, which consists of three primary dimensions (i.e., management, technology,\
    \ and talent capability) and 11 subdimensions (i.e., planning, investment, coordination,\
    \ control, connectivity, compatibility, modularity, technology management knowledge,\
    \ technical knowledge, business knowledge and relational knowledge). The findings\
    \ from two Delphi studies and 152 online surveys of business analysts in the U.S.\
    \ confirm the value of the entanglement conceptualization of the higher-order\
    \ BDAC model and its impact on FPER. The results also illuminate the significant\
    \ moderating impact of analytics capability\xE2\u20AC\u201Cbusiness strategy alignment\
    \ on the BDAC\xE2\u20AC\u201CFPER relationship."
  Author: Shahriar Akter and Samuel Fosso Wamba and Angappa Gunasekaran and Rameshwar
    Dubey and Stephen J. Childe
  Book_Title_Journal: International Journal of Production Economics
  DOI: https://doi.org/10.1016/j.ijpe.2016.08.018
  JCS_FACTOR: 7.885
  Keywords: Capabilities, Entanglement view, Big data analytics, Hierarchical modeling
  SCI_FACTOR: 2.406
  Title: How to improve firm performance using big data analytics capability and business
    strategy alignment?
  Title_JCS: INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS
  Title_SCI: International Journal of Production Economics
  Type_Publication: article
  Year: 2016
- Abstract: Smart manufacturing refers to a future-state of manufacturing and it can
    lead to remarkable changes in all aspects of operations through minimizing energy
    and material usage while simultaneously maximizing sustainability enabling a futuristic
    more digitalized scenario of manufacturing. This research develops a big data
    analytics framework that optimizes the maintenance schedule through condition-based
    maintenance (CBM) optimization and also improves the prediction accuracy to quantify
    the remaining life prediction uncertainty. Through effective utilization of condition
    monitoring and prediction information, CBM would enhance equipment reliability
    leading to reduction in maintenance cost. The proposed framework uses a CBM optimization
    method that utilizes a new linguistic interval-valued fuzzy reasoning method for
    predicting the information. The proposed big data analytics framework in our study
    for estimating the uncertainty based on backward feature elimination and fuzzy
    unordered rule induction algorithm prediction errors, is an innovative contribution
    to the remaining life prediction field. Our paper elaborates on the basic underlying
    structure of CBM system that is defined by transaction matrix and the threshold
    value of failure probability. We developed this framework for analysing the CBM
    policy cost more accurately and to find the probabilistic threshold values of
    covariate that corresponds to the lowest price of predictive maintenance cost.
    The experimental results are performed on a big dataset which is generated from
    a sophisticated simulator of a gas turbine propulsion plant. A comparative analysis
    confirms that the method used in the proposed framework outpaces the classical
    methods in terms of classification accuracy and other statistical performance
    evaluation metrics.
  Author: Ajay Kumar and Ravi Shankar and Lakshman S. Thakur
  Book_Title_Journal: Journal of Computational Science
  DOI: https://doi.org/10.1016/j.jocs.2017.06.006
  JCS_FACTOR: 3.976
  Keywords: data driven sustainable enterprise, fuzzy unordered induction algo, big
    data analytics, condition-based maintenance, machine learning techniques, backward
    feature elimination
  SCI_FACTOR: 0.704
  Title: A big data driven sustainable manufacturing framework for condition-based
    maintenance prediction
  Title_JCS: Journal of Computational Science
  Title_SCI: Journal of Computational Science
  Type_Publication: article
  Year: 2018
- Abstract: The current task scheduling mainly concerns the availability of machining
    resources, rather than the potential errors after scheduling. To minimise such
    errors in advance, this paper presents a big data analytics based fault prediction
    approach for shop floor scheduling. Within the context, machining tasks, machining
    resources, and machining processes are represented by data attributes. Based on
    the available data on the shop floor, the potential fault/error patterns, referring
    to machining errors, machine faults and maintenance states, are mined for unsuitable
    scheduling arrangements before machining as well as upcoming errors during machining.
    Comparing the data-represented tasks with the mined error patterns, their similarities
    or differences are calculated. Based on the calculated similarities, the fault
    probabilities of the scheduled tasks or the current machining tasks can be obtained,
    and they provide a reference of decision making for scheduling and rescheduling
    the tasks. By rescheduling high-risk tasks carefully, the potential errors can
    be avoided. In this paper, the architecture of the approach consisting of three
    steps in three levels is proposed. Furthermore, big data are considered in three
    levels, i.e. local data, local network data and cloud data. In order to implement
    this idea, several key techniques are illustrated in detail, e.g. data attribute,
    data cleansing, data integration of databases in different levels, and big data
    analytic algorithms. Finally, a simplified case study is described to show the
    prediction process of the proposed method.
  Author: Wei Ji and Lihui Wang
  Book_Title_Journal: Journal of Manufacturing Systems
  DOI: https://doi.org/10.1016/j.jmsy.2017.03.008
  JCS_FACTOR: 8.633
  Keywords: Big data analytics, Fault prediction, Shop floor, Scheduling
  SCI_FACTOR: 2.31
  Title: Big data analytics based fault prediction for shop floor scheduling
  Title_JCS: JOURNAL OF MANUFACTURING SYSTEMS
  Title_SCI: Journal of Manufacturing Systems
  Type_Publication: article
  Year: 2017
- Abstract: "There are many expectations and concerns about Big Data in the sector\
    \ of Earth Observation. It is necessary to understand whether Big Data is a radical\
    \ shift or an incremental change for the existing digital infrastructures. This\
    \ manuscript explores the impact of Big Data dimensionalities (commonly known\
    \ as \xE2\u20AC\u02DCV\xE2\u20AC\u2122 axes: volume, variety, velocity, veracity,\
    \ visualization) on the Global Earth Observation System of Systems (GEOSS) and\
    \ particularly its common digital infrastructure (i.e. the GEOSS Common Infrastructure).\
    \ GEOSS is a global and flexible network of content providers allowing decision\
    \ makers to access an extraordinary range of data and information. GEOSS is a\
    \ pioneering framework for global and multidisciplinary data sharing in the EO\
    \ realm. The manuscript introduces and discusses the general GEOSS strategies\
    \ to address Big Data challenges, focusing on the cloud-based discovery and access\
    \ solutions. A final section reports the results of the scalability and flexibility\
    \ performance tests."
  Author: Stefano Nativi and Paolo Mazzetti and Mattia Santoro and Fabrizio Papeschi
    and Max Craglia and Osamu Ochiai
  Book_Title_Journal: Environmental Modelling & Software
  DOI: https://doi.org/10.1016/j.envsoft.2015.01.017
  JCS_FACTOR: 5.288
  Keywords: GEOSS, Big Data, Multidisciplinary systems, Earth System Science, Research
    infrastructures, Interoperability, Cloud systems
  SCI_FACTOR: 0.0
  Title: Big Data challenges in building the Global Earth Observation System of Systems
  Title_JCS: ENVIRONMENTAL MODELLING & SOFTWARE
  Title_SCI: N/A
  Type_Publication: article
  Year: 2015
- Abstract: "The introduction of clinical information systems (CIS) in Intensive Care\
    \ Units (ICUs) offers the possibility of storing a huge amount of machine-ready\
    \ clinical data that can be used to improve patient outcomes and the allocation\
    \ of resources, as well as suggest topics for randomized clinical trials. Clinicians,\
    \ however, usually lack the necessary training for the analysis of large databases.\
    \ In addition, there are issues referred to patient privacy and consent, and data\
    \ quality. Multidisciplinary collaboration among clinicians, data engineers, machine-learning\
    \ experts, statisticians, epidemiologists and other information scientists may\
    \ overcome these problems. A multidisciplinary event (Critical Care Datathon)\
    \ was held in Madrid (Spain) from 1 to 3 December 2017. Under the auspices of\
    \ the Spanish Critical Care Society (SEMICYUC), the event was organized by the\
    \ Massachusetts Institute of Technology (MIT) Critical Data Group (Cambridge,\
    \ MA, USA), the Innovation Unit and Critical Care Department of San Carlos Clinic\
    \ Hospital, and the Life Supporting Technologies group of Madrid Polytechnic University.\
    \ After presentations referred to big data in the critical care environment, clinicians,\
    \ data scientists and other health data science enthusiasts and lawyers worked\
    \ in collaboration using an anonymized database (MIMIC III). Eight groups were\
    \ formed to answer different clinical research questions elaborated prior to the\
    \ meeting. The event produced analyses for the questions posed and outlined several\
    \ future clinical research opportunities. Foundations were laid to enable future\
    \ use of ICU databases in Spain, and a timeline was established for future meetings,\
    \ as an example of how big data analysis tools have tremendous potential in our\
    \ field.\nResumen\nLa aparici\xC3\xB3n de los sistemas de informaci\xC3\xB3n cl\xC3\
    \xADnica (SIC) en el entorno de los cuidados intensivos brinda la posibilidad\
    \ de almacenar una ingente cantidad de datos cl\xC3\xADnicos en formato electr\xC3\
    \xB3nico durante el ingreso de los pacientes. Estos datos pueden ser empleados\
    \ posteriormente para obtener respuestas a preguntas cl\xC3\xADnicas, para su\
    \ uso en la gesti\xC3\xB3n de recursos o para sugerir l\xC3\xADneas de investigaci\xC3\
    \xB3n que luego pueden ser explotadas mediante ensayos cl\xC3\xADnicos aleatorizados.\
    \ Sin embargo, los m\xC3\xA9dicos cl\xC3\xADnicos carecen de la formaci\xC3\xB3\
    n necesaria para la explotaci\xC3\xB3n de grandes bases de datos, lo que supone\
    \ un obst\xC3\xA1culo para aprovechar esta oportunidad. Adem\xC3\xA1s, existen\
    \ cuestiones de \xC3\xADndole legal (seguridad, privacidad, consentimiento de\
    \ los pacientes) que deben ser abordadas para poder utilizar esta potente herramienta.\
    \ El trabajo multidisciplinar con otros profesionales (analistas de datos, estad\xC3\
    \xADsticos, epidemi\xC3\xB3logos, especialistas en derecho aplicado a grandes\
    \ bases de datos), puede resolver estas cuestiones y permitir utilizar esta herramienta\
    \ para investigaci\xC3\xB3n cl\xC3\xADnica o an\xC3\xA1lisis de resultados (benchmarking).\
    \ Se describe la reuni\xC3\xB3n multidisciplinar (Critical Care Datathon) realizada\
    \ en Madrid los d\xC3\xADas 1, 2 y 3 de diciembre de 2017. Esta reuni\xC3\xB3\
    n, celebrada bajo los auspicios de la Sociedad Espa\xC3\xB1ola de Medicina Intensiva,\
    \ Cr\xC3\xADtica y Unidades Coronarias (SEMICYUC) entre otros, fue organizada\
    \ por el Massachusetts Institute of Technology (MIT), la Unidad de Innovaci\xC3\
    \xB3n y el Servicio de Medicina Intensiva del Hospital Cl\xC3\xADnico San Carlos,\
    \ as\xC3\xAD como el grupo de investigaci\xC3\xB3n \xC2\xABLife Supporting Technologies\xC2\
    \xBB de la Universidad Polit\xC3\xA9cnica de Madrid. Tras unas ponencias de formaci\xC3\
    \xB3n sobre big data, seguridad y calidad de los datos, y su aplicaci\xC3\xB3\
    n al entorno de la medicina intensiva, un grupo de cl\xC3\xADnicos, analistas\
    \ de datos, estad\xC3\xADsticos, expertos en seguridad inform\xC3\xA1tica de datos\
    \ realizaron sesiones de trabajo colaborativo en grupos utilizando una base de\
    \ datos reales anonimizada (MIMIC III), para analizar varias preguntas cl\xC3\xAD\
    nicas establecidas previamente a la reuni\xC3\xB3n. El trabajo colaborativo permiti\xC3\
    \xB3 establecer resultados relevantes con respecto a las preguntas planteadas\
    \ y esbozar varias l\xC3\xADneas de investigaci\xC3\xB3n cl\xC3\xADnica a desarrollar\
    \ en el futuro. Adem\xC3\xA1s, se sentaron las bases para poder utilizar las bases\
    \ de datos de las UCI con las que contamos en Espa\xC3\xB1a, y se estableci\xC3\
    \xB3 un calendario de trabajo para planificar futuras reuniones contando con los\
    \ datos de nuestras unidades. El empleo de herramientas de big data y el trabajo\
    \ colaborativo con otros profesionales puede permitir ampliar los horizontes en\
    \ aspectos como el control de calidad de nuestra labor cotidiana, la comparaci\xC3\
    \xB3n de resultados entre unidades o la elaboraci\xC3\xB3n de nuevas l\xC3\xAD\
    neas de investigaci\xC3\xB3n cl\xC3\xADnica."
  Author: "Antonio {N\xC3\xBA\xC3\xB1ez Reiz} and Fernando {Mart\xC3\xADnez Sagasti}\
    \ and Manuel {\xC3\x81lvarez Gonz\xC3\xA1lez} and Antonio {Blesa Malpica} and\
    \ Juan Carlos {Mart\xC3\xADn Ben\xC3\xADtez} and Mercedes {Nieto Cabrera} and\
    \ \xC3\x81ngela {del Pino Ram\xC3\xADrez} and Jos\xC3\xA9 Miguel {Gil Perdomo}\
    \ and Jes\xC3\xBAs {Prada Alonso} and Leo Anthony Celi and Miguel \xC3\x81ngel\
    \ {Armengol de la Hoz} and Rodrigo Deliberato and Kenneth Paik and Tom Pollard\
    \ and Jesse Raffa and Felipe Torres and Julio Mayol and Joan Chafer and Arturo\
    \ {Gonz\xC3\xA1lez Ferrer} and \xC3\x81ngel Rey and Henar {Gonz\xC3\xA1lez Luengo}\
    \ and Giuseppe Fico and Ivana Lombroni and Liss Hernandez and Laura L\xC3\xB3\
    pez and Beatriz Merino and Mar\xC3\xADa Fernanda Cabrera and Mar\xC3\xADa Teresa\
    \ Arredondo and Mar\xC3\xADa Bod\xC3\xAD and Josep G\xC3\xB3mez and Alejandro\
    \ Rodr\xC3\xADguez and Miguel {S\xC3\xA1nchez Garc\xC3\xADa}"
  Book_Title_Journal: Medicina Intensiva
  DOI: https://doi.org/10.1016/j.medin.2018.06.002
  JCS_FACTOR: 2.491
  Keywords: "Big data, Machine learning, Artificial intelligence, Clinical databases,\
    \ MIMIC III, Datathon, Collaborative work, , , Inteligencia artificial, Bases\
    \ de datos cl\xC3\xADnicos, MIMIC III, Datathon, Trabajo colaborativo"
  SCI_FACTOR: 0.336
  Title: 'Big data and machine learning in critical care: Opportunities for collaborative
    research'
  Title_JCS: Medicina Intensiva
  Title_SCI: Medicina Intensiva
  Type_Publication: article
  Year: 2019
- Abstract: 'Owing to wide applications of automatic control systems in the process
    industries, the impacts of controller performance on industrial processes are
    becoming increasingly significant. Consequently, controller maintenance is critical
    to guarantee routine operations of industrial processes. The workflow of controller
    maintenance generally involves the following steps: monitor operating controller
    performance and detect performance degradation, diagnose probable root causes
    of control system malfunctions, and take specific actions to resolve associated
    problems. In this article, a comprehensive overview of the mainstream of control
    loop monitoring and diagnosis is provided, and some existing problems are also
    analyzed and discussed. From the viewpoint of synthesizing abundant information
    in the context of big data, some prospective ideas and promising methods are outlined
    to potentially solve problems in industrial applications.'
  Author: Xinqing Gao and Fan Yang and Chao Shang and Dexian Huang
  Book_Title_Journal: Chinese Journal of Chemical Engineering
  DOI: https://doi.org/10.1016/j.cjche.2016.05.039
  JCS_FACTOR: 3.171
  Keywords: Control loop performance assessment, Industrial alarm system, Process
    knowledge, Root cause diagnosis, Big data
  SCI_FACTOR: 0.595
  Title: 'A review of control loop monitoring and diagnosis: Prospects of controller
    maintenance in big data era'
  Title_JCS: CHINESE JOURNAL OF CHEMICAL ENGINEERING
  Title_SCI: Chinese Journal of Chemical Engineering
  Type_Publication: article
  Year: 2016
- Abstract: "Oncology is undergoing a data-driven metamorphosis. Armed with new and\
    \ ever more efficient molecular and information technologies, we have entered\
    \ an era where data is helping us spearhead the fight against cancer. This technology\
    \ driven data explosion, often referred to as \xE2\u20AC\u0153big data\xE2\u20AC\
    \x9D, is not only expediting biomedical discovery, but it is also rapidly transforming\
    \ the practice of oncology into an information science. This evolution is critical,\
    \ as results to-date have revealed the immense complexity and genetic heterogeneity\
    \ of patients and their tumors, a sobering reminder of the challenge facing every\
    \ patient and their oncologist. This can only be addressed through development\
    \ of clinico-molecular data analytics that provide a deeper understanding of the\
    \ mechanisms controlling the biological and clinical response to available therapeutic\
    \ options. Beyond the exciting implications for improved patient care, such advancements\
    \ in predictive and evidence-based analytics stand to profoundly affect the processes\
    \ of cancer drug discovery and associated clinical trials."
  Author: Guillaume Taglang and David B. Jackson
  Book_Title_Journal: Gynecologic Oncology
  DOI: https://doi.org/10.1016/j.ygyno.2016.02.022
  JCS_FACTOR: 5.482
  Keywords: Big data, Drug discovery, Clinical trials, Precision medicine, Biomarkers
  SCI_FACTOR: 2.105
  Title: "Use of \xE2\u20AC\u0153big data\xE2\u20AC\x9D in drug discovery and clinical\
    \ trials"
  Title_JCS: GYNECOLOGIC ONCOLOGY
  Title_SCI: Gynecologic Oncology
  Type_Publication: article
  Year: 2016
- Abstract: The tremendous expansion of data analytics and public and private big
    datasets presents an important opportunity for pre-clinical drug discovery and
    development. In the field of life sciences, the growth of genetic, genomic, transcriptomic
    and proteomic data is partly driven by a rapid decline in experimental costs as
    biotechnology improves throughput, scalability, and speed. Yet far too many researchers
    tend to underestimate the challenges and consequences involving data integrity
    and quality standards. Given the effect of data integrity on scientific interpretation,
    these issues have significant implications during preclinical drug development.
    We describe standardized approaches for maximizing the utility of publicly available
    or privately generated biological data and address some of the common pitfalls.
    We also discuss the increasing interest to integrate and interpret cross-platform
    data. Principles outlined here should serve as a useful broad guide for existing
    analytical practices and pipelines and as a tool for developing additional insights
    into therapeutics using big data.
  Author: John F. Brothers and Matthew Ung and Renan Escalante-Chong and Jermaine
    Ross and Jenny Zhang and Yoonjeong Cha and Andrew Lysaght and Jason Funt and Rebecca
    Kusko
  Book_Title_Journal: Biochemical Pharmacology
  DOI: https://doi.org/10.1016/j.bcp.2018.03.014
  JCS_FACTOR: 5.858
  Keywords: Big data, Genomics, Transcriptomics, RNA-seq, Microarray, Exome
  SCI_FACTOR: 1.595
  Title: Integrity, standards, and QC-related issues with big data in pre-clinical
    drug discovery
  Title_JCS: BIOCHEMICAL PHARMACOLOGY
  Title_SCI: Biochemical Pharmacology
  Type_Publication: article
  Year: 2018
- Abstract: "This paper describes the design and implementation of the Data Quality\
    \ Query System (DQ2S), a query processing framework and tool incorporating data\
    \ quality profiling functionality in the processing of queries involving quality-aware\
    \ query language extensions. DQ2S supports the combination of performance and\
    \ quality-oriented query optimizations, and a query processing platform that enables\
    \ advanced data profiling queries to be formulated based on well established query\
    \ language constructs, often used to interact with relational database management\
    \ systems. DQ2S encompasses a declarative query language and a data model that\
    \ provides users with the capability to express constraints on the quality of\
    \ query results as well as query quality-related information; a set of algebraic\
    \ operators for manipulating data quality-related information, and optimization\
    \ heuristics. The proposed query language and algebra represent seamless extensions\
    \ to SQL and relational database engines, respectively. The constructs of the\
    \ proposed data model are implemented at the user\xE2\u20AC\u2122s view level\
    \ and are internally mapped into relational model constructs. The quality-aware\
    \ extensions and features are extremely useful when users need to assess the quality\
    \ of relational data sets and define quality constraints for acceptable data prior\
    \ to using candidate data sources in decision support systems and conducting big\
    \ data analytical tasks."
  Author: Sandra de F. {Mendes Sampaio} and Chao Dong and Pedro Sampaio
  Book_Title_Journal: Expert Systems with Applications
  DOI: https://doi.org/10.1016/j.eswa.2015.06.050
  JCS_FACTOR: 6.954
  Keywords: Information management, Data quality, Query language extensions, Data
    profiling, Decision support systems, Big data
  SCI_FACTOR: 1.368
  Title: "DQ2S \xE2\u20AC\u201C A framework for data quality-aware information management"
  Title_JCS: EXPERT SYSTEMS WITH APPLICATIONS
  Title_SCI: Expert Systems with Applications
  Type_Publication: article
  Year: 2015
- Abstract: 'With corporate investment in Big Data of $34 billion in 2013 growing
    to $232 billion through 2016 (Gartner 2012), the Big 4 accounting firms are aiming
    to be at the forefront of Big Data implementations. Notably, they see Big Data
    as an increasingly essential part of their assurance practice. We argue that while
    there is a place for Big Data in auditing, its application to auditing is less
    clear than it is in the other fields, such as marketing and medical research.
    The objectives of this paper are to: (1) provide a discussion of both the inhibitors
    of incorporating Big Data into financial statement audits; and (3) present a research
    agenda to identify approaches to ameliorate those inhibitors.'
  Author: Michael Alles and Glen L. Gray
  Book_Title_Journal: International Journal of Accounting Information Systems
  DOI: https://doi.org/10.1016/j.accinf.2016.07.004
  JCS_FACTOR: 4.4
  Keywords: Big Data, Auditing, Accounting information systems
  SCI_FACTOR: 0.897
  Title: 'Incorporating big data in audits: Identifying inhibitors and a research
    agenda to address those inhibitors'
  Title_JCS: International Journal of Accounting Information Systems
  Title_SCI: International Journal of Accounting Information Systems
  Type_Publication: article
  Year: 2016
- Abstract: This paper discusses approaches and environments for carrying out analytics
    on Clouds for Big Data applications. It revolves around four important areas of
    analytics and Big Data, namely (i) data management and supporting architectures;
    (ii) model development and scoring; (iii) visualisation and user interaction;
    and (iv) business models. Through a detailed survey, we identify possible gaps
    in technology and provide recommendations for the research community on future
    directions on Cloud-supported Big Data computing and analytics solutions.
  Author: "Marcos D. Assun\xC3\xA7\xC3\xA3o and Rodrigo N. Calheiros and Silvia Bianchi\
    \ and Marco A.S. Netto and Rajkumar Buyya"
  Book_Title_Journal: Journal of Parallel and Distributed Computing
  DOI: https://doi.org/10.1016/j.jpdc.2014.08.003
  JCS_FACTOR: 3.734
  Keywords: Big Data, Cloud computing, Analytics, Data management
  SCI_FACTOR: 0.638
  Title: 'Big Data computing and clouds: Trends and future directions'
  Title_JCS: JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING
  Title_SCI: Journal of Parallel and Distributed Computing
  Type_Publication: article
  Year: 2015
- Abstract: 'Smart Farming is a development that emphasizes the use of information
    and communication technology in the cyber-physical farm management cycle. New
    technologies such as the Internet of Things and Cloud Computing are expected to
    leverage this development and introduce more robots and artificial intelligence
    in farming. This is encompassed by the phenomenon of Big Data, massive volumes
    of data with a wide variety that can be captured, analysed and used for decision-making.
    This review aims to gain insight into the state-of-the-art of Big Data applications
    in Smart Farming and identify the related socio-economic challenges to be addressed.
    Following a structured approach, a conceptual framework for analysis was developed
    that can also be used for future studies on this topic. The review shows that
    the scope of Big Data applications in Smart Farming goes beyond primary production;
    it is influencing the entire food supply chain. Big data are being used to provide
    predictive insights in farming operations, drive real-time operational decisions,
    and redesign business processes for game-changing business models. Several authors
    therefore suggest that Big Data will cause major shifts in roles and power relations
    among different players in current food supply chain networks. The landscape of
    stakeholders exhibits an interesting game between powerful tech companies, venture
    capitalists and often small start-ups and new entrants. At the same time there
    are several public institutions that publish open data, under the condition that
    the privacy of persons must be guaranteed. The future of Smart Farming may unravel
    in a continuum of two extreme scenarios: 1) closed, proprietary systems in which
    the farmer is part of a highly integrated food supply chain or 2) open, collaborative
    systems in which the farmer and every other stakeholder in the chain network is
    flexible in choosing business partners as well for the technology as for the food
    production side. The further development of data and application infrastructures
    (platforms and standards) and their institutional embedment will play a crucial
    role in the battle between these scenarios. From a socio-economic perspective,
    the authors propose to give research priority to organizational issues concerning
    governance issues and suitable business models for data sharing in different supply
    chain scenarios.'
  Author: Sjaak Wolfert and Lan Ge and Cor Verdouw and Marc-Jeroen Bogaardt
  Book_Title_Journal: Agricultural Systems
  DOI: https://doi.org/10.1016/j.agsy.2017.01.023
  JCS_FACTOR: 5.37
  Keywords: Agriculture, Data, Information and communication technology, Data infrastructure,
    Governance, Business modelling
  SCI_FACTOR: 1.694
  Title: "Big Data in Smart Farming \xE2\u20AC\u201C A review"
  Title_JCS: AGRICULTURAL SYSTEMS
  Title_SCI: Agricultural Systems
  Type_Publication: article
  Year: 2017
- Abstract: Industrial process data are usually mixed with missing data and outliers
    which can greatly affect the statistical explanation abilities for traditional
    data-driven modeling methods. In this sense, more attention should be paid on
    robust data mining methods so as to investigate those stable and reliable modeling
    prototypes for decision-making. This paper gives a systematic review of various
    state-of-the-art data preprocessing tricks as well as robust principal component
    analysis methods for process understanding and monitoring applications. Afterwards,
    comprehensive robust techniques have been discussed for various circumstances
    with diverse process characteristics. Finally, big data perspectives on potential
    challenges and opportunities have been highlighted for future explorations in
    the community.
  Author: Jinlin Zhu and Zhiqiang Ge and Zhihuan Song and Furong Gao
  Book_Title_Journal: Annual Reviews in Control
  DOI: https://doi.org/10.1016/j.arcontrol.2018.09.003
  JCS_FACTOR: 6.091
  Keywords: Data mining, Robustness, Process modeling, Statistical process monitoring,
    Big data analytics
  SCI_FACTOR: 1.78
  Title: Review and big data perspectives on robust data mining approaches for industrial
    process modeling with outliers and missing data
  Title_JCS: ANNUAL REVIEWS IN CONTROL
  Title_SCI: Annual Reviews in Control
  Type_Publication: article
  Year: 2018
- Abstract: The expansion of big data and the evolution of Internet of Things (IoT)
    technologies have played an important role in the feasibility of smart city initiatives.
    Big data offer the potential for cities to obtain valuable insights from a large
    amount of data collected through various sources, and the IoT allows the integration
    of sensors, radio-frequency identification, and Bluetooth in the real-world environment
    using highly networked services. The combination of the IoT and big data is an
    unexplored research area that has brought new and interesting challenges for achieving
    the goal of future smart cities. These new challenges focus primarily on problems
    related to business and technology that enable cities to actualize the vision,
    principles, and requirements of the applications of smart cities by realizing
    the main smart environment characteristics. In this paper, we describe the state-of-the-art
    communication technologies and smart-based applications used within the context
    of smart cities. The visions of big data analytics to support smart cities are
    discussed by focusing on how big data can fundamentally change urban populations
    at different levels. Moreover, a future business model of big data for smart cities
    is proposed, and the business and technological research challenges are identified.
    This study can serve as a benchmark for researchers and industries for the future
    progress and development of smart cities in the context of big data.
  Author: Ibrahim Abaker Targio Hashem and Victor Chang and Nor Badrul Anuar and Kayode
    Adewole and Ibrar Yaqoob and Abdullah Gani and Ejaz Ahmed and Haruna Chiroma
  Book_Title_Journal: International Journal of Information Management
  DOI: https://doi.org/10.1016/j.ijinfomgt.2016.05.002
  JCS_FACTOR: 14.098
  Keywords: Smart city, Big data, Internet of things, Smart environments, Cloud computing,
    Distributed computing
  SCI_FACTOR: 2.77
  Title: The role of big data in smart city
  Title_JCS: INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
  Title_SCI: International Journal of Information Management
  Type_Publication: article
  Year: 2016
- Abstract: "The purpose of this paper is to propose and test a theoretical framework\
    \ to explain resilience in supply chain networks for sustainability using unstructured\
    \ Big Data, based upon 36,422 items gathered in the form of tweets, news, Facebook,\
    \ WordPress, Instagram, Google+, and YouTube, and structured data, via responses\
    \ from 205 managers involved in disaster relief activities in the aftermath of\
    \ Nepal earthquake in 2015. The paper uses Big Data analysis, followed by a survey\
    \ which was analyzed using content analysis and confirmatory factor analysis (CFA).\
    \ The results of the analysis suggest that swift trust, information sharing and\
    \ public\xE2\u20AC\u201Cprivate partnership are critical enablers of resilience\
    \ in supply chain networks. The current study used cross-sectional data. However\
    \ the hypotheses of the study can be tested using longitudinal data to attempt\
    \ to establish causality. The article advances the literature on resilience in\
    \ disaster supply chain networks for sustainability in that (i) it suggests the\
    \ use of Big Data analysis to propose and test particular frameworks in the context\
    \ of resilient supply chains that enable sustainability; (ii) it argues that swift\
    \ trust, public private partnerships, and quality information sharing link to\
    \ resilience in supply chain networks; and (iii) it uses the context of Nepal,\
    \ at the moment of the disaster relief activities to provide contemporaneous perceptions\
    \ of the phenomenon as it takes place."
  Author: Thanos Papadopoulos and Angappa Gunasekaran and Rameshwar Dubey and Nezih
    Altay and Stephen J. Childe and Samuel Fosso-Wamba
  Book_Title_Journal: Journal of Cleaner Production
  DOI: https://doi.org/10.1016/j.jclepro.2016.03.059
  JCS_FACTOR: 9.297
  Keywords: Resilience, Big Data, Sustainability, Disaster, Exploratory factor analysis,
    Confirmatory factor analysis
  SCI_FACTOR: 1.937
  Title: The role of Big Data in explaining disaster resilience in supply chains for
    sustainability
  Title_JCS: Journal of Cleaner Production
  Title_SCI: Journal of Cleaner Production
  Type_Publication: article
  Year: 2017
- Abstract: "With ever-accelerating advancement of information, communication, sensing\
    \ and characterization technologies, such as industrial Internet of Things (IoT)\
    \ and high-throughput instruments, it is expected that the data generated from\
    \ manufacturing will grow exponentially, generating so called \xE2\u20AC\u02DC\
    big data\xE2\u20AC\u2122. One of the focuses of smart manufacturing is to create\
    \ manufacturing intelligence from real-time data to support accurate and timely\
    \ decision-making. Therefore, big data analytics is expected to contribute significantly\
    \ to the advancement of smart manufacturing. In this work, a roadmap of statistical\
    \ process monitoring (SPM) is presented. Most recent developments in SPM are briefly\
    \ reviewed and summarized. Specific challenges and potential solutions in handling\
    \ manufacturing big data are discussed. We suggest that process characteristics\
    \ or feature based SPM, instead of process variable based SPM, is a promising\
    \ route for next generation SPM and could play a significant role in smart manufacturing.\
    \ The advantages of feature based SPM are discussed to support the suggestion\
    \ and future directions in SPM are discussed in the context of smart manufacturing."
  Author: Q. Peter He and Jin Wang
  Book_Title_Journal: Journal of Process Control
  DOI: https://doi.org/10.1016/j.jprocont.2017.06.012
  JCS_FACTOR: 3.666
  Keywords: Statistical process monitoring, Big data, Smart manufacturing, Feature
    extraction, Internet of things
  SCI_FACTOR: 1.102
  Title: Statistical process monitoring as a big data analytics tool for smart manufacturing
  Title_JCS: JOURNAL OF PROCESS CONTROL
  Title_SCI: Journal of Process Control
  Type_Publication: article
  Year: 2018
- Abstract: "Large population-based health administrative databases, clinical registries,\
    \ and data linkage systems are a rapidly expanding resource for health research.\
    \ Ophthalmic research has benefited from the use of these databases in expanding\
    \ the breadth of knowledge in areas such as disease surveillance, disease etiology,\
    \ health services utilization, and health outcomes. Furthermore, the quantity\
    \ of data available for research has increased exponentially in recent times,\
    \ particularly as e-health initiatives come online in health systems across the\
    \ globe. We review some big data concepts, the databases and data linkage systems\
    \ used in eye research\xE2\u20AC\u201Dincluding their advantages and limitations,\
    \ the types of studies previously undertaken, and the future direction for big\
    \ data in eye research."
  Author: Antony Clark and Jonathon Q. Ng and Nigel Morlet and James B. Semmens
  Book_Title_Journal: Survey of Ophthalmology
  DOI: https://doi.org/10.1016/j.survophthal.2016.01.003
  JCS_FACTOR: 6.048
  Keywords: data linkage, clinical registry, health services research, ophthalmic
    epidemiology, big data
  SCI_FACTOR: 2.131
  Title: Big data and ophthalmic research
  Title_JCS: SURVEY OF OPHTHALMOLOGY
  Title_SCI: Survey of Ophthalmology
  Type_Publication: article
  Year: 2016
- Abstract: This paper aims to figure out the potential impact of Big Data (BD) on
    Critical Success Factors (CSFs) of Customer Relationship Management (CRM). In
    fact, while some authors have posited a relationship between BD and CRM, literature
    lacks works that go into the heart of the matter. Through an extensive up-to-date
    in-depth literature review about CRM, twenty (20) CSFs were singled out from 104
    selected papers, and organized within an ad-hoc classification framework. The
    consistency of the classification was checked by means of a content analysis.
    Evidences were discussed and linked to the BD literature, and five propositions
    about how BD could affect CRM CSFs were formalized. Our results suggest that BD-enabled
    CRM initiatives could require several changes in the pertinent CSFs. In order
    to get rid of the hype effect surrounding BD, we suggest to adopt an explorative
    approach towards them by defining a mandatory business direction through sound
    business cases and pilot tests. From a general standpoint, BD could be framed
    as an enabling factor of well-known projects, like CRM initiatives, in order to
    reap the benefits from the new technologies by addressing the efforts through
    already acknowledged management paths.
  Author: Pierluigi Zerbino and Davide Aloini and Riccardo Dulmin and Valeria Mininno
  Book_Title_Journal: Information Processing & Management
  DOI: https://doi.org/10.1016/j.ipm.2017.10.005
  JCS_FACTOR: 6.222
  Keywords: Big Data, CRM, Literature review, Critical Success Factors (CSFs), Word
    tree
  SCI_FACTOR: 0.0
  Title: 'Big Data-enabled Customer Relationship Management: A holistic approach'
  Title_JCS: INFORMATION PROCESSING & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2018
- Abstract: This paper aims to figure out the potential impact of Big Data (BD) on
    Critical Success Factors (CSFs) of Customer Relationship Management (CRM). In
    fact, while some authors have posited a relationship between BD and CRM, literature
    lacks works that go into the heart of the matter. Through an extensive up-to-date
    in-depth literature review about CRM, twenty (20) CSFs were singled out from 104
    selected papers, and organized within an ad-hoc classification framework. The
    consistency of the classification was checked by means of a content analysis.
    Evidences were discussed and linked to the BD literature, and five propositions
    about how BD could affect CRM CSFs were formalized. Our results suggest that BD-enabled
    CRM initiatives could require several changes in the pertinent CSFs. In order
    to get rid of the hype effect surrounding BD, we suggest to adopt an explorative
    approach towards them by defining a mandatory business direction through sound
    business cases and pilot tests. From a general standpoint, BD could be framed
    as an enabling factor of well-known projects, like CRM initiatives, in order to
    reap the benefits from the new technologies by addressing the efforts through
    already acknowledged management paths.
  Author: Pierluigi Zerbino and Davide Aloini and Riccardo Dulmin and Valeria Mininno
  Book_Title_Journal: Information Processing & Management
  DOI: https://doi.org/10.1016/j.ipm.2017.10.005
  JCS_FACTOR: 6.222
  Keywords: Big Data, CRM, Literature review, Critical Success Factors (CSFs), Word
    tree
  SCI_FACTOR: 0.0
  Title: 'Big Data-enabled Customer Relationship Management: A holistic approach'
  Title_JCS: INFORMATION PROCESSING & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2018
- Abstract: 'The rapidly growing interest from both academics and practitioners in
    the application of big data analytics (BDA) in supply chain management (SCM) has
    urged the need for review of up-to-date research development in order to develop
    a new agenda. This review responds to the call by proposing a novel classification
    framework that provides a full picture of current literature on where and how
    BDA has been applied within the SCM context. The classification framework is structurally
    based on the content analysis method of Mayring (2008), addressing four research
    questions: (1) in what areas of SCM is BDA being applied? (2) At what level of
    analytics is BDA used in these SCM areas? (3) What types of BDA models are used
    in SCM? (4) What BDA techniques are employed to develop these models? The discussion
    tackling these four questions reveals a number of research gaps, which leads to
    future research directions.'
  Author: Truong Nguyen and Li ZHOU and Virginia Spiegler and Petros Ieromonachou
    and Yong Lin
  Book_Title_Journal: Computers & Operations Research
  DOI: https://doi.org/10.1016/j.cor.2017.07.004
  JCS_FACTOR: 4.008
  Keywords: Literature review, Big data, Big data analytics, Supply chain management,
    Research directions
  SCI_FACTOR: 0.0
  Title: 'Big data analytics in supply chain management: A state-of-the-art literature
    review'
  Title_JCS: COMPUTERS & OPERATIONS RESEARCH
  Title_SCI: N/A
  Type_Publication: article
  Year: 2018
- Abstract: Privacy trust directly affects the personal willingness to share data
    and thus influences the quality and size of the data, thus affecting the development
    of big data technology and industry. As China is probably the largest personal
    data pool and vastest application market of big data, the situation of Chinese
    privacy trust plays a significant role. Based on the 17 most common data collection
    scenarios, the following aspects have been observed through 508 questionnaires
    and interviews of 20 samples. To start with, there is a severe privacy trust crisis
    in China, both in the field of enterprise services such as online shopping and
    social networks, etc. and in some public services like medical care and education,
    etc. Besides, there are also doubts about data collected by the government since
    individuals refuse to offer personal information or give false information as
    much as possible. Some people even buy two phone numbers, one is in use, while
    the other is not carried around or used by them, which is only bought to be offered
    to data collectors. Secondly, in terms of gender, females have lower trust in
    enterprises and social associations than males, especially in the fields of social
    networks and personal consumption. However, there is no obvious difference in
    fields of government and public services. Females possess stronger awareness but
    less skilled in precautions than males. Thirdly, people between the ages of 18
    and 50 are more suspicious of data collected by enterprises, while age exerts
    little obvious influence on the credibility of data collected by the government,
    social associations and public services. Older people are less aware of precautions
    than people at other ages. In addition, from the perspective of education background,
    people with higher degrees possess stronger awareness of precautions and thus
    lower degree of trust. Therefore, it is suggested that more education on privacy
    consciousness should be given, and relative laws as well as regulations need improving.
    Besides, innovation in privacy protection technologies should be encouraged. What
    is more, we need to reinforce the management of the internet industry and strictly
    regulate personal data collection of the government.
  Author: Zhong Wang and Qian Yu
  Book_Title_Journal: Computer Law & Security Review
  DOI: https://doi.org/10.1016/j.clsr.2015.08.006
  JCS_FACTOR: 2.98
  Keywords: Personal data, Privacy trust, Questionnaires, Interview, Big data
  SCI_FACTOR: 0.0
  Title: 'Privacy trust crisis of personal data in China in the era of Big Data: The
    survey and countermeasures'
  Title_JCS: Computer Law & Security Review
  Title_SCI: N/A
  Type_Publication: article
  Year: 2015
- Abstract: 'This paper presents a multi-objective optimization model for a green
    supply chain management scheme that minimizes the inherent risk occurred by hazardous
    materials, associated carbon emission and economic cost. The model related parameters
    are capitalized on a big data analysis. Three scenarios are proposed to improve
    green supply chain management. The first scenario divides optimization into three
    options: the first involves minimizing risk and then dealing with carbon emissions
    (and thus economic cost); the second minimizes both risk and carbon emissions
    first, with the ultimate goal of minimizing overall cost; and the third option
    attempts to minimize risk, carbon emissions, and economic cost simultaneously.
    This paper provides a case study to verify the optimization model. Finally, the
    limitations of this research and approach are discussed to lay a foundation for
    further improvement.'
  Author: Rui Zhao and Yiyun Liu and Ning Zhang and Tao Huang
  Book_Title_Journal: Journal of Cleaner Production
  DOI: https://doi.org/10.1016/j.jclepro.2016.03.006
  JCS_FACTOR: 9.297
  Keywords: Hazardous materials, Inherent risk, Carbon emissions, Multi-objective
    optimization, Green supply chain management, Big data analysis
  SCI_FACTOR: 1.937
  Title: An optimization model for green supply chain management by using a big data
    analytic approach
  Title_JCS: Journal of Cleaner Production
  Title_SCI: Journal of Cleaner Production
  Type_Publication: article
  Year: 2017
- Abstract: "Big data and predictive analytics (BDPA) tools and methodologies are\
    \ leveraged by businesses in many ways to improve operational and strategic capabilities,\
    \ and ultimately, to positively impact corporate financial performance. BDPA has\
    \ become crucial for managing supply chain functions, where data intensive processes\
    \ can be vastly improved through its effective use. BDPA has also become a competitive\
    \ necessity for the management of supply chains, with practitioners and scholars\
    \ focused almost entirely on how BDPA is used to increase economic measures of\
    \ performance. There is limited understanding, however, as to how BDPA can impact\
    \ other aspects of the triple bottom-line, namely environmental and social sustainability\
    \ outcomes. Indeed, this area is in immediate need of attention from scholars\
    \ in many fields including industrial engineering, supply chain management, information\
    \ systems, business analytics, as well as other business and engineering disciplines.\
    \ The purpose of this article is to motivate such research by proposing an agenda\
    \ based in well-established theory. This article reviews eight theories that can\
    \ be used by researchers to examine and clarify the nature of BDPA\xE2\u20AC\u2122\
    s impact on supply chain sustainability, and presents research questions based\
    \ upon this review. Scholars can leverage this article as the basis for future\
    \ research activity, and practitioners can use this article as a means to understand\
    \ how company-wide BDPA initiatives might impact measures of supply chain sustainability."
  Author: Benjamin T. Hazen and Joseph B. Skipper and Jeremy D. Ezell and Christopher
    A. Boone
  Book_Title_Journal: Computers & Industrial Engineering
  DOI: https://doi.org/10.1016/j.cie.2016.06.030
  JCS_FACTOR: 5.431
  Keywords: Big data, Predictive analytics, Supply chain management
  SCI_FACTOR: 0.0
  Title: 'Big data and predictive analytics for supply chain sustainability: A theory-driven
    research agenda'
  Title_JCS: COMPUTERS & INDUSTRIAL ENGINEERING
  Title_SCI: N/A
  Type_Publication: article
  Year: 2016
- Abstract: "Big Data (BD), with their potential to ascertain valued insights for\
    \ enhanced decision-making process, have recently attracted substantial interest\
    \ from both academics and practitioners. Big Data Analytics (BDA) is increasingly\
    \ becoming a trending practice that many organizations are adopting with the purpose\
    \ of constructing valuable information from BD. The analytics process, including\
    \ the deployment and use of BDA tools, is seen by organizations as a tool to improve\
    \ operational efficiency though it has strategic potential, drive new revenue\
    \ streams and gain competitive advantages over business rivals. However, there\
    \ are different types of analytic applications to consider. Therefore, prior to\
    \ hasty use and buying costly BD tools, there is a need for organizations to first\
    \ understand the BDA landscape. Given the significant nature of the BD and BDA,\
    \ this paper presents a state-of-the-art review that presents a holistic view\
    \ of the BD challenges and BDA methods theorized/proposed/employed by organizations\
    \ to help others understand this landscape with the objective of making robust\
    \ investment decisions. In doing so, systematically analysing and synthesizing\
    \ the extant research published on BD and BDA area. More specifically, the authors\
    \ seek to answer the following two principal questions: Q1 \xE2\u20AC\u201C What\
    \ are the different types of BD challenges theorized/proposed/confronted by organizations?\
    \ and Q2 \xE2\u20AC\u201C What are the different types of BDA methods theorized/proposed/employed\
    \ to overcome BD challenges?. This systematic literature review (SLR) is carried\
    \ out through observing and understanding the past trends and extant patterns/themes\
    \ in the BDA research area, evaluating contributions, summarizing knowledge, thereby\
    \ identifying limitations, implications and potential further research avenues\
    \ to support the academic community in exploring research themes/patterns. Thus,\
    \ to trace the implementation of BD strategies, a profiling method is employed\
    \ to analyze articles (published in English-speaking peer-reviewed journals between\
    \ 1996 and 2015) extracted from the Scopus database. The analysis presented in\
    \ this paper has identified relevant BD research studies that have contributed\
    \ both conceptually and empirically to the expansion and accrual of intellectual\
    \ wealth to the BDA in technology and organizational resource management discipline."
  Author: Uthayasankar Sivarajah and Muhammad Mustafa Kamal and Zahir Irani and Vishanth
    Weerakkody
  Book_Title_Journal: Journal of Business Research
  DOI: https://doi.org/10.1016/j.jbusres.2016.08.001
  JCS_FACTOR: 7.55
  Keywords: Big Data, Big Data Analytics, Challenges, Methods, Systematic literature
    review
  SCI_FACTOR: 2.049
  Title: Critical analysis of Big Data challenges and analytical methods
  Title_JCS: JOURNAL OF BUSINESS RESEARCH
  Title_SCI: Journal of Business Research
  Type_Publication: article
  Year: 2017
- Abstract: In the recent years the problems of using generic storage (i.e., relational)
    techniques for very specific applications have been detected and outlined and,
    as a consequence, some alternatives to Relational DBMSs (e.g., HBase) have bloomed.
    Most of these alternatives sit on the cloud and benefit from cloud computing,
    which is nowadays a reality that helps us to save money by eliminating the hardware
    as well as software fixed costs and just pay per use. On top of this, specific
    querying frameworks to exploit the brute force in the cloud (e.g., MapReduce)
    have also been devised. The question arising next tries to clear out if this (rather
    naive) exploitation of the cloud is an alternative to tuning DBMSs or it still
    makes sense to consider other options when retrieving data from these settings.
    In this paper, we study the feasibility of solving OLAP queries with Hadoop (the
    Apache project implementing MapReduce) while benefiting from secondary indexes
    and partitioning in HBase. Our main contribution is the comparison of different
    access plans and the definition of criteria (i.e., cost estimation) to choose
    among them in terms of consumed resources (namely CPU, bandwidth and I/O).
  Author: "Oscar Romero and Victor Herrero and Alberto Abell\xC3\xB3 and Jaume Ferrarons"
  Book_Title_Journal: Information Systems
  DOI: https://doi.org/10.1016/j.is.2014.09.005
  JCS_FACTOR: 2.309
  Keywords: Big Data, OLAP, Multidimensional model, Indexes, Partitioning, Cost estimation
  SCI_FACTOR: 0.547
  Title: 'Tuning small analytics on Big Data: Data partitioning and secondary indexes
    in the Hadoop ecosystem'
  Title_JCS: INFORMATION SYSTEMS
  Title_SCI: Information Systems
  Type_Publication: article
  Year: 2015
- Abstract: "User-generated content, such as online product reviews, is a valuable\
    \ source of consumer insight. Such unstructured big data is generated in real-time,\
    \ is easily accessed, and contains messages consumers want managers to hear. Analyzing\
    \ such data has potential to revolutionize market research and competitive analysis,\
    \ but how can the messages be extracted? How can the vast amount of data be condensed\
    \ into insights to help steer businesses\xE2\u20AC\u2122 strategy? We describe\
    \ a non-proprietary technique that can be applied by anyone with statistical training.\
    \ Latent Dirichlet Allocation (LDA) can analyze huge amounts of text and describe\
    \ the content as focusing on unseen attributes in a specific weighting. For example,\
    \ a review of a graphic novel might be analyzed to focus 70% on the storyline\
    \ and 30% on the graphics. Aggregating the content from numerous consumers allows\
    \ us to understand what is, collectively, on consumers\xE2\u20AC\u2122 minds,\
    \ and from this we can infer what consumers care about. We can even highlight\
    \ which attributes are seen positively or negatively. The value of this technique\
    \ extends well beyond the CMO's office as LDA can map the relative strategic positions\
    \ of competitors where they matter most: in the minds of consumers."
  Author: Neil T. Bendle and Xin (Shane) Wang
  Book_Title_Journal: Business Horizons
  DOI: https://doi.org/10.1016/j.bushor.2015.10.001
  JCS_FACTOR: 6.361
  Keywords: Big data, User-Generated content, Latent Dirichlet Allocation, Topic modeling,
    Market research, Qualitative data
  SCI_FACTOR: 2.174
  Title: Uncovering the message from the mess of big data
  Title_JCS: BUSINESS HORIZONS
  Title_SCI: Business Horizons
  Type_Publication: article
  Year: 2016
- Abstract: "In the digital age, the interaction between privacy, data protection\
    \ and advanced technological developments such as big data analytics has become\
    \ pertinent to Europol's effectiveness in providing accurate crime analyses. For\
    \ the purposes of preventing and combating crime falling within the scope of its\
    \ objectives, it is imperative for Europol to employ the fullest and most up-to-date\
    \ information and technical capabilities possible whilst respecting fundamental\
    \ human rights. The present article addresses precisely the \xE2\u20AC\u0153paradox\xE2\
    \u20AC\x9D of on one side protecting fundamental human rights against external\
    \ terrorist and/or cybercrime intrusions, and on the other providing a privacy-conscious\
    \ approach to data collection and analytics, so that Europol can even more effectively\
    \ support and strengthen action in protecting society against internal threats\
    \ in a proportionate, responsible and legitimate manner. The advantage proposed\
    \ in this very context of large quantities of data informing strategic analysis\
    \ at Europol is a purpose-oriented data protection impact assessment. Namely,\
    \ the evolution from traditional instruments in the fight against organised crime\
    \ and terrorism to more technologically advanced ones equally requires an alteration\
    \ of the conventional notions of privacy and investigative and information-sharing\
    \ methods."
  Author: Daniel Drewer and Vesela Miladinova
  Book_Title_Journal: Computer Law & Security Review
  DOI: https://doi.org/10.1016/j.clsr.2017.03.006
  JCS_FACTOR: 2.98
  Keywords: Europol, Big data, Privacy, Data protection, Data protection impact assessment,
    Risk assessment, Privacy by design, Advanced technologies, Europol Regulation,
    Integrated Data Management Concept (IDMC)
  SCI_FACTOR: 0.0
  Title: 'The BIG DATA Challenge: Impact and opportunity of large quantities of information
    under the Europol Regulation'
  Title_JCS: Computer Law & Security Review
  Title_SCI: N/A
  Type_Publication: article
  Year: 2017
- Abstract: Precision medicine relies on an increasing amount of heterogeneous data.
    Advances in radiation oncology, through the use of CT Scan, dosimetry and imaging
    performed before each fraction, have generated a considerable flow of data that
    needs to be integrated. In the same time, Electronic Health Records now provide
    phenotypic profiles of large cohorts of patients that could be correlated to this
    information. In this review, we describe methods that could be used to create
    integrative predictive models in radiation oncology. Potential uses of machine
    learning methods such as support vector machine, artificial neural networks, and
    deep learning are also discussed.
  Author: Jean-Emmanuel Bibault and Philippe Giraud and Anita Burgun
  Book_Title_Journal: Cancer Letters
  DOI: https://doi.org/10.1016/j.canlet.2016.05.033
  JCS_FACTOR: 8.679
  Keywords: Radiation oncology, Big Data, Predictive model, Machine learning
  SCI_FACTOR: 2.47
  Title: 'Big Data and machine learning in radiation oncology: State of the art and
    future prospects'
  Title_JCS: CANCER LETTERS
  Title_SCI: Cancer Letters
  Type_Publication: article
  Year: 2016
- Abstract: "In the past few decades, extensive epidemiological studies have focused\
    \ on exploring the adverse effects of PM2.5 (particulate matters with aerodynamic\
    \ diameters less than 2.5\xE2\u20AC\xAF\xCE\xBCm) on public health. However, most\
    \ of them failed to consider the dynamic changes of population distribution adequately\
    \ and were limited by the accuracy of PM2.5 estimations. Therefore, in this study,\
    \ location-based service (LBS) data from social media and satellite-derived high-quality\
    \ PM2.5 concentrations were collected to perform highly spatiotemporal exposure\
    \ assessments for thirteen cities in the Beijing-Tianjin-Hebei (BTH) region, China.\
    \ The city-scale exposure levels and the corresponding health outcomes were first\
    \ estimated. Then the uncertainties in exposure risk assessments were quantified\
    \ based on in-situ PM2.5 observations and static population data. The results\
    \ showed that approximately half of the population living in the BTH region were\
    \ exposed to monthly mean PM2.5 concentration greater than 80\xE2\u20AC\xAF\xCE\
    \xBCg/m3 in 2015, and the highest risk was observed in December. In terms of all-cause,\
    \ cardiovascular, and respiratory disease, the premature deaths attributed to\
    \ PM2.5 were estimated to be 138,150, 80,945, and 18,752, respectively. A comparative\
    \ analysis between five different exposure models further illustrated that the\
    \ dynamic population distribution and accurate PM2.5 estimations showed great\
    \ influence on environmental exposure and health assessments and need be carefully\
    \ considered. Otherwise, the results would be considerably over- or under-estimated."
  Author: Yimeng Song and Bo Huang and Qingqing He and Bin Chen and Jing Wei and Rashed
    Mahmood
  Book_Title_Journal: Environmental Pollution
  DOI: https://doi.org/10.1016/j.envpol.2019.06.057
  JCS_FACTOR: 8.071
  Keywords: Human mobility, Spatiotemporal heterogeneity, Remote sensing, Big data,
    Environmental health
  SCI_FACTOR: 2.136
  Title: Dynamic assessment of PM2.5 exposure and health risk using remote sensing
    and geo-spatial big data
  Title_JCS: ENVIRONMENTAL POLLUTION
  Title_SCI: Environmental Pollution
  Type_Publication: article
  Year: 2019
- Abstract: "With gigabit networking becoming economically feasible and widely installed\
    \ at homes, there are new opportunities to revisit in-home, personalized telehealth\
    \ services. In this paper, we describe a novel telehealth eldercare service that\
    \ we developed viz., \xE2\u20AC\u0153PhysicalTherapy-as-a-Service\xE2\u20AC\x9D\
    \ (PTaaS) that connects a remote physical therapist at a clinic to a senior at\
    \ home. The service leverages a high-speed, low-latency network connection through\
    \ an interactive interface built on top of Microsoft Kinect motion sensing capabilities.\
    \ The interface that is built using user-centered design principles for wellness\
    \ coaching exercises is essentially a \xE2\u20AC\u02DCSynchronous Big Data\xE2\
    \u20AC\u2122 application due to its: (i) high data-in-motion velocity (i.e., peak\
    \ data rate is \xE2\u2030\u02C6400 Mbps), (ii) considerable variety (i.e., measurements\
    \ include 3D sensing, network health, user opinion surveys and video clips of\
    \ RGB, skeletal and depth data), and (iii) large volume (i.e., several GB of measurement\
    \ data for a simple exercise activity). The successful PTaaS delivery through\
    \ this interface is dependent on the veracity analytics needed for correlation\
    \ of the real-time Big Data streams within a session, in order to assess exercise\
    \ balance of the senior without any bias due to network quality effects. Our experiments\
    \ with PTaaS in an actual testbed involving senior homes in Kansas City with Google\
    \ Fiber connections and our university clinic demonstrate the network configuration\
    \ and time synchronization related challenges in order to perform online analytics.\
    \ Our findings provide insights on how to: (a) enable suitable resource calibration\
    \ and perform network troubleshooting for high user experience for both the therapist\
    \ and the senior, and (b) realize a Big Data architecture for PTaaS and other\
    \ similar personalized healthcare services to be remotely delivered at a large-scale\
    \ in a reliable, secure and cost-effective manner."
  Author: Prasad Calyam and Anup Mishra and Ronny Bazan Antequera and Dmitrii Chemodanov
    and Alex Berryman and Kunpeng Zhu and Carmen Abbott and Marjorie Skubic
  Book_Title_Journal: Pervasive and Mobile Computing
  DOI: https://doi.org/10.1016/j.pmcj.2015.09.004
  JCS_FACTOR: 3.453
  Keywords: Smart health care, Personalized remote physical therapy, Synchronous Big
    Data, Gigabit networking app
  SCI_FACTOR: 0.687
  Title: Synchronous Big Data analytics for personalized and remote physical therapy
  Title_JCS: Pervasive and Mobile Computing
  Title_SCI: Pervasive and Mobile Computing
  Type_Publication: article
  Year: 2016
- Abstract: "Undoubtedly, sustainable development has inspired a generation of scholars\
    \ and practitioners in different disciplines into a quest for the immense opportunities\
    \ created by the development of sustainable urban forms for human settlements\
    \ that will enable built environments to function in a more constructive and efficient\
    \ way. However, there are still significant challenges that need to be addressed\
    \ and overcome. The issue of such forms has been problematic and difficult to\
    \ deal with, particularly in relation to the evaluation and improvement of their\
    \ contribution to the goals of sustainable development. As it is an urban world\
    \ where the informational and physical landscapes are increasingly being merged,\
    \ sustainable urban forms need to embrace and leverage what current and future\
    \ ICT has to offer as innovative solutions and sophisticated methods so as to\
    \ thrive\xE2\u20AC\u201Di.e. advance their contribution to sustainability. The\
    \ need for ICT of the new wave of computing to be embedded in such forms is underpinned\
    \ by the recognition that urban sustainability applications are deemed of high\
    \ relevance to the contemporary research agenda of computing and ICT. To unlock\
    \ and exploit the underlying potential, the field of sustainable urban planning\
    \ is required to extend its boundaries and broaden its horizons beyond the ambit\
    \ of the built form of cities to include technological innovation opportunities.\
    \ This paper explores and substantiates the real potential of ICT of the new wave\
    \ of computing to evaluate and improve the contribution of sustainable urban forms\
    \ to the goals of sustainable development. This entails merging big data and context-aware\
    \ technologies and their applications with the typologies and design concepts\
    \ of sustainable urban forms to achieve multiple hitherto unrealized goals. In\
    \ doing so, this paper identifies models of smart sustainable city and their technologies\
    \ and applications and models of sustainable urban form and their design concepts\
    \ and typologies. In addition, it addresses the question of how these technologies\
    \ and applications can be amalgamated with these design concepts and typologies\
    \ in ways that ultimately evaluate and improve the contribution of sustainable\
    \ urban forms to the goals of sustainable development. The overall aim of this\
    \ paper suits a mix of three methodologies: literature review, thematic analysis,\
    \ and secondary (qualitative) data analysis to achieve different but related objectives.\
    \ The study identifies four technologies and two classes of applications pertaining\
    \ to models of smart sustainable city as well as three design concepts and four\
    \ typologies related to models of sustainable urban form. Finally, this paper\
    \ proposes a Matrix to help scholars and planners in understanding and analyzing\
    \ how and to what extent the contribution of sustainable urban forms to sustainability\
    \ can be improved through ICT of the new wave of computing as to the underlying\
    \ novel technologies and their applications, as well as a data-centric approach\
    \ into investigating and evaluating this contribution and a simulation method\
    \ for strategically optimizing it."
  Author: Simon Elias Bibri and John Krogstie
  Book_Title_Journal: Sustainable Cities and Society
  DOI: https://doi.org/10.1016/j.scs.2017.04.012
  JCS_FACTOR: 7.587
  Keywords: Sustainable urban forms, Smart sustainable cities, Big data analytics,
    Context-aware computing, Typologies and design concepts, Technologies and applications,
    ICT of the new wave of computing
  SCI_FACTOR: 1.645
  Title: 'ICT of the new wave of computing for sustainable urban forms: Their big
    data and context-aware augmented typologies and design concepts'
  Title_JCS: Sustainable Cities and Society
  Title_SCI: Sustainable Cities and Society
  Type_Publication: article
  Year: 2017
- Abstract: The increasing presence of geo-distributed sensor networks implies the
    generation of huge volumes of data from multiple geographical locations at an
    increasing rate. This raises important issues which become more challenging when
    the final goal is that of the analysis of the data for forecasting purposes or,
    more generally, for predictive tasks. This paper proposes a framework which supports
    predictive modeling tasks from streaming data coming from multiple geo-referenced
    sensors. In particular, we propose a distance-based anomaly detection strategy
    which considers objects described by embedding features learned via a stacked
    auto-encoder. We then devise a repair strategy which repairs the data detected
    as anomalous exploiting non-anomalous data measured by sensors in nearby spatial
    locations. Subsequently, we adopt Gradient Boosted Trees (GBTs) to predict/forecast
    values assumed by a target variable of interest for the repaired newly arriving
    (unlabeled) data, using the original feature representation or the embedding feature
    representation learned via the stacked auto-encoder. The workflow is implemented
    with distributed Apache Spark programming primitives and tested on a cluster environment.
    We perform experiments to assess the performance of each module, separately and
    in a combined manner, considering the predictive modeling of one-day-ahead energy
    production, for multiple renewable energy sites. Accuracy results show that the
    proposed framework allows reducing the error up to 13.56%. Moreover, scalability
    results demonstrate the efficiency of the proposed framework in terms of speedup,
    scaleup and execution time under a stress test.
  Author: Roberto Corizzo and Michelangelo Ceci and Nathalie Japkowicz
  Book_Title_Journal: Big Data Research
  DOI: https://doi.org/10.1016/j.bdr.2019.04.001
  JCS_FACTOR: 3.578
  Keywords: Anomaly detection, Data repair, Geo-distributed big data, Spatial autocorrelation,
    Neural networks, Gradient-boosting
  SCI_FACTOR: 0.565
  Title: Anomaly Detection and Repair for Accurate Predictions in Geo-distributed
    Big Data
  Title_JCS: Big Data Research
  Title_SCI: Big Data Research
  Type_Publication: article
  Year: 2019
- Abstract: Building energy data has been used for decades to understand energy flows
    in buildings and plan for future energy demand. Recent market, technology and
    policy drivers have resulted in widespread data collection by stakeholders across
    the buildings industry. Consolidation of independently collected and maintained
    datasets presents a cost-effective opportunity to build a database of unprecedented
    size. Applications of the data include peer group analysis to evaluate building
    performance, and data-driven algorithms that use empirical data to estimate energy
    savings associated with building retrofits. This paper discusses technical considerations
    in compiling such a database using the DOE Buildings Performance Database (BPD)
    as a case study. We gathered data on over 750,000 residential and commercial buildings.
    We describe the process and challenges of mapping and cleansing data from disparate
    sources. We analyze the distributions of buildings in the BPD relative to the
    Commercial Building Energy Consumption Survey (CBECS) and Residential Energy Consumption
    Survey (RECS), evaluating peer groups of buildings that are well or poorly represented,
    and discussing how differences in the distributions of the three datasets impact
    use-cases of the data. Finally, we discuss the usefulness and limitations of the
    current dataset and the outlook for increasing its size and applications.
  Author: Paul A. Mathew and Laurel N. Dunn and Michael D. Sohn and Andrea Mercado
    and Claudine Custudio and Travis Walter
  Book_Title_Journal: Applied Energy
  DOI: https://doi.org/10.1016/j.apenergy.2014.11.042
  JCS_FACTOR: 9.746
  Keywords: Buildings Performance Database, Building performance, Big data, Building
    data collection, Data-driven decision support
  SCI_FACTOR: 3.035
  Title: 'Big-data for building energy performance: Lessons from assembling a very
    large national database of building energy use'
  Title_JCS: APPLIED ENERGY
  Title_SCI: Applied Energy
  Type_Publication: article
  Year: 2015
- Abstract: 'The entity reconciliation (ER) problem aroused much interest as a research
    topic in today''s Big Data era, full of big and open heterogeneous data sources.
    This problem poses when relevant information on a topic needs to be obtained using
    methods based on: (i) identifying records that represent the same real world entity,
    and (ii) identifying those records that are similar but do not correspond to the
    same real-world entity. ER is an operational intelligence process, whereby organizations
    can unify different and heterogeneous data sources in order to relate possible
    matches of non-obvious entities. Besides, the complexity that the heterogeneity
    of data sources involves, the large number of records and differences among languages,
    for instance, must be added. This paper describes a Systematic Mapping Study (SMS)
    of journal articles, conferences and workshops published from 2010 to 2017 to
    solve the problem described before, first trying to understand the state-of-the-art,
    and then identifying any gaps in current research. Eleven digital libraries were
    analyzed following a systematic, semiautomatic and rigorous process that has resulted
    in 61 primary studies. They represent a great variety of intelligent proposals
    that aim to solve ER. The conclusion obtained is that most of the research is
    based on the operational phase as opposed to the design phase, and most studies
    have been tested on real-world data sources, where a lot of them are heterogeneous,
    but just a few apply to industry. There is a clear trend in research techniques
    based on clustering/blocking and graphs, although the level of automation of the
    proposals is hardly ever mentioned in the research work.'
  Author: "J.G. Enr\xC3\xADquez and F.J. Dom\xC3\xADnguez-Mayo and M.J. Escalona and\
    \ M. Ross and G. Staples"
  Book_Title_Journal: Expert Systems with Applications
  DOI: https://doi.org/10.1016/j.eswa.2017.03.010
  JCS_FACTOR: 6.954
  Keywords: Systematic mapping study, Entity reconciliation, Heterogeneous databases,
    Big data
  SCI_FACTOR: 1.368
  Title: 'Entity reconciliation in big data sources: A systematic mapping study'
  Title_JCS: EXPERT SYSTEMS WITH APPLICATIONS
  Title_SCI: Expert Systems with Applications
  Type_Publication: article
  Year: 2017
- Abstract: 'This paper presents a bi-level mathematical programming model for the
    data-pricing problem that considers both data quality and data versioning strategies.
    Data products and data-related services differ from information products or services
    in terms of quality assessment methods. For this problem, we consider two aspects
    of data quality: (1) its multidimensionality and (2) the interaction between the
    dimensions. We designed a multi-version data strategy and propose a data-pricing
    bi-level programming model based on the data quality to maximize the profit by
    the owner of the data platform and the utility to consumers. A genetic algorithm
    was used to solve the model. The numerical solutions for the data-pricing model
    indicate that the multi-version strategy achieves a better market segmentation
    and is more profitable and feasible when the multiple dimensions of data quality
    are considered. These results also provide managerial guidance on data provision
    and data pricing for platform owners.'
  Author: Haifei Yu and Mengxiao Zhang
  Book_Title_Journal: Computers & Industrial Engineering
  DOI: https://doi.org/10.1016/j.cie.2017.08.008
  JCS_FACTOR: 5.431
  Keywords: Big data, Data marketplace, Data pricing, Production management, Bi-level
    programming model
  SCI_FACTOR: 0.0
  Title: Data pricing strategy based on data quality
  Title_JCS: COMPUTERS & INDUSTRIAL ENGINEERING
  Title_SCI: N/A
  Type_Publication: article
  Year: 2017
- Abstract: Recent evolutions in computing science and web technology provide the
    environmental community with continuously expanding resources for data collection
    and analysis that pose unprecedented challenges to the design of analysis methods,
    workflows, and interaction with data sets. In the light of the recent UK Research
    Council funded Environmental Virtual Observatory pilot project, this paper gives
    an overview of currently available implementations related to web-based technologies
    for processing large and heterogeneous datasets and discuss their relevance within
    the context of environmental data processing, simulation and prediction. We found
    that, the processing of the simple datasets used in the pilot proved to be relatively
    straightforward using a combination of R, RPy2, PyWPS and PostgreSQL. However,
    the use of NoSQL databases and more versatile frameworks such as OGC standard
    based implementations may provide a wider and more flexible set of features that
    particularly facilitate working with larger volumes and more heterogeneous data
    sources.
  Author: Claudia Vitolo and Yehia Elkhatib and Dominik Reusser and Christopher J.A.
    Macleod and Wouter Buytaert
  Book_Title_Journal: Environmental Modelling & Software
  DOI: https://doi.org/10.1016/j.envsoft.2014.10.007
  JCS_FACTOR: 5.288
  Keywords: Web-based modelling, Big Data, Web services, OGC standards
  SCI_FACTOR: 0.0
  Title: Web technologies for environmental Big Data
  Title_JCS: ENVIRONMENTAL MODELLING & SOFTWARE
  Title_SCI: N/A
  Type_Publication: article
  Year: 2015
- Abstract: Staggering statistics regarding the global burden of disease due to lack
    of surgical care worldwide has been gaining attention in the global health literature
    over the last 10 years. The Lancet Commission on Global Surgery reported that
    16.9 million lives were lost due to an absence of surgical care in 2010, equivalent
    to 33% of all deaths worldwide. Although data from low- and middle-income countries
    (LMICs) are limited, recent investigations, such as the African Surgical Outcomes
    Study, highlight that despite operating on low risk patients, there is increased
    postoperative mortality in LMICs versus higher-resource settings, a majority of
    which occur secondary to seemingly preventable complications like surgical site
    infections. We propose that implementing creative, low-cost surgical outcomes
    monitoring and select quality improvement systems proven effective in high-income
    countries, such as surgical infection prevention programs and safety checklists,
    can enhance the delivery of safe surgical care in existing LMIC surgical systems.
    While efforts to initiate and expand surgical access and capacity continues to
    deserve attention in the global health community, here we advocate for creative
    modifications to current service structures, such as promoting a culture of safety,
    employing technology and mobile health (mHealth) for patient data collection and
    follow-up, and harnessing partnerships for information sharing, to create a framework
    for improving morbidity and mortality in responsible, scalable, and sustainable
    ways.
  Author: Belain Eyob and Marissa A. Boeck and Patrick FaSiOen and Shamir Cawich and
    Michael D. Kluger
  Book_Title_Journal: International Journal of Surgery
  DOI: https://doi.org/10.1016/j.ijsu.2019.07.036
  JCS_FACTOR: 6.071
  Keywords: Surgical outcomes, Developing countries, Caribbean, Safe surgery, Quality
    improvement, Big data
  SCI_FACTOR: 1.315
  Title: Ensuring safe surgical care across resource settings via surgical outcomes
    data & quality improvement initiatives
  Title_JCS: International Journal of Surgery
  Title_SCI: International Journal of Surgery
  Type_Publication: article
  Year: 2019
- Abstract: Using service-oriented decision support systems (DSS in cloud) is one
    of the major trends for many organizations in hopes of becoming more agile. In
    this paper, after defining a list of requirements for service-oriented DSS, we
    propose a conceptual framework for DSS in cloud, and discus about research directions.
    A unique contribution of this paper is its perspective on how to servitize the
    product oriented DSS environment, and demonstrate the opportunities and challenges
    of engineering service oriented DSS in cloud. When we define data, information
    and analytics as services, we see that traditional measurement mechanisms, which
    are mainly time and cost driven, do not work well. Organizations need to consider
    value of service level and quality in addition to the cost and duration of delivered
    services. DSS in CLOUD enables scale, scope and speed economies. This article
    contributes new knowledge in service science by tying the information technology
    strategy perspectives to the database and design science perspectives for a broader
    audience.
  Author: Haluk Demirkan and Dursun Delen
  Book_Title_Journal: Decision Support Systems
  DOI: https://doi.org/10.1016/j.dss.2012.05.048
  JCS_FACTOR: 5.795
  Keywords: Cloud computing, Service orientation, Service science, Data-as-a-service,
    Information-as-a-service, Analytics-as-a-service, Big data
  SCI_FACTOR: 1.564
  Title: 'Leveraging the capabilities of service-oriented decision support systems:
    Putting analytics and big data in cloud'
  Title_JCS: DECISION SUPPORT SYSTEMS
  Title_SCI: Decision Support Systems
  Type_Publication: article
  Year: 2013
- Abstract: This study presents a unique approach in investigating the knowledge diffusion
    structure for the field of data quality through an analysis of the main paths.
    We study a dataset of 1880 papers to explore the knowledge diffusion path, using
    citation data to build the citation network. The main paths are then investigated
    and visualized via social network analysis. This paper takes three different main
    path analyses, namely local, global, and key-route, to depict the knowledge diffusion
    path and additionally implements the g-index and h-index to evaluate the most
    important journals and researchers in the data quality domain.
  Author: Yu Xiao and Louis Y.Y. Lu and John S. Liu and Zhili Zhou
  Book_Title_Journal: Journal of Informetrics
  DOI: https://doi.org/10.1016/j.joi.2014.05.001
  JCS_FACTOR: 5.107
  Keywords: Data quality, Main path analysis, Knowledge diffusion, Citation analysis,
    Social network analysis, Big data
  SCI_FACTOR: 1.605
  Title: 'Knowledge diffusion path analysis of data quality literature: A main path
    analysis'
  Title_JCS: Journal of Informetrics
  Title_SCI: Journal of Informetrics
  Type_Publication: article
  Year: 2014
- Abstract: This study presents a unique approach in investigating the knowledge diffusion
    structure for the field of data quality through an analysis of the main paths.
    We study a dataset of 1880 papers to explore the knowledge diffusion path, using
    citation data to build the citation network. The main paths are then investigated
    and visualized via social network analysis. This paper takes three different main
    path analyses, namely local, global, and key-route, to depict the knowledge diffusion
    path and additionally implements the g-index and h-index to evaluate the most
    important journals and researchers in the data quality domain.
  Author: Yu Xiao and Louis Y.Y. Lu and John S. Liu and Zhili Zhou
  Book_Title_Journal: Journal of Informetrics
  DOI: https://doi.org/10.1016/j.joi.2014.05.001
  JCS_FACTOR: 5.107
  Keywords: Data quality, Main path analysis, Knowledge diffusion, Citation analysis,
    Social network analysis, Big data
  SCI_FACTOR: 1.605
  Title: 'Knowledge diffusion path analysis of data quality literature: A main path
    analysis'
  Title_JCS: Journal of Informetrics
  Title_SCI: Journal of Informetrics
  Type_Publication: article
  Year: 2014
- Abstract: Machine learning is a dynamic field with wide-ranging applications, including
    drought modeling and forecasting. Drought is a complex, devastating natural disaster
    for which it is challenging to develop effective prediction models. Therefore,
    our review focuses on basic information about machine learning methods (MLMs)
    and their potential applications in developing efficient and effective drought
    forecasting models. We observed that MLMs have achieved significant advances in
    the robustness, effectiveness, and accuracy of the algorithms for drought modelling
    in recent years. The performance comparison of MLMs with other models provides
    a comprehensive conception of different model evaluation metrics. Further challenges
    of MLMs, such as inadequate training data sets, noise, outliers, and observation
    bias for spatial data sets, are explored. Finally, our review conveys in-depth
    understanding to researchers on machine learning applications in forecasting and
    modeling and provides drought mitigation strategy guidance for policymakers.
  Author: Foyez Ahmed Prodhan and Jiahua Zhang and Shaikh Shamim Hasan and Til Prasad
    {Pangali Sharma} and Hasiba Pervin Mohana
  Book_Title_Journal: Environmental Modelling & Software
  DOI: https://doi.org/10.1016/j.envsoft.2022.105327
  JCS_FACTOR: 5.288
  Keywords: Machine learning, Deep learning, Forecasting, Drought, Big data
  SCI_FACTOR: 0.0
  Title: 'A review of machine learning methods for drought hazard monitoring and forecasting:
    Current research trends, challenges, and future research directions'
  Title_JCS: ENVIRONMENTAL MODELLING & SOFTWARE
  Title_SCI: N/A
  Type_Publication: article
  Year: 2022
- Abstract: "This paper presents a knowledge infrastructure which has recently been\
    \ implemented as a genuine novelty at the leading Swedish mountain tourism destination,\
    \ \xC3\u2026re. By applying a Business Intelligence approach, the Destination\
    \ Management Information System \xC3\u2026re (DMIS-\xC3\u2026re) drives knowledge\
    \ creation and application as a precondition for organizational learning at tourism\
    \ destinations. Schianetz, Kavanagh, and Lockington\xE2\u20AC\u2122s (2007) concept\
    \ of the \xE2\u20AC\u02DCLearning Tourism Destination\xE2\u20AC\u2122 and the\
    \ \xE2\u20AC\u02DCKnowledge Destination Framework\xE2\u20AC\u2122 introduced by\
    \ H\xC3\xB6pken, Fuchs, Keil, and Lexhagen (2011) build the theoretical fundament\
    \ for the technical architecture of the presented Business Intelligence application.\
    \ After having introduced the development process of indicators measuring destination\
    \ performance as well as customer behaviour and experience, the paper highlights\
    \ how DMIS-\xC3\u2026re can be used by tourism managers to gain new knowledge\
    \ about customer-based destination processes focused on pre- and post-travel phases,\
    \ like \xE2\u20AC\u0153Web-Navigation\xE2\u20AC\x9D, \xE2\u20AC\u0153Booking\xE2\
    \u20AC\x9D and \xE2\u20AC\u0153Feedback\xE2\u20AC\x9D. After a concluding discussion\
    \ about the various components building the prototypically implemented BI-based\
    \ DMIS infrastructure with data from destination stakeholders, the agenda of future\
    \ research is sketched. The agenda considers, for instance, the application of\
    \ real-time Business Intelligence to gain real-time knowledge on tourists\xE2\u20AC\
    \u2122 on-site behaviour at tourism destinations."
  Author: "Matthias Fuchs and Wolfram H\xC3\xB6pken and Maria Lexhagen"
  Book_Title_Journal: Journal of Destination Marketing & Management
  DOI: https://doi.org/10.1016/j.jdmm.2014.08.002
  JCS_FACTOR: 6.952
  Keywords: Big data analytics, Tourism destination, Destination management information
    system, Business intelligence, Data mining, Online Analytical Processing (OLAP)
  SCI_FACTOR: 0.0
  Title: "Big data analytics for knowledge generation in tourism destinations \xE2\
    \u20AC\u201C A case from Sweden"
  Title_JCS: Journal of Destination Marketing & Management
  Title_SCI: N/A
  Type_Publication: article
  Year: 2014
- Abstract: Machine learning (ML) is expected to transform the business landscape
    in the near future completely. Hitherto, some successful ML case-stories have
    emerged. However, how organizations can derive business value (BV) from ML has
    not yet been substantiated. We assemble a conceptual model, grounded on the dynamic
    capabilities theory, to uncover key drivers of ML BV, in terms of financial and
    strategic performance. The proposed model was assessed by surveying 319 corporations.
    Our findings are that ML use, big data analytics maturity, platform maturity,
    top management support, and process complexity are, to some extent, drivers of
    ML BV. We also find that platform maturity has, to some degree, a moderator influence
    between ML use and ML BV, and between big data analytics maturity and ML BV. To
    the best of our knowledge, this is the first research to deliver such findings
    in the ML field.
  Author: Carolina Reis and Pedro Ruivo and Tiago Oliveira and Paulo Faroleiro
  Book_Title_Journal: Journal of Business Research
  DOI: https://doi.org/10.1016/j.jbusres.2020.05.053
  JCS_FACTOR: 7.55
  Keywords: Machine learning, Business value, Competitive advantage, Dynamic capabilities
    theory
  SCI_FACTOR: 2.049
  Title: Assessing the drivers of machine learning business value
  Title_JCS: JOURNAL OF BUSINESS RESEARCH
  Title_SCI: Journal of Business Research
  Type_Publication: article
  Year: 2020
- Abstract: Data analytics has gained importance in human resource management (HRM)
    for its ability to provide insights based on data-driven decision-making processes.
    However, integrating an analytics-based approach in HRM is a complex process,
    and hence, many organizations are unable to adopt HR Analytics (HRA). Using a
    framework synthesis approach, we first identify the challenges that hinder the
    practice of HRA and then develop a framework to explain the different factors
    that impact the adoption of HRA within organizations. This study identifies the
    key aspects related to the technological, organizational, environmental, data
    governance, and individual factors that influence the adoption of HRA. In addition,
    this paper determines 23 sub-dimensions of these five factors as the crucial aspects
    for successfully implementing and practicing HRA within organizations. We also
    discuss the implications of the framework for HR leaders, HR Managers, CEOs, IT
    Managers and consulting practitioners for effective adoption of HRA in organization.
  Author: Sateesh.V. Shet and Tanuj Poddar and Fosso {Wamba Samuel} and Yogesh K.
    Dwivedi
  Book_Title_Journal: Journal of Business Research
  DOI: https://doi.org/10.1016/j.jbusres.2021.03.054
  JCS_FACTOR: 7.55
  Keywords: Human resource analytics, HRM analytics, People analytics, Adoption of
    HR analytics, Challenges, Implementation of HR analytics, Big data, Data analytics,
    Framework synthesis
  SCI_FACTOR: 2.049
  Title: "Examining the determinants of successful adoption of data analytics in human\
    \ resource management \xE2\u20AC\u201C A framework for implications"
  Title_JCS: JOURNAL OF BUSINESS RESEARCH
  Title_SCI: Journal of Business Research
  Type_Publication: article
  Year: 2021
- Abstract: "Improving the operational energy efficiency of existing ships is attracting\
    \ considerable interests to reduce the environmental footprint due to air emissions.\
    \ As the shipping industry is entering into Shipping 4.0 with digitalization as\
    \ a disruptive force, an intriguing area in the field of ship\xE2\u20AC\u2122\
    s operational energy efficiency is big data analytics. This paper proposes a big\
    \ data analytics framework for ship performance monitoring under localized operational\
    \ conditions with the help of appropriate data analytics together with domain\
    \ knowledge. The proposed framework is showcased through a data set obtained from\
    \ a bulk carrier pertaining the detection of data anomalies, the investigation\
    \ of the ship\xE2\u20AC\u2122s localized operational conditions, the identification\
    \ of the relative correlations among parameters and the quantification of the\
    \ ship\xE2\u20AC\u2122s performance in each of the respective conditions. The\
    \ novelty of this study is to provide a KPI (i.e. key performance indicator) for\
    \ ship performance quantification in order to identify the best performance trim-draft\
    \ mode under the engine modes of the case study ship. The proposed framework has\
    \ the features to serve as an operational energy efficiency measure to provide\
    \ data quality evaluation and decision support for ship performance monitoring\
    \ that is of value for both ship operators and decision-makers."
  Author: Khanh Q. Bui and Lokukaluge P. Perera
  Book_Title_Journal: Ocean Engineering
  DOI: https://doi.org/10.1016/j.oceaneng.2021.109392
  JCS_FACTOR: 3.795
  Keywords: Big data analytics, Machine learning, Ship performance monitoring, Energy
    efficiency, Emission control, Data anomaly detection
  SCI_FACTOR: 1.321
  Title: Advanced data analytics for ship performance monitoring under localized operational
    conditions
  Title_JCS: OCEAN ENGINEERING
  Title_SCI: Ocean Engineering
  Type_Publication: article
  Year: 2021
- Abstract: During the execution of business processes involving various organizations,
    Master Data is usually shared and exchanged. It is necessary to keep appropriate
    levels of quality in these Master Data in order to prevent problems in the business
    processes. Organizations can be benefitted from having information about the level
    of quality of master data along with the master data to support decision about
    the usage of data in business processes is to include information about the level
    of quality alongside the Master Data. ISO 8000-1x0 specifies how to add this information
    to the master data messages. From the clauses stated in the various part of standard
    we developed a reference architecture, enhanced with big data technologies to
    better support the management of large datasets The main contribution of this
    paper is a service architecture for Master Data Exchange supporting the requirements
    stated by the different parts of the standard like the development of a data dictionary
    with master data terms; a communication protocol; an API to manage the master
    data messages; and the algorithms in MapReduce to measure the data quality.
  Author: Bibiano Rivas and Jorge Merino and Ismael Caballero and Manuel Serrano and
    Mario Piattini
  Book_Title_Journal: Computer Standards & Interfaces
  DOI: https://doi.org/10.1016/j.csi.2016.10.004
  JCS_FACTOR: 2.487
  Keywords: Master data, Data quality, ISO 8000, Big data
  SCI_FACTOR: 0.0
  Title: Towards a service architecture for master data exchange based on ISO 8000
    with support to process large datasets
  Title_JCS: COMPUTER STANDARDS & INTERFACES
  Title_SCI: N/A
  Type_Publication: article
  Year: 2017
- Abstract: 'This article provides an overview of extant literature addressing consumer
    interaction with cutting-edge technologies. Six focal cutting-edge technologies
    are identified: artificial intelligence, augmented reality, virtual reality, wearable
    technology, robotics and big data analytics. Our analysis shows research on consumer
    interaction with cutting-edge technologies is at a nascent stage, and there are
    several gaps requiring attention. To further advance knowledge, our article offers
    avenues for future interdisciplinary research addressing implications of consumer
    interaction with cutting-edge technologies. More specifically, we propose six
    main areas for future research namely: rethinking consumer behaviour models, identifying
    behavioural differences among different generations of consumers, understanding
    how consumers interact with automated services, ethics, privacy and the blackbox,
    consumer security concerns and consumer interaction with new-age technologies
    during and after a major global crisis such as the COVID-19 pandemic.'
  Author: Nisreen Ameen and Sameer Hosany and Ali Tarhini
  Book_Title_Journal: Computers in Human Behavior
  DOI: https://doi.org/10.1016/j.chb.2021.106761
  JCS_FACTOR: 6.829
  Keywords: Consumer interaction, Cutting-edge technologies, Artificial intelligence,
    Virtual reality and augmented reality, Robotics, Wearable technology, Big data
    analytics
  SCI_FACTOR: 2.108
  Title: 'Consumer interaction with cutting-edge technologies: Implications for future
    research'
  Title_JCS: COMPUTERS IN HUMAN BEHAVIOR
  Title_SCI: Computers in Human Behavior
  Type_Publication: article
  Year: 2021
- Abstract: Efficient and reliable analysis of chemical analytical data is a great
    challenge due to the increase in data size, variety and velocity. New methodologies,
    approaches and methods are being proposed not only by chemometrics but also by
    other data scientific communities to extract relevant information from big datasets
    and provide their value to different applications. Besides common goal of big
    data analysis, different perspectives and terms on big data are being discussed
    in scientific literature and public media. The aim of this comprehensive review
    is to present common trends in the analysis of chemical analytical data across
    different data scientific fields together with their data type-specific and generic
    challenges. Firstly, common data science terms used in different data scientific
    fields are summarized and discussed. Secondly, systematic methodologies to plan
    and run big data analysis projects are presented together with their steps. Moreover,
    different analysis aspects like assessing data quality, selecting data pre-processing
    strategies, data visualization and model validation are considered in more detail.
    Finally, an overview of standard and new data analysis methods is provided and
    their suitability for big analytical chemical datasets shortly discussed.
  Author: "Ewa Szyma\xC5\u201Eska"
  Book_Title_Journal: Analytica Chimica Acta
  DOI: https://doi.org/10.1016/j.aca.2018.05.038
  JCS_FACTOR: 6.558
  Keywords: Chemometrics, Data science, Big data, Chemical analytical data, Methodology
  SCI_FACTOR: 1.403
  Title: "Modern data science for analytical chemical data \xE2\u20AC\u201C A comprehensive\
    \ review"
  Title_JCS: ANALYTICA CHIMICA ACTA
  Title_SCI: Analytica Chimica Acta
  Type_Publication: article
  Year: 2018
- Abstract: "Introduction\nUntil the recent approval of immunotherapy after completing\
    \ concurrent chemoradiotherapy (CCRT), there has been little progress in treating\
    \ unresectable stage III non-small cell lung cancer (NSCLC). This prompted us\
    \ to search real-world data (RWD) to better understand diagnosis and treatment\
    \ patterns, and outcomes.\nMethods\nThis non-interventional observational study\
    \ used a unique, novel algorithm for big data analysis to collect and assess anonymized\
    \ patient electronic medical records from a clinical data warehouse (CDW) over\
    \ a 10-year period to capture real-world patterns of diagnosis, treatment, and\
    \ outcomes of stage III NSCLC patients. We describe real-world patterns of diagnosis\
    \ and treatment of patients with newly-diagnosed stage III NSCLC, and patients\xE2\
    \u20AC\u2122 characteristics, and assessment of treatment outcomes.\nResults\n\
    We analyzed clinical variables from 23,735 NSCLC patients. Stage III patients\
    \ (N\xE2\u20AC\xAF=\xE2\u20AC\xAF4138, 18.2 %) were diagnosed as IIIA (N\xE2\u20AC\
    \xAF=\xE2\u20AC\xAF2,547, 11.2 %) or IIIB (N\xE2\u20AC\xAF=\xE2\u20AC\xAF1,591.\
    \ 7.0 %). Treated stage III patients (N\xE2\u20AC\xAF=\xE2\u20AC\xAF2530, 61.1\
    \ %) had a median age of 64.2 years, were mostly male (78.5 %) and had an ECOG\
    \ performance status of 1 (65.2 %). Treatment comprised curative-intent surgery\
    \ (N\xE2\u20AC\xAF=\xE2\u20AC\xAF1,254, 49.6 %) with 705 receiving neoadjuvant\
    \ therapy; definitive CRT (N\xE2\u20AC\xAF=\xE2\u20AC\xAF648, 25.6 %); palliative\
    \ CT (N\xE2\u20AC\xAF=\xE2\u20AC\xAF270, 10.7 %), or thoracic RT (N\xE2\u20AC\xAF\
    =\xE2\u20AC\xAF170, 6.7 %). Median OS (range) for neoadjuvant, surgery, CRT, palliative\
    \ chemotherapy, lung RT alone, and supportive care was 49.2 (42.0\xE2\u20AC\u201C\
    56.5), 52.5 (43.1\xE2\u20AC\u201C61.9), 30.3 (26.6\xE2\u20AC\u201C34.0), 14.7\
    \ (13.0\xE2\u20AC\u201C16.4), 8.8 (6.2\xE2\u20AC\u201C11.3), and 2.0 (1.0\xE2\u20AC\
    \u201C3.0) months, respectively.\nConclusions\nThis unique in-house algorithm\
    \ enabled a rapid and comprehensive analysis of big data through a CDW, with daily\
    \ automatic updates that documented real-world PFS and OS consistent with the\
    \ published literature, and real-world treatment patterns and clinical outcomes\
    \ in stage III NSCLC patients."
  Author: Hyun Ae Jung and Jong-Mu Sun and Se-Hoon Lee and Jin Seok Ahn and Myung-Ju
    Ahn and Keunchil Park
  Book_Title_Journal: Lung Cancer
  DOI: https://doi.org/10.1016/j.lungcan.2020.05.033
  JCS_FACTOR: 5.705
  Keywords: Real-time updated system, Big data, Real-world data, NSCLC, Treatment
  SCI_FACTOR: 1.989
  Title: 'Ten-year patient journey of stage III non-small cell lung cancer patients:
    A single-center, observational, retrospective study in Korea (Realtime autOmatically
    updated data warehOuse in healTh care; UNIVERSE-ROOT study)'
  Title_JCS: LUNG CANCER
  Title_SCI: Lung Cancer
  Type_Publication: article
  Year: 2020
- Abstract: "In the age of big data, intelligence, and Industry 4.0, intelligence\
    \ plays an increasingly significant role in management or, more specifically,\
    \ decision making; thus, it becomes a popular topic and is recognised as an important\
    \ discipline. Hence, safety intelligence (SI) as a new safety concept and term\
    \ was proposed. SI aims to transform raw safety data and information into meaningful\
    \ and actionable information for safety management; it is considered an essential\
    \ perspective for safety management in the era of Safety 4.0 (computational safety\
    \ science\xE2\u20AC\u201Da new paradigm for safety science in the age of big data,\
    \ intelligence, and Industry 4.0). However, thus far, no existing research provides\
    \ a framework that comprehensively describes SI and guides the implementation\
    \ of SI practices in organisations. To address this research gap and to provide\
    \ a framework for SI and its practice in the context of safety management, based\
    \ on a systematic and comprehensive explanation on SI from different perspectives,\
    \ this study attempts to propose a theoretical framework for SI from a safety\
    \ management perspective and then presents an SI practice model aimed at supporting\
    \ safety management in organisations."
  Author: Bing Wang
  Book_Title_Journal: Process Safety and Environmental Protection
  DOI: https://doi.org/10.1016/j.psep.2020.10.008
  JCS_FACTOR: 6.158
  Keywords: Safety intelligence (SI), Safety big data, Safety 4.0, Safety management,
    Safety decision-making
  SCI_FACTOR: 1.173
  Title: 'Safety intelligence as an essential perspective for safety management in
    the era of Safety 4.0: From a theoretical to a practical framework'
  Title_JCS: PROCESS SAFETY AND ENVIRONMENTAL PROTECTION
  Title_SCI: Process Safety and Environmental Protection
  Type_Publication: article
  Year: 2021
- Abstract: The increased availability of social media big data has created a unique
    challenge for marketing decision-makers; turning this data into useful information.
    One of the significant areas of opportunity in digital marketing is influencer
    marketing, but identifying these influencers from big data sets is a continual
    challenge. This research illustrates how one type of influencer, the market maven,
    can be identified using big data. Using a mixed-method combination of both self-report
    survey data and publicly accessible big data, we gathered 556,150 tweets from
    370 active Twitter users. We then proposed and tested a range of social-media-based
    metrics to identify market mavens. Findings show that market mavens (when compared
    to non-mavens) have more followers, post more often, have less readable posts,
    use more uppercase letters, use less distinct words, and use hashtags more often.
    These metrics are openly available from public Twitter accounts and could integrate
    into a broad-scale decision support system for marketing and information systems
    managers. These findings have the potential to improve influencer identification
    effectiveness and efficiency, and thus improve influencer marketing.
  Author: Paul Harrigan and Timothy M. Daly and Kristof Coussement and Julie A. Lee
    and Geoffrey N. Soutar and Uwana Evers
  Book_Title_Journal: International Journal of Information Management
  DOI: https://doi.org/10.1016/j.ijinfomgt.2020.102246
  JCS_FACTOR: 14.098
  Keywords: Influencers, Market mavens, Big data, Social media, Twitter
  SCI_FACTOR: 2.77
  Title: Identifying influencers on social media
  Title_JCS: INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
  Title_SCI: International Journal of Information Management
  Type_Publication: article
  Year: 2021
- Abstract: "With continuous collaborative research in sensor technology, communication\
    \ technology, plant science, computer science and engineering science, Internet\
    \ of Things (IoT) in agriculture has made a qualitative leap through environmental\
    \ sensor networks, non-destructive imaging, spectral analysis, robotics, machine\
    \ vision and laser radar technology. Physical and chemical analysis can continuously\
    \ obtain environmental data, experimental metadata (including text, image and\
    \ spectral, 3D point cloud and real-time growth data) through integrated automation\
    \ platform equipment and technical means. Based on data on multi-scale, multi-environmental\
    \ and multi-mode plant traits that constitute big data on plant phenotypes, genotype\xE2\
    \u20AC\u201Cphenotype\xE2\u20AC\u201Cenvirotype relationship in the omics system\
    \ can be explored deeply. Detailed information on the formation mechanism of specific\
    \ biological traits can promote the process of functional genomics, plant molecular\
    \ breeding and efficient cultivation. This study summarises the development background,\
    \ research process and characteristics of high-throughput plant phenotypes. A\
    \ systematic review of the research progress of IoT in agriculture and plant high-throughput\
    \ phenotypes is conducted, including the acquisition and analysis of plant phenotype\
    \ big data, phenotypic trait prediction and multi-recombination analysis based\
    \ on plant phenomics. This study proposes key techniques for current plant phenotypes,\
    \ and looks forward to the research on plant phenotype detection technology in\
    \ the field environment, fusion and data mining of plant phenotype multivariate\
    \ data, simultaneous observation of multi-scale phenotype platform and promotion\
    \ of a comprehensive high-throughput phenotype technology."
  Author: Jiangchuan Fan and Ying Zhang and Weiliang Wen and Shenghao Gu and Xianju
    Lu and Xinyu Guo
  Book_Title_Journal: Journal of Cleaner Production
  DOI: https://doi.org/10.1016/j.jclepro.2020.123651
  JCS_FACTOR: 9.297
  Keywords: Internet of things in agriculture, Big data, High-throughput phenotype,
    Data mining
  SCI_FACTOR: 1.937
  Title: 'The future of Internet of Things in agriculture: Plant high-throughput phenotypic
    platform'
  Title_JCS: Journal of Cleaner Production
  Title_SCI: Journal of Cleaner Production
  Type_Publication: article
  Year: 2021
- Abstract: "The energy industry is at a crossroads. Digital technological developments\
    \ have the potential to change our energy supply, trade, and consumption dramatically.\
    \ The new digitalization model is powered by the artificial intelligence (AI)\
    \ technology. The integration of energy supply, demand, and renewable sources\
    \ into the power grid will be controlled autonomously by smart software that optimizes\
    \ decision-making and operations. AI will play an integral role in achieving this\
    \ goal. This study focuses on the use of AI techniques in the energy sector. This\
    \ study aims to present a realistic baseline that allows researchers and readers\
    \ to compare their AI efforts, ambitions, new state-of-the-art applications, challenges,\
    \ and global roles in policymaking. We covered three major aspects, including:\
    \ i) the use of AI in solar and hydrogen power generation; (ii) the use of AI\
    \ in supply and demand management control; and (iii) recent advances in AI technology.\
    \ This study explored how AI techniques outperform traditional models in controllability,\
    \ big data handling, cyberattack prevention, smart grid, IoT, robotics, energy\
    \ efficiency optimization, predictive maintenance control, and computational efficiency.\
    \ Big data, the development of a machine learning model, and AI will play an important\
    \ role in the future energy market. Our study\xE2\u20AC\u2122s findings show that\
    \ AI is becoming a key enabler of a complex, new and data-related energy industry,\
    \ providing a key magic tool to increase operational performance and efficiency\
    \ in an increasingly cut-throat environment. As a result, the energy industry,\
    \ utilities, power system operators, and independent power producers may need\
    \ to focus more on AI technologies if they want meaningful results to remain competitive.\
    \ New competitors, new business strategies, and a more active approach to customers\
    \ would require informed and flexible regulatory engagement with the associated\
    \ complexities of customer safety, privacy, and information security. Given the\
    \ pace of development in information technology, AI and data analysis, regulatory\
    \ approvals for new services and products in the new Era of digital energy markets\
    \ can be enforced as quickly and efficiently as possible."
  Author: Tanveer Ahmad and Dongdong Zhang and Chao Huang and Hongcai Zhang and Ningyi
    Dai and Yonghua Song and Huanxin Chen
  Book_Title_Journal: Journal of Cleaner Production
  DOI: https://doi.org/10.1016/j.jclepro.2021.125834
  JCS_FACTOR: 9.297
  Keywords: Artificial intelligence, Renewable energy, Energy demand, Decision making,
    Big data, Energy digitization
  SCI_FACTOR: 1.937
  Title: 'Artificial intelligence in sustainable energy industry: Status Quo, challenges
    and opportunities'
  Title_JCS: Journal of Cleaner Production
  Title_SCI: Journal of Cleaner Production
  Type_Publication: article
  Year: 2021
- Abstract: The Internet of Things (IoT) and the relevant technologies have had a
    significant impact on smart farming as a major sub-domain within the field of
    agriculture. Modern technology supports data collection from IoT devices through
    several farming processes. The extensive amount of collected smart farming data
    can be utilized for daily decision making and analysis such as yield prediction,
    growth analysis, quality maintenance, animal and aquaculture, as well as farm
    management. This survey focuses on three major aspects of contemporary smart farming.
    First, it highlights various types of big data generated through smart farming
    and makes a broad categorization of such data. Second, this paper discusses a
    comprehensive set of typical applications of big data in smart farming. Third,
    it identifies and introduces the principal big data and machine learning techniques
    that are utilized in smart farming data analysis. In doing so, this survey also
    identifies some of the major, current challenges in smart farming big data analysis.This
    paper provides a discussion on potential pathways toward more effective smart
    farming through relevant analytics-guided decision making.
  Author: Sandya De Alwis and Ziwei Hou and Yishuo Zhang and Myung Hwan Na and Bahadorreza
    Ofoghi and Atul Sajjanhar
  Book_Title_Journal: Computers in Industry
  DOI: https://doi.org/10.1016/j.compind.2022.103624
  JCS_FACTOR: 7.635
  Keywords: Smart farming, Data analysis, Big data, Machine learning, Digital farming,
    Predictive farming, Farming industry
  SCI_FACTOR: 1.432
  Title: A survey on smart farming data, applications and techniques
  Title_JCS: COMPUTERS IN INDUSTRY
  Title_SCI: Computers in Industry
  Type_Publication: article
  Year: 2022
- Abstract: Modern artificial intelligence techniques have solved some previously
    intractable problems and produced impressive results in selected medical domains.
    One of their drawbacks is that they often need very large amounts of data. Pre-existing
    datasets in the form of national cancer registries, image/genetic depositories
    and clinical datasets already exist and have been used for research. In theory,
    the combination of healthcare Big Data with modern, data-hungry artificial intelligence
    techniques should offer significant opportunities for artificial intelligence
    development, but this has not yet happened. Here we discuss some of the structural
    reasons for this, barriers preventing artificial intelligence from making full
    use of existing datasets, and make suggestions as to enable progress. To do this,
    we use the framework of the 6Vs of Big Data and the FAIR criteria for data sharing
    and availability (Findability, Accessibility, Interoperability, and Reuse). We
    share our experience in navigating these barriers through The Brain Tumour Data
    Accelerator, a Brain Tumour Charity-supported initiative to integrate fragmented
    patient data into an enriched dataset. We conclude with some comments as to the
    limits of such approaches.
  Author: J.W. Wang and M. Williams
  Book_Title_Journal: Clinical Oncology
  DOI: https://doi.org/10.1016/j.clon.2021.11.040
  JCS_FACTOR: 4.126
  Keywords: Artificial intelligence, Big Data, database, deep learning, registries,
    repository
  SCI_FACTOR: 1.037
  Title: Registries, Databases and Repositories for Developing Artificial Intelligence
    in Cancer Care
  Title_JCS: CLINICAL ONCOLOGY
  Title_SCI: Clinical Oncology
  Type_Publication: article
  Year: 2022
- Abstract: "Huge volumes of data are generated at rates faster than the speed of\
    \ computing resources and executing processors available in market place. This\
    \ anticipates a draft of information challenges associated with the performance\
    \ capacity and the ability of big data processing systems to retort in real-time.\
    \ Moreover, the elapsed time between probabilistic failures drops as the scale\
    \ of information increases. An error occurred at a specific cluster node of a\
    \ large Cyber\xE2\u20AC\u201CPhysical System influences the overall computation\
    \ requires to unfold big data transactions. Numerous failure characteristics,\
    \ statistical response time and lifetime evaluation can be modeled through Weibull\
    \ Distribution. In this paper, to scrutinize the latency for a data infrastructure,\
    \ the three-parameter Weibull Cumulative Distribution is used through software\
    \ defined networking in cyber\xE2\u20AC\u201Cphysical system. This speculation\
    \ predicts that the shape of the response time distribution confide in the shape\
    \ of the learning curve and depicts its parameters to the criterion of the input\
    \ distribution."
  Author: Gifty R. and Bharathi R.
  Book_Title_Journal: Computer Communications
  DOI: https://doi.org/10.1016/j.comcom.2019.11.018
  JCS_FACTOR: 3.167
  Keywords: "Cyber\xE2\u20AC\u201CPhysical Systems (CPS), Weibull Cumulative Distribution,\
    \ Big data, Response time"
  SCI_FACTOR: 0.627
  Title: "Weibull Cumulative Distribution based real-time response and performance\
    \ capacity modeling of Cyber\xE2\u20AC\u201CPhysical Systems through software\
    \ defined networking"
  Title_JCS: COMPUTER COMMUNICATIONS
  Title_SCI: Computer Communications
  Type_Publication: article
  Year: 2020
- Abstract: Building heat demand is responsible for a significant share of the total
    global final energy consumption. Building stock models with a high spatio-temporal
    resolution are a powerful tool to investigate the effects of new building policies
    aimed at increasing energy efficiency, the introduction of new heating technologies
    or the integration of buildings within an energy system based on renewable energy
    sources. Therefore, building stock models have to be able to model the improvements
    and variation of used materials in buildings. In this paper, we propose a method
    based on generalized large-scale geographic information system (GIS) to model
    building heat demand of large regions with a high temporal resolution. In contrast
    to existing building stock models, our approach allows to derive the envelope
    of all buildings from digital elevation models and to model location dependent
    effects such as shadowing due to the topography and climate conditions. We integrate
    spatio-temporal climate data for temperature and solar radiation to model climate
    effects of complex terrain. The model is validated against a database containing
    the measured energy demand of 1845 buildings of the city of St. Gallen, Switzerland
    and 120 buildings of the Alpine village of Zernez, Switzerland. The proposed model
    is able to assess and investigate large regions by using spatial data describing
    natural and anthropogenic land features. The validation resulted in an average
    goodness of fit (R2) of 0.6.
  Author: "Ren\xC3\xA9 Buffat and Andreas Froemelt and Niko Heeren and Martin Raubal\
    \ and Stefanie Hellweg"
  Book_Title_Journal: Applied Energy
  DOI: https://doi.org/10.1016/j.apenergy.2017.10.041
  JCS_FACTOR: 9.746
  Keywords: Building heat demand, Big data, Large scale modelling, Bottom-up modelling,
    GIS, Climate data, Spatio-temporal modelling
  SCI_FACTOR: 3.035
  Title: Big data GIS analysis for novel approaches in building stock modelling
  Title_JCS: APPLIED ENERGY
  Title_SCI: Applied Energy
  Type_Publication: article
  Year: 2017
- Abstract: Although big data, big data analytics (BDA) and business intelligence
    have attracted growing attention of both academics and practitioners, a lack of
    clarity persists about how BDA has been applied in business and management domains.
    In reflecting on Professor Ayre's contributions, we want to extend his ideas on
    technological change by incorporating the discourses around big data, BDA and
    business intelligence. With this in mind, we integrate the burgeoning but disjointed
    streams of research on big data, BDA and business intelligence to develop unified
    frameworks. Our review takes on both technical and managerial perspectives to
    explore the complex nature of big data, techniques in big data analytics and utilisation
    of big data in business and management community. The advanced analytics techniques
    appear pivotal in bridging big data and business intelligence. The study of advanced
    analytics techniques and their applications in big data analytics led to identification
    of promising avenues for future research.
  Author: Jie Sheng and Joseph Amankwah-Amoah and Xiaojun Wang
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2018.06.009
  JCS_FACTOR: 8.593
  Keywords: Business intelligence, Big data, Big data analytics, Advanced techniques,
    Decision-making
  SCI_FACTOR: 2.226
  Title: 'Technology in the 21st century: New challenges and opportunities'
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2019
- Abstract: "Smart Sustainable Cities (SSC) consist of multiple stakeholders, who\
    \ must cooperate in order for SSCs to be successful. Housing is an important challenge\
    \ and in many cities, therefore, a key stakeholder are social housing organisations.\
    \ This paper introduces a qualitative case study of a social housing provider\
    \ in the UK who implemented a business intelligence project (a method to assess\
    \ data networks within an organisation) to increase data quality and data interoperability.\
    \ Our analysis suggests that creating pathways for different information systems\
    \ within an organisation to \xE2\u20AC\u02DCtalk to\xE2\u20AC\u2122 each other\
    \ is the first step. Some of the issues during the project implementation include\
    \ the lack of training and development, organisational reluctance to change, and\
    \ the lack of a project plan. The challenges faced by the organisation during\
    \ this project can be helpful for those implementing SSCs. Currently, many SSC\
    \ frameworks and models exist, yet most seem to neglect localised challenges faced\
    \ by the different stakeholders. This paper hopes to help bridge this gap in the\
    \ SSC research agenda."
  Author: Caroline Duvier and P.B. Anand and Crina Oltean-Dumbrava
  Book_Title_Journal: Sustainable Cities and Society
  DOI: https://doi.org/10.1016/j.scs.2018.02.015
  JCS_FACTOR: 7.587
  Keywords: Data quality, Data interoperability, Social housing, Smart sustainable
    cities, Business intelligence
  SCI_FACTOR: 1.645
  Title: 'Data quality and governance in a UK social housing initiative: Implications
    for smart sustainable cities'
  Title_JCS: Sustainable Cities and Society
  Title_SCI: Sustainable Cities and Society
  Type_Publication: article
  Year: 2018
- Abstract: "Six Sigma is one of the most successful quality management philosophies\
    \ of the past 20 years. However, the current challenges facing companies, such\
    \ as rising process and supply chain complexity, as well as high volumes of unstructured\
    \ data, cannot easily be answered by relying on traditional Six Sigma tools. Instead,\
    \ the Process Mining (PM) technology using big data analytics promises valuable\
    \ support for 6S and its data analysis capabilities. The article presents a design\
    \ science research project in which a method for the integration of PM in Six\
    \ Sigma\xE2\u20AC\u2122s DMAIC project structure was developed. This method could\
    \ be extended, refined and tested during three evaluation cycles: an expert evaluation\
    \ with Six Sigma professionals, a technical experiment and finally a multi case\
    \ study in a company. The method therefore was eventually endorsed by 6S experts\
    \ and successfully applied in a first pilot setting. This article presents the\
    \ first developed method for the integration of PM and Six Sigma. It follows the\
    \ recommendations of many researchers to test Six Sigma as an application field\
    \ of PM as well as using the potential of big data analytics. The method can be\
    \ used by researchers and practitioners alike to implement, test and verify its\
    \ design in organisations."
  Author: I. Kregel and D. Stemann and J. Koch and A. Coners
  Book_Title_Journal: Computers & Industrial Engineering
  DOI: https://doi.org/10.1016/j.cie.2020.107083
  JCS_FACTOR: 5.431
  Keywords: process mining, six sigma, DMAIC, big data analytics, data science, project
    management
  SCI_FACTOR: 0.0
  Title: 'Process Mining for Six Sigma: Utilising Digital Traces'
  Title_JCS: COMPUTERS & INDUSTRIAL ENGINEERING
  Title_SCI: N/A
  Type_Publication: article
  Year: 2021
- Abstract: Artificial Intelligence (AI) could be an important foundation of competitive
    advantage in the market for firms. As such, firms use AI to achieve deep market
    engagement when the firm's data are employed to make informed decisions. This
    study examines the role of computer-mediated AI agents in detecting crises related
    to events in a firm. A crisis threatens organizational performance; therefore,
    a data-driven strategy will result in an efficient and timely reflection, which
    increases the success of crisis management. The study extends the situational
    crisis communication theory (SCCT) and Attribution theory frameworks built on
    big data and machine learning capabilities for early detection of crises in the
    market. This research proposes a structural model composed of a statistical and
    sentimental big data analytics approach. The findings of our empirical research
    suggest that knowledge extracted from day-to-day data communications such as email
    communications of a firm can lead to the sensing of critical events related to
    business activities. To test our model, we use a publicly available dataset containing
    517,401 items belonging to 150 users, mostly senior managers of Enron during 1999
    through the 2001 crisis. The findings suggest that the model is plausible in the
    early detection of Enron's critical events, which can support decision making
    in the market.
  Author: Aydin Farrokhi and Farid Shirazi and Nick Hajli and Mina Tajvidi
  Book_Title_Journal: Industrial Marketing Management
  DOI: https://doi.org/10.1016/j.indmarman.2020.09.015
  JCS_FACTOR: 6.96
  Keywords: Big data, Artificial intelligence, Machine learning, Data mining, Sentiment
    analytics
  SCI_FACTOR: 2.022
  Title: 'Using artificial intelligence to detect crisis related to events: Decision
    making in B2B by artificial intelligence'
  Title_JCS: INDUSTRIAL MARKETING MANAGEMENT
  Title_SCI: Industrial Marketing Management
  Type_Publication: article
  Year: 2020
- Abstract: "The myriad potential benefits of digital farming hinge on the promise\
    \ of increased accuracy, which allows \xE2\u20AC\u02DCdoing more with less\xE2\
    \u20AC\u2122 through precise, data-driven operations. Yet, precision farming's\
    \ foundational claim of increased accuracy has hardly been the subject of comprehensive\
    \ examination. Drawing on social science studies of big data, this article examines\
    \ digital agriculture's (in)accuracies and their repercussions. Based on an examination\
    \ of the daily functioning of the various components of yield mapping, it finds\
    \ that digital farming is often \xE2\u20AC\u02DCprecisely inaccurate\xE2\u20AC\
    \u2122, with the high volume and granularity of big data erroneously equated with\
    \ high accuracy. The prevailing discourse of \xE2\u20AC\u02DCultra-precise\xE2\
    \u20AC\u2122 digital technologies ignores farmers' essential efforts in making\
    \ these technologies more accurate, via calibration, corroboration and interpretation.\
    \ We suggest that there is the danger of a \xE2\u20AC\u02DCprecision trap\xE2\u20AC\
    \u2122. Namely, an exaggerated belief in the precision of big data that over time\
    \ leads to an erosion of checks and balances (analogue data, farmer observation\
    \ et cetera) on farms. The danger of \xE2\u20AC\u02DCprecision traps\xE2\u20AC\
    \u2122 increases with the opacity of algorithms, with shifts from real-time measurement\
    \ and advice towards forecasting, and with farmers' increased remoteness from\
    \ field operations. Furthermore, we identify an emerging \xE2\u20AC\u02DCprecision\
    \ divide\xE2\u20AC\u2122: unequally distributed precision benefits resulting from\
    \ the growing algorithmic divide between farmers focusing on staple crops, catered\
    \ well by technological innovation on the one hand, and farmers cultivating other\
    \ crops, who have to make do with much less advanced or applicable algorithms\
    \ on the other. Consequently, for the latter farms digital farming may feel more\
    \ like \xE2\u20AC\u02DCimprecision farming\xE2\u20AC\u2122."
  Author: Oane Visser and Sarah Ruth Sippel and Louis Thiemann
  Book_Title_Journal: Journal of Rural Studies
  DOI: https://doi.org/10.1016/j.jrurstud.2021.07.024
  JCS_FACTOR: 4.849
  Keywords: Digital agriculture, Smart farming, Precision agriculture, Accuracy, Big
    data
  SCI_FACTOR: 1.497
  Title: Imprecision farming? Examining the (in)accuracy and risks of digital agriculture
  Title_JCS: JOURNAL OF RURAL STUDIES
  Title_SCI: Journal of Rural Studies
  Type_Publication: article
  Year: 2021
- Abstract: "The vague but vogue notion of \xE2\u20AC\u02DCbig data\xE2\u20AC\u2122\
    \ is enjoying a prolonged honeymoon. Well-funded, ambitious projects are reaching\
    \ fruition, and inferences are being drawn from inadequate data processed by inadequately\
    \ understood and often inappropriate data analytic techniques. As decisions are\
    \ made and actions taken on the basis of those inferences, harm will arise to\
    \ external stakeholders, and, over time, to internal stakeholders as well. A set\
    \ of Guidelines is presented, whose purpose is to intercept ill-advised uses of\
    \ data and analytical tools, prevent harm to important values, and assist organisations\
    \ to extract the achievable benefits from data, rather than dreaming dangerous\
    \ dreams."
  Author: Roger Clarke
  Book_Title_Journal: Computer Law & Security Review
  DOI: https://doi.org/10.1016/j.clsr.2017.11.002
  JCS_FACTOR: 2.98
  Keywords: Big data, Data science, Data quality, Decision quality, Regulation
  SCI_FACTOR: 0.0
  Title: Guidelines for the responsible application of data analytics
  Title_JCS: Computer Law & Security Review
  Title_SCI: N/A
  Type_Publication: article
  Year: 2018
- Abstract: Many SMEs still seem reluctant to accept the management of large datasets,
    which still appear to be too complex for them. However, our study reveals that
    the majority of small French car dealers are developing Big data and Smart data
    policies to improve the quality of their offers, the dynamism of their sales and
    their access to new opportunities. However, not every policy has the same effects
    on the development of their business. Whereas Big data improves all the components
    of SME development in a global, short-term and operational way, Smart data presents
    itself as a more targeted, prospective and strategic approach.
  Author: "David Salvetat and Jean-S\xC3\xA9bastien Lacam"
  Book_Title_Journal: Journal of Engineering and Technology Management
  DOI: https://doi.org/10.1016/j.jengtecman.2020.101602
  JCS_FACTOR: 3.347
  Keywords: Big data, Smart data, Development, Automobile, SME
  SCI_FACTOR: 0.0
  Title: Data determinants of the activity of SMEs automobile dealers
  Title_JCS: JOURNAL OF ENGINEERING AND TECHNOLOGY MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: Many SMEs still seem reluctant to accept the management of large datasets,
    which still appear to be too complex for them. However, our study reveals that
    the majority of small French car dealers are developing Big data and Smart data
    policies to improve the quality of their offers, the dynamism of their sales and
    their access to new opportunities. However, not every policy has the same effects
    on the development of their business. Whereas Big data improves all the components
    of SME development in a global, short-term and operational way, Smart data presents
    itself as a more targeted, prospective and strategic approach.
  Author: "David Salvetat and Jean-S\xC3\xA9bastien Lacam"
  Book_Title_Journal: Journal of Engineering and Technology Management
  DOI: https://doi.org/10.1016/j.jengtecman.2020.101602
  JCS_FACTOR: 3.347
  Keywords: Big data, Smart data, Development, Automobile, SME
  SCI_FACTOR: 0.0
  Title: Data determinants of the activity of SMEs automobile dealers
  Title_JCS: JOURNAL OF ENGINEERING AND TECHNOLOGY MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: "This study investigates the literary corpus of the role and potential\
    \ of data intelligence and analytics through the lenses of artificial intelligence\
    \ (AI), big data, and the human\xE2\u20AC\u201CAI interface to improve overall\
    \ decision-making processes. It investigates how data intelligence and analytics\
    \ improve decision-making processes in the public sector. A bibliometric analysis\
    \ of a database containing 161 English-language articles published between 2017\
    \ and 2021 is performed, providing a map of the knowledge produced and disseminated\
    \ in previous studies. It provides insights into key topics, citation patterns,\
    \ publication activities, the status of collaborations between contributors over\
    \ past studies, aggregated data intelligence, and analytics research contributions.\
    \ The study provides a retrospective review of published content in the field\
    \ of data intelligence and analytics. The findings indicate that field research\
    \ has been concentrated mainly on emerging technologies' intelligence capabilities\
    \ rather than on human\xE2\u20AC\u201Cartificial intelligence in decision-making\
    \ performance in the public sector. This study extends an ambidexterity theory\
    \ in decision support, which enlightens how this ambidexterity can be encouraged\
    \ and how it affects decision outcomes. The study emphasises the importance of\
    \ the public sector adoption of data intelligence and analytics, as well as its\
    \ efficiency. Furthermore, this study expands how researchers and practitioners\
    \ interpret and understand data intelligence and analytics, AI, and big data for\
    \ effective public sector decision-making."
  Author: Assunta {Di Vaio} and Rohail Hassan and Claude Alavoine
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2021.121201
  JCS_FACTOR: 8.593
  Keywords: Ambidexterity, Industry 4.0, Business intelligence, Big data, Intellectual
    capital, Human intellect, Accountability and performance
  SCI_FACTOR: 2.226
  Title: "Data intelligence and analytics: A bibliometric analysis of human\xE2\u20AC\
    \u201CArtificial intelligence in public sector decision-making effectiveness"
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2022
- Abstract: The fourth industrial revolution, or Industry 4.0, represents a new stage
    of evolution in the organization, management and control of the value chain throughout
    the product or service life cycle. This is mainly based on the digitalization
    of the industrial environment by means of the convergence of Information Technologies
    (IT) and operational Technologies (OT) through cyber-physical systems and the
    Industrial IoT (IIoT) and the use of data generated in real time for gaining insights
    and making decisions. Therefore data becomes a critical asset for Industry 4.0
    and must be managed and governed like a strategic asset. We rely on Data Governance
    (DG) as a key instrument for carrying out this transformation. This paper presents
    the design of a specific governance framework for Industry 4.0. First, this contextualizes
    data governance for Industry 4.0 environments and identifies the requirements
    that this framework must address, which are conditioned by the specific features
    of Industry 4.0, among others, the intensive use of big data, the cloud and edge
    computing, the artificial intelligence and the current regulations. Next, we formally
    define a reference framework for the implementation of Data Governance Systems
    for Industry 4.0 using international standards and providing several examples
    of architecture building blocks.
  Author: Marta Zorrilla and Juan Yebenes
  Book_Title_Journal: Computer Standards & Interfaces
  DOI: https://doi.org/10.1016/j.csi.2021.103595
  JCS_FACTOR: 2.487
  Keywords: Data governance, Data-Centric architecture, Industry 4.0, Big data, IoT
  SCI_FACTOR: 0.0
  Title: A reference framework for the implementation of data governance systems for
    industry 4.0
  Title_JCS: COMPUTER STANDARDS & INTERFACES
  Title_SCI: N/A
  Type_Publication: article
  Year: 2022
- Abstract: 'Data science has employed great research efforts in developing advanced
    analytics, improving data models and cultivating new algorithms. However, not
    many authors have come across the organizational and socio-technical challenges
    that arise when executing a data science project: lack of vision and clear objectives,
    a biased emphasis on technical issues, a low level of maturity for ad-hoc projects
    and the ambiguity of roles in data science are among these challenges. Few methodologies
    have been proposed on the literature that tackle these type of challenges, some
    of them date back to the mid-1990, and consequently they are not updated to the
    current paradigm and the latest developments in big data and machine learning
    technologies. In addition, fewer methodologies offer a complete guideline across
    team, project and data & information management. In this article we would like
    to explore the necessity of developing a more holistic approach for carrying out
    data science projects. We first review methodologies that have been presented
    on the literature to work on data science projects and classify them according
    to the their focus: project, team, data and information management. Finally, we
    propose a conceptual framework containing general characteristics that a methodology
    for managing data science projects with a holistic point of view should have.
    This framework can be used by other researchers as a roadmap for the design of
    new data science methodologies or the updating of existing ones.'
  Author: "I\xC3\xB1igo Martinez and Elisabeth Viles and Igor {G. Olaizola}"
  Book_Title_Journal: Big Data Research
  DOI: https://doi.org/10.1016/j.bdr.2020.100183
  JCS_FACTOR: 3.578
  Keywords: Data science, Big data, Data science methodology, Project life-cycle,
    Organizational impacts, Knowledge management
  SCI_FACTOR: 0.565
  Title: 'Data Science Methodologies: Current Challenges and Future Approaches'
  Title_JCS: Big Data Research
  Title_SCI: Big Data Research
  Type_Publication: article
  Year: 2021
- Abstract: Big data are no longer an obstacle; now, by using artificial intelligence
    (AI), previously undiscovered knowledge can be found in massive data collections.
    The radiation oncology clinic daily produces a large amount of multisource data
    and metadata during its routine clinical and research activities. These data involve
    multiple stakeholders and users. Because of a lack of interoperability, most of
    these data remain unused, and powerful insights that could improve patient care
    are lost. Changing the paradigm by introducing powerful AI analytics and a common
    vision for empowering big data in radiation oncology is imperative. However, this
    can only be achieved by creating a clinical data science community in radiation
    oncology. In this work, we present why such a community is needed to translate
    multisource data into clinical decision aids.
  Author: "Joanna Kazmierska and Andrew Hope and Emiliano Spezi and Sam Beddar and\
    \ William H. Nailon and Biche Osong and Anshu Ankolekar and Ananya Choudhury and\
    \ Andre Dekker and Kathrine R\xC3\xB8e Redalen and Alberto Traverso"
  Book_Title_Journal: Radiotherapy and Oncology
  DOI: https://doi.org/10.1016/j.radonc.2020.09.054
  JCS_FACTOR: 6.28
  Keywords: Artificial intelligence, Big data, Data science, Personalized treatment,
    Radiotherapy, Shared decision making
  SCI_FACTOR: 1.892
  Title: 'From multisource data to clinical decision aids in radiation oncology: The
    need for a clinical data science community'
  Title_JCS: RADIOTHERAPY AND ONCOLOGY
  Title_SCI: Radiotherapy and Oncology
  Type_Publication: article
  Year: 2020
- Abstract: 'Background

    Chronic diseases, such as opioid use disorder (OUD) require a multifaceted scientific
    approach to address their evolving complexity. The Council for the Advancement
    of Nursing Science''s (Council) four nursing science priority areas (precision
    health; global health, determinants of health, and big data/data analytics) were
    established to provide a framework to address current complex health problems.

    Purpose

    To examine OUD research through the nursing science priority areas and evaluate
    the appropriateness of the priority areas as a framework for research on complex
    health conditions.

    Method

    OUD was used as an exemplar to explore the relevance of the nursing science priorities
    for future research.

    Findings

    Research in the four priority areas is advancing knowledge in OUD identification,
    prevention, and treatment. Intersection of OUD research population focus and methodological
    approach was identified among the priority areas.

    Discussion

    The Council priorities provide a relevant framework for nurse scientists to address
    complex health problems like OUD.'
  Author: Patricia Eckardt and Donald Bailey and Holli A. DeVon and Cynthia Dougherty
    and Pamela Ginex and Cheryl A. Krause-Parello and Rita H. Pickler and Therese
    S. Richmond and Eleanor Rivera and Carol F. Roye and Nancy Redeker
  Book_Title_Journal: Nursing Outlook
  DOI: https://doi.org/10.1016/j.outlook.2020.02.001
  JCS_FACTOR: 3.25
  Keywords: Precision health, Big data and Data analytics, Determinants of health,
    Global health, Opioid use disorder research
  SCI_FACTOR: 0.953
  Title: Opioid use disorder research and the Council for the Advancement of Nursing
    Science priority areas
  Title_JCS: NURSING OUTLOOK
  Title_SCI: Nursing Outlook
  Type_Publication: article
  Year: 2020
- Abstract: 'Background

    Chronic diseases, such as opioid use disorder (OUD) require a multifaceted scientific
    approach to address their evolving complexity. The Council for the Advancement
    of Nursing Science''s (Council) four nursing science priority areas (precision
    health; global health, determinants of health, and big data/data analytics) were
    established to provide a framework to address current complex health problems.

    Purpose

    To examine OUD research through the nursing science priority areas and evaluate
    the appropriateness of the priority areas as a framework for research on complex
    health conditions.

    Method

    OUD was used as an exemplar to explore the relevance of the nursing science priorities
    for future research.

    Findings

    Research in the four priority areas is advancing knowledge in OUD identification,
    prevention, and treatment. Intersection of OUD research population focus and methodological
    approach was identified among the priority areas.

    Discussion

    The Council priorities provide a relevant framework for nurse scientists to address
    complex health problems like OUD.'
  Author: Patricia Eckardt and Donald Bailey and Holli A. DeVon and Cynthia Dougherty
    and Pamela Ginex and Cheryl A. Krause-Parello and Rita H. Pickler and Therese
    S. Richmond and Eleanor Rivera and Carol F. Roye and Nancy Redeker
  Book_Title_Journal: Nursing Outlook
  DOI: https://doi.org/10.1016/j.outlook.2020.02.001
  JCS_FACTOR: 3.25
  Keywords: Precision health, Big data and Data analytics, Determinants of health,
    Global health, Opioid use disorder research
  SCI_FACTOR: 0.953
  Title: Opioid use disorder research and the Council for the Advancement of Nursing
    Science priority areas
  Title_JCS: NURSING OUTLOOK
  Title_SCI: Nursing Outlook
  Type_Publication: article
  Year: 2020
- Abstract: "This paper aims to estimate the causal effect of accidents on traffic\
    \ congestion and vice versa. In order to identify both effects of this two-way\
    \ relationship, I use dynamic panel data techniques and open access \xE2\u20AC\
    \u02DCbig data\xE2\u20AC\u2122 of highway traffic and accidents in England for\
    \ the period 2012\xE2\u20AC\u201C2014. The research design is based on the daily-and-hourly\
    \ specific mean reversion pattern of highway traffic, which can be used to define\
    \ a recurrent congestion benchmark. Using this benchmark, I am able to identify\
    \ the causal effect of accidents on non-recurrent traffic congestion. A positive\
    \ relationship between traffic congestion and road accidents would yield multiplicative\
    \ benefits for policies that aim at reducing either of these issues. Additionally,\
    \ I explore the duration of the effect of an accident on congestion, the \xE2\u20AC\
    \u02DCrubbernecking\xE2\u20AC\u2122 effect, as well as heterogeneous effects in\
    \ the most congested highway segments. Then, I test the use of methods which employ\
    \ the bulk of information in big data and other methods using a very reduced sample.\
    \ In my application, both approaches produce similar results. Finally, I find\
    \ a non-linear negative effect of traffic congestion on the probability of an\
    \ accident."
  Author: Ilias Pasidis
  Book_Title_Journal: Journal of Transport Geography
  DOI: https://doi.org/10.1016/j.jtrangeo.2017.10.006
  JCS_FACTOR: 4.986
  Keywords: Accidents, Traffic congestion, Big data, Highways, England
  SCI_FACTOR: 1.809
  Title: Congestion by accident? A two-way relationship for highways in England
  Title_JCS: Journal of Transport Geography
  Title_SCI: Journal of Transport Geography
  Type_Publication: article
  Year: 2019
- Abstract: The efficiency and effectiveness of business processes are usually evaluated
    by Process Performance Indicators (PPIs), which are computed using process event
    logs. PPIs can be insightful only when they are measurable, i.e., reliable. This
    paper proposes to define PPI measurability on the basis of the quality of the
    data in the process logs. Then, based on this definition, a framework for PPI
    measurability assessment and improvement is presented. For the assessment, we
    propose novel definitions of PPI accuracy, completeness, consistency, timeliness
    and volume that contextualise the traditional definitions in the data quality
    literature to the case of process logs. For the improvement, we define a set of
    guidelines for improving the measurability of a PPI. These guidelines may concern
    improving existing event logs, for instance through data imputation, implementation
    or enhancement of the process monitoring systems, or updating the PPI definitions.
    A case study in a large-sized institution is discussed to show the feasibility
    and the practical value of the proposed framework.
  Author: Cinzia Cappiello and Marco Comuzzi and Pierluigi Plebani and Matheus Fim
  Book_Title_Journal: Information Systems
  DOI: https://doi.org/10.1016/j.is.2021.101874
  JCS_FACTOR: 2.309
  Keywords: Business process, Event log, Data quality assessment, Data quality improvement
  SCI_FACTOR: 0.547
  Title: Assessing and improving measurability of process performance indicators based
    on quality of logs
  Title_JCS: INFORMATION SYSTEMS
  Title_SCI: Information Systems
  Type_Publication: article
  Year: 2022
- Abstract: "Wildfires, whether natural or caused by humans, are considered among\
    \ the most dangerous and devastating disasters around the world. Their complexity\
    \ comes from the fact that they are hard to predict, hard to extinguish and cause\
    \ enormous financial losses. To address this issue, many research efforts have\
    \ been conducted in order to monitor, predict and prevent wildfires using several\
    \ Artificial Intelligence techniques and strategies such as Big Data, Machine\
    \ Learning, and Remote Sensing. The latter offers a rich source of satellite images,\
    \ from which we can retrieve a huge amount of data that can be used to monitor\
    \ wildfires. The method used in this paper combines Big Data, Remote Sensing and\
    \ Data Mining algorithms (Artificial Neural Network and SVM) to process data collected\
    \ from satellite images over large areas and extract insights from them to predict\
    \ the occurrence of wildfires and avoid such disasters. For this reason, we implemented\
    \ a methodology that serves this purpose by building a dataset based on Remote\
    \ Sensing data related to the state of the crops (NDVI), meteorological conditions\
    \ (LST), as well as the fire indicator \xE2\u20AC\u0153Thermal Anomalies\xE2\u20AC\
    \x9D, these data, were acquired from \xE2\u20AC\u0153MODIS\xE2\u20AC\x9D (Moderate\
    \ Resolution Imaging Spectroradiometer), a key instrument aboard the Terra and\
    \ Aqua satellites. This dataset is available on GitHub via this link (https://github.com/ouladsayadyounes/Wildfires).\
    \ Experiments were made using the big data platform \xE2\u20AC\u0153Databricks\xE2\
    \u20AC\x9D. Experimental results gave high prediction accuracy (98.32%). These\
    \ results were assessed using several validation strategies (e.g., classification\
    \ metrics, cross-validation, and regularization) as well as a comparison with\
    \ some wildfire early warning systems."
  Author: Younes Oulad Sayad and Hajar Mousannif and Hassan {Al Moatassime}
  Book_Title_Journal: Fire Safety Journal
  DOI: https://doi.org/10.1016/j.firesaf.2019.01.006
  JCS_FACTOR: 2.764
  Keywords: Big data, Remote sensing, Machine learning, Wildfire prediction, Data
    mining, Artificial intelligence
  SCI_FACTOR: 0.958
  Title: 'Predictive modeling of wildfires: A new dataset and machine learning approach'
  Title_JCS: FIRE SAFETY JOURNAL
  Title_SCI: Fire Safety Journal
  Type_Publication: article
  Year: 2019
- Abstract: "Accurate information about the location, extent, and type of Land Cover\
    \ (LC) is essential for various applications. The only recent available country-wide\
    \ LC map of Iran was generated in 2016 by the Iranian Space Agency (ISA) using\
    \ Moderate Resolution Imaging Spectroradiometer (MODIS) images with a considerably\
    \ low accuracy. Therefore, the production of an up-to-date and accurate Iran-wide\
    \ LC map using the most recent remote sensing, machine learning, and big data\
    \ processing algorithms is required. Moreover, it is important to develop an efficient\
    \ method for automatic LC generation for various time periods without the need\
    \ to collect additional ground truth data from this immense country. Therefore,\
    \ this study was conducted to fulfill two objectives. First, an improved Iranian\
    \ LC map with 13 LC classes and a spatial resolution of 10\xC2\_m was produced\
    \ using multi-temporal synergy of Sentinel-1 and Sentinel-2 satellite datasets\
    \ applied to an object-based Random forest (RF) algorithm. For this purpose, 2,869\
    \ Sentinel-1 and 11,994 Sentinel-2 scenes acquired in 2017 were processed and\
    \ classified within the Google Earth Engine (GEE) cloud computing platform allowing\
    \ big geospatial data analysis. The Overall Accuracy (OA) and Kappa Coefficient\
    \ (KC) of the final Iran-wide LC map for 2017 was 95.6% and 0.95, respectively,\
    \ indicating the considerable potential of the proposed big data processing method.\
    \ Second, an efficient automatic method was developed based on Sentinel-2 images\
    \ to migrate ground truth samples from a reference year to automatically generate\
    \ an LC map for any target year. The OA and KC for the LC map produced for the\
    \ target year 2019 were 91.35% and 0.91, respectively, demonstrating the efficiency\
    \ of the proposed method for automatic LC mapping. Based on the obtained accuracies,\
    \ this method can potentially be applied to other regions of interest for LC mapping\
    \ without the need for ground truth data from the target year."
  Author: Arsalan Ghorbanian and Mohammad Kakooei and Meisam Amani and Sahel Mahdavi
    and Ali Mohammadzadeh and Mahdi Hasanlou
  Book_Title_Journal: ISPRS Journal of Photogrammetry and Remote Sensing
  DOI: https://doi.org/10.1016/j.isprsjprs.2020.07.013
  JCS_FACTOR: 8.979
  Keywords: Land cover classification, Sentinel, Google Earth Engine, Big data, Remote
    sensing, Iran
  SCI_FACTOR: 2.96
  Title: Improved land cover map of Iran using Sentinel imagery within Google Earth
    Engine and a novel automatic workflow for land cover classification using migrated
    training samples
  Title_JCS: ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
  Title_SCI: ISPRS Journal of Photogrammetry and Remote Sensing
  Type_Publication: article
  Year: 2020
- Abstract: "Discrete global grid systems (DGGS) have been proposed as a data model\
    \ for a digital earth framework. We introduce a new data model and analytics system\
    \ called IDEAS \xE2\u20AC\u201C integrated discrete environmental analysis system\
    \ to create an operational DGGS-based GIS which is suitable for large scale environmental\
    \ modelling and analysis. Our analysis demonstrates that DGGS-based GIS is feasible\
    \ within a relational database environment incorporating common data analytics\
    \ tools. Common GIS operations implemented in our DGGS data model outperformed\
    \ the same operations computed using traditional geospatial data types. A case\
    \ study into wildfire modelling demonstrates the capability for data integration\
    \ and supporting big data geospatial analytics. These results indicate that DGGS\
    \ data models have significant capability to solve some of the key outstanding\
    \ problems related to geospatial data analytics, providing a common representation\
    \ upon which fast and scalable algorithms can be built."
  Author: Colin Robertson and Chiranjib Chaudhuri and Majid Hojati and Steven A. Roberts
  Book_Title_Journal: ISPRS Journal of Photogrammetry and Remote Sensing
  DOI: https://doi.org/10.1016/j.isprsjprs.2020.02.009
  JCS_FACTOR: 8.979
  Keywords: DGGS, Data model, Big data, Spatial data, Analytics, Environment
  SCI_FACTOR: 2.96
  Title: An integrated environmental analytics system (IDEAS) based on a DGGS
  Title_JCS: ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
  Title_SCI: ISPRS Journal of Photogrammetry and Remote Sensing
  Type_Publication: article
  Year: 2020
- Abstract: In this study, a data driven predictive maintenance system was developed
    for production lines in manufacturing. By utilizing the data generated from IoT
    sensors in real-time, the system aims to detect signals for potential failures
    before they occur by using machine learning methods. Consequently, it helps address
    the issues by notifying operators early such that preventive actions can be taken
    prior to a production stop. In current study, the effectiveness of the system
    was also assessed using real-world manufacturing system IoT data. The evaluation
    results indicated that the predictive maintenance system was successful in identifying
    the indicators of potential failures and it can help prevent some production stops
    from happening. The findings of comparative evaluations of machine learning algorithms
    indicated that models of Random Forest, a bagging ensemble algorithm, and XGBoost,
    a boosting method, appeared to outperform the individual algorithms in the assessment.
    The best performing machine learning models in this study have been integrated
    into the production system in the factory.
  Author: Serkan Ayvaz and Koray Alpay
  Book_Title_Journal: Expert Systems with Applications
  DOI: https://doi.org/10.1016/j.eswa.2021.114598
  JCS_FACTOR: 6.954
  Keywords: Predictive maintenance, Internet of things, Manufacturing systems, Artificial
    intelligence, Machine learning, Big data
  SCI_FACTOR: 1.368
  Title: 'Predictive maintenance system for production lines in manufacturing: A machine
    learning approach using IoT data in real-time'
  Title_JCS: EXPERT SYSTEMS WITH APPLICATIONS
  Title_SCI: Expert Systems with Applications
  Type_Publication: article
  Year: 2021
- Abstract: "The paper at hand motivates, proposes, demonstrates, and evaluates a\
    \ novel systematic approach to discovering causal dependencies between events\
    \ encoded in large arrays of data, called causality mining. The approach has emerged\
    \ in the discussions with our project partner, an Australian public energy company.\
    \ It was successfully evaluated in a case study with the project partner to extract\
    \ valuable, and otherwise unknown, information on the causal dependencies between\
    \ observations reported by the company\xE2\u20AC\u2122s employees as part of the\
    \ organizational health and safety management practices and incidents that had\
    \ occurred at the organization\xE2\u20AC\u2122s sites. The dependencies were derived\
    \ based on the notion of proximity of the observations and incidents. The setup\
    \ and results of the evaluation are reported in this paper. The new approach and\
    \ the delivered insights aim at improving the overall health and safety culture\
    \ of the project partner practices, as they can be applied to caution and, thus,\
    \ prevent future incidents."
  Author: Artem Polyvyanyy and Anastasiia Pika and Moe T. Wynn and Arthur H.M. {ter
    Hofstede}
  Book_Title_Journal: Safety Science
  DOI: https://doi.org/10.1016/j.ssci.2019.04.045
  JCS_FACTOR: 4.877
  Keywords: Big data, Data mining, Process mining, Proximity of events, Causality,
    Health and safety, Cause of incidents
  SCI_FACTOR: 1.178
  Title: A systematic approach for discovering causal dependencies between observations
    and incidents in the health and safety domain
  Title_JCS: SAFETY SCIENCE
  Title_SCI: Safety Science
  Type_Publication: article
  Year: 2019
- Abstract: For the past few years, we have been hearing about Industry 4.0 (or the
    fourth industrial revolution), which promises to improve productivity, flexibility,
    quality, customer satisfaction and employee well-being. To assess whether these
    goals are achieved, it is necessary to implement a performance management system
    (PMS). However, a PMS must take into account the various challenges associated
    with Industry 4.0, including the availability of large amounts of data. While
    it represents an opportunity for companies to improve performance, big data does
    not necessarily mean good data. It can be uncertain, imprecise, ambiguous, etc.
    Uncertainty is one of the major challenges and it is essential to take it into
    account when computing performance indicators to increase confidence in decision
    making. To address this issue, we propose a method to model uncertainty in key
    performance indicators (KPIs). Our work allows associating with each indicator
    an uncertainty noted m, computed on the basis of the theory of belief functions.
    The KPI and its associated uncertainty form a pair (KP I, m). The method developed
    allows calculating this uncertainty m for the input data of the performance management
    system. We show how these modeled uncertainties should be propagated to the KPIs.
    For these KPI uncertainties, we have defined rules to support decision-making.
    The method developed, based on the theory of belief functions, is part of a methodology
    we propose to define and extract smart data from massive data. To our knowledge,
    this is the first attempt to use this theory to model uncertain performance indicators.
    Our work has shown its effectiveness and its applicability to a case of bottle
    filling line simulation. In addition to these results, this work opens up new
    perspectives, particularly for taking uncertainty into account in expert opinions
    and in industrial risk assessment.
  Author: Amel Souifi and Zohra Cherfi Boulanger and Marc Zolghadri and Maher Barkallah
    and Mohamed Haddar
  Book_Title_Journal: Computers in Industry
  DOI: https://doi.org/10.1016/j.compind.2022.103666
  JCS_FACTOR: 7.635
  Keywords: Industry 4.0, Performance management, Decision support, Big Data, Uncertainty
    modeling
  SCI_FACTOR: 1.432
  Title: 'Uncertainty of key performance indicators for Industry 4.0: A methodology
    based on the theory of belief functions'
  Title_JCS: COMPUTERS IN INDUSTRY
  Title_SCI: Computers in Industry
  Type_Publication: article
  Year: 2022
- Abstract: In state-of-the-art big-data applications, the process of building machine
    learning models can be very challenging due to continuous changes in data structures
    and the need for human interaction to tune the variables and models over time.
    Hence, expedited learning in rapidly changing environments is required. In this
    work, we address this challenge by implementing concepts from the field of intrinsically
    motivated computational learning, also known as artificial curiosity (AC). In
    AC, an autonomous agent acts to optimize its learning about itself and its environment
    by receiving internal rewards based on prediction errors. We present a novel method
    of intrinsically motivated learning, based on the curiosity loop, to learn the
    data structures in large and varied datasets. An autonomous agent learns to select
    a subset of relevant features in the data, i.e., feature selection, to be used
    later for model construction. The agent optimizes its learning about the data
    structure over time without requiring external supervision. We show that our method,
    called the Curious Feature Selection (CFS) algorithm, positively impacts the accuracy
    of learning models on three public datasets.
  Author: Michal Moran and Goren Gordon
  Book_Title_Journal: Information Sciences
  DOI: https://doi.org/10.1016/j.ins.2019.02.009
  JCS_FACTOR: 6.795
  Keywords: Intrinsic motivation learning, Curiosity loop, Reinforcement learning,
    Big data, Data science, Feature selection
  SCI_FACTOR: 1.524
  Title: Curious Feature Selection
  Title_JCS: INFORMATION SCIENCES
  Title_SCI: Information Sciences
  Type_Publication: article
  Year: 2019
- Abstract: "Forecasting tourism demand has important implications for both policy\
    \ makers and companies operating in the tourism industry. In this research, we\
    \ applied methods and tools of social network and semantic analysis to study user-generated\
    \ content retrieved from online communities which interacted on the TripAdvisor\
    \ travel forum. We analyzed the forums of 7 major European capital cities, over\
    \ a period of 10\xE2\u20AC\xAFyears, collecting more than 2,660,000 posts, written\
    \ by about 147,000 users. We present a new methodology of analysis of tourism-related\
    \ big data and a set of variables which could be integrated into traditional forecasting\
    \ models. We implemented Factor Augmented Autoregressive and Bridge models with\
    \ social network and semantic variables which often led to a better forecasting\
    \ performance than univariate models and models based on Google Trend data. Forum\
    \ language complexity and the centralization of the communication network \xE2\
    \u20AC\u201C i.e. the presence of eminent contributors \xE2\u20AC\u201C were the\
    \ variables that contributed more to the forecasting of international airport\
    \ arrivals."
  Author: Andrea {Fronzetti Colladon} and Barbara Guardabascio and Rosy Innarella
  Book_Title_Journal: Decision Support Systems
  DOI: https://doi.org/10.1016/j.dss.2019.113075
  JCS_FACTOR: 5.795
  Keywords: Tourism forecasting, Social network analysis, Semantic analysis, Online
    community, Text mining, Big data
  SCI_FACTOR: 1.564
  Title: Using social network and semantic analysis to analyze online travel forums
    and forecast tourism demand
  Title_JCS: DECISION SUPPORT SYSTEMS
  Title_SCI: Decision Support Systems
  Type_Publication: article
  Year: 2019
- Abstract: Previous research studied the spatiotemporal patterns in different visitor
    segments but lacks evidence of the segmentation of resident tourists and non-resident
    tourists in multi-city travel. To fill this gap, this study conducts a big data
    study using hotel check-in registers. The exploratory data analysis visualizes
    the spatiotemporal patterns and the differences between resident tourists and
    non-resident tourists. Then, the spatiotemporal patterns are measured by the length
    of stay and the number of visited cities. The regression shows that both the length
    of stay and the number of visited cities of non-resident tourists are higher than
    those of resident tourists. Moreover, non-resident tourists reduce their length
    of stay and their number of visited cities more than resident tourists on three-day
    holidays, while they increase their number of visited cities less than resident
    tourists on seven-day holidays. This study has significant implications for understanding
    spatiotemporal patterns and visitors' segmentations.
  Author: Yuquan Xu and Xiaobin Ran and Yuewen Liu and Wei Huang
  Book_Title_Journal: Tourism Management Perspectives
  DOI: https://doi.org/10.1016/j.tmp.2021.100860
  JCS_FACTOR: 6.586
  Keywords: Big data, Spatiotemporal patterns, Resident tourists and non-resident
    tourists, Multiple city travel, Hotel check-in registers
  SCI_FACTOR: 1.454
  Title: Comparing differences in the spatiotemporal patterns between resident tourists
    and non-resident tourists using hotel check-in registers
  Title_JCS: Tourism Management Perspectives
  Title_SCI: Tourism Management Perspectives
  Type_Publication: article
  Year: 2021
- Abstract: "Recently, with the development of \xE2\u20AC\u0153Industry 4.0\xE2\u20AC\
    \x9D, \xE2\u20AC\u0153Oil and Gas 4.0\xE2\u20AC\x9D has also been put on the agenda\
    \ in the past two years. Some companies and experts believe that \xE2\u20AC\u0153\
    Oil and Gas 4.0\xE2\u20AC\x9D can completely change the status quo of the oil\
    \ and gas industry, which can bring huge benefits because it accelerates the digitization\
    \ and intelligentization of the oil and gas industry. However, the \xE2\u20AC\u0153\
    Oil and Gas 4.0\xE2\u20AC\x9D is still in its infancy. Therefore, this paper systematically\
    \ introduces the concept and core technologies of \xE2\u20AC\u0153Oil and Gas\
    \ 4.0\xE2\u20AC\x9D, such as big data and the industrial Internet of Things (IIoT).\
    \ Moreover, this paper analyzes typical application scenarios of the oil and gas\
    \ industry chain (upstream, midstream and downstream) through examples, such as\
    \ intelligent oilfield, intelligent pipeline, and intelligent refinery. It is\
    \ concluded that the essence of \xE2\u20AC\u0153Oil and Gas 4.0\xE2\u20AC\x9D\
    \ is a data-driven intelligence system based on the highly digitization. To the\
    \ best of our knowledge, this is the first academic peer-reviewed paper on the\
    \ \xE2\u20AC\u0153Oil and Gas 4.0\xE2\u20AC\x9D era, aiming to let more oil and\
    \ gas industry personnel understand its benefits and application scenarios, so\
    \ as to better apply it to practical engineering in the future. In the discussion\
    \ section, this paper also analyzes the opportunities and difficulties that may\
    \ be brought about by the \xE2\u20AC\u0153Oil and Gas 4.0\xE2\u20AC\x9D era. Finally,\
    \ relevant policy recommendations are proposed."
  Author: Hongfang Lu and Lijun Guo and Mohammadamin Azimi and Kun Huang
  Book_Title_Journal: Computers in Industry
  DOI: https://doi.org/10.1016/j.compind.2019.06.007
  JCS_FACTOR: 7.635
  Keywords: Oil and Gas 4.0, Big data, Digitization, IIoT, Intelligentization
  SCI_FACTOR: 1.432
  Title: 'Oil and Gas 4.0 era: A systematic review and outlook'
  Title_JCS: COMPUTERS IN INDUSTRY
  Title_SCI: Computers in Industry
  Type_Publication: article
  Year: 2019
- Abstract: Business intelligence (BI) incorporates business research, data mining,
    data visualization, data tools,infrastructure, and best practices to help businesses
    make more data-driven choices.Business intelligence's challenging characteristics
    include data breaches, difficulty in analyzing different data sources, and poor
    data quality is consideredessential factors. In this paper, IoT-based Efficient
    Data Visualization Framework (IoT- EDVF) has been proposed to strengthen leaks'
    risk, analyze multiple data sources, and data quality management for business
    intelligence in corporate finance.Corporate analytics management is introduced
    to enhance the data analysis system's risk, and the complexity of different sources
    can allow accessing Business Intelligence. Financial risk analysis is implemented
    to improve data quality management initiative helps use main metrics of success,
    which are essential to the individual needs and objectives. The statistical outcomes
    of the simulation analysis show the increasedperformance with a lower delay response
    of 5ms and improved revenue analysis with the improvement of 29.42% over existing
    models proving the proposed framework's reliability.
  Author: Cuili Shao and Yonggang Yang and Sapna Juneja and Tamizharasi GSeetharam
  Book_Title_Journal: Information Processing & Management
  DOI: https://doi.org/10.1016/j.ipm.2021.102736
  JCS_FACTOR: 6.222
  Keywords: IoT, Data visualization, Business intelligence, Corporate finance
  SCI_FACTOR: 0.0
  Title: IoT data visualization for business intelligence in corporate finance
  Title_JCS: INFORMATION PROCESSING & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2022
- Abstract: Business intelligence (BI) incorporates business research, data mining,
    data visualization, data tools,infrastructure, and best practices to help businesses
    make more data-driven choices.Business intelligence's challenging characteristics
    include data breaches, difficulty in analyzing different data sources, and poor
    data quality is consideredessential factors. In this paper, IoT-based Efficient
    Data Visualization Framework (IoT- EDVF) has been proposed to strengthen leaks'
    risk, analyze multiple data sources, and data quality management for business
    intelligence in corporate finance.Corporate analytics management is introduced
    to enhance the data analysis system's risk, and the complexity of different sources
    can allow accessing Business Intelligence. Financial risk analysis is implemented
    to improve data quality management initiative helps use main metrics of success,
    which are essential to the individual needs and objectives. The statistical outcomes
    of the simulation analysis show the increasedperformance with a lower delay response
    of 5ms and improved revenue analysis with the improvement of 29.42% over existing
    models proving the proposed framework's reliability.
  Author: Cuili Shao and Yonggang Yang and Sapna Juneja and Tamizharasi GSeetharam
  Book_Title_Journal: Information Processing & Management
  DOI: https://doi.org/10.1016/j.ipm.2021.102736
  JCS_FACTOR: 6.222
  Keywords: IoT, Data visualization, Business intelligence, Corporate finance
  SCI_FACTOR: 0.0
  Title: IoT data visualization for business intelligence in corporate finance
  Title_JCS: INFORMATION PROCESSING & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2022
- Abstract: Leveraging data science can enable businesses to exploit data for competitive
    advantage by generating valuable insights. However, many industries cannot effectively
    incorporate data science into their business processes, as there is no comprehensive
    approach that allows strategic planning for organization-wide data science efforts
    and data assets. Accordingly, this study explores the Data Science Roadmapping
    (DSR) to guide organizations in aligning their business strategies with data-related,
    technological, and organizational resources. The proposed approach is built on
    the widely adopted technology roadmapping framework and customizes its context,
    architecture, and process by synthesizing data science, big data, and data-driven
    organization literature. Based on industry collaborations, the framework provides
    a hybrid and agile methodology comprising the recommended steps. We applied DSR
    with a research group with sector experience to create a comprehensive data science
    roadmap to validate and refine the framework. The results indicate that the framework
    facilitates DSR initiatives by creating a comprehensive roadmap capturing strategy,
    data, technology, and organizational perspectives. The contemporary literature
    illustrates prebuilt roadmaps to help businesses become data-driven. However,
    becoming data-driven also necessitates significant social change toward openness
    and trust. The DSR initiative can facilitate this social change by opening communication
    channels, aligning perspectives, and generating consensus among stakeholders.
  Author: "Kerem Kayabay and Mert Onuralp G\xC3\xB6kalp and Ebru G\xC3\xB6kalp and\
    \ P. {Erhan Eren} and Altan Ko\xC3\xA7yi\xC4\u0178it"
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2021.121264
  JCS_FACTOR: 8.593
  Keywords: Technology roadmapping, Technology management, Data science, Digital transformation,
    Data-driven organization, Big data
  SCI_FACTOR: 2.226
  Title: 'Data science roadmapping: An architectural framework for facilitating transformation
    towards a data-driven organization'
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2022
- Abstract: Most organisations using Open Data currently focus on data processing
    and analysis. However, although Open Data may be available online, these data
    are generally of poor quality, thus discouraging others from contributing to and
    reusing them. This paper describes an approach to publish statistical data from
    public repositories by using Semantic Web standards published by the W3C, such
    as RDF and SPARQL, in order to facilitate the analysis of multidimensional models.
    We have defined a framework based on the entire lifecycle of data publication
    including a novel step of Linked Open Data assessment and the use of external
    repositories as knowledge base for data enrichment. As a result, users are able
    to interact with the data generated according to the RDF Data Cube vocabulary,
    which makes it possible for general users to avoid the complexity of SPARQL when
    analysing data. The use case was applied to the Barcelona Open Data platform and
    revealed the benefits of the application of our approach, such as helping in the
    decision-making process.
  Author: "Pilar Escobar and Gustavo Candela and Juan Trujillo and Manuel Marco-Such\
    \ and Jes\xC3\xBAs Peral"
  Book_Title_Journal: Computer Standards & Interfaces
  DOI: https://doi.org/10.1016/j.csi.2019.103378
  JCS_FACTOR: 2.487
  Keywords: Linked Open Data, Multidimensional modelling, Conceptual modelling, RDF
    Data Cube vocabulary, Semantic web, Big data
  SCI_FACTOR: 0.0
  Title: Adding value to Linked Open Data using a multidimensional model approach
    based on the RDF Data Cube vocabulary
  Title_JCS: COMPUTER STANDARDS & INTERFACES
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: Agile methodologies were introduced in 2001. Since this time, practitioners
    have applied Agile methodologies to many delivery disciplines. This article explores
    the application of Agile methodologies and principles to business intelligence
    delivery and how Agile has changed with the evolution of business intelligence.
    Business intelligence has evolved because the amount of data generated through
    the internet and smart devices has grown exponentially altering how organizations
    and individuals use information. The practice of business intelligence delivery
    with an Agile methodology has matured; however, business intelligence has evolved
    altering the use of Agile principles and practices. The Big Data phenomenon, the
    volume, variety, and velocity of data, has impacted business intelligence and
    the use of information. New trends such as fast analytics and data science have
    emerged as part of business intelligence. This paper addresses how Agile principles
    and practices have evolved with business intelligence, as well as its challenges
    and future directions.
  Author: Deanne Larson and Victor Chang
  Book_Title_Journal: International Journal of Information Management
  DOI: https://doi.org/10.1016/j.ijinfomgt.2016.04.013
  JCS_FACTOR: 14.098
  Keywords: Agile methodologies, Business intelligence (BI), Analytics and big data,
    Lifecycle for BI and Big Data
  SCI_FACTOR: 2.77
  Title: A review and future direction of agile, business intelligence, analytics
    and data science
  Title_JCS: INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
  Title_SCI: International Journal of Information Management
  Type_Publication: article
  Year: 2016
- Abstract: The main purpose of this study is based on qualitative and quantitative
    research procedures, and integrates the key service factors for the online food
    delivery (OFD) industry extracted by Internet Big Data Analytics (IBDA) to construct
    a OFD service quality scale (OFD-SERV). This study takes OFD customers in Taipei
    City as the objects. The results show that 20 key service factors for the OFD
    industry are extracted through IBDA. The OFD-SERV scale contains six dimensions
    including reliability, maintenance of meal quality and hygiene, assurance, security,
    system operation and traceability, a total of 28 items. The results from the structural
    equation modeling showed that the reliability, assurance and system operation
    have a positive impact on customer satisfaction. Finally, the findings provide
    knowledge and inspiration for the current OFD, and enable OFD operators and future
    researchers to more accurately identify the deficiency of service quality.
  Author: Ching-Chan Cheng and Ya-Yuan Chang and Cheng-Ta Chen
  Book_Title_Journal: International Journal of Hospitality Management
  DOI: https://doi.org/10.1016/j.ijhm.2021.102938
  JCS_FACTOR: 9.237
  Keywords: Online food delivery, Service quality, Big data analytic, OFD service
    quality scale
  SCI_FACTOR: 2.321
  Title: Construction of a service quality scale for the online food delivery industry
  Title_JCS: International Journal of Hospitality Management
  Title_SCI: International Journal of Hospitality Management
  Type_Publication: article
  Year: 2021
- Abstract: The rapid growth of big data environment imposes new challenges that traditional
    knowledge discovery and data mining process (KDDM) models are not adequately suited
    to address. We propose a snail shell process model for knowledge discovery via
    data analytics (KDDA) to address these challenges. We evaluate the utility of
    the KDDA process model using real-world analytic case studies at a global multi-media
    company. By comparing against traditional KDDM models, we demonstrate the need
    and relevance of the snail shell model, particularly in addressing faster turnaround
    and frequent model updates that characterize knowledge discovery in the big data
    environment.
  Author: Yan Li and Manoj A. Thomas and Kweku-Muata Osei-Bryson
  Book_Title_Journal: Decision Support Systems
  DOI: https://doi.org/10.1016/j.dss.2016.07.003
  JCS_FACTOR: 5.795
  Keywords: Knowledge discovery via data analytics, Snail shell process model, KDDA,
    Big data analytics, Data-driven decision making
  SCI_FACTOR: 1.564
  Title: A snail shell process model for knowledge discovery via data analytics
  Title_JCS: DECISION SUPPORT SYSTEMS
  Title_SCI: Decision Support Systems
  Type_Publication: article
  Year: 2016
- Abstract: "The year 2017 has seen many EU and UK legislative initiatives and proposals\
    \ to consider and address the impact of artificial intelligence on society, covering\
    \ questions of liability, legal personality and other ethical and legal issues,\
    \ including in the context of data processing. In March 2017, the Information\
    \ Commissioner's Office (UK) updated its big data guidance to address the development\
    \ of artificial intelligence and machine learning, and to provide (GDPR), which\
    \ will apply from 25 May 2018. This paper situates the ICO's guidance in the context\
    \ of wider legal and ethical considerations and provides a critique of the position\
    \ adopted by the ICO. On the ICO's analysis, the key challenge for artificial\
    \ intelligence processing personal data is in establishing that such processing\
    \ is fair. This shift reflects the potential for artificial intelligence to have\
    \ negative social consequences (whether intended or unintended) that are not otherwise\
    \ addressed by the GDPR. The question of \xE2\u20AC\u02DCfairness\xE2\u20AC\u2122\
    \ is an important one, to address the imbalance between big data organisations\
    \ and individual data subjects, with a number of ethical and social impacts that\
    \ need to be evaluated."
  Author: Michael Butterworth
  Book_Title_Journal: Computer Law & Security Review
  DOI: https://doi.org/10.1016/j.clsr.2018.01.004
  JCS_FACTOR: 2.98
  Keywords: Artificial intelligence (AI), Big data analytics, General Data Protection
    Regulation (GDPR), Fairness, Regulations, Collective rights, Data ethics
  SCI_FACTOR: 0.0
  Title: 'The ICO and artificial intelligence: The role of fairness in the GDPR framework'
  Title_JCS: Computer Law & Security Review
  Title_SCI: N/A
  Type_Publication: article
  Year: 2018
- Abstract: 'The nature of management accountants'' responsibility is evolving from
    merely reporting aggregated historical value to also including organizational
    performance measurement and providing management with decision related information.
    Corporate information systems such as enterprise resource planning (ERP) systems
    have provided management accountants with both expanded data storage power and
    enhanced computational power. With big data extracted from both internal and external
    data sources, management accountants now could utilize data analytics techniques
    to answer the questions including: what has happened (descriptive analytics),
    what will happen (predictive analytics), and what is the optimized solution (prescriptive
    analytics). However, research shows that the nature and scope of managerial accounting
    has barely changed and that management accountants employ mostly descriptive analytics,
    some predictive analytics, and a bare minimum of prescriptive analytics. This
    paper proposes a Managerial Accounting Data Analytics (MADA) framework based on
    the balanced scorecard theory in a business intelligence context. MADA provides
    management accountants the ability to utilize comprehensive business analytics
    to conduct performance measurement and provide decision related information. With
    MADA, three types of business analytics (descriptive, predictive, and prescriptive)
    are implemented into four corporate performance measurement perspectives (financial,
    customer, internal process, and learning and growth) in an enterprise system environment.
    Other related issues that affect the successful utilization of business analytics
    within a corporate-wide business intelligence (BI) system, such as data quality
    and data integrity, are also discussed. This paper contributes to the literature
    by discussing the impact of business analytics on managerial accounting from an
    enterprise systems and BI perspective and by providing the Managerial Accounting
    Data Analytics (MADA) framework that incorporates balanced scorecard methodology.'
  Author: Deniz Appelbaum and Alexander Kogan and Miklos Vasarhelyi and Zhaokai Yan
  Book_Title_Journal: International Journal of Accounting Information Systems
  DOI: https://doi.org/10.1016/j.accinf.2017.03.003
  JCS_FACTOR: 4.4
  Keywords: Managerial accounting, Business analytics, Big data, Enterprise systems,
    Business intelligence
  SCI_FACTOR: 0.897
  Title: Impact of business analytics and enterprise systems on managerial accounting
  Title_JCS: International Journal of Accounting Information Systems
  Title_SCI: International Journal of Accounting Information Systems
  Type_Publication: article
  Year: 2017
- Abstract: Firms can achieve a competitive advantage by leveraging real-time Digital
    Data Streams (DDSs). The ability to profit from DDSs is emerging as a critical
    competency for firms and a novel area for Information Technology (IT) investments.
    We examine the relationship between DDS readiness and competitive advantage by
    studying the mediation effect of product effectiveness and process efficiency.
    The research model is tested with data obtained from 302 companies, and the results
    confirm the existence of the mediation effects. Interestingly, we confirm that
    competitive advantage is more significantly impacted by IT investments affecting
    product effectiveness than those affecting process efficiency.
  Author: Elisabetta Raguseo and Federico Pigni and Claudio Vitari
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2021.103451
  JCS_FACTOR: 7.555
  Keywords: Streams of big data, Process efficiency, Product effectiveness, Competitive
    advantage
  SCI_FACTOR: 0.0
  Title: 'Streams of digital data and competitive advantage: The mediation effects
    of process efficiency and product effectiveness'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2021
- Abstract: Firms can achieve a competitive advantage by leveraging real-time Digital
    Data Streams (DDSs). The ability to profit from DDSs is emerging as a critical
    competency for firms and a novel area for Information Technology (IT) investments.
    We examine the relationship between DDS readiness and competitive advantage by
    studying the mediation effect of product effectiveness and process efficiency.
    The research model is tested with data obtained from 302 companies, and the results
    confirm the existence of the mediation effects. Interestingly, we confirm that
    competitive advantage is more significantly impacted by IT investments affecting
    product effectiveness than those affecting process efficiency.
  Author: Elisabetta Raguseo and Federico Pigni and Claudio Vitari
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2021.103451
  JCS_FACTOR: 7.555
  Keywords: Streams of big data, Process efficiency, Product effectiveness, Competitive
    advantage
  SCI_FACTOR: 0.0
  Title: 'Streams of digital data and competitive advantage: The mediation effects
    of process efficiency and product effectiveness'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2021
- Abstract: "Smart City and IoT improves the performance of health, transportation,\
    \ energy and reduce the consumption of resources. Among the smart city services,\
    \ Big Data analytics is one of the imperative technologies that have a vast perspective\
    \ to reach sustainability, enhanced resilience, effective quality of life and\
    \ quick management of resources. This paper focuses on the privacy of big data\
    \ in the context of smart health to support smart cities. Furthermore, the trade-off\
    \ between the data privacy and utility in big data analytics is the foremost concern\
    \ for the stakeholders of a smart city. The majority of smart city application\
    \ databases focus on preserving the privacy of individuals with different disease\
    \ data. In this paper, we propose a trust-based hybrid data privacy approach named\
    \ as \xE2\u20AC\u0153MIDR-Angelization\xE2\u20AC\x9D to assure privacy and utility\
    \ in big data analytics when sharing same disease data of patients in IoT industry.\
    \ Above all, this study suggests that privacy-preserving policies and practices\
    \ to share disease and health information of patients having the same disease\
    \ should consider detailed disease information to enhance data utility. An extensive\
    \ experimental study performed on a real-world dataset to measure instance disclosure\
    \ risk which shows that the proposed scheme outperforms its counterpart in terms\
    \ of data utility and privacy."
  Author: Adeel Anjum and Tahir Ahmed and Abid Khan and Naveed Ahmad and Mansoor Ahmad
    and Muhammad Asif and Alavalapati Goutham Reddy and Tanzila Saba and Nayma Farooq
  Book_Title_Journal: Sustainable Cities and Society
  DOI: https://doi.org/10.1016/j.scs.2018.04.014
  JCS_FACTOR: 7.587
  Keywords: Big data, IoT data management, Disclosure risk, HIPAA, Patient privacy,
    Re-identification risk, Smart city
  SCI_FACTOR: 1.645
  Title: Privacy preserving data by conceptualizing smart cities using MIDR-Angelization
  Title_JCS: Sustainable Cities and Society
  Title_SCI: Sustainable Cities and Society
  Type_Publication: article
  Year: 2018
- Abstract: "Sensors are becoming ubiquitous in everyday life, generating data at\
    \ an unprecedented rate and scale. However, models that assess impacts of human\
    \ activities on environmental and human health, have typically been developed\
    \ in contexts where data scarcity is the norm. Models are essential tools to understand\
    \ processes, identify relationships, associations and causality, formalize stakeholder\
    \ mental models, and to quantify the effects of prevention and interventions.\
    \ They can help to explain data, as well as inform the deployment and location\
    \ of sensors by identifying hotspots and areas of interest where data collection\
    \ may achieve the best results. We identify a paradigm shift in how the integration\
    \ of models and sensors can contribute to harnessing \xE2\u20AC\u02DCBig Data\xE2\
    \u20AC\u2122 and, more importantly, make the vital step from \xE2\u20AC\u02DC\
    Big Data\xE2\u20AC\u2122 to \xE2\u20AC\u02DCBig Information\xE2\u20AC\u2122. In\
    \ this paper, we illustrate current developments and identify key research needs\
    \ using human and environmental health challenges as an example."
  Author: Stefan Reis and Edmund Seto and Amanda Northcross and Nigel W.T. Quinn and
    Matteo Convertino and Rod L. Jones and Holger R. Maier and Uwe Schlink and Susanne
    Steinle and Massimo Vieno and Michael C. Wimberly
  Book_Title_Journal: Environmental Modelling & Software
  DOI: https://doi.org/10.1016/j.envsoft.2015.06.003
  JCS_FACTOR: 5.288
  Keywords: Integrated modelling, Environmental sensors, Population health, Environmental
    health, Big data
  SCI_FACTOR: 0.0
  Title: Integrating modelling and smart sensors for environmental and human health
  Title_JCS: ENVIRONMENTAL MODELLING & SOFTWARE
  Title_SCI: N/A
  Type_Publication: article
  Year: 2015
- Abstract: "Measuring real-world fuel consumption of light duty vehicles can be challenging\
    \ due to the limited collection of actual data. In this paper, we use big data\
    \ retrieved from the record of real-world fuel consumptions of different brands\
    \ of vehicles in different areas (n\xE2\u20AC\xAF=\xE2\u20AC\xAF106,809 samples\
    \ from 201 brands of vehicles and 34 cities) in China to build up a real-world\
    \ fuel consumption rate (RFCR) model to estimate the fuel consumption given the\
    \ driving conditions and figure out the main factors that affect actual fuel consumption\
    \ in the real world. We find the average deviation of actual fuel consumptions\
    \ and the fitting results of RFCR model is 4.22% , which does not significantly\
    \ differ from zero, and the fuel consumptions calculated by RFCR model tend to\
    \ be 1.40\xE2\u20AC\xAFL/100\xE2\u20AC\xAFkm (about 25%) higher than the official\
    \ reported data. Furthermore, we find that annual average temperature and altitude\
    \ factors significantly influence the fuel consumption rate. The results indicate\
    \ that there is a real world performance discrepancy between the theoretical fuel\
    \ consumption released by authorities and that in the real world, and some green\
    \ behaviors (choose light duty vehicles, reduce the use of air conditioning and\
    \ change to manual transmission type) can reduce energy consumption of vehicles."
  Author: Tian Wu and Xiao Han and M. Mocarlo Zheng and Xunmin Ou and Hongbo Sun and
    Xiong Zhang
  Book_Title_Journal: Energy
  DOI: https://doi.org/10.1016/j.energy.2019.116388
  JCS_FACTOR: 7.147
  Keywords: Real-world fuel consumption rate, Energy consumption, Private passenger
    vehicles, Big data, China
  SCI_FACTOR: 1.961
  Title: Impact factors of the real-world fuel consumption rate of light duty vehicles
    in China
  Title_JCS: ENERGY
  Title_SCI: Energy
  Type_Publication: article
  Year: 2020
- Abstract: While the use of big data tends to add value for business throughout the
    entire value chain, the integration of big data analytics (BDA) to the decision-making
    process remains a challenge. This study, based on a systematic literature review,
    thematic analysis and qualitative interview findings, proposes a set of six-steps
    to establish both rigor and relevance in the process of analytics-driven decision-making.
    Our findings illuminate the key steps in this decision process including problem
    definition, review of past findings, model development, data collection, data
    analysis as well as actions on insights in the context of service systems. Although
    findings have been discussed in a sequence of steps, the study identifies them
    as interdependent and iterative. The proposed six-step analytics-driven decision-making
    process, practical evidence from service systems, and future research agenda,
    provide altogether the foundation for future scholarly research and can serve
    as a step-wise guide for industry practitioners.
  Author: Shahriar Akter and Ruwan Bandara and Umme Hani and Samuel {Fosso Wamba}
    and Cyril Foropon and Thanos Papadopoulos
  Book_Title_Journal: International Journal of Information Management
  DOI: https://doi.org/10.1016/j.ijinfomgt.2019.01.020
  JCS_FACTOR: 14.098
  Keywords: Big data analytics, Decision-making, Service systems
  SCI_FACTOR: 2.77
  Title: 'Analytics-based decision-making for service systems: A qualitative study
    and agenda for future research'
  Title_JCS: INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
  Title_SCI: International Journal of Information Management
  Type_Publication: article
  Year: 2019
- Abstract: We are living in a world where everything computes, everyone and everything
    is connected and sharing data. Going beyond just capturing and managing data,
    enterprises are tapping into IoT and Artificial Intelligence (AI) to create insights
    and intelligence in a revolutionary way that was not possible before. For instance,
    by analyzing unstructured data (such as text), call centers can extract entities,
    concepts, themes which can enable them to get faster insights that only few years
    back was not feasible. Public safety and law enforcement are only few of the examples
    that benefit from text analytics used to strengthen crime investigation. Sentiment
    Analysis, Content Classification, Language Detection and Intent Detection are
    just some of the Text Classification applications. The overall process model of
    such applications considering the complexity of the unstructured data, can be
    definitely challenging. In response to the chaotic emerging science of unstructured
    data analysis, the main goal of this paper is to first contribute to the gap of
    no existing methodology approach for Text Analytics projects, by introducing a
    methodology approach based on one of the most widely accepted and used methodology
    approach of CRISP-DM.
  Author: Christina G. Skarpathiotaki and Konstantinos E. Psannis
  Book_Title_Journal: Big Data Research
  DOI: https://doi.org/10.1016/j.bdr.2021.100274
  JCS_FACTOR: 3.578
  Keywords: Big data analytics, Advanced analysis, Artificial intelligence, Machine
    learning, Text analytics, Cross-industry processes
  SCI_FACTOR: 0.565
  Title: Cross-Industry Process Standardization for Text Analytics
  Title_JCS: Big Data Research
  Title_SCI: Big Data Research
  Type_Publication: article
  Year: 2022
- Abstract: The emergence of new technologies such as Internet/Web/Network-of-Things
    and large scale wireless sensor systems enables the collection of data from an
    increasing volume and variety of networked sensors for analysis. In this review
    article, we summarize the latest developments of big sensor data systems (a term
    to conceptualize the application of the big data model towards networked sensor
    systems) in various representative studies for urban environments, including for
    air pollution monitoring, assistive living, disaster management systems, and intelligent
    transportation. An important focus is the inclusion of how value is extracted
    from the big data system. We also discuss some recent techniques for big data
    acquisition, cleaning, aggregation, modeling, and interpretation in large scale
    sensor-based systems. We conclude the paper with a discussion on future perspectives
    and challenges of sensor-based data systems in the big data era.
  Author: Li-Minn Ang and Kah Phooi Seng
  Book_Title_Journal: Big Data Research
  DOI: https://doi.org/10.1016/j.bdr.2015.12.003
  JCS_FACTOR: 3.578
  Keywords: Big data, Sensor-based systems, Survey, Application, Challenges
  SCI_FACTOR: 0.565
  Title: Big Sensor Data Applications in Urban Environments
  Title_JCS: Big Data Research
  Title_SCI: Big Data Research
  Type_Publication: article
  Year: 2016
- Abstract: "The popularity of the big data domain has boosted corporate interest\
    \ in collecting and storing tremendous amounts of consumers\xE2\u20AC\u2122 textual\
    \ information. However, decision makers are often overwhelmed by the abundance\
    \ of information, and the usage of text mining (TM) tools is still at its infancy.\
    \ This study validates an extended technology acceptance model integrating information\
    \ quality (IQ) and top management support. Results confirm that IQ influences\
    \ behavioral intentions and TM tools usage, through perceptions of external control,\
    \ perceived ease of use, and perceived usefulness; top management support also\
    \ has a key role in determining the usage of TM tools."
  Author: Nathalie T.M. Demoulin and Kristof Coussement
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2018.10.006
  JCS_FACTOR: 7.555
  Keywords: Technology acceptance model (TAM), Text mining, Big data, Information
    quality, Top management support
  SCI_FACTOR: 0.0
  Title: 'Acceptance of text-mining systems: The signaling role of information quality'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: "The popularity of the big data domain has boosted corporate interest\
    \ in collecting and storing tremendous amounts of consumers\xE2\u20AC\u2122 textual\
    \ information. However, decision makers are often overwhelmed by the abundance\
    \ of information, and the usage of text mining (TM) tools is still at its infancy.\
    \ This study validates an extended technology acceptance model integrating information\
    \ quality (IQ) and top management support. Results confirm that IQ influences\
    \ behavioral intentions and TM tools usage, through perceptions of external control,\
    \ perceived ease of use, and perceived usefulness; top management support also\
    \ has a key role in determining the usage of TM tools."
  Author: Nathalie T.M. Demoulin and Kristof Coussement
  Book_Title_Journal: Information & Management
  DOI: https://doi.org/10.1016/j.im.2018.10.006
  JCS_FACTOR: 7.555
  Keywords: Technology acceptance model (TAM), Text mining, Big data, Information
    quality, Top management support
  SCI_FACTOR: 0.0
  Title: 'Acceptance of text-mining systems: The signaling role of information quality'
  Title_JCS: INFORMATION & MANAGEMENT
  Title_SCI: N/A
  Type_Publication: article
  Year: 2020
- Abstract: "In the age of \xE2\u20AC\u0153Internet+\xE2\u20AC\x9D, many Internet\
    \ service platforms (ISPs) in China have been widely introduced to the closed-loop\
    \ supply chain (CLSC). To further study the role of the Internet service platform,\
    \ this paper considers a CLSC composed of a manufacturer, a retailer and an Internet\
    \ service platform who invests in research and development (R&D), advertising\
    \ and Big Data marketing, and develops the goodwill dynamic model based on the\
    \ differential game theory. The construction of a goodwill dynamic model has two\
    \ purposes, namely, to increase sales and the return rate. The optimal decisions\
    \ for 3 players under two different cooperative scenarios are obtained, namely,\
    \ the retailer payment scenario (scenario D) and the manufacturer cost-sharing\
    \ scenario (scenario S). The supply chain members gain more profit or achieve\
    \ a higher level of goodwill for products under certain conditions, i.e., a high\
    \ residual value from remanufacturing, a high sharing rate of residual value from\
    \ the retailer's recycled products, and a low recycling cost. Interestingly, the\
    \ wholesale price increases with the residual value of recycled products when\
    \ goodwill effectiveness is low, while the price declines when goodwill effectiveness\
    \ is high. After comparing two cooperative scenarios, the result shows that an\
    \ Internet service platform will invest more in Big Data marketing under the manufacturer\
    \ cost-sharing scenario, and cooperation between the manufacturer and the Internet\
    \ service platform can help improve the goodwill of enterprises or products. Moreover,\
    \ the manufacturer cost-sharing scenario is payoff-Pareto-improving in most cases\
    \ through the coordination of a cost-sharing rate, and the effectiveness of Big\
    \ Data marketing exerts a positive effect on goodwill and the development of the\
    \ industry. In addition, the retailer has \xE2\u20AC\u0153free rider\xE2\u20AC\
    \x9D tendencies in the manufacturer cost-sharing scenario. The results encourage\
    \ more enterprises to enhance the value of goodwill through cooperation with Internet\
    \ service platforms because Internet service platforms conveniently utilize Big\
    \ Data marketing to increase the sales of products and the collecting rate of\
    \ used products, which in turn helps environmental sustainability."
  Author: Zehua Xiang and Minli Xu
  Book_Title_Journal: Journal of Cleaner Production
  DOI: https://doi.org/10.1016/j.jclepro.2019.01.310
  JCS_FACTOR: 9.297
  Keywords: Big data marketing, Differential game, Closed-loop supply chain, Internet
    service platform
  SCI_FACTOR: 1.937
  Title: Dynamic cooperation strategies of the closed-loop supply chain involving
    the internet service platform
  Title_JCS: Journal of Cleaner Production
  Title_SCI: Journal of Cleaner Production
  Type_Publication: article
  Year: 2019
- Abstract: 'Global health threats such as the recent Ebola and Zika virus outbreaks
    require rapid and robust responses to prevent, reduce and recover from disease
    dispersion. As part of broader big data and digital humanitarianism discourses,
    there is an emerging interest in data produced through mobile phone communications
    for enhancing the data environment in such circumstances. This paper assembles
    user perspectives and critically examines existing evidence and future potential
    of mobile phone data derived from call detail records (CDRs) and two-way short
    message service (SMS) platforms, for managing and responding to humanitarian disasters
    caused by communicable disease outbreaks. We undertake a scoping review of relevant
    literature and in-depth interviews with key informants to ascertain the: (i) information
    that can be gathered from CDRs or SMS data; (ii) phase(s) in the disease disaster
    management cycle when mobile data may be useful; (iii) value added over conventional
    approaches to data collection and transfer; (iv) barriers and enablers to use
    of mobile data in disaster contexts; and (v) the social and ethical challenges.
    Based on this evidence we develop a typology of mobile phone data sources, types,
    and end-uses, and a decision-tree for mobile data use, designed to enable effective
    use of mobile data for disease disaster management. We show that mobile data holds
    great potential for improving the quality, quantity and timing of selected information
    required for disaster management, but that testing and evaluation of the benefits,
    constraints and limitations of mobile data use in a wider range of mobile-user
    and disaster contexts is needed to fully understand its utility, validity, and
    limitations.'
  Author: Jonathan Cinnamon and Sarah K. Jones and W. Neil Adger
  Book_Title_Journal: Geoforum
  DOI: https://doi.org/10.1016/j.geoforum.2016.07.019
  JCS_FACTOR: 3.901
  Keywords: Mobile phone, Call detail records, SMS, Disaster, Disease, Big data
  SCI_FACTOR: 1.584
  Title: Evidence and future potential of mobile phone data for disease disaster management
  Title_JCS: GEOFORUM
  Title_SCI: Geoforum
  Type_Publication: article
  Year: 2016
- Abstract: Recent advancements in data-driven process control and performance analysis
    could provide the wastewater treatment industry with an opportunity to reduce
    costs and improve operations. However, big data in wastewater treatment plants
    (WWTP) is widely underutilized, due in part to a workforce that lacks background
    knowledge of data science required to fully analyze the unique characteristics
    of WWTP. Wastewater treatment processes exhibit nonlinear, nonstationary, autocorrelated,
    and co-correlated behavior that (i) is very difficult to model using first principals
    and (ii) must be considered when implementing data-driven methods. This review
    provides an overview of data-driven methods of achieving fault detection, variable
    prediction, and advanced control of WWTP. We present how big data has been used
    in the context of WWTP, and much of the discussion can also be applied to water
    treatment. Due to the assumptions inherent in different data-driven modeling approaches
    (e.g., control charts, statistical process control, model predictive control,
    neural networks, transfer functions, fuzzy logic), not all methods are appropriate
    for every goal or every dataset. Practical guidance is given for matching a desired
    goal with a particular methodology along with considerations regarding the assumed
    data structure. References for further reading are provided, and an overall analysis
    framework is presented.
  Author: Kathryn B. Newhart and Ryan W. Holloway and Amanda S. Hering and Tzahi Y.
    Cath
  Book_Title_Journal: Water Research
  DOI: https://doi.org/10.1016/j.watres.2019.03.030
  JCS_FACTOR: 11.236
  Keywords: Wastewater treatment, Big data, Statistical process control, Process optimization,
    Monitoring
  SCI_FACTOR: 3.099
  Title: 'Data-driven performance analyses of wastewater treatment plants: A review'
  Title_JCS: WATER RESEARCH
  Title_SCI: Water Research
  Type_Publication: article
  Year: 2019
- Abstract: Vibration serviceability issue has attracted increasing attentions recently.
    Many studies on vibration serviceability limitations have been performed in labs
    using simulation. The proposed limits were incompatible and lacked details about
    the physiological and environmental factors because of small sample sizes and
    unrealistic environments. This study proposes a novel online big data approach
    for investigating vibration serviceability limits in real environment. A smartphone-based
    application (App) was designed and spread to volunteers to collect multi-source
    heterogeneous data including questionnaires of personal judgement on vibration
    level, vibration signals, environmental and biological factors in their daily
    life. So far, 8521 records have been received. Data cleaning was performed and
    a qualified database with large volume and various types of factor information
    was produced. Analysis of the database showed that vibration limits given by the
    new method were compatible with previous results, but with more abundant details
    that were ignored in previous studies.
  Author: Lei Cao and Jun Chen
  Book_Title_Journal: Measurement
  DOI: https://doi.org/10.1016/j.measurement.2020.107850
  JCS_FACTOR: 3.927
  Keywords: Vibration serviceability, Online sampling, Big data, Data cleaning
  SCI_FACTOR: 1.293
  Title: Online investigation of vibration serviceability limitations using smartphones
  Title_JCS: MEASUREMENT
  Title_SCI: Measurement
  Type_Publication: article
  Year: 2020
- Abstract: Dashboards visualize a consolidated set data for a certain purpose which
    enables users to see what is happening and to initiate actions. Dashboards can
    be used by governments to support their decision-making and policy processes or
    to communicate and interact with the public. The objective of this paper is to
    understand and to support the design of dashboards for creating transparency and
    accountability. Two smart city cases are investigated showing that dashboards
    can improve transparency and accountability, however, realizing these benefits
    was cumbersome and encountered various risks and challenges. Challenges include
    insufficient data quality, lack of understanding of data, poor analysis, wrong
    interpretation, confusion about the outcomes, and imposing a pre-defined view.
    These challenges can easily result in misconceptions, wrong decision-making, creating
    a blurred picture resulting in less transparency and accountability, and ultimately
    in even less trust in the government. Principles guiding the design of dashboards
    are presented. Dashboards need to be complemented by mechanisms supporting citizens'
    engagement, data interpretation, governance and institutional arrangements.
  Author: Ricardo Matheus and Marijn Janssen and Devender Maheshwari
  Book_Title_Journal: Government Information Quarterly
  DOI: https://doi.org/10.1016/j.giq.2018.01.006
  JCS_FACTOR: 7.279
  Keywords: Data science, Dashboards, E-government, Open government, Open data, Big
    data, Smart City, Design principles, Transparency, Accountability, Trust, Policy-making,
    Decision-making
  SCI_FACTOR: 2.121
  Title: 'Data science empowering the public: Data-driven dashboards for transparent
    and accountable decision-making in smart cities'
  Title_JCS: GOVERNMENT INFORMATION QUARTERLY
  Title_SCI: Government Information Quarterly
  Type_Publication: article
  Year: 2020
- Abstract: The rise of Big, Open and Linked Data (BOLD) enables Big Data Algorithmic
    Systems (BDAS) which are often based on machine learning, neural networks and
    other forms of Artificial Intelligence (AI). As such systems are increasingly
    requested to make decisions that are consequential to individuals, communities
    and society at large, their failures cannot be tolerated, and they are subject
    to stringent regulatory and ethical requirements. However, they all rely on data
    which is not only big, open and linked but varied, dynamic and streamed at high
    speeds in real-time. Managing such data is challenging. To overcome such challenges
    and utilize opportunities for BDAS, organizations are increasingly developing
    advanced data governance capabilities. This paper reviews challenges and approaches
    to data governance for such systems, and proposes a framework for data governance
    for trustworthy BDAS. The framework promotes the stewardship of data, processes
    and algorithms, the controlled opening of data and algorithms to enable external
    scrutiny, trusted information sharing within and between organizations, risk-based
    governance, system-level controls, and data control through shared ownership and
    self-sovereign identities. The framework is based on 13 design principles and
    is proposed incrementally, for a single organization and multiple networked organizations.
  Author: Marijn Janssen and Paul Brous and Elsa Estevez and Luis S. Barbosa and Tomasz
    Janowski
  Book_Title_Journal: Government Information Quarterly
  DOI: https://doi.org/10.1016/j.giq.2020.101493
  JCS_FACTOR: 7.279
  Keywords: Big data, Data governance, AI, Algorithmic governance, Information sharing,
    Artificial Intelligence, Trusted frameworks
  SCI_FACTOR: 2.121
  Title: 'Data governance: Organizing data for trustworthy Artificial Intelligence'
  Title_JCS: GOVERNMENT INFORMATION QUARTERLY
  Title_SCI: Government Information Quarterly
  Type_Publication: article
  Year: 2020
- Abstract: "The technical features of blockchain, including decentralization, data\
    \ transparency, tamper-proofing, traceability, privacy protection and open-sourcing,\
    \ make it a suitable technology for solving the information asymmetry problem\
    \ in personal credit reporting transactions. Applying blockchain technology to\
    \ credit reporting meets the needs of social credit system construction and may\
    \ become an important technical direction in the future. This paper analyzed the\
    \ problems faced by China\xE2\u20AC\u2122s personal credit reporting market, designed\
    \ the framework of personal credit information sharing platform based on blockchain\
    \ 3.0 architecture, studied the technical details of the platform and the technical\
    \ advantages, and finally, applied the platform to the credit blacklist sharing\
    \ transaction and explored the possible implementation approach. The in-depth\
    \ integration of blockchain technology and personal credit reporting helps to\
    \ realize the safe sharing of credit data and reduce the cost of credit data collection,\
    \ thereby helping the technological and efficiency transformation of the personal\
    \ credit reporting industry and promoting the overall development of the social\
    \ credit system."
  Author: Jing Zhang and Rong Tan and Chunhua Su and Wen Si
  Book_Title_Journal: Journal of Information Security and Applications
  DOI: https://doi.org/10.1016/j.jisa.2020.102659
  JCS_FACTOR: 3.872
  Keywords: Consortium blockchain, Personal credit reporting, Credit information sharing,
    Big data crediting
  SCI_FACTOR: 0.61
  Title: Design and application of a personal credit information sharing platform
    based on consortium blockchain
  Title_JCS: Journal of Information Security and Applications
  Title_SCI: Journal of Information Security and Applications
  Type_Publication: article
  Year: 2020
- Abstract: "The big data approach offers a powerful alternative to Evidence-based\
    \ medicine. This approach could guide cancer management thanks to machine learning\
    \ application to large-scale data. Aim of the Thyroid CoBRA (Consortium for Brachytherapy\
    \ Data Analysis) project is to develop a standardized web data collection system,\
    \ focused on thyroid cancer. The Metabolic Radiotherapy Working Group of Italian\
    \ Association of Radiation Oncology (AIRO) endorsed the implementation of a consortium\
    \ directed to thyroid cancer management and data collection. The agreement conditions,\
    \ the ontology of the collected data and the related software services were defined\
    \ by a multicentre ad hoc working-group (WG). Six Italian cancer centres were\
    \ firstly started the project, defined and signed the Thyroid COBRA consortium\
    \ agreement. Three data set tiers were identified: Registry, Procedures and Research.\
    \ The COBRA-Storage System (C-SS) appeared to be not time-consuming and to be\
    \ privacy respecting, as data can be extracted directly from the single centre's\
    \ storage platforms through a secured connection that ensures reliable encryption\
    \ of sensible data. Automatic data archiving could be directly performed from\
    \ Image Hospital Storage System or the Radiotherapy Treatment Planning Systems.\
    \ The C-SS architecture will allow \xE2\u20AC\u0153Cloud storage way\xE2\u20AC\
    \x9D or \xE2\u20AC\u0153distributed learning\xE2\u20AC\x9D approaches for predictive\
    \ model definition and further clinical decision support tools development. The\
    \ development of the Thyroid COBRA data Storage System C-SS through a multicentre\
    \ consortium approach appeared to be a feasible tool in the setup of complex and\
    \ privacy saving data sharing system oriented to the management of thyroid cancer\
    \ and in the near future every cancer type."
  Author: Luca Tagliaferri and Carlo Gobitti and Giuseppe Ferdinando Colloca and Luca
    Boldrini and Eleonora Farina and Carlo Furlan and Fabiola Paiar and Federica Vianello
    and Michela Basso and Lorenzo Cerizza and Fabio Monari and Gabriele Simontacchi
    and Maria Antonietta Gambacorta and Jacopo Lenkowicz and Nicola Dinapoli and Vito
    Lanzotti and Renzo Mazzarotto and Elvio Russi and Monica Mangoni
  Book_Title_Journal: European Journal of Internal Medicine
  DOI: https://doi.org/10.1016/j.ejim.2018.02.012
  JCS_FACTOR: 4.487
  Keywords: Big data, Data pooling, Personalized medicine, Radiotherapy, Thyroid,
    Cancer management
  SCI_FACTOR: 0.894
  Title: 'A new standardized data collection system for interdisciplinary thyroid
    cancer management: Thyroid COBRA'
  Title_JCS: European Journal of Internal Medicine
  Title_SCI: European Journal of Internal Medicine
  Type_Publication: article
  Year: 2018
- Abstract: Infectious diseases, including vector-borne diseases transmitted by arthropods,
    are a leading cause of morbidity and mortality worldwide. In the era of big data,
    addressing broad-scale, fundamental questions regarding the complex dynamics of
    these diseases will increasingly require the integration of diverse datasets to
    produce new biological knowledge. This review provides a current snapshot of the
    systematic assessment of the relationships between microbial pathogens, arthropod
    vectors and mammalian hosts using data mining and machine learning. We employ
    PRISMA to identify 32 key papers relevant to this topic. Our analysis shows an
    increasing use of data mining and machine learning tasks and techniques, including
    prediction, classification, clustering, association rules mining, and deep learning,
    over the last decade. However, it also reveals a number of critical challenges
    in applying these to the study of vector-host-pathogen interactions at various
    systems biology levels. Here, relevant studies, current limitations and future
    directions are discussed. Furthermore, the quality of data in relevant papers
    was assessed using the FAIR (Findable, Accessible, Interoperable, Reusable) compliance
    criteria to evaluate and encourage reproducibility and shareability of research
    outcomes. Although shortcomings in their application remain, data mining and machine
    learning have significant potential to break new ground in understanding fundamental
    aspects of vector-host-pathogen relationships and their application in this field
    should be encouraged. In particular, while predictive modeling, feature engineering
    and supervised machine learning are already being used in the field, other data
    mining and machine learning methods such as deep learning and association rules
    analysis lag behind and should be implemented in combination with established
    methods to accelerate hypothesis and knowledge generation in the domain.
  Author: Diing D.M. Agany and Jose E. Pietri and Etienne Z. Gnimpieba
  Book_Title_Journal: Computational and Structural Biotechnology Journal
  DOI: https://doi.org/10.1016/j.csbj.2020.06.031
  JCS_FACTOR: 7.271
  Keywords: Systems Bioscience, OMICs, Pathogenicity, Transmission, Adaptation, Data
    Mining, Big Data, Machine Learning, Association Mining, Host-Pathogen, Interaction,
    Infectious Disease, Vector-Borne Disease
  SCI_FACTOR: 1.908
  Title: Assessment of vector-host-pathogen relationships using data mining and machine
    learning
  Title_JCS: Computational and Structural Biotechnology Journal
  Title_SCI: Computational and Structural Biotechnology Journal
  Type_Publication: article
  Year: 2020
- Abstract: Machine learning holds great promise for lowering product and service
    costs, speeding up business processes, and serving customers better. It is recognized
    as one of the most important application areas in this era of unprecedented technological
    development, and its adoption is gaining momentum across almost all industries.
    In view of this, we offer a brief discussion of categories of machine learning
    and then present three types of machine-learning usage at enterprises. We then
    discuss the trade-off between the accuracy and interpretability of machine-learning
    algorithms, a crucial consideration in selecting the right algorithm for the task
    at hand. We next outline three cases of machine-learning development in financial
    services. Finally, we discuss challenges all managers must confront in deploying
    machine-learning applications.
  Author: In Lee and Yong Jae Shin
  Book_Title_Journal: Business Horizons
  DOI: https://doi.org/10.1016/j.bushor.2019.10.005
  JCS_FACTOR: 6.361
  Keywords: Machine learning, Artificial intelligence, Deep learning, Big data, Neural
    networks, Chatbot, Innovation capability, Resources and capabilities
  SCI_FACTOR: 2.174
  Title: 'Machine learning for enterprises: Applications, algorithm selection, and
    challenges'
  Title_JCS: BUSINESS HORIZONS
  Title_SCI: Business Horizons
  Type_Publication: article
  Year: 2020
- Abstract: 'As companies become increasingly digital, growth hacking emerged as a
    new way of scaling businesses. While the term is fashionable in business, many
    executives remain confused about the concept. Even if firms have an idea of what
    growth hacking is, they may still be puzzled as to how to do it, creating a strategy-execution
    gap. Our article assists firms by bridging the growth hacking strategy-execution
    gap. First, we provide a growth hacking framework and deconstruct its building
    blocks: marketing, data analysis, coding, and the lean startup philosophy. We
    then present a taxonomy of 34 growth hacking patterns along the customer lifecycle
    of acquisition, activation, revenue, retention, and referral; categorize them
    on the two dimensions of resource intensity and time lag; and provide an example
    of how to apply the taxonomy in the case of a fitness application. Finally, we
    discuss seven opportunities and challenges of growth hacking that firms should
    keep in mind.'
  Author: "Ren\xC3\xA9 Bohnsack and Meike Malena Liesner"
  Book_Title_Journal: Business Horizons
  DOI: https://doi.org/10.1016/j.bushor.2019.09.001
  JCS_FACTOR: 6.361
  Keywords: Growth hacking, Digital transformation, Lean startup, Digital marketing,
    Big data
  SCI_FACTOR: 2.174
  Title: What the hack? A growth hacking taxonomy and practical applications for firms
  Title_JCS: BUSINESS HORIZONS
  Title_SCI: Business Horizons
  Type_Publication: article
  Year: 2019
- Abstract: "As sensory evaluation relies upon humans accurately communicating their\
    \ sensory experience, the diverse and overlapping vocabulary of flavor descriptors\
    \ remains a major challenge. The lexicon generation protocols used in methods\
    \ like Descriptive Analysis are expensive and time-consuming, while the post-facto\
    \ analyses of natural vocabulary in \xE2\u20AC\u0153quick and dirty\xE2\u20AC\x9D\
    \ methods like Free Choice or Flash Profiling require considerable subjective\
    \ decision-making on the part of the analyst. A potential alternative for producing\
    \ lexicons and analyzing the sensory attributes of products in nonstandardized\
    \ text can be found in Natural Language Processing (NLP). NLP tools allow for\
    \ the analysis of larger volumes of free text with fewer subjective decisions.\
    \ This paper describes the steps necessary to automatically collect, clean, and\
    \ analyze existing product descriptions from the web. As a case study, online\
    \ reviews of international whiskies from two prominent websites (2309 reviews\
    \ from WhiskyCast and 4289 reviews from WhiskyAdvocate) were collected, preprocessed\
    \ to only retain potentially-descriptive nouns, adjectives, and verbs, and then\
    \ the final term list was grouped into a flavor wheel using Correspondence Analysis\
    \ and Agglomerative Hierarchical Clustering. The wheel is compared to an existing\
    \ Scotch flavor wheel. The ease of collecting nonstandardized descriptions of\
    \ products and the improved speed of automated methods can facilitate collection\
    \ of descriptive sensory data for products where no lexicon exists. This has the\
    \ potential to speed up and standardize many of the bottlenecks in rapid descriptive\
    \ methods and facilitate the collection and use of very large datasets of product\
    \ descriptions."
  Author: Leah M. Hamilton and Jacob Lahne
  Book_Title_Journal: Food Quality and Preference
  DOI: https://doi.org/10.1016/j.foodqual.2020.103926
  JCS_FACTOR: 5.565
  Keywords: Natural language processing, Rapid descriptive methods, Big data, Whisky,
    Research methodology, Machine learning
  SCI_FACTOR: 1.135
  Title: 'Fast and automated sensory analysis: Using natural language processing for
    descriptive lexicon development'
  Title_JCS: FOOD QUALITY AND PREFERENCE
  Title_SCI: Food Quality and Preference
  Type_Publication: article
  Year: 2020
- Abstract: Executives see technology, data and analytics as a transforming force
    in business. Many organizations are therefore implementing business intelligence
    & analytics (BI&A) technologies to support reporting and decision-making. Traditionally,
    management accounting is the primary support for decision-making and control in
    an organization. As such, it has clear links to and can benefit from applying
    BI&A technologies. This indicates an interesting research area for accounting
    and AIS researchers. However, a review of the literature in top accounting and
    information systems journals indicates that to date, little research has focused
    on this link. This article reviews the literature, points to several research
    gaps and proposes a framework for studying the relationship between BI&A and management
    accounting.
  Author: Pall Rikhardsson and Ogan Yigitbasioglu
  Book_Title_Journal: International Journal of Accounting Information Systems
  DOI: https://doi.org/10.1016/j.accinf.2018.03.001
  JCS_FACTOR: 4.4
  Keywords: Business intelligence, Management accounting, Big data, Analytics
  SCI_FACTOR: 0.897
  Title: 'Business intelligence & analytics in management accounting research: Status
    and future focus'
  Title_JCS: International Journal of Accounting Information Systems
  Title_SCI: International Journal of Accounting Information Systems
  Type_Publication: article
  Year: 2018
- Abstract: The advancement of various research sectors such as Internet of Things
    (IoT), Machine Learning, Data Mining, Big Data, and Communication Technology has
    shed some light in transforming an urban city integrating the aforementioned techniques
    to a commonly known term - Smart City. With the emergence of smart city, plethora
    of data sources have been made available for wide variety of applications. The
    common technique for handling multiple data sources is data fusion, where it improves
    data output quality or extracts knowledge from the raw data. In order to cater
    evergrowing highly complicated applications, studies in smart city have to utilize
    data from various sources and evaluate their performance based on multiple aspects.
    To this end, we introduce a multi-perspectives classification of the data fusion
    to evaluate the smart city applications. Moreover, we applied the proposed multi-perspectives
    classification to evaluate selected applications in each domain of the smart city.
    We conclude the paper by discussing potential future direction and challenges
    of data fusion integration.
  Author: Billy Pik Lik Lau and Sumudu Hasala Marakkalage and Yuren Zhou and Naveed
    Ul Hassan and Chau Yuen and Meng Zhang and U-Xuan Tan
  Book_Title_Journal: Information Fusion
  DOI: https://doi.org/10.1016/j.inffus.2019.05.004
  JCS_FACTOR: 12.975
  Keywords: Data fusion, Sensor fusion, Smart city, Big data, Internet of things,
    Multi-perspectives classification
  SCI_FACTOR: 2.776
  Title: A survey of data fusion in smart city applications
  Title_JCS: Information Fusion
  Title_SCI: Information Fusion
  Type_Publication: article
  Year: 2019
- Abstract: "The critical factors in the big data era are collection, analysis, and\
    \ dissemination of information to improve an organization\xE2\u20AC\u2122s competitive\
    \ position and enhance its products and services. In this scenario, it is imperative\
    \ that organizations use Intelligence, which is understood as a process of gathering,\
    \ analyzing, interpreting, and disseminating high-value data and information at\
    \ the right time for use in the decision-making process. Earlier, the concept\
    \ of Intelligence was associated with the military and national security sector;\
    \ however, in present times, and as organizations evolve, Intelligence has been\
    \ defined in several ways for the purposes of different applications. Given that\
    \ the purpose of Intelligence is to obtain real value from data, information,\
    \ and the dynamism of the organizations, the study of this discipline provides\
    \ an opportunity to analyze the core trends related to data collection and processing,\
    \ information management, decision-making process, and organizational capabilities.\
    \ Therefore, the present study makes a conceptual analysis of the existing definitions\
    \ of intelligence in the literature by quantifying the main bibliometric performance\
    \ indicators, identifying the main authors and research areas, and evaluating\
    \ the development of the field using SciMAT as a bibliometric analysis software."
  Author: "J.R. L\xC3\xB3pez-Robles and J.R. Otegi-Olaso and I. {Porto G\xC3\xB3mez}\
    \ and M.J. Cobo"
  Book_Title_Journal: International Journal of Information Management
  DOI: https://doi.org/10.1016/j.ijinfomgt.2019.01.013
  JCS_FACTOR: 14.098
  Keywords: Business Intelligence, Competitive Intelligence, Strategic Intelligence,
    Science information management, Mapping analysis
  SCI_FACTOR: 2.77
  Title: '30 years of intelligence models in management and business: A bibliometric
    review'
  Title_JCS: INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
  Title_SCI: International Journal of Information Management
  Type_Publication: article
  Year: 2019
- Abstract: "The effect of height on pollen concentration is not well documented and\
    \ little is known about the near-ground vertical profile of airborne pollen. This\
    \ is important as most measuring stations are on roofs, but patient exposure is\
    \ at ground level. Our study used a big data approach to estimate the near-ground\
    \ vertical profile of pollen concentrations based on a global study of paired\
    \ stations located at different heights. We analyzed paired sampling stations\
    \ located at different heights between 1.5 and 50\xE2\u20AC\xAFm above ground\
    \ level (AGL). This provided pollen data from 59 Hirst-type volumetric traps from\
    \ 25 different areas, mainly in Europe, but also covering North America and Australia,\
    \ resulting in about 2,000,000 daily pollen concentrations analyzed. The daily\
    \ ratio of the amounts of pollen from different heights per location was used,\
    \ and the values of the lower station were divided by the higher station. The\
    \ lower station of paired traps recorded more pollen than the higher trap. However,\
    \ while the effect of height on pollen concentration was clear, it was also limited\
    \ (average ratio 1.3, range 0.7\xE2\u20AC\u201C2.2). The standard deviation of\
    \ the pollen ratio was highly variable when the lower station was located close\
    \ to the ground level (below 10\xE2\u20AC\xAFm AGL). We show that pollen concentrations\
    \ measured at >10\xE2\u20AC\xAFm are representative for background near-ground\
    \ levels."
  Author: "Jes\xC3\xBAs Rojo and Jose Oteros and Rosa P\xC3\xA9rez-Badia and Patricia\
    \ Cervig\xC3\xB3n and Zuzana Ferencova and A. Monserrat Guti\xC3\xA9rrez-Bustillo\
    \ and Karl-Christian Bergmann and Gilles Oliver and Michel Thibaudon and Roberto\
    \ Albertini and David {Rodr\xC3\xADguez-De la Cruz} and Estefan\xC3\xADa S\xC3\
    \xA1nchez-Reyes and Jos\xC3\xA9 S\xC3\xA1nchez-S\xC3\xA1nchez and Anna-Mari Pessi\
    \ and Jukka Reiniharju and Annika Saarto and M. Carmen Calder\xC3\xB3n and C\xC3\
    \xA9sar Guerrero and Daniele Berra and Maira Bonini and Elena Chiodini and Delia\
    \ Fern\xC3\xA1ndez-Gonz\xC3\xA1lez and Jos\xC3\xA9 Garc\xC3\xADa and M. Mar Trigo\
    \ and Dorota Myszkowska and Santiago Fern\xC3\xA1ndez-Rodr\xC3\xADguez and Rafael\
    \ Tormo-Molina and Athanasios Damialis and Franziska Kolek and Claudia Traidl-Hoffmann\
    \ and Elena Severova and Elsa Caeiro and Helena Ribeiro and Don\xC3\xA1t Magyar\
    \ and L\xC3\xA1szl\xC3\xB3 Makra and Orsolya Udvardy and Purificaci\xC3\xB3n Alc\xC3\
    \xA1zar and Carmen Gal\xC3\xA1n and Katarzyna Borycka and Idalia Kasprzyk and\
    \ Ed Newbigin and Beverley Adams-Groom and Godfrey P. Apangu and Carl A. Frisk\
    \ and Carsten A. Skj\xC3\xB8th and Predrag Radi\xC5\xA1i\xC4\u2021 and Branko\
    \ \xC5\_ikoparija and Sevcan Celenk and Carsten B. Schmidt-Weber and Jeroen Buters"
  Book_Title_Journal: Environmental Research
  DOI: https://doi.org/10.1016/j.envres.2019.04.027
  JCS_FACTOR: 6.498
  Keywords: Height, Pollen, Aerobiology, Monitoring network, Big data
  SCI_FACTOR: 1.46
  Title: Near-ground effect of height on pollen exposure
  Title_JCS: ENVIRONMENTAL RESEARCH
  Title_SCI: Environmental Research
  Type_Publication: article
  Year: 2019
- Abstract: With the rapid developments in ICT, the current agriculture businesses
    have become increasingly data-driven and are supported by advanced data analytics
    techniques. In this context, several studies have investigated the adopted data
    analytics platforms in the agricultural sector. However, the main characteristics
    and overall findings on these platforms are scattered over the various studies,
    and to the best of our knowledge, there has been no attempt yet to systematically
    synthesize the features and obstacles of the adopted data analytics platforms.
    This article presents the results of an in-depth systematic literature review
    (SLR) that has explicitly focused on the domains of the platforms, the stakeholders,
    the objectives, the adopted technologies, the data properties and the obstacles.
    According to the year-wise analysis, it is found that no relevant primary study
    between 2010 and 2013 was found. This implies that the research of data analytics
    in agricultural sectors is a popular topic from recent years, so the results from
    before 2010 are likely less relevant. In total, 535 papers published from 2010
    to 2020 were retrieved using both automatic and manual search strategies, among
    which 45 journal articles were selected for further analysis. From these primary
    studies, 33 features and 34 different obstacles were identified. The identified
    features and obstacles help characterize the different data analytics platforms
    and pave the way for further research.
  Author: Ngakan {Nyoman Kutha Krisnawijaya} and Bedir Tekinerdogan and Cagatay Catal
    and Rik van der Tol
  Book_Title_Journal: Computers and Electronics in Agriculture
  DOI: https://doi.org/10.1016/j.compag.2022.106813
  JCS_FACTOR: 5.565
  Keywords: Data analytics platforms, Agriculture, Systematic literature review, Big
    Data
  SCI_FACTOR: 1.208
  Title: 'Data analytics platforms for agricultural systems: A systematic literature
    review'
  Title_JCS: COMPUTERS AND ELECTRONICS IN AGRICULTURE
  Title_SCI: Computers and Electronics in Agriculture
  Type_Publication: article
  Year: 2022
- Abstract: The Internet of Things is allowing agriculture, here specifically arable
    farming, to become data-driven, leading to more timely and cost-effective production
    and management of farms, and at the same time reducing their environmental impact.
    This review is addressing an analytical survey of the current and potential application
    of Internet of Things in arable farming, where spatial data, highly varying environments,
    task diversity and mobile devices pose unique challenges to be overcome compared
    to other agricultural systems. The review contributes an overview of the state
    of the art of technologies deployed. It provides an outline of the current and
    potential applications, and discusses the challenges and possible solutions and
    implementations. Lastly, it presents some future directions for the Internet of
    Things in arable farming. Current issues such as smart phones, intelligent management
    of Wireless Sensor Networks, middleware platforms, integrated Farm Management
    Information Systems across the supply chain, or autonomous vehicles and robotics
    stand out because of their potential to lead arable farming to smart arable farming.
    During the implementation, different challenges are encountered, and here interoperability
    is a key major hurdle throughout all the layers in the architecture of an Internet
    of Things system, which can be addressed by shared standards and protocols. Challenges
    such as affordability, device power consumption, network latency, Big Data analysis,
    data privacy and security, among others, have been identified by the articles
    reviewed and are discussed in detail. Different solutions to all identified challenges
    are presented addressing technologies such as machine learning, middleware platforms,
    or intelligent data management.
  Author: "Andr\xC3\xA9s Villa-Henriksen and Gareth T.C. Edwards and Liisa A. Pesonen\
    \ and Ole Green and Claus Aage Gr\xC3\xB8n S\xC3\xB8rensen"
  Book_Title_Journal: Biosystems Engineering
  DOI: https://doi.org/10.1016/j.biosystemseng.2019.12.013
  JCS_FACTOR: 4.123
  Keywords: Smart farming, Internet of things, Wireless sensor network, Farm management
    information system, Big data, Machine learning
  SCI_FACTOR: 0.894
  Title: 'Internet of Things in arable farming: Implementation, applications, challenges
    and potential'
  Title_JCS: BIOSYSTEMS ENGINEERING
  Title_SCI: Biosystems Engineering
  Type_Publication: article
  Year: 2020
- Abstract: The world population is estimated to reach nine billion by 2050. Many
    challenges are adding pressure on the current agriculture supply chains that include
    shrinking land sizes, ever increasing demand for natural resources and environmental
    issues. The agriculture systems need a major transformation from the traditional
    practices to precision agriculture or smart farming practices to overcome these
    challenges. Geographic information system (GIS) is one such technology that pushes
    the current methods to precision agriculture. In this paper, we present a systematic
    literature review (SLR) of 120 research papers on various applications of big
    GIS analytics (BGA) in agriculture. The selected papers are classified into two
    broad categories; the level of analytics and GIS applications in agriculture.
    The GIS applications viz., land suitability, site search and selection, resource
    allocation, impact assessment, land allocation, and knowledge-based systems are
    considered in this study. The outcome of this study is a proposed BGA framework
    for agriculture supply chain. This framework identifies big data analytics to
    play a significant role in improving the quality of GIS application in agriculture
    and provides the researchers, practitioners, and policymakers with guidelines
    on the successful management of big GIS data for improved agricultural productivity.
  Author: Rohit Sharma and Sachin S. Kamble and Angappa Gunasekaran
  Book_Title_Journal: Computers and Electronics in Agriculture
  DOI: https://doi.org/10.1016/j.compag.2018.10.001
  JCS_FACTOR: 5.565
  Keywords: Agriculture supply chain, GIS analytics, Big data analytics, Internet
    of things, Drones, Smart farming
  SCI_FACTOR: 1.208
  Title: 'Big GIS analytics framework for agriculture supply chains: A literature
    review identifying the current trends and future perspectives'
  Title_JCS: COMPUTERS AND ELECTRONICS IN AGRICULTURE
  Title_SCI: Computers and Electronics in Agriculture
  Type_Publication: article
  Year: 2018
- Abstract: "Digital technologies are growing in importance for accelerating firms\xE2\
    \u20AC\u2122 circular economy transition. However, so far, the focus has primarily\
    \ been on the technical aspects of implementing these technologies with limited\
    \ research on the organizational resources and capabilities required for successfully\
    \ leveraging digital technologies for circular economy. To address this gap, this\
    \ paper explores the business analytics resources firms should develop and how\
    \ these should be orchestrated towards a firm-wide capability. The paper proposes\
    \ a conceptual model highlighting eight business analytics resources that, in\
    \ combination, build a business analytics capability for the circular economy\
    \ and how this relates to firms\xE2\u20AC\u2122 circular economy implementation,\
    \ resource orchestration capability, and competitive performance. The model is\
    \ based on the results of a thematic analysis of 15 semi-structured expert interviews\
    \ with key positions in industry. Our approach is informed by and further develops,\
    \ the theory of the resource-based view and the resource orchestration view. Based\
    \ on the results, we develop a deeper understanding of the importance of taking\
    \ a holistic approach to business analytics when leveraging data and analytics\
    \ towards a more efficient and effective digital-enabled circular economy, the\
    \ smart circular economy."
  Author: Eivind Kristoffersen and Patrick Mikalef and Fenna Blomsma and Jingyue Li
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2021.120957
  JCS_FACTOR: 8.593
  Keywords: Digital circular economy, Sustainability, Big data analytics, Competitive
    advantage, Resource-based view, Expert interviews
  SCI_FACTOR: 2.226
  Title: Towards a business analytics capability for the circular economy
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2021
- Abstract: Insurance plays a crucial role in human efforts to adapt to environmental
    hazards. Effective insurance can serve as both a measure to distribute, and a
    method to communicate risk. In order for insurance to fulfil these roles successfully,
    policy pricing and cover choices must be risk-based and founded on accurate information.
    This is reliant on a robust evidence base forming the foundation of policy choices.
    This paper focuses on the evidence available to insurers and emergent innovation
    in the use of data. The main risk considered is coastal flooding, for which the
    insurance sector offers an option for potential adaptation, capable of increasing
    resilience. However, inadequate supply and analysis of data have been highlighted
    as factors preventing insurance from fulfilling this role. Research was undertaken
    to evaluate how data are currently, and could potentially, be used within risk
    evaluations for the insurance industry. This comprised of 50 interviews with those
    working and associated with the London insurance market. The research reveals
    new opportunities, which could facilitate improvements in risk-reflective pricing
    of policies. These relate to a new generation of data collection techniques and
    analytics, such as those associated with satellite-derived data, IoT (Internet
    of Things) sensors, cloud computing, and Big Data solutions. Such technologies
    present opportunities to reduce moral hazard through basing predictions and pricing
    of risk on large empirical datasets. The value of insurers' claims data is also
    revealed, and is shown to have the potential to refine, calibrate, and validate
    models and methods. The adoption of such data-driven techniques could enable insurers
    to re-evaluate risk ratings, and in some instances, extend coverage to locations
    and developments, previously rated as too high a risk to insure. Conversely, other
    areas may be revealed more vulnerable, which could generate negative impacts for
    residents in these regions, such as increased premiums. However, the enhanced
    risk awareness generated, by new technology, data and data analytics, could positively
    alter future planning, development and investment decisions.
  Author: Alexander G. Rumson and Stephen H. Hallett
  Book_Title_Journal: Science of The Total Environment
  DOI: https://doi.org/10.1016/j.scitotenv.2019.01.114
  JCS_FACTOR: 7.963
  Keywords: Risk analytics, Adaptation, Remote sensing, Big Data
  SCI_FACTOR: 1.795
  Title: Innovations in the use of data facilitating insurance as a resilience mechanism
    for coastal flood risk
  Title_JCS: SCIENCE OF THE TOTAL ENVIRONMENT
  Title_SCI: Science of the Total Environment
  Type_Publication: article
  Year: 2019
- Abstract: With the advances of information technologies, today's building automation
    systems (BASs) are capable of managing building operational performance in an
    efficient and convenient way. Meanwhile, the amount of real-time monitoring and
    control data in BASs grows continually in the building lifecycle, which stimulates
    an intense demand for powerful big data analysis tools in BASs. Existing big data
    analytics adopted in the building automation industry focus on mining cross-sectional
    relationships, whereas the temporal relationships, i.e., the relationships over
    time, are usually overlooked. However, building operations are typically dynamic
    and BAS data are essentially multivariate time series data. This paper presents
    a time series data mining methodology for temporal knowledge discovery in big
    BAS data. A number of time series data mining techniques are explored and carefully
    assembled, including the Symbolic Aggregate approXimation (SAX), motif discovery,
    and temporal association rule mining. This study also develops two methods for
    the efficient post-processing of knowledge discovered. The methodology has been
    applied to analyze the BAS data retrieved from a real building. The temporal knowledge
    discovered is valuable to identify dynamics, patterns and anomalies in building
    operations, derive temporal association rules within and between subsystems, assess
    building system performance and spot opportunities in energy conservation.
  Author: Cheng Fan and Fu Xiao and Henrik Madsen and Dan Wang
  Book_Title_Journal: Energy and Buildings
  DOI: https://doi.org/10.1016/j.enbuild.2015.09.060
  JCS_FACTOR: 5.879
  Keywords: Temporal knowledge discovery, Time series data mining, Big data, Building
    automation system, Building energy management
  SCI_FACTOR: 1.737
  Title: Temporal knowledge discovery in big BAS data for building energy management
  Title_JCS: ENERGY AND BUILDINGS
  Title_SCI: Energy and Buildings
  Type_Publication: article
  Year: 2015
- Abstract: The proliferation of urban sensing, IoT, and big data in cities provides
    unprecedented opportunities for a deeper understanding of occupant behaviour and
    energy usage patterns at the urban scale. This enables data-driven building and
    energy models to capture the urban dynamics, specifically the intrinsic occupant
    and energy use behavioural profiles that are not usually considered in traditional
    models. Although there are related reviews, none investigated urban data for use
    in modelling occupant behaviour and energy use at multiple scales, from buildings
    to neighbourhood to city. This survey paper aims to fill this gap by providing
    a critical summary and analysis of the works reported in the literature. We present
    the different sources of occupant-centric urban data that are useful for data-driven
    modelling and categorise the range of applications and recent data-driven modelling
    techniques for urban behaviour and energy modelling, along with the traditional
    stochastic and simulation-based approaches. Finally, we present a set of recommendations
    for future directions in data-driven modelling of occupant behaviour and energy
    in buildings at the urban scale.
  Author: "Flora D. Salim and Bing Dong and Mohamed Ouf and Qi Wang and Ilaria Pigliautile\
    \ and Xuyuan Kang and Tianzhen Hong and Wenbo Wu and Yapan Liu and Shakila Khan\
    \ Rumi and Mohammad Saiedur Rahaman and Jingjing An and Hengfang Deng and Wei\
    \ Shao and Jakub Dziedzic and Fisayo Caleb Sangogboye and Mikkel Baun Kj\xC3\xA6\
    rgaard and Meng Kong and Claudia Fabiani and Anna Laura Pisello and Da Yan"
  Book_Title_Journal: Building and Environment
  DOI: https://doi.org/10.1016/j.buildenv.2020.106964
  JCS_FACTOR: 6.456
  Keywords: Big data, Occupant behaviour, Energy modelling, Mobility, Urban data,
    Sensors, Machine learning, Energy in buildings, Energy in cities
  SCI_FACTOR: 1.736
  Title: 'Modelling urban-scale occupant behaviour, mobility, and energy in buildings:
    A survey'
  Title_JCS: BUILDING AND ENVIRONMENT
  Title_SCI: Building and Environment
  Type_Publication: article
  Year: 2020
- Abstract: "Crowdsourcing, understood as outsourcing tasks or data collection by\
    \ a large group of non-professionals, is increasingly used in scientific research\
    \ and operational applications. In this paper, we reviewed crowdsourcing initiatives\
    \ in agricultural science and farming activities and further discussed the particular\
    \ characteristics of this approach in the field of agriculture. On-going crowdsourcing\
    \ initiatives in agriculture were analysed and categorised according to their\
    \ crowdsourcing component. We identified eight types of agricultural data and\
    \ information that can be generated from crowdsourcing initiatives. Subsequently\
    \ we described existing methods of quality control of the crowdsourced data. We\
    \ analysed the profiles of potential contributors in crowdsourcing initiatives\
    \ in agriculture, suggested ways for increasing farmers\xE2\u20AC\u2122 participation,\
    \ and discussed the on-going initiatives in the light of their target beneficiaries.\
    \ While crowdsourcing is reported to be an efficient way of collecting observations\
    \ relevant to environmental monitoring and contributing to science in general,\
    \ we pointed out that crowdsourcing applications in agriculture may be hampered\
    \ by privacy issues and other barriers to participation. Close connections with\
    \ the farming sector, including extension services and farm advisory companies,\
    \ could leverage the potential of crowdsourcing for both agricultural research\
    \ and farming applications. This paper coins the term of farmsourcing asa professional\
    \ crowdsourcing strategy in farming activities and provides a source of recommendations\
    \ and inspirations for future collaborative actions in agricultural crowdsourcing."
  Author: "Julien Minet and Yannick Curnel and Anne Gobin and Jean-Pierre Goffart\
    \ and Fran\xC3\xA7ois M\xC3\xA9lard and Bernard Tychon and Joost Wellens and Pierre\
    \ Defourny"
  Book_Title_Journal: Computers and Electronics in Agriculture
  DOI: https://doi.org/10.1016/j.compag.2017.08.026
  JCS_FACTOR: 5.565
  Keywords: Crowdsourcing, Citizen science, Smart farming, Participatory approaches,
    Big data, ICT, Data collection
  SCI_FACTOR: 1.208
  Title: 'Crowdsourcing for agricultural applications: A review of uses and opportunities
    for a farmsourcing approach'
  Title_JCS: COMPUTERS AND ELECTRONICS IN AGRICULTURE
  Title_SCI: Computers and Electronics in Agriculture
  Type_Publication: article
  Year: 2017
- Abstract: 'Background

    In the age of information superhighway, big data play a significant role in information
    processing, extractions, retrieving and management. In computational biology,
    the continuous challenge is to manage the biological data. Data mining techniques
    are sometimes imperfect for new space and time requirements. Thus, it is critical
    to process massive amounts of data to retrieve knowledge. The existing software
    and automated tools to handle big data sets are not sufficient. As a result, an
    expandable mining technique that enfolds the large storage and processing capability
    of distributed or parallel processing platforms is essential.

    Method

    In this analysis, a contemporary distributed clustering methodology for imbalance
    data reduction using k-nearest neighbor (K-NN) classification approach has been
    introduced. The pivotal objective of this work is to illustrate real training
    data sets with reduced amount of elements or instances. These reduced amounts
    of data sets will ensure faster data classification and standard storage management
    with less sensitivity. However, general data reduction methods cannot manage very
    big data sets. To minimize these difficulties, a MapReduce-oriented framework
    is designed using various clusters of automated contents, comprising multiple
    algorithmic approaches.

    Results

    To test the proposed approach, a real DNA (deoxyribonucleic acid) dataset that
    consists of 90 million pairs has been used. The proposed model reduces the imbalance
    data sets from large-scale data sets without loss of its accuracy.

    Conclusions

    The obtained results depict that MapReduce based K-NN classifier provided accurate
    results for big data of DNA.'
  Author: Sarwar Kamal and Shamim Hasnat Ripon and Nilanjan Dey and Amira S. Ashour
    and V. Santhi
  Book_Title_Journal: Computer Methods and Programs in Biomedicine
  DOI: https://doi.org/10.1016/j.cmpb.2016.04.005
  JCS_FACTOR: 5.428
  Keywords: MapReduce, K-nearest neighbor, Big data, DNA (deoxyribonucleic acid),
    Computational biology, Imbalance data
  SCI_FACTOR: 0.924
  Title: A MapReduce approach to diminish imbalance parameters for big deoxyribonucleic
    acid dataset
  Title_JCS: COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE
  Title_SCI: Computer Methods and Programs in Biomedicine
  Type_Publication: article
  Year: 2016
- Abstract: "This paper investigates the usability of Future Internet technologies\
    \ (aka \xE2\u20AC\u0153Generic Enablers of the Future Internet\xE2\u20AC\x9D)\
    \ in the context of environmental applications. The paper incorporates the best\
    \ aspects of the state-of-the-art in environmental informatics with geospatial\
    \ solutions and scalable processing capabilities of Internet-based tools. It specifically\
    \ targets the promotion of the \xE2\u20AC\u0153Environmental Observation Web\xE2\
    \u20AC\x9D as an observation-centric paradigm for building the next generation\
    \ of environmental applications. In the Environmental Observation Web, the great\
    \ majority of data are considered as observations. These can be generated from\
    \ sensors (hardware), numerical simulations (models), as well as by humans (human\
    \ sensors). Independently from the observation provenance and application scope,\
    \ data can be represented and processed in a standardised way in order to understand\
    \ environmental processes and their interdependencies. The development of cross-domain\
    \ applications is then leveraged by technologies such as Cloud Computing, Internet\
    \ of Things, Big Data Processing and Analytics. For example, \xE2\u20AC\u0153\
    the cloud\xE2\u20AC\x9D can satisfy the peak-performance needs of applications\
    \ which may occasionally use large amounts of processing power at a fraction of\
    \ the price of a dedicated server farm. The paper also addresses the need for\
    \ Specific Enablers that connect mainstream Future Internet capabilities with\
    \ sensor and geospatial technologies. Main categories of such Specific Enablers\
    \ are described with an overall architectural approach for developing environmental\
    \ applications and exemplar use cases."
  Author: "Carlos Granell and Denis Havlik and Sven Schade and Zoheir Sabeur and Conor\
    \ Delaney and Jasmin Pielorz and Thomas Usl\xC3\xA4nder and Paolo Mazzetti and\
    \ Katharina Schleidt and Mike Kobernus and Fuada Havlik and Nils Rune Bodsberg\
    \ and Arne Berre and Jose Lorenzo Mon"
  Book_Title_Journal: Environmental Modelling & Software
  DOI: https://doi.org/10.1016/j.envsoft.2015.12.015
  JCS_FACTOR: 5.288
  Keywords: Environmental informatics, Environmental observation web, Future internet,
    Cloud computing, Internet of things, Big data, Environmental specific enablers,
    Volunteered geographic information, Crowdtasking
  SCI_FACTOR: 0.0
  Title: Future Internet technologies for environmental applications
  Title_JCS: ENVIRONMENTAL MODELLING & SOFTWARE
  Title_SCI: N/A
  Type_Publication: article
  Year: 2016
- Abstract: The consensus in the literature on providing accurate inflation forecasts
    underlines the importance of precise nowcasts. In this paper, we focus on this
    issue by employing a unique, extensive dataset of online food and non-alcoholic
    beverages prices gathered automatically from the webpages of major online retailers
    in Poland since 2009. We perform a real-time nowcasting experiment by using a
    highly disaggregated framework among popular, simple univariate approaches. We
    demonstrate that pure estimates of online price changes are already effective
    in nowcasting food inflation, but accounting for online food prices in a simple,
    recursively optimized model delivers further gains in the nowcast accuracy. Our
    framework outperforms various other approaches, including judgmental methods,
    traditional benchmarks, and model combinations. After the outbreak of the COVID-19
    pandemic, its nowcasting quality has improved compared to other approaches and
    remained comparable with judgmental nowcasts. We also show that nowcast accuracy
    increases with the volume of online data, but their quality and relevance are
    essential for providing accurate in-sample fit and out-of-sample nowcasts. We
    conclude that online prices can markedly aid the decision-making process at central
    banks.
  Author: "Pawe\xC5\u201A Macias and Damian Stelmasiak and Karol Szafranek"
  Book_Title_Journal: International Journal of Forecasting
  DOI: https://doi.org/10.1016/j.ijforecast.2022.02.007
  JCS_FACTOR: 3.779
  Keywords: Inflation nowcasting, Online prices, Big data, Nowcasting competition,
    Web scraping
  SCI_FACTOR: 1.268
  Title: Nowcasting food inflation with a massive amount of online prices
  Title_JCS: INTERNATIONAL JOURNAL OF FORECASTING
  Title_SCI: International Journal of Forecasting
  Type_Publication: article
  Year: 2022
- Abstract: 'Air pollution is a major problem today that causes serious damage to
    human health. Urban areas are the most affected by the degradation of air quality
    caused by anthropogenic gas emissions. Although there are multiple proposals for
    air quality monitoring, in most cases, two limitations are imposed: the impossibility
    of processing data in Near Real-Time (NRT) for remote sensing approaches and the
    impossibility of reaching areas of limited accessibility or low network coverage
    for ground data approaches. We propose a software architecture that efficiently
    combines complex event processing with remote sensing data from various satellite
    sensors to monitor air quality in NRT, giving support to decision-makers. We illustrate
    the proposed solution by calculating the air quality levels for several areas
    of Morocco and Spain, extracting and processing satellite information in NRT.
    This study also validates the air quality measured by ground stations and satellite
    sensor data.'
  Author: Badr-Eddine Boudriki Semlali and Chaker El Amrani and Guadalupe Ortiz and
    Juan Boubeta-Puig and Alfonso Garcia-de-Prado
  Book_Title_Journal: Computers & Electrical Engineering
  DOI: https://doi.org/10.1016/j.compeleceng.2021.107257
  JCS_FACTOR: 3.818
  Keywords: Remote sensing, Satellite sensors, Air quality, Complex event processing,
    Big data, Decision-making
  SCI_FACTOR: 0.0
  Title: 'SAT-CEP-monitor: An air quality monitoring software architecture combining
    complex event processing with satellite remote sensing'
  Title_JCS: COMPUTERS & ELECTRICAL ENGINEERING
  Title_SCI: N/A
  Type_Publication: article
  Year: 2021
- Abstract: The explosive growth of data in volume, velocity and diversity that are
    produced by medical applications has contributed to abundance of big data. Current
    solutions for efficient data storage and management cannot fulfill the needs of
    heterogeneous data. Therefore, by applying computational intelligence (CI) approaches
    in medical data helps get better management, faster performance and higher level
    of accuracy in detection. This paper aims to investigate the state-of-the-art
    of computational intelligence approaches in medical data and to categorize the
    existing CI techniques, used in medical fields, as single and hybrid. In addition,
    the techniques and methodologies, their limitations and performances are presented
    in this study. The limitations are addressed as challenges to obtain a set of
    requirements for Computational Intelligence Medical Data (CIMD) in establishing
    an efficient CIMD architectural design. The results show that on the one hand
    Support Vector Machine (SVM) and Artificial Immune Recognition System (AIRS) as
    a single based computational intelligence approach were the best methods in medical
    applications. On the other hand, the hybridization of SVM with other methods such
    as SVM-Genetic Algorithm (SVM-GA), SVM-Artificial Immune System (SVM-AIS), SVM-AIRS
    and fuzzy support vector machine (FSVM) had great performances achieving better
    results in terms of accuracy, sensitivity and specificity.
  Author: Ali Kalantari and Amirrudin Kamsin and Shahaboddin Shamshirband and Abdullah
    Gani and Hamid Alinejad-Rokny and Anthony T. Chronopoulos
  Book_Title_Journal: Neurocomputing
  DOI: https://doi.org/10.1016/j.neucom.2017.01.126
  JCS_FACTOR: 5.719
  Keywords: Computational intelligence, Medical application, Big data, Detection,
    Ensemble algorithm
  SCI_FACTOR: 1.085
  Title: 'Computational intelligence approaches for classification of medical data:
    State-of-the-art, future challenges and research directions'
  Title_JCS: NEUROCOMPUTING
  Title_SCI: Neurocomputing
  Type_Publication: article
  Year: 2018
- Abstract: As a new term in the financial industry, FinTech has become a popular
    term that describes novel technologies adopted by the financial service institutions.
    This term covers a large scope of techniques, from data security to financial
    service deliveries. An accurate and up-to-date awareness of FinTech has an urgent
    demand for both academics and professionals. This work aims to produce a survey
    of FinTech by collecting and reviewing contemporary achievements, by which a theoretical
    data-driven FinTech framework is proposed. Five technical aspects are summarized
    and involved, which include security and privacy, data techniques, hardware and
    infrastructure, applications and management, and service models. The main findings
    of this work are fundamentals of forming active FinTech solutions.
  Author: Keke Gai and Meikang Qiu and Xiaotong Sun
  Book_Title_Journal: Journal of Network and Computer Applications
  DOI: https://doi.org/10.1016/j.jnca.2017.10.011
  JCS_FACTOR: 6.281
  Keywords: FinTech, Cloud computing, Cyber security, Big data, Financial computing,
    Data-driven framework
  SCI_FACTOR: 1.145
  Title: A survey on FinTech
  Title_JCS: JOURNAL OF NETWORK AND COMPUTER APPLICATIONS
  Title_SCI: Journal of Network and Computer Applications
  Type_Publication: article
  Year: 2018
- Abstract: 'The Sustainable Development Goals (SDGs) within the United Nations 2030
    Agenda emerged in 2015, becoming an unprecedented global compass for navigating
    extant sustainability challenges. Nevertheless, it still represents a nascent
    field enduring uncertainties and complexities. In this regard, the interplay between
    digitalization and sustainability unfolds bright opportunities for shaping a greener
    economy and society, paving the way towards the SDGs. However, little evidence
    exists so far, about a genuine contribution of digital paradigms to sustainability.
    Besides, their role to tackle the SDGs research gaps remains unexplored. Thus,
    a holistic characterization of the aforementioned topics has not been fully explored
    in the emerging literature, deserving further research. The article endeavors
    a twofold purpose: (1) categorizing the main SDGs research gaps; (2) coupled with
    a critical exploration of the potential contribution of digital paradigms, particularly
    Big Data and Artificial Intelligence, towards overcoming the aforesaid caveats
    and pursuing the 2030 Agenda. Ultimately, the study seeks to bridge literature
    gaps by providing a first-of-its-kind overview on the SDGs and their nexus with
    digitalization, while unraveling policy implications and future research directions.
    The methodology has consisted of a systematic holistic review and in-depth qualitative
    analysis of the literature on the realms of the SDGs and digitalization. Our findings
    evidence that the SDGs present several research gaps, namely: flawed understanding
    of complexities and interlinkages; design shortcomings and imbalances; implementation
    and governance hurdles; unsuitable indicators and assessment methodologies; truncated
    adoption and off-target progress; unclear responsibilities and lacking coordination;
    untapped role of technological innovation and knowledge management. Moreover,
    our results show growing expectations about the added value brought by digitalization
    for pursuing the SDGs, through novel data sources, enhanced analytical capacities
    and collaborative digital ecosystems. However, current research and practice remains
    in early-stage, pointing to ethical, social and environmental controversies, along
    with policy caveats, which merit additional research. In light of the findings,
    the authors suggest a first-approach exploration of research and policy implications.
    Results suggest that further multidisciplinary research, dialogue and concerted
    efforts for transformation are required. Reframing the Agenda, while aligning
    the sustainable development and digitalization policies, seems advisable to ensure
    a holistic sustainability. The findings aim at guiding and stimulating further
    research and science-policy dialogue on the promising nexus amid the SDGs and
    digitalization.'
  Author: "Gema {Del R\xC3\xADo Castro} and Mar\xC3\xADa Camino {Gonz\xC3\xA1lez Fern\xC3\
    \xA1ndez} and \xC3\x81ngel {Uruburu Colsa}"
  Book_Title_Journal: Journal of Cleaner Production
  DOI: https://doi.org/10.1016/j.jclepro.2020.122204
  JCS_FACTOR: 9.297
  Keywords: Sustainability, Sustainable development goals (SDGs), Digitalization,
    ICT, Big data, Artificial intelligence
  SCI_FACTOR: 1.937
  Title: 'Unleashing the convergence amid digitalization and sustainability towards
    pursuing the Sustainable Development Goals (SDGs): A holistic review'
  Title_JCS: Journal of Cleaner Production
  Title_SCI: Journal of Cleaner Production
  Type_Publication: article
  Year: 2021
- Abstract: In this paper, we present the problem formulation and methodology framework
    of Super Resolution Perception (SRP) on smart meter data. With the widespread
    use of smart meters, a massive amount of electricity consumption data can be obtained.
    Smart meter data is the basis of automated billing and pricing, appliance identification,
    demand response, etc. However, the provision of high-quality data may be expensive
    in many cases. In this paper, we propose a novel problem - the SRP problem as
    reconstructing high-quality data from unsatisfactory data in smart grids. Advanced
    generative models are then proposed to solve the problem. This technology makes
    it possible for empowering existing facilities without upgrading existing meters
    or deploying additional meters. We first mathematically formulate the SRP problem
    under the Maximum a Posteriori (MAP) estimation framework. The dataset namely
    Super Resolution Perception Dataset (SRPD) is designed for this problem and released.
    A case study is then presented, which performs SRP on smart meter data. A network
    namely Super Resolution Perception Convolutional Neural Network (SRPCNN) is proposed
    to generate high-frequency load data from low-frequency data. Experiments demonstrate
    that our SRP models can reconstruct high-frequency data effectively. Moreover,
    the reconstructed high-frequency data can lead to better appliance identification
    results.
  Author: Guolong Liu and Jinjin Gu and Junhua Zhao and Fushuan Wen and Gaoqi Liang
  Book_Title_Journal: Information Sciences
  DOI: https://doi.org/10.1016/j.ins.2020.03.088
  JCS_FACTOR: 6.795
  Keywords: Super resolution perception, Smart meter data, High-frequency data, Big
    data analysis
  SCI_FACTOR: 1.524
  Title: Super Resolution Perception for Smart Meter Data
  Title_JCS: INFORMATION SCIENCES
  Title_SCI: Information Sciences
  Type_Publication: article
  Year: 2020
- Abstract: Building operations account for the largest proportion of energy use throughout
    the building life cycle. The energy saving potential is considerable taking into
    account the existence of a wide variety of building operation deficiencies. The
    advancement in information technologies has made modern buildings to be not only
    energy-intensive, but also information-intensive. Massive amounts of building
    operational data, which are in essence the reflection of actual building operating
    conditions, are available for knowledge discovery. It is very promising to extract
    potentially useful insights from big building operational data, based on which
    actionable measures for energy efficiency enhancement are devised. Data mining
    is an advanced technology for analyzing big data. It consists of two main types
    of data analytics, i.e., supervised and unsupervised analytics. Despite of the
    power of supervised analytics in predictive modeling, unsupervised analytics are
    more practical and promising in discovering novel knowledge given limited prior
    knowledge. This paper provides a comprehensive review on the current utilization
    of unsupervised data analytics in mining massive building operational data. The
    commonly used unsupervised analytics are summarized according to their knowledge
    representations and applications. The challenges and opportunities are elaborated
    as guidance for future research in this multi-disciplinary field.
  Author: Cheng Fan and Fu Xiao and Zhengdao Li and Jiayuan Wang
  Book_Title_Journal: Energy and Buildings
  DOI: https://doi.org/10.1016/j.enbuild.2017.11.008
  JCS_FACTOR: 5.879
  Keywords: Unsupervised data mining, Big data, Building operational performance,
    Building energy management, Building energy efficiency
  SCI_FACTOR: 1.737
  Title: 'Unsupervised data analytics in mining big building operational data for
    energy efficiency enhancement: A review'
  Title_JCS: ENERGY AND BUILDINGS
  Title_SCI: Energy and Buildings
  Type_Publication: article
  Year: 2018
- Abstract: 'Context

    The need for business intelligence has led to advances in machine learning in
    the business domain, especially with the rise of big data analytics. However,
    the resulting predictive systems often fail to maintain a satisfactory level of
    performance in production. Besides, for predictive systems used in business-to-business
    scenarios, user trust is subject to the model performance. Therefore, the processes
    of creating, evaluating, and deploying machine learning systems in the business
    domain need innovative solutions to solve the critical challenges of assuring
    the quality of the resulting systems.

    Objective

    Applying machine learning in business-to-business situations imposes specific
    requirements. This paper aims at providing an integrated solution to businesses
    to help them transform their data into actions.

    Method

    The paper presents MLean, an end-to-end framework, that aims at guiding businesses
    in designing, developing, evaluating, and deploying business-to-business predictive
    systems. The framework employs the Lean Startup methodology and aims at maximizing
    the business value while eliminating wasteful development practices.

    Results

    To evaluate the proposed framework, with the help of our industrial partner, we
    applied the framework to a case study to build a predictive product. The case
    study resulted in a predictive system to predict the risks of software license
    cancellations. The system was iteratively developed and evaluated while adopting
    the management and end-user perspectives.

    Conclusion

    It is concluded that, in industry, it is important to be aware of the businesses
    requirements before considering the application of machine learning. The framework
    accommodates business perspective from the beginning to produce a holistic product.
    From the results of the case study, we think that this framework can help businesses
    define the right opportunities for applying machine learning, developing solutions,
    evaluating the effectiveness of these solutions, and maintaining their performance
    in production.'
  Author: Mona Nashaat and Aindrila Ghosh and James Miller and Shaikh Quader and Chad
    Marston
  Book_Title_Journal: Information and Software Technology
  DOI: https://doi.org/10.1016/j.infsof.2019.05.009
  JCS_FACTOR: 2.73
  Keywords: Big data, Machine learning, Business-to-business, User trust, Case study
  SCI_FACTOR: 0.606
  Title: 'M-Lean: An end-to-end development framework for predictive models in B2B
    scenarios'
  Title_JCS: INFORMATION AND SOFTWARE TECHNOLOGY
  Title_SCI: Information and Software Technology
  Type_Publication: article
  Year: 2019
- Abstract: 'Although business analytics (BA) have been increasingly adopted into
    businesses, there is limited empirical research examining the drivers of each
    stage of BA adoption in organizations. Drawing upon technological-organizational-environmental
    framework and innovation diffusion process, we developed an integrative model
    to examine BA adoption processes and tested with 170 Korean firms. The analysis
    shows data-related technological characteristics derive all stages of BA adoption:
    initiation, adoption and assimilation. While organizational characteristics are
    associated with adoption and assimilation stage, only competition intensity in
    environmental characteristics is associated with initiation stage. Our findings
    help practitioners and researchers to understand what factors can enable companies
    to adopt BA in each stage.'
  Author: Dalwoo Nam and Junyeong Lee and Heeseok Lee
  Book_Title_Journal: International Journal of Information Management
  DOI: https://doi.org/10.1016/j.ijinfomgt.2019.07.017
  JCS_FACTOR: 14.098
  Keywords: Business analytics, Innovation diffusion, Adoption process, Data infrastructure,
    Data quality management, Analytics centralization
  SCI_FACTOR: 2.77
  Title: 'Business analytics adoption process: An innovation diffusion perspective'
  Title_JCS: INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
  Title_SCI: International Journal of Information Management
  Type_Publication: article
  Year: 2019
- Abstract: 'With the explosion of the digital universe, it is becoming increasingly
    important to understand how organizational decision making (i.e., the business-oriented
    perspective) is intertwined with an understanding of enterprise data assets (i.e.,
    the data-oriented perspective). This article first compares the business- and
    data-oriented perspectives to describe how the two views mesh with each other.
    It then presents three elements in the data-oriented perspective that are collectively
    referred to as the data triad: (1) use, (2) design and storage, and (3) processes
    and people. In describing the data triad, this article highlights practices, architectural
    techniques, and example tools that are used to manage, access, analyze, and deliver
    data. By presenting different elements of the data-oriented perspective, this
    article broadly and concretely describes the data triad and how it can play a
    role in the redefined scope of work for data-driven business managers.'
  Author: Vijay Khatri
  Book_Title_Journal: Business Horizons
  DOI: https://doi.org/10.1016/j.bushor.2016.06.001
  JCS_FACTOR: 6.361
  Keywords: Analytics, Big data, Managerial decision making, Managerial work, Digital
    universe
  SCI_FACTOR: 2.174
  Title: 'Managerial work in the realm of the digital universe: The role of the data
    triad'
  Title_JCS: BUSINESS HORIZONS
  Title_SCI: Business Horizons
  Type_Publication: article
  Year: 2016
- Abstract: 'Service is a key context for the application of IT, as IT digitizes information
    interactions in service and facilitates value creation, thereby contributing to
    service innovation. The recent proliferation of big data provides numerous opportunities
    for information-intensive services (IISs), in which information interactions exert
    the greatest effect on value creation. In the modern data-rich economy, understanding
    mechanisms and related factors of data-based value creation in IISs is essential
    for using IT to improve such services. This study identified nine key factors
    that characterize this data-based value creation: (1) data source, (2) data collection,
    (3) data, (4) data analysis, (5) information on the data source, (6) information
    delivery, (7) customer (information user), (8) value in information use, and (9)
    provider network. These factors were identified and defined through six action
    research projects with industry and government that used specific datasets to
    design new IISs and by analyzing data usage in 149 IIS cases. This paper demonstrates
    the usefulness of these factors for describing, analyzing, and designing the entire
    value creation chain, from data collection to value creation, in IISs. The main
    contribution of this study is to provide a simple yet comprehensive and empirically
    tested basis for the use and management of data to facilitate service value creation.'
  Author: Chiehyeon Lim and Ki-Hun Kim and Min-Jun Kim and Jun-Yeon Heo and Kwang-Jae
    Kim and Paul P. Maglio
  Book_Title_Journal: International Journal of Information Management
  DOI: https://doi.org/10.1016/j.ijinfomgt.2017.12.007
  JCS_FACTOR: 14.098
  Keywords: "Big data, Data-based value creation, Information-intensive service, Factor,\
    \ Data\xE2\u20AC\u201CValue Chain"
  SCI_FACTOR: 2.77
  Title: 'From data to value: A nine-factor framework for data-based value creation
    in information-intensive services'
  Title_JCS: INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
  Title_SCI: International Journal of Information Management
  Type_Publication: article
  Year: 2018
- Abstract: In the big data era, new technologies and powerful analytics make it possible
    to collect and analyse large amounts of data in order to identify patterns in
    the behaviour of groups, communities and even entire countries. Existing case
    law and regulations are inadequate to address the potential risks and issues related
    to this change of paradigm in social investigation. This is due to the fact that
    both the right to privacy and the more recent right to data protection are protected
    as individual rights. The social dimension of these rights has been taken into
    account by courts and policymakers in various countries. Nevertheless, the rights
    holder has always been the data subject and the rights related to informational
    privacy have mainly been exercised by individuals. This atomistic approach shows
    its limits in the existing context of mass predictive analysis, where the larger
    scale of data processing and the deeper analysis of information make it necessary
    to consider another layer, which is different from individual rights. This new
    layer is represented by the collective dimension of data protection, which protects
    groups of persons from the potential harms of discriminatory and invasive forms
    of data processing. On the basis of the distinction between individual, group
    and collective dimensions of privacy and data protection, the author outlines
    the main elements that characterise the collective dimension of these rights and
    the representation of the underlying interests.
  Author: Alessandro Mantelero
  Book_Title_Journal: Computer Law & Security Review
  DOI: https://doi.org/10.1016/j.clsr.2016.01.014
  JCS_FACTOR: 2.98
  Keywords: Big data, Right to privacy, Data protection, Group privacy, Collective
    interests, Data protection authorities, Risk assessment
  SCI_FACTOR: 0.0
  Title: 'Personal data for decisional purposes in the age of analytics: From an individual
    to a collective dimension of data protection'
  Title_JCS: Computer Law & Security Review
  Title_SCI: N/A
  Type_Publication: article
  Year: 2016
- Abstract: "In recent years, Earth system sciences are urgently calling for innovation\
    \ on improving accuracy, enhancing model intelligence level, scaling up operation,\
    \ and reducing costs in many subdomains amid the exponentially accumulated datasets\
    \ and the promising artificial intelligence (AI) revolution in computer science.\
    \ This paper presents work led by the NASA Earth Science Data Systems Working\
    \ Groups and ESIP machine learning cluster to give a comprehensive overview of\
    \ AI in Earth sciences. It holistically introduces the current status, technology,\
    \ use cases, challenges, and opportunities, and provides all the levels of AI\
    \ practitioners in geosciences with an overall big picture and to \xE2\u20AC\u0153\
    blow away the fog to get a clearer vision\xE2\u20AC\x9D about the future development\
    \ of Earth AI. The paper covers all the majorspheres in the Earth system and investigates\
    \ representative AI research in each domain. Widely used AI algorithms and computing\
    \ cyberinfrastructure are briefly introduced. The mandatory steps in a typical\
    \ workflow of specializing AI to solve Earth scientific problems are decomposed\
    \ and analyzed. Eventually, it concludes with the grand challenges and reveals\
    \ the opportunities to give some guidance and pre-warnings on allocating resources\
    \ wisely to achieve the ambitious Earth AI goals in the future."
  Author: Ziheng Sun and Laura Sandoval and Robert Crystal-Ornelas and S. Mostafa
    Mousavi and Jinbo Wang and Cindy Lin and Nicoleta Cristea and Daniel Tong and
    Wendy Hawley Carande and Xiaogang Ma and Yuhan Rao and James A. Bednar and Amanda
    Tan and Jianwu Wang and Sanjay Purushotham and Thomas E. Gill and Julien Chastang
    and Daniel Howard and Benjamin Holt and Chandana Gangodagamage and Peisheng Zhao
    and Pablo Rivas and Zachary Chester and Javier Orduz and Aji John
  Book_Title_Journal: Computers & Geosciences
  DOI: https://doi.org/10.1016/j.cageo.2022.105034
  JCS_FACTOR: 3.372
  Keywords: Geosphere, Hydrology, Atmosphere, Artificial intelligence/machine learning,
    Big data, Cyberinfrastructure
  SCI_FACTOR: 0.0
  Title: A review of Earth Artificial Intelligence
  Title_JCS: COMPUTERS & GEOSCIENCES
  Title_SCI: N/A
  Type_Publication: article
  Year: 2022
- Abstract: "Audit firms are increasingly engaging with advanced data analytics to\
    \ improve the efficiency and effectiveness of external audits through the automation\
    \ of audit work and obtaining a better understanding of the client\xE2\u20AC\u2122\
    s business risk and thus their own audit risk. This paper examines the process\
    \ by which audit firms adopt advanced data analytics, which has been left unaddressed\
    \ by previous research. We derive a process theory from expert interviews which\
    \ describes the activities within the process and the organizational units involved.\
    \ It further describes how the adoption process is affected by technological,\
    \ organizational and environmental contextual factors. Our work contributes to\
    \ the extent body of research on technology adoption in auditing by using a previously\
    \ unused theoretical perspective, and contextualizing known factors of technology\
    \ adoption. The findings presented in this paper emphasize the importance of technological\
    \ capabilities of audit firms for the adoption of advanced data analytics; technological\
    \ capabilities within audit teams can be leveraged to support both the ideation\
    \ of possible use cases for advanced data analytics, as well as the diffusion\
    \ of solutions into practice."
  Author: Felix Krieger and Paul Drews and Patrick Velte
  Book_Title_Journal: International Journal of Accounting Information Systems
  DOI: https://doi.org/10.1016/j.accinf.2021.100511
  JCS_FACTOR: 4.4
  Keywords: Audit digitization, Audit data analytics, Big data, Machine learning,
    Advanced data analytics in auditing, Audit innovation
  SCI_FACTOR: 0.897
  Title: 'Explaining the (non-) adoption of advanced data analytics in auditing: A
    process theory'
  Title_JCS: International Journal of Accounting Information Systems
  Title_SCI: International Journal of Accounting Information Systems
  Type_Publication: article
  Year: 2021
- Abstract: The circular economy (CE) has the potential to capitalise upon emerging
    digital technologies, such as big data, artificial intelligence (AI), blockchain
    and the Internet of things (IoT), amongst others. These digital technologies combined
    with business model innovation are deemed to provide solutions to myriad problems
    in the world, including those related to circular economy transformation. Given
    the societal and practical importance of CE and digitalisation, last decade has
    witnessed a significant increase in academic publication on these topics. Therefore,
    this study aims to capture the essence of the scholarly work at the intersection
    of the CE and digital technologies. A detailed analysis of the literature based
    on emerging themes was conducted with a focus on illuminating the path of CE implementation.
    The results reveal that IoT and AI play a key role in the transition towards the
    CE. A multitude of studies focus on barriers to digitalisation-led CE transition
    and highlight policy-related issues, the lack of predictability, psychological
    issues and information vulnerability as some important barriers. In addition,
    product-service system (PSS) has been acknowledged as an important business model
    innovation for achieving the digitalisation enabled CE. Through a detailed assessment
    of the existing literature, a viable systems-based framework for digitalisation
    enabled CE has been developed which show the literature linkages amongst the emerging
    research streams and provide novel insights regarding the realisation of CE benefits.
  Author: Chetna Chauhan and Vinit Parida and Amandeep Dhir
  Book_Title_Journal: Technological Forecasting and Social Change
  DOI: https://doi.org/10.1016/j.techfore.2022.121508
  JCS_FACTOR: 8.593
  Keywords: Circular economy, Sustainability, Product-service system (PSS), Circular
    business model, Artificial intelligence, Internet of things
  SCI_FACTOR: 2.226
  Title: 'Linking circular economy and digitalisation technologies: A systematic literature
    review of past achievements and future promises'
  Title_JCS: TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE
  Title_SCI: Technological Forecasting and Social Change
  Type_Publication: article
  Year: 2022
- Abstract: "Uninterrupted and reliable weather data is a necessary foundation for\
    \ agricultural decision making, required for models based on accumulated growing\
    \ degree days (GDD), chill units, and evapotranspiration. When a weather station\
    \ experiences a mechanical or communications failure, a replacement (imputed)\
    \ value should be substituted for any missing data. This study introduces a machine\
    \ learning, network-based approach to imputing missing 15-minute and daily maximum/minimum\
    \ air temperature observations from 8.5\xC2\_years of air temperature, relative\
    \ humidity, wind, and solar radiation observations at 134 AgWeatherNet (AWN) stations\
    \ in Washington State. A random forest imputation model trained on temperature\
    \ and humidity observations from the full network predicted 15-minute, daily maximum,\
    \ and daily minimum temperature values with mean absolute errors of 0.43\xC2\_\
    \xC2\xB0C, 0.53\xC2\_\xC2\xB0C, and 0.70\xC2\_\xC2\xB0C, respectively. Sensitivity\
    \ experiments determined that imputation skill was related a number of external\
    \ factors including volume and type of training data, proximity of surrounding\
    \ stations, and regional topography. In particular, nocturnal cold air flows in\
    \ the upper Yakima Valley of south-central Washington caused temperature to be\
    \ less correlated with surrounding stations in the overnight hours. In a separate\
    \ experiment, the imputation model was used to predict base- 10\xC2\_\xC2\xB0\
    C GDD on 2020 July 1 trained entirely on 15-minute station data from previous\
    \ years. Even with the entire season of observations missing, the model predicted\
    \ the GDD value within an average error 1.4% with 125 of 134 stations within 5%\
    \ of observations. Since missing data can typically be resolved within a timeframe\
    \ of a few days, the network-based imputation model is a sufficient substitute\
    \ for short periods of missing observational weather data. Other potential applications\
    \ of an imputation model are briefly discussed."
  Author: Joseph P. Boomgard-Zagrodnik and David J. Brown
  Book_Title_Journal: Computers and Electronics in Agriculture
  DOI: https://doi.org/10.1016/j.compag.2021.106580
  JCS_FACTOR: 5.565
  Keywords: Machine learning, Big data, Surface weather observations, Degree day models,
    Missing data imputation
  SCI_FACTOR: 1.208
  Title: Machine learning imputation of missing Mesonet temperature observations
  Title_JCS: COMPUTERS AND ELECTRONICS IN AGRICULTURE
  Title_SCI: Computers and Electronics in Agriculture
  Type_Publication: article
  Year: 2022
- Abstract: "Tunnel fire is one of the most severe global fire hazards and causes\
    \ a significant amount of economic losses and casualties every year. Over the\
    \ last 50\xC2\_years, numerous full-scale and reduced-scale tunnel fire tests,\
    \ as well as numerical simulations have been conducted to quantify the critical\
    \ fire events and key parameters to guide the fire safety design of the tunnel.\
    \ In light of the recent advances in big data and artificial intelligence, this\
    \ paper aims to establish a database that contains all existing experimental data\
    \ of tunnel fire, based on an extensive literature review on tunnel fire tests.\
    \ This tunnel-fire database summarizes seven key parameters of flame, ventilation,\
    \ and smoke in that is open access at a GitHub site: https://github.com/PolyUFire/Tunnel_Fire_Database.\
    \ The test conditions, experimental phenomena, and data of each literature work\
    \ were organized and categorized in a standard format that could be conveniently\
    \ accessed and continuously updated. Based on this database, machine learning\
    \ is applied to predict the critical ventilation velocity of a tunnel fire as\
    \ a demonstration. The review of the current database not only reveals more valuable\
    \ information and hidden problems in the conventional collection of test data,\
    \ but also provides new directions in future tunnel fire research. The established\
    \ database and methodology help promote the application of artificial intelligence\
    \ and smart firefighting in tunnel fire safety."
  Author: Xiaoning Zhang and Xiqiang Wu and Younggi Park and Tianhang Zhang and Xinyan
    Huang and Fu Xiao and Asif Usmani
  Book_Title_Journal: Tunnelling and Underground Space Technology
  DOI: https://doi.org/10.1016/j.tust.2020.103691
  JCS_FACTOR: 5.915
  Keywords: Big data, Empirical model, Deep learning, Critical event, Smart firefighting
  SCI_FACTOR: 2.172
  Title: Perspectives of big experimental database and artificial intelligence in
    tunnel fire research
  Title_JCS: TUNNELLING AND UNDERGROUND SPACE TECHNOLOGY
  Title_SCI: Tunnelling and Underground Space Technology
  Type_Publication: article
  Year: 2021
- Abstract: 'Background

    Extensive data available in electronic health records (EHRs) have the potential
    to improve asthma care and understanding of factors influencing asthma outcomes.
    However, this work can be accomplished only when the EHR data allow for accurate
    measures of severity, which at present are complex and inconsistent.

    Objective

    Our aims were to create and evaluate a standardized pediatric asthma severity
    phenotype based in clinical asthma guidelines for use in EHR-based health initiatives
    and studies and also to examine the presence and absence of these data in relation
    to patient characteristics.

    Methods

    We developed an asthma severity computable phenotype and compared the concordance
    of different severity components contributing to the phenotype to trends in the
    literature. We used multivariable logistic regression to assess the presence of
    EHR data relevant to asthma severity.

    Results

    The asthma severity computable phenotype performs as expected in comparison with
    national statistics and the literature. Severity classification for a child is
    maximized when based on the long-term medication regimen component and minimized
    when based only on the symptom data component. Use of the severity phenotype results
    in better, clinically grounded classification. Children for whom severity could
    be ascertained from these EHR data were more likely to be seen for asthma in the
    outpatient setting and less likely to be older or Hispanic. Black children were
    less likely to have lung function testing data present.

    Conclusion

    We developed a pragmatic computable phenotype for pediatric asthma severity that
    is transportable to other EHRs.'
  Author: "Komal Peer and William G. Adams and Aaron Legler and Megan Sandel and Jonathan\
    \ I. Levy and Ren\xC3\xA9e Boynton-Jarrett and Chanmin Kim and Jessica H. Leibler\
    \ and M. Patricia Fabian"
  Book_Title_Journal: Journal of Allergy and Clinical Immunology
  DOI: https://doi.org/10.1016/j.jaci.2020.11.045
  JCS_FACTOR: 10.793
  Keywords: Asthma, electronic health records, big data, respiratory function tests,
    selection bias, health care disparities, delivery of health care, observer variation,
    National Heart, Lung, and Blood Institute (US), pediatrics
  SCI_FACTOR: 3.281
  Title: Developing and evaluating a pediatric asthma severity computable phenotype
    derived from electronic health records
  Title_JCS: JOURNAL OF ALLERGY AND CLINICAL IMMUNOLOGY
  Title_SCI: Journal of Allergy and Clinical Immunology
  Type_Publication: article
  Year: 2021
- Abstract: 'The emergence of infectious agents with pandemic potential present scientific
    challenges from detection to data interpretation to understanding determinants
    of risk and forecasts. Mathematical models could play an essential role in how
    we prepare for future emergent pathogens. Here, we describe core directions for
    expansion of the existing tools and knowledge base, including: using mathematical
    models to identify critical directions and paths for strengthening data collection
    to detect and respond to outbreaks of novel pathogens; expanding basic theory
    to identify infectious agents and contexts that present the greatest risks, over
    both the short and longer term; by strengthening estimation tools that make the
    most use of the likely range and uncertainties in existing data; and by ensuring
    modelling applications are carefully communicated and developed within diverse
    and equitable collaborations for increased public health benefit.'
  Author: Emma E. Glennon and Marjolein Bruijning and Justin Lessler and Ian F. Miller
    and Benjamin L. Rice and Robin N. Thompson and Konstans Wells and C. Jessica E.
    Metcalf
  Book_Title_Journal: Epidemics
  DOI: https://doi.org/10.1016/j.epidem.2021.100516
  JCS_FACTOR: 4.396
  Keywords: Immune landscape, Genotype to phenotype map, Big data, Data integration,
    Fundamental theory, Health system functioning
  SCI_FACTOR: 2.023
  Title: Challenges in modeling the emergence of novel pathogens
  Title_JCS: Epidemics
  Title_SCI: Epidemics
  Type_Publication: article
  Year: 2021
- Abstract: "Financial services organisations facilitate the movement of money worldwide,\
    \ and keep records of their clients\xE2\u20AC\u2122 identity and financial behaviour.\
    \ As such, they have been enlisted by governments worldwide to assist with the\
    \ detection and prevention of money laundering, which is a key tool in the fight\
    \ to reduce crime and create sustainable economic development, corresponding to\
    \ Goal 16 of the United Nations Sustainable Development Goals. In this paper,\
    \ we investigate how the technical and contextual affordances of machine learning\
    \ algorithms may enable these organisations to accomplish that task. We find that,\
    \ due to the unavailability of high-quality, large training datasets regarding\
    \ money laundering methods, there is limited scope for using supervised machine\
    \ learning. Conversely, it is possible to use reinforced machine learning and,\
    \ to an extent, unsupervised learning, although only to model unusual financial\
    \ behaviour, not actual money laundering."
  Author: Ana Isabel Canhoto
  Book_Title_Journal: Journal of Business Research
  DOI: https://doi.org/10.1016/j.jbusres.2020.10.012
  JCS_FACTOR: 7.55
  Keywords: Big data, Artificial intelligence, Machine learning, Algorithm, Customer
    profiling, Financial services, Anti-money laundering, United Nations, Sustainable
    development goals
  SCI_FACTOR: 2.049
  Title: 'Leveraging machine learning in the global fight against money laundering
    and terrorism financing: An affordances perspective'
  Title_JCS: JOURNAL OF BUSINESS RESEARCH
  Title_SCI: Journal of Business Research
  Type_Publication: article
  Year: 2021
- Abstract: "Today\xE2\u20AC\u2122s intelligent system based on cloud computing platform\
    \ can realize \xE2\u20AC\u0153unattended\xE2\u20AC\x9D, real-time monitoring observation\
    \ and forecast by remote sensing. In order to import the development and efficiency\
    \ of groundwater potential assessment(GPA) by remote sensing, the cloud computing\
    \ platform was tried to use in the computing GPA. In this study, the Pearl River\
    \ Estuary islands region(China) was selected as the study area. The slope, aspect,\
    \ water-density(WD), land surface temperature(LST), NDVI and NDWI were used as\
    \ the GPA indexes, which have been used before. Considering the similar geological\
    \ and geomorphological conditions of the islands area, the analytic hierarchy\
    \ process (AHP) method and these indexes can be used to assess GPA in the remote\
    \ sensing cloud computing platform efficiently and conveniently. The results of\
    \ the assessment were in good agreement with the actual hydrogeological map. Besides,\
    \ the other intelligent algorithms can also be applied in this platform. Finally,\
    \ this study realized the rapid \xE2\u20AC\u0153unattended\xE2\u20AC\x9D and \xE2\
    \u20AC\u0153real-time monitoring\xE2\u20AC\x9D groundwater potential assessment,\
    \ and carried out a multi-level GPA. It will be of certain reference significance\
    \ to the exploitation of groundwater in the island area, which has realized convenient\
    \ and efficient processing and analysis of data anytime and anywhere. At the same\
    \ time, attention must be paid to the security of data and the maintenance of\
    \ the system."
  Author: Daqing Wang and Haoli Xu and Yue Shi and Zhibin Ding and Zhengdong Deng
    and Zhixin Liu and Xingang Xu and Zhao Lu and Guangyuan Wang and Zijian Cheng
    and Xiaoning Zhao
  Book_Title_Journal: Computer Communications
  DOI: https://doi.org/10.1016/j.comcom.2021.06.028
  JCS_FACTOR: 3.167
  Keywords: Big data, Cloud computing, Remote sensing, Groundwater potential, Bedrock
    islands
  SCI_FACTOR: 0.627
  Title: 'The groundwater potential assessment system based on cloud computing: A
    case study in islands region'
  Title_JCS: COMPUTER COMMUNICATIONS
  Title_SCI: Computer Communications
  Type_Publication: article
  Year: 2021
- Abstract: "This study establishes a new understanding of the contributions of Al\
    \ residue in a megalopolitan drinking water supply system with mixed water sources.\
    \ The different influences and contributions of foreign water source, resident\
    \ migration and season changing to Al residue in drinking water were investigated.\
    \ Especially, the role of Southern water transferred over 1200 km via the South-to-North\
    \ Water Diversion Project in the Al residue of drinking water supply system of\
    \ a northern megalopolitan were revealed for the first time. Comparisons of big\
    \ data on Al residue in the water supply system with sole and mixed water sources\
    \ showed that the introduction of Southern water enhanced the Al residue in drinking\
    \ water by over 35%. The world's largest annual residents\xE2\u20AC\u2122 migration\
    \ during Chinese Lunar New Year and the changes of season affect the water pipework\
    \ hydrodynamics, which were embodied as the periodic changes of particulate aluminium\
    \ and the relations with resident's temporal-spatial distribution in the megalopolitan.\
    \ Because of the differences in water quality, Southern water promotes the release\
    \ of historically deposited Al and facilitates the cleaning of old pipes."
  Author: Chenhao Tian and Chenghong Feng and Lei Chen and Qixuan Wang
  Book_Title_Journal: Water Research
  DOI: https://doi.org/10.1016/j.watres.2020.116335
  JCS_FACTOR: 11.236
  Keywords: Al residue, Mixed water sources, Big data analysis, Megalopolitan, Drinking
    water
  SCI_FACTOR: 3.099
  Title: Impact of water source mixture and population changes on the Al residue in
    megalopolitan drinking water
  Title_JCS: WATER RESEARCH
  Title_SCI: Water Research
  Type_Publication: article
  Year: 2020
- Abstract: In online review systems, a participant's level of knowledge impacts his/her
    posting behaviors, and an increase in knowledge occurs when the participant reads
    the reviews posted on the systems. To capture the collective dynamics of posting
    reviews, we used real-world big data collected over 153 months to drive an agent-based
    model for replicating the operation process of online review systems. The model
    explains the effects of clicking position (e.g., on a review webpage's serial
    list) and the number of items per webpage on posting contributions. Reading reviews
    from the last webpage only, or from the first webpage and last webpage simultaneously,
    can promote a greater review volume than reading reviews in other positions. This
    illustrates that representing primacy (first items) and recency (recent items)
    within one page simultaneously, or displaying recent items in reverse chronological
    order, are relatively better strategies for the webpage display of online reviews.
    The number of items plays a nonlinear moderating role in bridging the clicking
    position and posting behavior, and we determine the optimal number of items. To
    effectively establish strategies for webpage design in online review systems,
    business managers must switch from reliance on experience to reliance on an agent-based
    model as a decision support system for the formalized webpage design of online
    review systems.
  Author: Guoyin Jiang and Xiaodong Feng and Wenping Liu and Xingjun Liu
  Book_Title_Journal: Information Sciences
  DOI: https://doi.org/10.1016/j.ins.2019.09.053
  JCS_FACTOR: 6.795
  Keywords: Agent-based modeling, Big data, Online review systems, Clicking position,
    Posting behavior
  SCI_FACTOR: 1.524
  Title: 'Clicking position and user posting behavior in online review systems: A
    data-driven agent-based modeling approach'
  Title_JCS: INFORMATION SCIENCES
  Title_SCI: Information Sciences
  Type_Publication: article
  Year: 2020
